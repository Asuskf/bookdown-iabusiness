<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Parte 4 Annex 1: Artificial Neural Networks | Inteligencia Artificial aplicada a Negocios y Empresas</title>
  <meta name="description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Parte 4 Annex 1: Artificial Neural Networks | Inteligencia Artificial aplicada a Negocios y Empresas" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://www.udemy.com/course/ia4business/?couponCode=B85F8D52148DF5AAD8F7" />
  <meta property="og:image" content="https://www.udemy.com/course/ia4business/?couponCode=B85F8D52148DF5AAD8F7Images/cover.jpg" />
  <meta property="og:description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="github-repo" content="https://github.com/joanby/ia4business" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Parte 4 Annex 1: Artificial Neural Networks | Inteligencia Artificial aplicada a Negocios y Empresas" />
  
  <meta name="twitter:description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="twitter:image" content="https://www.udemy.com/course/ia4business/?couponCode=B85F8D52148DF5AAD8F7Images/cover.jpg" />

<meta name="author" content="Hadelin de Ponteves y Kirill Ermenko" />


<meta name="date" content="2020-03-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="Images/apple-icon-120x120.png" />
  <link rel="shortcut icon" href="Images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="conclusion.html"/>
<link rel="next" href="annex-2-three-extra-ai-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Inteligencia Artificial aplicada Negocios y Empresas</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="1" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html"><i class="fa fa-check"></i><b>1</b> Optimización de Procesos</a><ul>
<li class="chapter" data-level="1.1" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#caso-práctico-optimización-de-tareas-en-un-almacén-de-comercio-electrónico"><i class="fa fa-check"></i><b>1.1</b> Caso Práctico: Optimización de tareas en un almacén de comercio electrónico</a><ul>
<li class="chapter" data-level="1.1.1" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#problema-a-resolver"><i class="fa fa-check"></i><b>1.1.1</b> Problema a resolver</a></li>
<li class="chapter" data-level="1.1.2" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#entorno-a-definir"><i class="fa fa-check"></i><b>1.1.2</b> Entorno a definir</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#solución-de-inteligencia-artificial"><i class="fa fa-check"></i><b>1.2</b> Solución de Inteligencia Artificial</a><ul>
<li class="chapter" data-level="1.2.1" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#proceso-de-decisión-de-markov"><i class="fa fa-check"></i><b>1.2.1</b> Proceso de Decisión de Markov</a></li>
<li class="chapter" data-level="1.2.2" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#q-learning"><i class="fa fa-check"></i><b>1.2.2</b> Q-Learning</a></li>
<li class="chapter" data-level="1.2.3" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#el-algoritmo-de-q-learning-al-completo"><i class="fa fa-check"></i><b>1.2.3</b> El algoritmo de Q-Learning al completo</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="optimización-de-procesos.html"><a href="optimización-de-procesos.html#implementación"><i class="fa fa-check"></i><b>1.3</b> Implementación</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html"><i class="fa fa-check"></i><b>2</b> Parte 2 - Minimización de Costes</a><ul>
<li class="chapter" data-level="2.1" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#caso-práctico-minimización-de-costes-en-el-consumo-energético-de-un-centro-de-datos"><i class="fa fa-check"></i><b>2.1</b> Caso Práctico: Minimización de Costes en el Consumo Energético de un Centro de Datos</a><ul>
<li class="chapter" data-level="2.1.1" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#problema-a-resolver-1"><i class="fa fa-check"></i><b>2.1.1</b> Problema a resolver</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#solución-de-ia"><i class="fa fa-check"></i><b>2.2</b> Solución de IA</a><ul>
<li class="chapter" data-level="2.2.1" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#q-learning-en-deep-learning"><i class="fa fa-check"></i><b>2.2.1</b> Q-Learning en Deep Learning</a></li>
<li class="chapter" data-level="2.2.2" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#experience-replay"><i class="fa fa-check"></i><b>2.2.2</b> Experience Replay</a></li>
<li class="chapter" data-level="2.2.3" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#el-cerebro"><i class="fa fa-check"></i><b>2.2.3</b> El cerebro</a></li>
<li class="chapter" data-level="2.2.4" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#el-algoritmo-de-deep-q-learning-al-completo"><i class="fa fa-check"></i><b>2.2.4</b> El algoritmo de Deep Q-Learning al completo</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#implementation"><i class="fa fa-check"></i><b>2.3</b> Implementation</a><ul>
<li class="chapter" data-level="2.3.1" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#paso-1-construcción-del-entorno"><i class="fa fa-check"></i><b>2.3.1</b> Paso 1: Construcción del Entorno</a></li>
<li class="chapter" data-level="2.3.2" data-path="parte-2-minimización-de-costes.html"><a href="parte-2-minimización-de-costes.html#paso-2-construcción-del-cerebro"><i class="fa fa-check"></i><b>2.3.2</b> Paso 2: Construcción del cerebro</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="part-3-maximizing-revenues.html"><a href="part-3-maximizing-revenues.html"><i class="fa fa-check"></i><b>3</b> Part 3 - Maximizing Revenues</a><ul>
<li class="chapter" data-level="3.1" data-path="part-3-maximizing-revenues.html"><a href="part-3-maximizing-revenues.html#case-study-maximizing-revenue-of-an-online-retail-business"><i class="fa fa-check"></i><b>3.1</b> Case Study: Maximizing Revenue of an Online Retail Business</a><ul>
<li class="chapter" data-level="3.1.1" data-path="part-3-maximizing-revenues.html"><a href="part-3-maximizing-revenues.html#problem-to-solve"><i class="fa fa-check"></i><b>3.1.1</b> Problem to solve</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="chapter" data-level="4" data-path="annex-1-artificial-neural-networks.html"><a href="annex-1-artificial-neural-networks.html"><i class="fa fa-check"></i><b>4</b> Annex 1: Artificial Neural Networks</a></li>
<li class="chapter" data-level="5" data-path="annex-2-three-extra-ai-models.html"><a href="annex-2-three-extra-ai-models.html"><i class="fa fa-check"></i><b>5</b> Annex 2: Three Extra AI Models</a></li>
<li class="chapter" data-level="6" data-path="annex-3-questions-and-answers.html"><a href="annex-3-questions-and-answers.html"><i class="fa fa-check"></i><b>6</b> Annex 3: Questions and Answers</a></li>
<li class="divider"></li>
<li><a href="https://www.udemy.com/course/ia4business/?couponCode=B85F8D52148DF5AAD8F7" target="blank">Curso en Udemy</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Inteligencia Artificial aplicada a Negocios y Empresas</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="annex-1-artificial-neural-networks" class="section level1">
<h1><span class="header-section-number">Parte 4</span> Annex 1: Artificial Neural Networks</h1>
<p>In this annex part you will find all the intuition and theory of Artificial Neural Networks, which are at the heart of the Deep Q-Learning model we build in Part 2 - Minimizing the Costs. Here is the plan of attack to study Artificial Neural Networks:</p>


<p>The neuron is the basic building block of Artificial Neural Networks. In the images below are actual real life neurons which have been smeared onto a glass, colored a little bit and observed through a microscope:</p>

<p>As we can see, they have the structure of a body with lots of different branches coming out of them. But the question is: How can we recreate that in a machine? Indeed, we really need to recreate it in a machine since the whole purpose of Deep Learning is to mimic how the human brain works, in the hope that by doing so we are going to create something amazing: a powerful infrastructure for machines to be able to learn.</p>
<p><br />
</p>
<p>Why do we hope for that? Because the human brain just happens to be one of the most powerful learning tools on the planet. So we just hope that if we recreate it then we will have something as awesome as that. So our challenge right now, that is our very first step to creating artificial neural networks, is to recreate a neuron.</p>
<p><br />
</p>
<p>So how do we do it? Well, first of all let’s have a closer look at what a neuron actually is. The image below was first created by a Spanish neuroscientist and Chagga Ramon Yi Kajal in 1899:</p>

<p>This neuroscientist dyed in neurons in actual brain tissue, and looked at them under a microscope. While he was looking at them he actually drew what he saw, which is exactly what we see on the above image. Today technology has advanced quite a lot allowing us to see neurons much closer in more detail so that we can actually draw what it looks like diagrammatically.</p>

<p>Above is a neuron. This neuron exchanges signals between its neighbour neurons. The dendrites are the receivers of the signal and the axon is the transmitter of the signal. Here is an image of how it all works conceptually:</p>

<p>We can see that the dendrites of the neuron are connected to the axons of other neurons above it. Then the signal travels down its axon and passes on to the dendrites of the next neuron. That is how they are connected and how a neuron works. Thus now is the time to move from neuroscience to technology.</p>
<p><br />
</p>
<p>Here is how a neuron is represented inside an Artificial Neural Network:</p>

<p>Just as a human neuron, it gets some input signals and it has an output signal. The blue arrow connecting the input signals to the neuron, and the neuron to the output signal, are like the synapses in the human neuron. But here in the machine neuron, what are exactly going to be these input and output signals? Well, the input signals are going to be the scaled independent variables composing the states of the environment, which remember in the case study are the temperature of the server, the number of users and the rate of data transmission, and the output signal will be the output values, which in the Deep Q-Learning model are always the Q-Values. Hence we get the general representation of a neuron for machines:</p>

<p>And now to finish with the neuron, let’s add the last missing elements in this representation, but also the most important ones: the weights. Each synapse (blue arrow) will be attributed a weight. The larger is the weight, the stronger the signal will be through the synapse. And what is fundamental to understand is that, these weights, will be what the machine will update and update over time to improve the predictions. Let’s represent them on the previous graphic, to make sure we all visualize them well:</p>


<p>The Activation Function is the function <span class="math inline">\(\phi\)</span> operating inside the neuron, that will take as inputs the linear sum of the input values multiplied by their associated weights, and that will return the output value:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>such that:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
    y = \phi\left( \sum_{i=1}^m w_i x_i \right)
\end{equation*}\]</span></p>
<p><br />
</p>
<p>Now what exactly is going to be the function <span class="math inline">\(\phi\)</span>?</p>
<p><br />
</p>
<p>There can be many of them, but let’s give the four most used ones, including of course the one we used in Part 2 - Minimizing Costs:</p>
<p><br />
</p>

<p><br />
</p>
<p>Let’s have a look at them one by one.</p>
<div style="page-break-after: always;"></div>

<p><br />
</p>
<p>The Threshold Activation Function is simply defined by the following:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
    \phi(x) =
    \begin{cases}
        1 \textrm{ if } x \ge 0 \\
        0 \textrm{ if } x &lt; 0
    \end{cases}
\end{equation*}\]</span></p>
<p><br />
</p>
<p>so that we get the following curve:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>This means that the signal passing through the neuron will be discontinuous, and will only be activated if:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
    \sum_{i=1}^m w_i x_i \ge 0
\end{equation*}\]</span></p>
<p><br />
</p>
<p>Now let’s have a look at the next activation function: the Sigmoid Activation function.</p>
<p><br />
</p>
<p>The Sigmoid Activation Function is the most effective and widely used one in Artificial Neural Networks, but mostly inside the last hidden layer (if we are dealing with a Deep Neural Network composed of several hidden layers) passing the signal towards the output layer.</p>
<div style="page-break-after: always;"></div>

<p><br />
</p>
<p>The Sigmoid Activation Function is defined by the following:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
\phi(x) = \frac{1}{1+e^{-x}}
\end{equation*}\]</span></p>
<p><br />
</p>
<p>so that we get the following curve:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>This means that the signal passing through the neuron will be continuous and will always be activated. And the higher is <span class="math inline">\(\sum_{i=1}^m w_i x_i\)</span>, the stronger will be that signal.</p>
<p><br />
</p>
<p>Now let’s have a look at another widely used activation function: the Rectifier Activation function.</p>
<p><br />
</p>
<p>You will find it in most of the  Neural Networks, but mostly inside the hidden layers, as opposed to the sigmoid function which is rather used for the output layer.</p>
<div style="page-break-after: always;"></div>

<p><br />
</p>
<p>The Threshold Activation Function is simply defined by the following:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
    \phi(x) = \max(x,0)
\end{equation*}\]</span></p>
<p><br />
</p>
<p>so that we get the following curve:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>This means that the signal passing through the neuron will be continuous, and will only be activated if:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
    \sum_{i=1}^m w_i x_i \ge 0
\end{equation*}\]</span></p>
<p><br />
</p>
<p>And the higher is <span class="math inline">\(\sum_{i=1}^m w_i x_i\)</span> above 0, the stronger will be that signal.</p>
<p><br />
</p>
<p>Now let’s have a look at the next activation function: the Hyperbolic Tangent Activation function.</p>
<p><br />
</p>
<p>The Hyperbolic Tangent activation function is less widely used, though it can sometimes be a more relevant choice in some Artificial Neural Networks, especially when the inputs are standardized.</p>
<div style="page-break-after: always;"></div>

<p><br />
</p>
<p>The Hyperbolic Tangent Activation Function is defined by the following:</p>
<p><br />
</p>
<p><span class="math display">\[\begin{equation*}
    \phi(x) = \frac{1-e^{-2x}}{1+e^{-2x}}
\end{equation*}\]</span></p>
<p><br />
</p>
<p>so that we get the following curve:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>This means that the signal passing through the neuron will be continuous and will always be activated. The higher <span class="math inline">\(\sum_{i=1}^m w_i x_i\)</span> is above 0, the stronger will be that signal. The lower <span class="math inline">\(\sum_{i=1}^m w_i x_i\)</span> is below 0, the weaker will be that signal.</p>
<div style="page-break-after: always;"></div>
<p>So that raises the question: which activation function should we choose, or, more frequently asked, how do we know which one to choose?</p>
<p><br />
</p>
<p>Good news, the answer is simple, and let’s give it inside a small blueprint.</p>
<p><br />
</p>
<p>That actually depends on what is returned as the dependent variable. If it is a binary outcome 0 or 1, then a good choice would be the threshold activation function. If what you want to be returned is the probability that the dependent variable is 1, then an excellent choice is the sigmoid activation function, since its sigmoid curve is a perfect fit to model probabilities.</p>
<p><br />
</p>
<p>Here is this small blueprint highlighted in this slide:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>But then when should I use the other two activation functions, i.e. the Rectifier activation function and the Hyperbolic Tangent activation function?</p>
<p><br />
</p>
<p>Easy again, the Rectifier and the Hyperbolic Tangent activation functions should be used within the hidden layers of a Deep Neural Network (with more than one hidden layer), except the last hidden layer leading to the output layer for which it is recommended to use a Sigmoid Activation function.</p>
<div style="page-break-after: always;"></div>
<p>Let’s recap this again inside the following slide:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>And lastly, how to choose between the Rectifier activation function and the Hyperbolic Tangent activation function in the hidden layers? Still easy, you should consider using the Rectifier activation function when the inputs are normalized (scaled between 0 and 1), and the Hyperbolic Tangent activation function when the inputs are standardized (scaled between -1 and +1):</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>Now let’s move on to the next section to explain, how Neural Networks work.</p>
<div style="page-break-after: always;"></div>

<p>To explain this, let’s consider the problem of predicting Real Estate prices. We have some independent variables which we are going to use to predict the price of houses and apartments. For simplicity purpose, and to be able to represent everything in a graph, let’s say that our independent variables (our predictors) are the following:</p>

<p>Then, our dependent variable is of course the apartment price to predict.</p>
<p><br />
</p>
<p>Each of the independent variables is attributed a weight, in such a way that the higher is the weight, the more effect the independent variable will have on the dependent variable, that is, the stronger predictor it will be of the dependent variable. Hence, as soon as new inputs enter the Neural Network, the signals are forward-propagated from each of the inputs, reaching the neurons of the hidden layer. Then inside each neuron of the hidden layer, the activation function is applied, so that the lower is the weight of the input, the more the activation function will block the signal coming from that input, and the higher is the weight of that input, the more the activation will let that signal go through. And finally, all the signals coming from the hidden neurons, more or less blocked by the activation functions, are forward propagated to the output layer, to return the final outcome, that is the price prediction.</p>
<p><br />
</p>
<p>Let’s represent this in the following graphic:</p>

<div style="page-break-after: always;"></div>

<p>Simply put, Neural Networks learn by updating, over many iterations, the weights of all the inputs and hidden neurons (when having several hidden layers), towards always the same goal to reduce the loss error between the predictions and the real values.</p>
<p><br />
</p>
<p>Indeed, in order for Neural Networks to learn, we need the actual values, which are also called the targets. In our example above about Real Estate Pricing, the actual values are the real prices of the houses and apartments in sales. These real prices depend on the independent variables listed above (area, number of bedrooms, distance to city, and age), and the Neural Network will learn to make better predictions of these prices, by running the following process:</p>
<p><br />
</p>

<p><br />
</p>
<p>Let’s represent the two main phases, forward-propagation and back-propagation, of this whole process in the two following separate graphics (see next page):</p>
<div style="page-break-after: always;"></div>

<p><br />
</p>
<p></p>

<p></p>

<div style="page-break-after: always;"></div>


<p>When people talk about Machine Learning or Deep Learning they mostly talk about algorithms that are used. But the real questions are, why are those algorithms considered to be Machine Learning or Deep Learning algorithms and others are not? What is the underlining technique that connects them?</p>
<p><br />
</p>
<p>The answer to the first question is pretty intuitive: those algorithms are considered to learn their parameters by themselves. This property was not very common before and most algorithms were hand tuned by engineers to achieve a required specification/goal.</p>
<p><br />
</p>
<p>But then Gradient Descent came on stage and most algorithms that did not work before suddenly made sense and started to optimize themselves.</p>
<p><br />
</p>
<p>So is Gradient Descent magic? Well to someone it is, but for us it is a mathematical algorithm that is used to optimize a model that has its internal parameters (weights). Or, to be more technical, let’s see what Wikipedia says about it:</p>

<p>That is a correct but mouthful definition, and for someone that is just starting, it is the scary one as well! Let’s break it down:</p>
<p><br />
</p>
<p> - In simple words, it is a blueprint on how to solve a problem. Everyday example of an algorithm would be a cooking recipe.</p>
<p><br />
</p>
<p> - This means that it uses some kind of loop (for programmers, for-loops or while-loops) to perform steps. Each step uses previously calculated values as an input for the current step. Now, one question rises, “What is our initial value?”. We will answer on this a bit later through examples.</p>
<p><br />
</p>
<p> - It tries to find the best solutions according to some criteria leading to several alternative solutions, but only one is consider the best.</p>
<p><br />
</p>
<p> - Gradient Descent is using first derivative of a criterion function (cost, loss) in order to find what is a better solution to the given problem.</p>
<p><br />
</p>
<p>Hence, when we put everything together in simple words, we get the following:</p>
<p><br />
</p>
<p>Gradient descent is a blueprint on how to find the best solution to a problem where more than one solution is acceptable. It uses a goal to determine how far we are from finding the best solution.</p>
<p><br />
</p>
<p>Until this point we have everything clarified except the cost function.</p>
<p><br />
</p>
<p>The cost is the indicator that we follow during the optimization process. Based on that indicator we can tell how far we are from the optimum of a function. One good example of the Cost is the Mean-Squared Error, which we have seen earlier in this book:</p>
<p><span class="math display">\[\begin{equation*}
    \textrm{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)
\end{equation*}\]</span></p>
<p>where:</p>
<p><span class="math display">\[\begin{equation*}
    \begin{cases}
        \textrm{$\hat{y}_i$ is the model prediction} \\
        \textrm{$y_i$ is the target (the actual value)} \\
        \textrm{$n$ is the number of samples in a dataset}
    \end{cases}
\end{equation*}\]</span></p>
<p>Every algorithm that uses Gradient Descent as an optimization technique has parameters (weights) which are changing during the optimization process. When we say that we are looking for the minimum of the loss function, we actually mean we are looking for the values of the weights for which the loss has the lowest possible value.</p>
<p><br />
</p>
<p>Accordingly, to answer our second question from the beginning, the technique that connects all the Machine Learning algorithms from Linear Regression to the most complicated neural networks is indeed, Gradient Descent.</p>
<p><br />
</p>

<p><br />
</p>
<p>As we have seen, Gradient Descent is an optimization technique that helps us find the minimum of a cost function. Now let’s visualize it in the most intuitive way, like the following ball in a bowl (with little math sprinkle on top of it):</p>

<p>Imagine this is a cross section of a bowl, inside which we drop a small red ball and let it find its way down to the bottom of the bowl. After some time it will stop rolling since it has found the sweet spot for it, at the bottom of the bowl.</p>
<p><br />
</p>
<p>You can think about the Gradient Descent in the same way. It starts somewhere in the bowl (initial values of parameters) and tries to find the bottom of the bowl, or in other words, the minimum of a cost function.</p>
<p><br />
</p>
<p>Let’s go through the example that is shown on the image above. The initial values of the parameters have set our ball at the position shown. Based on that we get some predictions, which we compare to our target values. The difference between these two sets will be our loss for the current set of parameters.</p>
<p><br />
</p>
<p>Then we calculate the first derivative of the cost function, with respect to the parameters. This is where the name  comes from. Here, this first derivative gives us the slope of the tangent to the curve where the ball is. If the slope is negative, like on the picture above, we take the next step to the right side. If the slope is positive we take the next step to the left side.</p>
<p><br />
</p>
<p>The name  thus comes from the fact that we always take the next step that points downhill, as represented in the following graphic:</p>

<p>Now at this position our ball has a positive slope, so we have to take the next step to the left.</p>

<p>Eventually, by repeating the same steps, the ball will end up at the bottom of the bowl:</p>

<p>And that’s it! This is how Gradient Descent operates in one dimension (one parameter). Now you might ask: “Great, but how does this scale?” We saw an example of one dimensional optimization, what about two or even 3 dimensions?</p>
<p><br />
</p>
<p>Excellent question. Gradient Descent guarantees that this approach scales on as many dimensions as needed, provided the cost function is convex. In fact, if the cost function is convex, Gradient Descent will find the absolute minimum of the cost function. Below is an example in 2 Dimensions:</p>

<p>However if the cost function is not convex, it will only find a local minimum. Below is an example in 3 Dimensions:</p>

<p>Now that we understand what Gradient Descent is all about, time to study the most advanced and most effective versions of it:</p>


<p>“Gradient Descent”, “Batch Gradient Descent”, “Mini Batch Gradient Descent”, “Stochastic Gradient Descent”.. There are so many terms and someone who is just starting may found him/her very confused.</p>
<p><br />
</p>
<p>The main difference across all of these versions of Gradient Descent is in the way we feed our data to a model, and how often we update our parameters (weights) to move our small red ball. Let’s start by explaining Batch Gradient Descent.</p>
<p><br />
</p>
<p>Batch Gradient Descent is exactly what we did in Part 2 - Minimizing Costs, where remember we had a batch of inputs feeding the neural network, forward-propagating them to obtain in the end a batch of predictions, which themselves are compared to a batch of targets. The global loss error between the predictions and the targets of the two batches is then computed as the sum of the loss errors between each prediction and its associated target. That global loss is back-propagated into the neural network, where gradient descent or stochastic gradient descent is performed to update all the weights, according to how much they were responsible for that global loss error.</p>
<p><br />
</p>
<p>In the next page below is an example of Batch Gradient Descent. The problem to solve is about predicting the score (from 0 to 100 %) students get at an exam, based on the time spent to study, and the time spent to sleep:</p>
<div style="page-break-after: always;"></div>

<p>An important thing to note on this graphic above is that these are not multiple neural networks, but a single one represented by separate weight updates. And again, as we can notice in this example of Batch Gradient Descent, we feed all of our data to the model at once. This will produce collective updates of the weights and fast optimization of the network. However, there is the bad side of this as well. There is once again the possibility to get stuck at a local minimum, as we can see in the next graphic below:</p>

<div style="page-break-after: always;"></div>
<p>The reason why this happens was explained a bit earlier: it is because the cost function in the graphic above is not convex. And this type of optimization (simple Gradient Descent) requires the cost function to be convex. If that is not the case we can find ourselves stuck in a local minimum and never find the global minimum having the optimal parameters. On the other hand, below is an example of a convex cost function, the same one as we saw earlier:</p>

<p>In simple terms, a function is convex if it has only one global minimum. And the graph of a convex function has the bowl shape.</p>
<p><br />
</p>
<p>However, in most of the problems, including the business problems, the cost function will not be convex (as in this same graphic example in 3D below), thus not allowing simple Gradient Descent to perform well. This is where Stochastic Gradient Descent comes into play.</p>


<p>Stochastic Gradient Descent (SGD) comes to save the day. It indeed provides better results overall, preventing the algorithm to get stuck in a local minimum. However, as its name suggests, it is stochastic, or in other words, random. Because of this property, no matter how many times you run the algorithm, the process will always be slightly different. And that, regardless of the initialization.</p>
<p><br />
</p>
<p>Stochastic Gradient Descent does not run on the whole dataset at once but instead input by input. Hence, the process goes like this:</p>

<p>Let’s represent the three first iterations on the three first single inputs for this same example given earlier about predicting the scores at an exam:</p>
<p><br />
</p>
<p></p>

<div style="page-break-after: always;"></div>
<p></p>

<p></p>

<p>Each of the three graphics above is an example of one weights update ran by Stochastic Gradient Descent. As we can see, each time we only input a single row of observation from our dataset to the neural network, then we update the weights accordingly and proceed to the next input row of observation.</p>
<p><br />
</p>
<p>At first glance, Stochastic Gradient Descent seems slower, because we input each row separately. But in reality, it is much faster because of the fact that we don’t have to load the whole dataset in the memory, nor to wait for whole dataset to pass through the model updating the weights.</p>
<p><br />
</p>
<p>To finish this section, let’s recap on the difference between Batch Gradient Descent and Stochastic Gradient Descent, with the following graphic:</p>


<p>Mini-Batch Gradient Descent is using the best from both worlds to combine Batch Gradient Descent with Stochastic Gradient Descent. This is done by feeding the neural network with batches of data instead of feeding single input rows of observations one by one or the whole dataset at once.</p>
<p><br />
</p>
<p>This approach is faster than classical Stochastic Gradient Descent and prevents from getting stuck in the local minimum. This also helps when people don’t have enough computing resources to load the whole dataset in the memory, or enough processing power to get full benefit of Stochastic Gradient Descent.</p>

<p>The optimizer is exactly the tool that will update the weights of the Neural Network through Stochastic Gradient Descent. Up to this point we have only mentioned the Adam optimizer (see Part 2 - Minimizing Costs), which is the most common optimizer used for the Deep Learning and Deep Reinforcement Learning models. Nevertheless there are a lot more optimizers which have their own benefits and applications.</p>
<p><br />
</p>
<p>Let’s go through the most famous and widely used Gradient Descent optimizers.</p>
<div style="page-break-after: always;"></div>

<p><br />
</p>
<p>The classical Stochastic Gradient Descent has very big oscillations, which leaves room for improvement. The Momentum optimizer handles these big oscillations by adding fractions of the directions calculated in the previous step to the current step. This amplifies the speed of the current direction update. In the graphic just below we can see and compare the Classical SGD and the Momentum SGD in action:</p>
<p><br />
</p>
<p><br />
</p>

<p><br />
</p>
<p><br />
</p>
<p>The benefits of the Momentum Optimizer are the following:</p>
<p><br />
</p>

<p><br />
</p>
<p>But the Momentum Optimizer also has drawbacks, which are the following:</p>
<p><br />
</p>

<div style="page-break-after: always;"></div>

<p>Yuri Nesterov solved the momentum the overshot minimum problem by reversing the calculation order in the update formula:</p>


<p>The idea of adapting our updates according to the slope of the error function, coming from the Nesterov optimizer, is taken and applied in the AdaGrad Optimizer while optimizing the learning rate as well.</p>
<p><br />
</p>
<p>Hence, in the AdaGrad optimizer we have the same principle, not only applied on gradients but also on the learning rate.</p>
<p><br />
</p>
<p>Here are the benefits of this optimizer:</p>

<p>And here are the drawbacks:</p>


<p>The AdaDelta Optimizer was invented to fix that decreasing learning rate issue of the AdaGrad Optimizer (first drawback). No need to get in further details, we just needed to introduce the AdaDelta optimizer and its particularity in order to understand the strength of the most widely used and most effective optimizer: the Adam Optimizer.</p>

<p>The Adam Optimizer is an improvement over the AdaDelta Optimizer. The idea behind it is to store in a memory the momentum changes, as we calculate the learning rate for each parameter separately.</p>
<p><br />
</p>
<p>Now remember the benefits of the Adam Optimizer, which are to be considered whenever building a Neural Network.</p>

<p>Of course, this is the one we use when building the Artificial Brain of our AI in Part 2 - Minimizing the Costs. Let’s again provide the code that builds this artificial brain and notice, at the last line of code, the simplicity of selecting the Adam Optimizer:</p>
<p><br />
</p>

<div style="page-break-after: always;"></div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="conclusion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="annex-2-three-extra-ai-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/joanby/ia4business/edit/master/5.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["curso-ia-business-udemy.pdf", "curso-ia-business-udemy.epub"],
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
