<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Tema 5 Vectores aleatorios bidimensionales | Probabilidad y variables aleatorias para ML con R y Python</title>
  <meta name="description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Tema 5 Vectores aleatorios bidimensionales | Probabilidad y variables aleatorias para ML con R y Python" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7" />
  <meta property="og:image" content="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7Images/cover.jpg" />
  <meta property="og:description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="github-repo" content="https://github.com/joanby/probabilidad" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tema 5 Vectores aleatorios bidimensionales | Probabilidad y variables aleatorias para ML con R y Python" />
  
  <meta name="twitter:description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="twitter:image" content="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7Images/cover.jpg" />

<meta name="author" content="Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir" />


<meta name="date" content="2019-12-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="Images/apple-icon-120x120.png" />
  <link rel="shortcut icon" href="Images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="variables-aleatorias-complementos.html"/>
<link rel="next" href="vectores-aleatorios.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso completo de Probabilidad y Variables Aleatorias con R y Python</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><i class="fa fa-check"></i>Pre requisitos: Teoría de conjuntos y combinatoria</a><ul>
<li class="chapter" data-level="0.1" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#teoría-de-conjuntos"><i class="fa fa-check"></i><b>0.1</b> Teoría de conjuntos</a><ul>
<li class="chapter" data-level="0.1.1" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#conjuntos-básicos"><i class="fa fa-check"></i><b>0.1.1</b> Conjuntos básicos</a></li>
<li class="chapter" data-level="0.1.2" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#características-y-propiedades-básicas-de-los-conjuntos"><i class="fa fa-check"></i><b>0.1.2</b> Características y propiedades básicas de los conjuntos</a></li>
<li class="chapter" data-level="0.1.3" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#operaciones-con-conjuntos"><i class="fa fa-check"></i><b>0.1.3</b> Operaciones con conjuntos</a></li>
<li class="chapter" data-level="0.1.4" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#más-propiedades-y-definiciones"><i class="fa fa-check"></i><b>0.1.4</b> Más propiedades y definiciones</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#combinatoria"><i class="fa fa-check"></i><b>0.2</b> Combinatoria</a><ul>
<li class="chapter" data-level="0.2.1" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#número-binomial."><i class="fa fa-check"></i><b>0.2.1</b> Número binomial.</a></li>
<li class="chapter" data-level="0.2.2" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#variaciones."><i class="fa fa-check"></i><b>0.2.2</b> Variaciones.</a></li>
<li class="chapter" data-level="0.2.3" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#variaciones-con-repetición."><i class="fa fa-check"></i><b>0.2.3</b> Variaciones con repetición.</a></li>
<li class="chapter" data-level="0.2.4" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#permutaciones"><i class="fa fa-check"></i><b>0.2.4</b> Permutaciones</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#para-acabar"><i class="fa fa-check"></i><b>0.3</b> Para acabar</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>1</b> Probabilidad</a><ul>
<li class="chapter" data-level="1.1" data-path="probabilidad.html"><a href="probabilidad.html#probabilidades-básicas"><i class="fa fa-check"></i><b>1.1</b> Probabilidades Básicas</a><ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad.html"><a href="probabilidad.html#operaciones-con-sucesos"><i class="fa fa-check"></i><b>1.1.1</b> Operaciones con sucesos</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad.html"><a href="probabilidad.html#propiedades"><i class="fa fa-check"></i><b>1.1.2</b> Propiedades</a></li>
<li class="chapter" data-level="1.1.3" data-path="probabilidad.html"><a href="probabilidad.html#definición-de-probabilidad"><i class="fa fa-check"></i><b>1.1.3</b> Definición de probabilidad</a></li>
<li class="chapter" data-level="1.1.4" data-path="probabilidad.html"><a href="probabilidad.html#propiedades-1"><i class="fa fa-check"></i><b>1.1.4</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.2</b> Probabilidad condicionada</a><ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad.html"><a href="probabilidad.html#atención"><i class="fa fa-check"></i><b>1.2.1</b> ¡Atención!</a></li>
<li class="chapter" data-level="1.2.2" data-path="probabilidad.html"><a href="probabilidad.html#propiedades-2"><i class="fa fa-check"></i><b>1.2.2</b> Propiedades</a></li>
<li class="chapter" data-level="1.2.3" data-path="probabilidad.html"><a href="probabilidad.html#teorema-de-la-probabilidad-total"><i class="fa fa-check"></i><b>1.2.3</b> Teorema de la probabilidad total</a></li>
<li class="chapter" data-level="1.2.4" data-path="probabilidad.html"><a href="probabilidad.html#clasificación-o-diagnósticos"><i class="fa fa-check"></i><b>1.2.4</b> Clasificación o Diagnósticos</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad.html"><a href="probabilidad.html#bayes"><i class="fa fa-check"></i><b>1.3</b> Bayes</a><ul>
<li class="chapter" data-level="1.3.1" data-path="probabilidad.html"><a href="probabilidad.html#fórmula-de-bayes"><i class="fa fa-check"></i><b>1.3.1</b> Fórmula de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probabilidad.html"><a href="probabilidad.html#independencia-de-sucesos"><i class="fa fa-check"></i><b>1.4</b> Independencia de sucesos</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probabilidad.html"><a href="probabilidad.html#sucesos-independientes"><i class="fa fa-check"></i><b>1.4.1</b> Sucesos independientes</a></li>
<li class="chapter" data-level="1.4.2" data-path="probabilidad.html"><a href="probabilidad.html#sucesos-independientes-vs-disjuntos"><i class="fa fa-check"></i><b>1.4.2</b> Sucesos independientes vs disjuntos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>2</b> Variables Aleatorias</a><ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#introducción-a-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.1</b> Introducción a las variables aleatorias</a><ul>
<li class="chapter" data-level="2.1.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#definición-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.1.1</b> Definición de variable aleatoria</a></li>
<li class="chapter" data-level="2.1.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>2.1.2</b> Tipos de variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.2</b> Variables aleatorias discretas</a><ul>
<li class="chapter" data-level="2.2.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#distribuciones-de-probabilidad-para-v.a.-discretas."><i class="fa fa-check"></i><b>2.2.1</b> Distribuciones de probabilidad para v.a. discretas.</a></li>
<li class="chapter" data-level="2.2.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#valores-esperados-o-esperanza"><i class="fa fa-check"></i><b>2.2.2</b> Valores esperados o esperanza</a></li>
<li class="chapter" data-level="2.2.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#medidas-de-la-variabilidad"><i class="fa fa-check"></i><b>2.2.3</b> Medidas de la variabilidad</a></li>
<li class="chapter" data-level="2.2.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#transformaciones-lineales."><i class="fa fa-check"></i><b>2.2.4</b> Transformaciones lineales.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.3</b> Variables aleatorias continuas</a><ul>
<li class="chapter" data-level="2.3.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#propiedades-3"><i class="fa fa-check"></i><b>2.3.1</b> Propiedades</a></li>
<li class="chapter" data-level="2.3.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#función-de-densidad"><i class="fa fa-check"></i><b>2.3.2</b> Función de densidad</a></li>
<li class="chapter" data-level="2.3.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#utilidad-de-la-función-de-densidad"><i class="fa fa-check"></i><b>2.3.3</b> Utilidad de la función de densidad</a></li>
<li class="chapter" data-level="2.3.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#esperanza-y-varianza-para-variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.3.4</b> Esperanza y varianza para variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#transformaciones-de-variables-aleatorias"><i class="fa fa-check"></i><b>2.4</b> Transformaciones de variables aleatorias</a></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#desigualdades-de-markov-y-de-chebychev"><i class="fa fa-check"></i><b>2.5</b> Desigualdades de Markov y de Chebychev</a><ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#desigualdad-de-markov"><i class="fa fa-check"></i><b>2.5.1</b> Desigualdad de Markov</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#desigualdad-de-chebychev"><i class="fa fa-check"></i><b>2.5.2</b> Desigualdad de Chebychev</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#cuantiles-de-variables-aleatorias"><i class="fa fa-check"></i><b>2.6</b> Cuantiles de variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a><ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a><ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-de-bernoulli"><i class="fa fa-check"></i><b>3.1.1</b> Distribución de Bernoulli</a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-binomial"><i class="fa fa-check"></i><b>3.1.2</b> Distribución binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-geométrica"><i class="fa fa-check"></i><b>3.1.3</b> Distribución geométrica</a></li>
<li class="chapter" data-level="3.1.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-binomial-negativa"><i class="fa fa-check"></i><b>3.1.4</b> Distribución binomial negativa</a></li>
<li class="chapter" data-level="3.1.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-de-poisson"><i class="fa fa-check"></i><b>3.1.5</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-hipergeométrica"><i class="fa fa-check"></i><b>3.1.6</b> Distribución hipergeométrica</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#cuantiles-de-distribuciones-notables-discretas"><i class="fa fa-check"></i><b>3.2</b> Cuantiles de distribuciones notables discretas</a></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.3</b> Distribuciones continuas</a><ul>
<li class="chapter" data-level="3.3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-uniforme"><i class="fa fa-check"></i><b>3.3.1</b> Distribución uniforme</a></li>
<li class="chapter" data-level="3.3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-exponencial"><i class="fa fa-check"></i><b>3.3.2</b> Distribución exponencial</a></li>
<li class="chapter" data-level="3.3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-normal-o-gaussiana"><i class="fa fa-check"></i><b>3.3.3</b> Distribución normal o Gaussiana</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html"><i class="fa fa-check"></i><b>4</b> Variables Aleatorias. Complementos</a><ul>
<li class="chapter" data-level="4.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#momentos-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.1</b> Momentos de variables aleatorias</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#momento-de-orden-n"><i class="fa fa-check"></i><b>4.1.1</b> Momento de orden <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="4.1.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#momento-central-de-orden-n"><i class="fa fa-check"></i><b>4.1.2</b> Momento central de orden <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#asimetría-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>4.2</b> Asimetría de una variable aleatoria</a></li>
<li class="chapter" data-level="4.3" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#curtosis-o-apuntamiento-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>4.3</b> Curtosis o apuntamiento de una variable aleatoria</a></li>
<li class="chapter" data-level="4.4" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#métodos-de-transformación"><i class="fa fa-check"></i><b>4.4</b> Métodos de transformación</a><ul>
<li class="chapter" data-level="4.4.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#función-generatriz-de-momentos"><i class="fa fa-check"></i><b>4.4.1</b> Función generatriz de momentos</a></li>
<li class="chapter" data-level="4.4.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#función-característica"><i class="fa fa-check"></i><b>4.4.2</b> Función característica</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#fiabilidad"><i class="fa fa-check"></i><b>4.5</b> Fiabilidad</a><ul>
<li class="chapter" data-level="4.5.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#tiempo-medio-de-vida"><i class="fa fa-check"></i><b>4.5.1</b> Tiempo medio de vida</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#generación-de-muestras-de-variables-aleatorias-por-ordenador"><i class="fa fa-check"></i><b>4.6</b> Generación de muestras de variables aleatorias por ordenador</a><ul>
<li class="chapter" data-level="4.6.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#método-de-transformación"><i class="fa fa-check"></i><b>4.6.1</b> Método de transformación</a></li>
<li class="chapter" data-level="4.6.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#método-de-rechazo"><i class="fa fa-check"></i><b>4.6.2</b> Método de rechazo</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#entropía"><i class="fa fa-check"></i><b>4.7</b> Entropía</a><ul>
<li class="chapter" data-level="4.7.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#entropía-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>4.7.1</b> Entropía de una variable aleatoria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html"><i class="fa fa-check"></i><b>5</b> Vectores aleatorios bidimensionales</a><ul>
<li class="chapter" data-level="5.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#dos-variables-aleatorias"><i class="fa fa-check"></i><b>5.1</b> Dos variables aleatorias</a><ul>
<li class="chapter" data-level="5.1.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#definición"><i class="fa fa-check"></i><b>5.1.1</b> Definición</a></li>
<li class="chapter" data-level="5.1.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#representación-del-dominio-de-una-variable-aleatoria-bidimensional"><i class="fa fa-check"></i><b>5.1.2</b> Representación del dominio de una variable aleatoria bidimensional</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#función-de-distribución-conjunta"><i class="fa fa-check"></i><b>5.2</b> Función de distribución conjunta</a><ul>
<li class="chapter" data-level="5.2.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#definición-1"><i class="fa fa-check"></i><b>5.2.1</b> Definición</a></li>
<li class="chapter" data-level="5.2.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#propiedades-4"><i class="fa fa-check"></i><b>5.2.2</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-bidimensionales-discretas"><i class="fa fa-check"></i><b>5.3</b> Variables aleatorias bidimensionales discretas</a><ul>
<li class="chapter" data-level="5.3.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#función-de-probabilidad-conjunta"><i class="fa fa-check"></i><b>5.3.1</b> Función de probabilidad conjunta</a></li>
<li class="chapter" data-level="5.3.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>5.3.2</b> Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-bidimensionales-continuas"><i class="fa fa-check"></i><b>5.4</b> Variables aleatorias bidimensionales continuas</a><ul>
<li class="chapter" data-level="5.4.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#definición-2"><i class="fa fa-check"></i><b>5.4.1</b> Definición</a></li>
<li class="chapter" data-level="5.4.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#propiedades-de-la-función-de-densidad"><i class="fa fa-check"></i><b>5.4.2</b> Propiedades de la función de densidad</a></li>
<li class="chapter" data-level="5.4.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#la-distribución-gaussiana-bidimensional"><i class="fa fa-check"></i><b>5.4.3</b> La distribución gaussiana bidimensional</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.5</b> Independencia de variables aleatorias</a><ul>
<li class="chapter" data-level="5.5.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#independencia-de-variables-aleatorias-discretas"><i class="fa fa-check"></i><b>5.5.1</b> Independencia de variables aleatorias discretas</a></li>
<li class="chapter" data-level="5.5.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#independencia-de-variables-aleatorias-continuas"><i class="fa fa-check"></i><b>5.5.2</b> Independencia de variables aleatorias continuas</a></li>
<li class="chapter" data-level="5.5.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#relación-de-la-independencia-y-la-función-de-distribución"><i class="fa fa-check"></i><b>5.5.3</b> Relación de la independencia y la función de distribución</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#momentos-conjuntos-y-valores-esperados-conjuntos"><i class="fa fa-check"></i><b>5.6</b> Momentos conjuntos y valores esperados conjuntos</a><ul>
<li class="chapter" data-level="5.6.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valor-esperado-de-una-función-de-dos-variables-aleatorias"><i class="fa fa-check"></i><b>5.6.1</b> Valor esperado de una función de dos variables aleatorias</a></li>
<li class="chapter" data-level="5.6.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valor-esperado-de-una-función-de-dos-variables-aleatorias-independientes"><i class="fa fa-check"></i><b>5.6.2</b> Valor esperado de una función de dos variables aleatorias independientes</a></li>
<li class="chapter" data-level="5.6.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#momentos-conjuntos"><i class="fa fa-check"></i><b>5.6.3</b> Momentos conjuntos</a></li>
<li class="chapter" data-level="5.6.4" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#momentos-conjuntos-centrados-en-las-medias"><i class="fa fa-check"></i><b>5.6.4</b> Momentos conjuntos centrados en las medias</a></li>
<li class="chapter" data-level="5.6.5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#covariancia-entre-las-variables"><i class="fa fa-check"></i><b>5.6.5</b> Covariancia entre las variables</a></li>
<li class="chapter" data-level="5.6.6" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#coeficiente-de-correlación-entre-las-variables"><i class="fa fa-check"></i><b>5.6.6</b> Coeficiente de correlación entre las variables</a></li>
<li class="chapter" data-level="5.6.7" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#incorrelación-e-independencia"><i class="fa fa-check"></i><b>5.6.7</b> Incorrelación e independencia</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-condicionales-y-valor-esperado-condicional"><i class="fa fa-check"></i><b>5.7</b> Variables aleatorias condicionales y valor esperado condicional</a><ul>
<li class="chapter" data-level="5.7.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-condicionales-discretas"><i class="fa fa-check"></i><b>5.7.1</b> Variables aleatorias condicionales discretas</a></li>
<li class="chapter" data-level="5.7.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-condicionales-continuas"><i class="fa fa-check"></i><b>5.7.2</b> Variables aleatorias condicionales continuas</a></li>
<li class="chapter" data-level="5.7.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valores-esperados-condicionales"><i class="fa fa-check"></i><b>5.7.3</b> Valores esperados condicionales</a></li>
<li class="chapter" data-level="5.7.4" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#relación-con-el-problema-de-la-regresión-general"><i class="fa fa-check"></i><b>5.7.4</b> Relación con el problema de la regresión general</a></li>
<li class="chapter" data-level="5.7.5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valores-esperados-condicionales.-caso-general"><i class="fa fa-check"></i><b>5.7.5</b> Valores esperados condicionales. Caso general</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-definidas-como-función-de-dos-variables-aleatorias-conjuntas"><i class="fa fa-check"></i><b>5.8</b> Variables aleatorias definidas como función de dos variables aleatorias conjuntas</a><ul>
<li class="chapter" data-level="5.8.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variable-aleatoria-función-de-la-variable-aleatoria-bidimensional"><i class="fa fa-check"></i><b>5.8.1</b> Variable aleatoria función de la variable aleatoria bidimensional</a></li>
<li class="chapter" data-level="5.8.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#transformaciones-lineales-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.8.2</b> Transformaciones lineales de variables aleatorias</a></li>
<li class="chapter" data-level="5.8.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#transformaciones-generales-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.8.3</b> Transformaciones generales de variables aleatorias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html"><i class="fa fa-check"></i><b>6</b> Vectores aleatorios</a><ul>
<li class="chapter" data-level="6.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#varias-variables-aleatorias"><i class="fa fa-check"></i><b>6.1</b> Varias variables aleatorias</a><ul>
<li class="chapter" data-level="6.1.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#definición-3"><i class="fa fa-check"></i><b>6.1.1</b> Definición</a></li>
<li class="chapter" data-level="6.1.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#representación-del-dominio-de-una-variable-aleatoria-n-dimensional"><i class="fa fa-check"></i><b>6.1.2</b> Representación del dominio de una variable aleatoria <span class="math inline">\(n\)</span>-dimensional</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#función-de-distribución-conjunta-1"><i class="fa fa-check"></i><b>6.2</b> Función de distribución conjunta</a><ul>
<li class="chapter" data-level="6.2.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#definición-4"><i class="fa fa-check"></i><b>6.2.1</b> Definición</a></li>
<li class="chapter" data-level="6.2.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-5"><i class="fa fa-check"></i><b>6.2.2</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#variables-aleatorias-n-dimensionales-discretas"><i class="fa fa-check"></i><b>6.3</b> Variables aleatorias <span class="math inline">\(n\)</span>-dimensionales discretas</a><ul>
<li class="chapter" data-level="6.3.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#función-de-probabilidad-conjunta-1"><i class="fa fa-check"></i><b>6.3.1</b> Función de probabilidad conjunta</a></li>
<li class="chapter" data-level="6.3.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-de-la-función-de-probabilidad-conjunta-1"><i class="fa fa-check"></i><b>6.3.2</b> Propiedades de la función de probabilidad conjunta</a></li>
<li class="chapter" data-level="6.3.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#funciones-de-distribución-marginales"><i class="fa fa-check"></i><b>6.3.3</b> Funciones de distribución marginales</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#variables-aleatorias-n-dimensionales-continuas"><i class="fa fa-check"></i><b>6.4</b> Variables aleatorias <span class="math inline">\(n\)</span>-dimensionales continuas</a><ul>
<li class="chapter" data-level="6.4.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#definición-5"><i class="fa fa-check"></i><b>6.4.1</b> Definición</a></li>
<li class="chapter" data-level="6.4.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-de-la-función-de-densidad-1"><i class="fa fa-check"></i><b>6.4.2</b> Propiedades de la función de densidad</a></li>
<li class="chapter" data-level="6.4.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#la-distribución-gaussiana-n-dimensional"><i class="fa fa-check"></i><b>6.4.3</b> La distribución gaussiana <span class="math inline">\(n\)</span>-dimensional</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#independencia-de-variables-aleatorias-1"><i class="fa fa-check"></i><b>6.5</b> Independencia de variables aleatorias</a><ul>
<li class="chapter" data-level="6.5.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#independencia-de-variables-aleatorias-discretas-1"><i class="fa fa-check"></i><b>6.5.1</b> Independencia de variables aleatorias discretas</a></li>
<li class="chapter" data-level="6.5.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#independencia-de-variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>6.5.2</b> Independencia de variables aleatorias continuas</a></li>
<li class="chapter" data-level="6.5.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#relación-de-la-independencia-y-la-función-de-distribución-1"><i class="fa fa-check"></i><b>6.5.3</b> Relación de la independencia y la función de distribución</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#momentos-conjuntos-y-valores-esperados-conjuntos-1"><i class="fa fa-check"></i><b>6.6</b> Momentos conjuntos y valores esperados conjuntos</a><ul>
<li class="chapter" data-level="6.6.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#valor-esperado-de-una-función-de-n-variables-aleatorias"><i class="fa fa-check"></i><b>6.6.1</b> Valor esperado de una función de <span class="math inline">\(n\)</span> variables aleatorias</a></li>
<li class="chapter" data-level="6.6.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#ejemplos-12"><i class="fa fa-check"></i><b>6.6.2</b> Ejemplos</a></li>
<li class="chapter" data-level="6.6.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedad-del-valor-esperado-de-la-suma-de-variables"><i class="fa fa-check"></i><b>6.6.3</b> Propiedad del valor esperado de la suma de variables</a></li>
<li class="chapter" data-level="6.6.4" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#valor-esperado-de-una-función-de-n-variables-aleatorias-independientes"><i class="fa fa-check"></i><b>6.6.4</b> Valor esperado de una función de <span class="math inline">\(n\)</span> variables aleatorias independientes</a></li>
<li class="chapter" data-level="6.6.5" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-de-la-covarianza-1"><i class="fa fa-check"></i><b>6.6.5</b> Propiedades de la covarianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><i class="fa fa-check"></i><b>7</b> Ley de los grandes números y Teorema Central del Límite</a><ul>
<li class="chapter" data-level="7.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#muestras-aleatorias-simples"><i class="fa fa-check"></i><b>7.1</b> Muestras aleatorias simples</a><ul>
<li class="chapter" data-level="7.1.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#la-distribución-de-la-media-muestral"><i class="fa fa-check"></i><b>7.1.1</b> La distribución de la media muestral</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-de-sucesiones-de-variables-aleatorias"><i class="fa fa-check"></i><b>7.2</b> Convergencia de sucesiones de variables aleatorias</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-casi-segura"><i class="fa fa-check"></i><b>7.2.1</b> Convergencia casi segura</a></li>
<li class="chapter" data-level="7.2.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-en-probabilidad"><i class="fa fa-check"></i><b>7.2.2</b> Convergencia en probabilidad</a></li>
<li class="chapter" data-level="7.2.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-en-ley-o-en-distribución"><i class="fa fa-check"></i><b>7.2.3</b> Convergencia en ley o en distribución</a></li>
<li class="chapter" data-level="7.2.4" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#relaciones-entre-las-distintas-convergencias"><i class="fa fa-check"></i><b>7.2.4</b> Relaciones entre las distintas convergencias</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#leyes-de-los-grandes-números"><i class="fa fa-check"></i><b>7.3</b> Leyes de los grandes números</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#leyes-débiles-de-los-grandes-números"><i class="fa fa-check"></i><b>7.3.1</b> Leyes débiles de los grandes números</a></li>
<li class="chapter" data-level="7.3.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>7.3.2</b> Convergencia de los momentos muestrales</a></li>
<li class="chapter" data-level="7.3.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#leyes-fuertes-de-los-grandes-números"><i class="fa fa-check"></i><b>7.3.3</b> Leyes fuertes de los grandes números</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-central-del-límite"><i class="fa fa-check"></i><b>7.4</b> Teorema Central del Límite</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-central-del-límite-1"><i class="fa fa-check"></i><b>7.4.1</b> Teorema Central del Límite</a></li>
<li class="chapter" data-level="7.4.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-central-del-límite-en-la-práctica"><i class="fa fa-check"></i><b>7.4.2</b> Teorema Central del Límite en la práctica</a></li>
<li class="chapter" data-level="7.4.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-de-moivre-laplace"><i class="fa fa-check"></i><b>7.4.3</b> Teorema de Moivre-Laplace</a></li>
<li class="chapter" data-level="7.4.4" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#aproximación-de-una-suma-de-variables-poisson"><i class="fa fa-check"></i><b>7.4.4</b> Aproximación de una suma de variables Poisson</a></li>
<li class="chapter" data-level="7.4.5" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#corrección-de-continuidad-de-fisher"><i class="fa fa-check"></i><b>7.4.5</b> Corrección de continuidad de Fisher</a></li>
<li class="chapter" data-level="7.4.6" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#simulación-del-teorema-central-del-límite"><i class="fa fa-check"></i><b>7.4.6</b> Simulación del Teorema Central del Límite</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7" target="blank">Curso en Udemy</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probabilidad y variables aleatorias para ML con R y Python</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="vectores-aleatorios-bidimensionales" class="section level1">
<h1><span class="header-section-number">Tema 5</span> Vectores aleatorios bidimensionales</h1>
<div id="dos-variables-aleatorias" class="section level2">
<h2><span class="header-section-number">5.1</span> Dos variables aleatorias</h2>
<p>Muchos experimentos aleatorios involucran varias variables aleatorias.</p>
<p>Por ejemplo, dado un individuo de 30 años escogido al azar de una cierta población, medir su altura y su peso conjuntamente.</p>
<p>Otro ejemplo más complejo es la medición continuada de un <em>fenómeno aleatorio</em> que se repite en el tiempo, como sería medir la temperatura media un día determinado del año, por ejemplo el día 1 de enero en un cierto lugar.</p>
<p>La variable aleatoria que nos da la medición en 10 años es una variable aleatoria de varias variables que involucra 10 variables aleatorias supuestas independientes e idénticamente distribuidas, lo que en <strong>estadística inferencial</strong> se le llama una <strong>muestra aleatoria simple</strong>.</p>
<div id="definición" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Definición</h3>
<p>Recordemos que una <strong>variable aleatoria</strong> <span class="math inline">\(X\)</span> es una aplicación que toma valores numéricos para cada resultado de un experimento aleatorio:
<span class="math display">\[
\begin{array}{rl}
X: \Omega &amp; \longrightarrow \mathbb{R}\\
w &amp; \longrightarrow X(w).
\end{array}
\]</span>
A partir de la definición anterior, generalizamos la noción de <strong>variable aleatoria unidimensional</strong> a <strong>variable aleatoria bidimensional</strong>:</p>
<p><l class="definition">Definición de variable aleatoria bidimensional:</l>
Dado un experimento aleatorio con <strong>espacio muestral</strong> <span class="math inline">\(\Omega\)</span>, definimos <strong>variable aleatoria bidimensional</strong> <span class="math inline">\((X,Y)\)</span> a toda aplicación
<span class="math display">\[
\begin{array}{rl}
(X,Y): \Omega &amp; \longrightarrow \mathbb{R}^2\\
w &amp; \longrightarrow (X(w),Y(w)).
\end{array}
\]</span></p>
<div class="example">
<p><strong>Ejemplo: lanzamiento dos dados</strong></p>
<p>Consideremos el experimento aleatorio de lanzar un dado no trucado dos veces.</p>
<p>Sea <span class="math inline">\(S\)</span> la suma de los resultados obtenidos y <span class="math inline">\(P\)</span> el producto de los mismos.</p>
<p>La variable aleatoria <span class="math inline">\((S,P)\)</span> que asigna a cada resultado <span class="math inline">\(w=(x_1,x_2)\)</span> donde <span class="math inline">\(x_1\)</span> es el resultado obtenido en el primer lanzamiento y <span class="math inline">\(x_2\)</span>, el resultado obtenido en el segundo, los valores: <span class="math inline">\(S(w)=x_1+x_2\)</span> y <span class="math inline">\(P(w)=x_1\cdot x_2\)</span> es una variable aleatoria bidimensional.</p>
<div class="example-sol">
<p>El suceso <span class="math inline">\(\{2\leq S\leq 4,\ 3\leq P\leq 6\}\)</span> seria:
<span class="math display">\[
\{2\leq S\leq 4,\ 3\leq P\leq 6\} = \{(1,3),(3,1),(2,2)\}.
\]</span></p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo</strong></p>
Consideremos el experimento aleatorio de elegir al azar un estudiante de primer curso de grado. Sea <span class="math inline">\(w\)</span> el estudiante elegido. Consideremos la variable aleatoria <span class="math inline">\((H,W)\)</span> que asigna a dicho estudiante <span class="math inline">\(w\)</span>, <span class="math inline">\(H(w):\)</span> la altura de dicho estudiante en cm. y <span class="math inline">\(W(w):\)</span> el peso de dicho estudiante en kg.
<div class="example-sol">
<p>Estamos interesado en sucesos del tipo <span class="math inline">\(A=\{H\leq 176,\ W\leq 85\}\)</span>, es decir, el conjunto de estudiantes que miden menos de 1.76 m. y que pesan menos de 85 kg.</p>
</div>
</div>
</div>
<div id="representación-del-dominio-de-una-variable-aleatoria-bidimensional" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Representación del dominio de una variable aleatoria bidimensional</h3>
<p>Los sucesos que se derivan de una <strong>variable aleatoria bidimensional</strong> estan especificados por regiones del plano.
Veamos algunos ejemplos:</p>
<p>Suceso: <span class="math inline">\(\{X+Y\leq 1\}\)</span>. Es la zona sombreada del gráfico siguiente:</p>
<div class="center">
<p><img src="Images/Bidim1.png" /><!-- --></p>
</div>
<p>Suceso: <span class="math inline">\(\{X^2+Y^2\leq 4\}\)</span>. Es la zona sombreada del gráfico siguiente:</p>
<div class="center">
<p><img src="Images/Bidim2.png" style="display: block; margin: auto;" /></p>
</div>
<p>Suceso: <span class="math inline">\(\{\max\{X,Y\}\geq 1\}\)</span>. Esta zona es la sombreada del gráfico siguiente:</p>
<div class="center">
<div class="figure"><span id="fig:bid3"></span>
<img src="Images/Bidim3.png" alt="Representación suceso"  />
<p class="caption">
Figure 5.1: Representación suceso
</p>
</div>
</div>
<p>La probabilidad de que la <strong>variable bidimensional</strong> pertenezca a una cierta <strong>región del plano <span class="math inline">\(B\)</span></strong> se define de la forma siguiente:
<span class="math display">\[
P((X,Y)\in B)=P\{w\in \Omega,\ |\ (X(w),Y(w))\in B\},
\]</span>
es decir, la probabilidad anterior es la probabilidad del suceso formado por los elementos de <span class="math inline">\(w\in\Omega\)</span> que cumplen que su <strong>imagen</strong> por la <strong>variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span></strong> esté en <span class="math inline">\(B\)</span>.</p>
<p>Por ejemplo, si consideramos <span class="math inline">\(B=\{X+Y\leq 1\}\)</span>, <span class="math inline">\(P((X,Y)\in B)\)</span> es la probabilidad del suceso formado por los elementos <span class="math inline">\(w\)</span> de <span class="math inline">\(\Omega\)</span> tal que la suma de las imágenes por <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sea menor o igual que 1: <span class="math inline">\(X(w)+Y(w)\leq 1\)</span>.</p>
</div>
</div>
<div id="función-de-distribución-conjunta" class="section level2">
<h2><span class="header-section-number">5.2</span> Función de distribución conjunta</h2>
<div id="definición-1" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Definición</h3>
<p>Dada una <strong>variable aleatoria bidimensional</strong> <span class="math inline">\((X,Y)\)</span>, queremos estudiar cómo se distribuye la probabilidad de sucesos cualesquiera de la forma <span class="math inline">\(\{(X,Y)\in B\}\)</span>, donde <span class="math inline">\(B\)</span> es una región del plano.</p>
<p>Para ello, definimos la <strong>función de distribución conjunta</strong>:</p>
<p><l class="definition">Definición de función de distribución conjunta:</l>
Dada una variable bidimensional <span class="math inline">\((X,Y)\)</span>, definimos su <strong>función de distribución conjunta</strong> <span class="math inline">\(F_{XY}\)</span> a la función definida sobre <span class="math inline">\(\mathbb{R}^2\)</span> de la manera siguiente:
<span class="math display">\[
\begin{array}{rl}
F_{XY}: \mathbb{R}^2 &amp; \longrightarrow \mathbb{R}\\
(x,y) &amp; \longrightarrow F_{XY}(x,y)=P(X\leq x,\ Y\leq y).
\end{array}
\]</span></p>
Por lo tanto, dado un valor <span class="math inline">\((x,y)\in \mathbb{R}^2\)</span>, consideramos la región del plano <span class="math inline">\((-\infty,x]\times (-\infty,y]\)</span>:
<div class="center">
<p><img src="Images/Fxy.png" /><!-- --></p>
</div>
<p>Entonces la <strong>función de distribución conjunta</strong> en el valor <span class="math inline">\((x,y)\)</span> es la probabilidad del suceso formado por aquellos elementos tal que la imagen por la <strong>variable aleatoria bidimensional</strong> <span class="math inline">\((X,Y)\)</span> caen dentro de la región sombreada en el gráfico anterior:</p>
<p><span class="math display">\[
\begin{array}{rl}
F_{XY}(x,y) &amp;= P\{w\in\Omega,\ |\ (X(w),Y(w))\in (-\infty,x]\times (-\infty,y]\} \\ 
&amp;= P\{w\in\Omega,\ |\ X(w)\leq x,\ Y(w)\leq y\}.
\end{array}
\]</span></p>
</div>
<div id="propiedades-4" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Propiedades</h3>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable bidimensional. y sea <span class="math inline">\(F_{XY}\)</span> su <strong>función de distribución conjunta</strong>. Dicha función satisface las propiedades siguientes:</p>
<ul>
<li><p>La función de distribución conjunta es no decreciente en cada una de las variables:
<span class="math display">\[
\mbox{Si }x_1\leq x_2, \mbox{ y }y_1\leq y_2,\mbox{ entonces, }F_{XY}(x_1,y_1)\leq F_{XY}(x_2,y_2).
\]</span></p></li>
<li><p><span class="math inline">\(F_{XY}(x,-\infty)=F_{XY}(-\infty,y)=0,\)</span> <span class="math inline">\(F_{XY}(\infty,\infty)=1\)</span>, para todo <span class="math inline">\(x,y\in\mathbb{R}\)</span>.</p></li>
<li><p>Las variables aleatorias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> se llaman <strong>variables aleatorias marginales</strong> y sus funciones de distribución <span class="math inline">\(F_X\)</span> y <span class="math inline">\(F_Y\)</span> pueden hallarse de la forma siguiente como función de la <strong>función de distribución conjunta</strong> <span class="math inline">\(F_{XY}\)</span>:
<span class="math display">\[
F_X(x)=F_{XY}(x,\infty),\ F_Y(y)=F_{XY}(\infty,y),
\]</span>
para todo <span class="math inline">\(x,y\in\mathbb{R}\)</span>.</p></li>
<li>La función de distribución conjunta es continua por el “<em>norte</em>” y por el “<em>este</em>”:
<span class="math display">\[
\begin{array}{rl}
\lim_{x\to a^+}F_{XY}(x,y) &amp; =\lim_{x\to a, x&gt; a}F_{XY}(x,y)=F_{XY}(a,y), \\
\lim_{y\to b^+}F_{XY}(x,y) &amp; =\lim_{y\to b, y&gt; b}F_{XY}(x,y)=F_{XY}(x,b),
\end{array}
\]</span>
para todo <span class="math inline">\(a,b\in\mathbb{R}\)</span>. Ver la siguiente figura.
<div class="center">

</li>
</ul>
<div class="figure"><span id="fig:bid5"></span>
<img src="Images/Fxy2.png" alt="Función de distribución conjunta"  />
<p class="caption">
Figure 5.2: Función de distribución conjunta
</p>
</div>
</div>
<ul>
<li>Dados <span class="math inline">\(x_1&lt;x_2\)</span> y <span class="math inline">\(y_1&lt;y_2\)</span>, consideramos <span class="math inline">\(B\)</span> el rectángulo de vértices <span class="math inline">\((x_1,y_1)\)</span>, <span class="math inline">\((x_1,y_2)\)</span>, <span class="math inline">\((x_2,y_1)\)</span> y <span class="math inline">\((x_2,y_2)\)</span>: <span class="math inline">\((x_1,x_2]\times (y_1,y_2]\)</span>. Entonces,
<span class="math display">\[
\begin{array}{rl}
P((X,Y)\in B)  = &amp; F_{XY}(x_2,y_2)-F_{XY}(x_2,y_1)-F_{XY}(x_1,y_2)\\ &amp; +F_{XY}(x_1,y_1).
\end{array}
\]</span></li>
</ul>
<div class="center">
<p><img src="Images/Fxy3.png" /><!-- --></p>
</div>
<div class="example">
<p><strong>Ejemplo: Función de distribución uniforme</strong></p>
<p>Consideremos una variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> con <strong>función de distribución conjunta</strong>:
<span class="math display">\[
F_{XY}(x,y)=\begin{cases}
0, &amp; \mbox{si }x&lt;0,\mbox{ o }y&lt;0,\\
xy, &amp; \mbox{si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
x, &amp; \mbox{si }0\leq x\leq 1,\ y&gt; 1, \\
y, &amp; \mbox{si }0\leq y\leq 1,\ x&gt; 1, \\
1, &amp; x\geq 1,\ y\geq 1.
\end{cases}
\]</span>
En la figura siguiente, hemos representado por zonas cómo está definida <span class="math inline">\(F_{XY}\)</span>.</p>
<div class="center">
<div class="figure"><span id="fig:bid7"></span>
<img src="Images/FxyEx.png" alt="Funciń de distribución uniforme bidimensional."  />
<p class="caption">
Figure 5.3: Funciń de distribución uniforme bidimensional.
</p>
</div>
<p>Comprobemos algunas de las propiedades que hemos enunciado anteriormente:</p>
</div>
<div class="example-sol">
<ul>
<li><p>Claramente <span class="math inline">\(F_{XY}(x,-\infty)=F_{XY}(-\infty,y)=0\)</span> ya que <span class="math inline">\(F_{XY}(x,y)=0\)</span> si <span class="math inline">\(x&lt;0\)</span> o <span class="math inline">\(y&lt;0\)</span>. Por tanto, si hacemos tender <span class="math inline">\(x\)</span> o <span class="math inline">\(y\)</span> hacia <span class="math inline">\(-\infty\)</span>, obtendremos que <span class="math inline">\(F_{XY}(x,-\infty)=F_{XY}(-\infty,y)=0\)</span>.</p></li>
<li><p>De la misma manera <span class="math inline">\(F_{XY}(\infty,\infty)=1\)</span> ya que <span class="math inline">\(F_{XY}(x,y)=1\)</span> para <span class="math inline">\(x&gt;1\)</span> e <span class="math inline">\(y&gt;1\)</span>. Por tanto, si hacemos tender <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> hacia <span class="math inline">\(\infty\)</span>, obtendremos <span class="math inline">\(F_{XY}(\infty,\infty)=1\)</span>.</p></li>
<li><p>Hallemos las marginales:
<span class="math display">\[
F_X(x)=F_{XY}(x,\infty)=\begin{cases}
0, &amp; \mbox{ si }x&lt;0,\\
x, &amp; \mbox{ si } 0\leq x\leq 1,\\
1, &amp; \mbox{ si } x&gt;1.
\end{cases}
\]</span>
Para ver la expresión anterior basta trazar la recta vertical <span class="math inline">\(X=x\)</span> en el gráfico anterior y ver hacia dónde tiende a medida que la <span class="math inline">\(y\)</span> se va hacia <span class="math inline">\(\infty\)</span>.</p></li>
</ul>
<p>¿Habéis averiguado cuál es la distribución de <span class="math inline">\(X\)</span>?</p>
<p>¡Efectivamente!, <span class="math inline">\(X\)</span> es la uniforme en el intervalo <span class="math inline">\((0,1)\)</span>.</p>
<p>Dejamos como ejercicio hallar la distribución marginal para la variable <span class="math inline">\(Y\)</span>.</p>
<ul>
<li>Comprobemos que <span class="math inline">\(F_{XY}\)</span> es continua por el “norte” y el “este” en el punto <span class="math inline">\((1,1)\)</span> que es un punto problemático:
<span class="math display">\[
\lim_{x\to 1,x&gt; 1} F_{XY}(x,1)=\lim_{x\to 1,x&gt; 1} 1  = F_{XY}(1,1),
\]</span></li>
</ul>
<p><span class="math display">\[
\lim_{y\to 1,y&gt; 1} F_{XY}(1,y)=\lim_{y\to 1,y&gt; 1} 1  = F_{XY}(1,1).
\]</span></p>
<p>Representemos en un gráfico tridimensional la <strong>función de distribución conjunta</strong> usando la función <code>persp</code> de <code>R</code> para <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> entre -2 y 2.</p>
<p>Primero definimos la <strong>función</strong> y luego la dibujamos:</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb364-1" data-line-number="1">f.dist.con =<span class="st"> </span><span class="cf">function</span>(x,y){<span class="kw">ifelse</span>(x<span class="op">&lt;</span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span>y<span class="op">&lt;</span><span class="dv">0</span>,<span class="dv">0</span>,</a>
<a class="sourceLine" id="cb364-2" data-line-number="2">                           <span class="kw">ifelse</span>(x<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>y<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>y<span class="op">&lt;=</span><span class="dv">1</span>,x<span class="op">*</span>y,</a>
<a class="sourceLine" id="cb364-3" data-line-number="3">                           <span class="kw">ifelse</span>(x<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>y <span class="op">&gt;</span><span class="dv">1</span>,x,<span class="kw">ifelse</span>(y<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>y<span class="op">&lt;=</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&gt;</span><span class="dv">1</span>,y,<span class="dv">1</span>))))}</a>
<a class="sourceLine" id="cb364-4" data-line-number="4">x=<span class="kw">seq</span>(<span class="dt">from=</span><span class="op">-</span><span class="dv">2</span>,<span class="dt">to=</span><span class="dv">2</span>,<span class="dt">by=</span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb364-5" data-line-number="5">y=<span class="kw">seq</span>(<span class="dt">from=</span><span class="op">-</span><span class="dv">2</span>,<span class="dt">to=</span><span class="dv">2</span>,<span class="dt">by=</span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb364-6" data-line-number="6">z=<span class="kw">outer</span>(x,y,f.dist.con)</a>
<a class="sourceLine" id="cb364-7" data-line-number="7"><span class="kw">persp</span>(x,y,z,<span class="dt">theta=</span><span class="dv">50</span>,<span class="dt">phi=</span><span class="dv">40</span>,<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,<span class="dt">shade=</span><span class="fl">0.25</span>,<span class="dt">ticktype=</span><span class="st">&quot;detailed&quot;</span>)</a></code></pre></div>
<p><img src="curso-probabilidad-udemy_files/figure-html/unnamed-chunk-117-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: dos lanzamientos de un dado no trucado</strong></p>
<p>Consideremos el experimento aleatorio de lanzar dos veces un dado no trucado.</p>
<p>Sea <span class="math inline">\((S,P)\)</span> la <strong>variable aleatoria bidimensional</strong> que nos da la suma y el producto de los resultados obtenidos, respectivamente.</p>
<div class="example-sol">
<p>La <strong>función de distribución conjunta</strong> en el valor <span class="math inline">\((3,4)\)</span> es:
<span class="math display">\[
F_{XY}(3,4) = P(S\leq 3,\ P\leq 4)=P\{(1,1), (1,2), (2,1) \}=\frac{3}{36}=\frac{1}{12}\approx 0.083, 
\]</span>
ya que <span class="math inline">\(\Omega\)</span> tiene en total <span class="math inline">\(36\)</span> resultados:
<span class="math display">\[
\Omega =\{(1,1),(1,2).\ldots, (6,6)\}.
\]</span>
y los únicos resultados en los que la suma es menor o igual que 3 y el producto menor o igual que 4 son <span class="math inline">\((1,1)\)</span> (suma 2 producto 1), <span class="math inline">\((1,2)\)</span> (suma 3 y producto 2) y <span class="math inline">\((2,1)\)</span> (suma 3 y producto 2).</p>
</div>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Hallar el valor de la <strong>función de distribución conjunta</strong> para la <strong>variable aleatoria bidimensional</strong> anterior <span class="math inline">\((S,P)\)</span> en los valores <span class="math inline">\((i,j)\)</span> siguientes: <span class="math inline">\((4,5),\ (4,9),\ (5,9),\ (6,10)\)</span>.</p>
</div>
</div>
</div>
<div id="variables-aleatorias-bidimensionales-discretas" class="section level2">
<h2><span class="header-section-number">5.3</span> Variables aleatorias bidimensionales discretas</h2>
<p><l class="definition">Definición de variable aleatoria bidimensional discreta:</l>
Sea <span class="math inline">\((X,Y)\)</span> una <strong>variable aleatoria bidimensional</strong>. Diremos
que es discreta cuando su conjunto de valores en <span class="math inline">\(\mathbb{R}^2\)</span>, <span class="math inline">\((X,Y)(\Omega)\)</span> es un conjunto finito o numerable.</p>
<p>En la mayoría de los casos, dicho conjunto es un subconjunto de los enteros naturales.</p>
<div class="example">
<p><strong>Ejemplo: lanzamiento de dos dados (continuación)</strong></p>
<p>La variable aleatoria bidimensional anterior que nos daba la suma y el producto de los resultados obtenidos por los dos lanzamientos, respectivamente es discreta ya que:
<span class="math display">\[
\begin{array}{rl}
(S,P)(\Omega) =&amp;\{(2,1),(3,2),(4,3),(4,4),(5,4),(5,6),(6,5),(6,8),(6,9),(7,6),\\ &amp; 
(7,10),(7,12),(8,12), (8,15),(8,16),(9,18),(9,20),(10,24),\\ &amp; (10,25),(11,30), (12,36)\}.
\end{array}
\]</span></p>
<p>Comprobar que el conjunto <span class="math inline">\((S,P)(\Omega)\)</span> dado por el ejemplo coincide con la expresión dada.
O lo que es lo mismo, hallar el conjunto <span class="math inline">\((S,P)(\Omega)\)</span>:</p>
<div class="example-sol">
<p><span class="math display">\[
\begin{array}{rl}
(S,P): \Omega &amp; \longrightarrow \mathbb{R}^2\\
(1,1) &amp; \longrightarrow (S(1,1),P(1,1))=(2,1),\\
(1,2) &amp; \longrightarrow (S(1,2),P(1,2))=(3,2),\\
\vdots &amp; \vdots \\
(6,6) &amp; \longrightarrow (S(6,6),P(6,6))=(12,36).
\end{array}
\]</span></p>
</div>
</div>
<div id="función-de-probabilidad-conjunta" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Función de probabilidad conjunta</h3>
<p><l class="definition">Definición de función de probabilidad conjunta:</l>
Dada una <strong>variable aleatoria bidimensional discreta</strong> <span class="math inline">\((X,Y)\)</span> con <span class="math inline">\((X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,\ j=1,2,\ldots,\}\)</span>, definimos la función de probabilidad discreta <span class="math inline">\(P_{XY}\)</span> para un valor <span class="math inline">\((x,y)\in\mathbb{R}^2\)</span> de la siguiente forma:</p>
<p><span class="math display">\[
\begin{array}{rl}
P_{XY}: \mathbb{R}^2 &amp; \longrightarrow \mathbb{R}\\
(x,y) &amp; \longrightarrow P_{XY}(x,y)=P(X= x,\ Y= y).
\end{array}
\]</span></p>
<p><l class="observ">Observación:</l>
Si <span class="math inline">\((x,y)\not\in (X,Y)(\Omega)\)</span>, el valor de la <strong>función de probabilidad conjunta</strong> en <span class="math inline">\((x,y)\)</span> es nula: <span class="math inline">\(P_{XY}(x,y)=0\)</span>. El motivo es que, en este caso, el conjunto <span class="math inline">\(\{w\in\Omega,\ | (X(w),Y(w))=(x,y)\}=\emptyset\)</span> es vacío pues <span class="math inline">\((x,y)\not\in (X,Y)(\Omega)\)</span>.</p>
<div class="example">
<p><strong>Ejemplo: lanzamiento de dos dados (continuación)</strong>
Por tanto, de cara a calcular <span class="math inline">\(P_{XY}\)</span> basta conocer los valores de <span class="math inline">\(P_{XY}(x_i,y_j)\)</span> para <span class="math inline">\((x_i,y_j)\in (X,Y)(\Omega)\)</span>:</p>
<div class="example-sol">
<div class="center">
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(X/Y\)</span></th>
<th><span class="math inline">\(y_1\)</span></th>
<th><span class="math inline">\(y_2\)</span></th>
<th><span class="math inline">\(\ldots\)</span></th>
<th><span class="math inline">\(y_N\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x_1\)</span></td>
<td><span class="math inline">\(P_{XY}(x_1,y_1)\)</span></td>
<td><span class="math inline">\(P_{XY}(x_1,y_2)\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(P_{XY}(x_1,y_N)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_2\)</span></td>
<td><span class="math inline">\(P_{XY}(x_2,y_1)\)</span></td>
<td><span class="math inline">\(P_{XY}(x_2,y_2)\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(P_{XY}(x_2,y_N)\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_M\)</span></td>
<td><span class="math inline">\(P_{XY}(x_M,y_1)\)</span></td>
<td><span class="math inline">\(P_{XY}(x_M,y_2)\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(P_{XY}(x_M,y_N)\)</span></td>
</tr>
</tbody>
</table>
</div>
La <strong>función de probabilidad conjunta</strong> es:
<div class="center">
<!--| $S/P$| 1 | 2| 3 | 4 | 5| 6 | 8| 9| 10 | 12 | 15 | 16 | 18 | 20 | 24 | 25 | 30 | 36 
|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--
| 2   |$\frac{1}{36}$|0 |0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0
| 3   | 0 | $\frac{2}{36}$ |0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0
| 4   | 0 | 0 | $\frac{2}{36}$ | $\frac{1}{36}$ | 0|0|0|0|0|0|0|0|0|0|0|0|0|0
| 5   | 0 | 0 | 0 | $\frac{2}{36}$ | 0 | $\frac{2}{36}$ | 0|0|0|0|0|0|0|0|0|0|0|0
| 6   | 0 | 0 | 0 | 0 | $\frac{2}{36}$ | 0 | $\frac{2}{36}$ |$\frac{1}{36}$|0|0|0|0|0|0|0|0|0|0
| 7 | 0 |0|0|0|0|$\frac{2}{36}$|0|0|$\frac{2}{36}$|$\frac{2}{36}$|0|0|0|0|0|0|0|0
|8  |0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|$\frac{2}{36}$|$\frac{1}{36}$|0|0|0|0|0|0
|9 |0|0|0|0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|$\frac{2}{36}$|0|0|0|0
| 10 | 0|0|0|0|0|0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|$\frac{1}{36}$|0|0
| 11 | 0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|0
| 12 |  0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|$\frac{1}{36}$-->
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(P/S\)</span></th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>2</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>6</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>9</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>10</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>12</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>15</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>16</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>18</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>20</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>24</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>25</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>30</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
</tr>
<tr class="even">
<td>36</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Vamos a definir unas funciones en <code>R</code> para calcular la <strong>función de probabilidad conjunta</strong>.</p>
<p>La función <code>pdado</code> devuelve la probabilidad de que salga la cara <code>x</code> en un dado de <code>n</code> caras donde por defecto <span class="math inline">\(n=6\)</span>:</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" data-line-number="1">pdado =<span class="cf">function</span>(x,<span class="dt">n=</span><span class="dv">6</span>)  <span class="kw">sapply</span>(x,<span class="dt">FUN=</span><span class="cf">function</span>(x) </a>
<a class="sourceLine" id="cb365-2" data-line-number="2">  <span class="cf">if</span>( x <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>n))  {<span class="kw">return</span>(<span class="dv">1</span><span class="op">/</span>n)} <span class="cf">else</span> {<span class="kw">return</span>(<span class="dv">0</span>)})</a></code></pre></div>
<p>Vamos a probarla. La probabilidad de que salga la cara 4 en un dado de 6 caras vale:</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb366-1" data-line-number="1"><span class="kw">pdado</span>(<span class="dv">4</span>,<span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.1666667</code></pre>
<p>La función <code>pdado2</code> devuelve la probabilidad de que salgan las caras <code>x</code> e <code>y</code> cuando lanzamos un dado de <code>n</code> caras dos veces:</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb368-1" data-line-number="1">pdado2 =<span class="cf">function</span>(x,y,<span class="dt">n=</span><span class="dv">6</span>) {<span class="kw">pdado</span>(x,n)<span class="op">*</span><span class="kw">pdado</span>(y,n)}</a></code></pre></div>
<p>Por ejemplo la probabilidad de que salgan las caras 3 y 4 en un dado de 6 caras es:</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb369-1" data-line-number="1"><span class="kw">pdado2</span>(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0.02777778</code></pre>
<p>La función <code>psum_prod</code> nos da la <strong>función de probabilidad conjunta</strong> de la suma y el producto cuando lanzamos dos dados de <code>n</code> caras:</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb371-1" data-line-number="1">psum_prod=<span class="cf">function</span>(x,y,<span class="dt">n=</span><span class="dv">6</span>){</a>
<a class="sourceLine" id="cb371-2" data-line-number="2">  Dxy=<span class="kw">data.frame</span>(<span class="dt">d1=</span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n,<span class="dt">each=</span>n),<span class="dt">d2=</span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n,<span class="dt">times=</span>n))</a>
<a class="sourceLine" id="cb371-3" data-line-number="3">  Dxy<span class="op">$</span>suma=Dxy<span class="op">$</span>d1<span class="op">+</span>Dxy<span class="op">$</span>d2</a>
<a class="sourceLine" id="cb371-4" data-line-number="4">  Dxy<span class="op">$</span>producto=Dxy<span class="op">$</span>d1<span class="op">*</span>Dxy<span class="op">$</span>d2</a>
<a class="sourceLine" id="cb371-5" data-line-number="5">  aux=Dxy[Dxy<span class="op">$</span>suma<span class="op">==</span>x<span class="op">&amp;</span><span class="st"> </span>Dxy<span class="op">$</span>producto<span class="op">==</span>y,]</a>
<a class="sourceLine" id="cb371-6" data-line-number="6">  <span class="kw">sum</span>(<span class="kw">apply</span>(aux[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],<span class="dt">FUN=</span><span class="cf">function</span>(x) {<span class="kw">pdado2</span>(x[<span class="dv">1</span>],x[<span class="dv">2</span>],<span class="dt">n=</span>n)},<span class="dv">1</span> ))</a>
<a class="sourceLine" id="cb371-7" data-line-number="7">}</a></code></pre></div>
<p>Por ejemplo, sabemos que <span class="math inline">\(P_{SP}(6,8)=\frac{2}{36}=0.0556\)</span>:</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb372-1" data-line-number="1"><span class="kw">psum_prod</span>(<span class="dv">6</span>,<span class="dv">8</span>)</a></code></pre></div>
<pre><code>## [1] 0.05555556</code></pre>
<p>la tabla de la <strong>función de probabilidad conjunta</strong> para la variable <span class="math inline">\((S,P)\)</span> hacemos lo siguiente:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb374-1" data-line-number="1">n=<span class="dv">6</span></a>
<a class="sourceLine" id="cb374-2" data-line-number="2">Dxy=<span class="kw">data.frame</span>(<span class="dt">d1=</span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n,<span class="dt">each=</span>n),<span class="dt">d2=</span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n,<span class="dt">times=</span>n))</a>
<a class="sourceLine" id="cb374-3" data-line-number="3">Dxy<span class="op">$</span>suma=Dxy<span class="op">$</span>d1<span class="op">+</span>Dxy<span class="op">$</span>d2</a>
<a class="sourceLine" id="cb374-4" data-line-number="4">Dxy<span class="op">$</span>producto=Dxy<span class="op">$</span>d1<span class="op">*</span>Dxy<span class="op">$</span>d2</a>
<a class="sourceLine" id="cb374-5" data-line-number="5">tabla.func.prob.conjunta=<span class="kw">prop.table</span>(<span class="kw">table</span>(Dxy<span class="op">$</span>suma,Dxy<span class="op">$</span>producto))</a>
<a class="sourceLine" id="cb374-6" data-line-number="6">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">round</span>(tabla.func.prob.conjunta[,<span class="dv">1</span><span class="op">:</span><span class="dv">9</span>],<span class="dv">3</span>))</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
<th align="right">6</th>
<th align="right">8</th>
<th align="right">9</th>
<th align="right">10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td align="right">0.028</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>3</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.028</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>5</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>6</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.028</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>7</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
</tr>
<tr class="odd">
<td>8</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>9</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>10</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>11</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb375-1" data-line-number="1">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">round</span>(tabla.func.prob.conjunta[,<span class="dv">10</span><span class="op">:</span><span class="dv">18</span>],<span class="dv">3</span>))</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">12</th>
<th align="right">15</th>
<th align="right">16</th>
<th align="right">18</th>
<th align="right">20</th>
<th align="right">24</th>
<th align="right">25</th>
<th align="right">30</th>
<th align="right">36</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>3</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>5</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>6</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>7</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>8</td>
<td align="right">0.056</td>
<td align="right">0.056</td>
<td align="right">0.028</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>9</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>10</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.028</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td>11</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.056</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.028</td>
</tr>
</tbody>
</table>
<p>lo cual finaliza nuestros cálculos en <code>R</code>.</p>
</div>
</div>
<div id="propiedades-de-la-función-de-probabilidad-conjunta" class="section level4">
<h4><span class="header-section-number">5.3.1.1</span> Propiedades de la función de probabilidad conjunta</h4>
<p>Sea <span class="math inline">\((X,Y)\)</span> una <strong>variable aleatoria bidimensional discreta</strong> con conjunto de valores <span class="math inline">\((X,Y)(\Omega)=\{(x_i,y_j)\, i=1,2,\ldots,\ j=1,2,\ldots\}\)</span>. Entonces su <strong>función de probabilidad conjunta</strong> verifica las propiedades siguientes:</p>
<p>La suma de todos los valores de la <strong>función de probabilidad conjunta</strong> sobre el conjunto de valores siempre vale 1: <span class="math display">\[\sum_{i}\sum_j P_{XY}(x_i,y_j)=1.\]</span></p>
<p>Sea <span class="math inline">\(B\)</span> una región del plano. El valor de la probabilidad <span class="math inline">\(P((X,Y)\in B)\)</span> se puede calcular de la forma siguiente:</p>
<p><span class="math display">\[
P((X,Y)\in B) =\sum_{(x_i,y_j)\in B} P_{XY}(x_i,y_j).
\]</span></p>
<p>Es decir, la probabilidad de que la variable bidimensional tome valores en <span class="math inline">\(B\)</span> es igual a la suma de todos aquellos valores de la función de probabilidad conjunta que están en <span class="math inline">\(B\)</span>.</p>
<p>En particular, tenemos la sigueinte propiedad que relaciona la <strong>función de distribución conjunta</strong> con la <strong>función de probabilidad conjunta</strong>:</p>
<p><span class="math display">\[
F_{XY}(x,y)=\sum_{x_i\leq x, y_j\leq y} P_{XY}(x_i,y_j).
\]</span>
Dicha expresión se deduce de la expresión anterior considerando <span class="math inline">\(B=(-\infty,x]\times (-\infty,y]\)</span>.</p>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>En el ejemplo del lanzamiento de los dos dados. Comprobad usando la tabla de la función de probabilidad conjunta que la suma de todos sus valores suma 1.</p>
</div>
<div class="example">
<p><strong>Ejemplo: lanzamientos de dados (continuación)</strong></p>
<p>Apliquemos la fórmula que relaciona la función de distribución conjunta con la función de probabilidad conjunta para <span class="math inline">\((x,y)=(5,4)\)</span>.</p>
<div class="example-sol">
<p>Recordemos la tabla de la función de probabilidad conjunta hasta <span class="math inline">\(S=5\)</span> y <span class="math inline">\(P=4\)</span>:</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(S/P\)</span></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\ldots\)</span></td>
</tr>
<tr class="even">
<td>3</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\ldots\)</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
</tr>
<tr class="even">
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Observamos que los únicos valores <span class="math inline">\((x_i,y_j)\in (X,Y)(\Omega)\)</span> que verifican <span class="math inline">\(x_i\leq 5\)</span> y <span class="math inline">\(y_j\leq 4\)</span> son <span class="math inline">\((2,1)\)</span>, <span class="math inline">\((3,2)\)</span>, <span class="math inline">\((4,3)\)</span>, <span class="math inline">\((4,4)\)</span> y <span class="math inline">\((5,4)\)</span>. Por tanto,</p>
<p><span class="math display">\[
\begin{array}{rl}
F_{SP}(5,4) &amp;= P_{SP}(2,1)+P_{SP}(3,2)+P_{SP}(4,3)+P_{SP}(4,4)+P_{SP}(5,4) \\ &amp; = \frac{1}{36}+\frac{2}{36}+\frac{2}{36}+\frac{1}{36}+\frac{2}{36} = \frac{8}{36}=\frac{2}{9}.
\end{array}
\]</span>
Es decir, “a largo plazo”, de cada 9 ocasiones que lanzamos un dado dos veces; en 2 ocasiones obtenemos un resultado cuya suma es menor o igual que 5 y cuyo producto es menor o igual que 4.</p>
<p>Para definir la <strong>función de distribución conjunta</strong> definimos la función siguiente en <code>R</code>:</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb376-1" data-line-number="1">func.dist.conj =<span class="st"> </span><span class="cf">function</span>(x,y,<span class="dt">n=</span><span class="dv">6</span>){</a>
<a class="sourceLine" id="cb376-2" data-line-number="2">  <span class="kw">sum</span>(tabla.func.prob.conjunta[<span class="kw">as.integer</span>(<span class="kw">rownames</span>(tabla.func.prob.conjunta))<span class="op">&lt;=</span>x,</a>
<a class="sourceLine" id="cb376-3" data-line-number="3">                            <span class="kw">as.integer</span>(<span class="kw">colnames</span>(tabla.func.prob.conjunta)) <span class="op">&lt;=</span>y])</a>
<a class="sourceLine" id="cb376-4" data-line-number="4">}</a></code></pre></div>
<p>Comprobemos que <span class="math inline">\(F_{SP}(5,4)=\frac{2}{9}=0.2222\)</span>:</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb377-1" data-line-number="1"><span class="kw">func.dist.conj</span>(<span class="dv">5</span>,<span class="dv">4</span>)</a></code></pre></div>
<pre><code>## [1] 0.2222222</code></pre>
</div>
</div>
</div>
</div>
<div id="distribuciones-marginales" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Distribuciones marginales</h3>
<p>Consideremos una variable aleatoria <strong>bidimensional discreta <span class="math inline">\((X,Y)\)</span></strong> con <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}(x_i,y_j)\)</span>, con <span class="math inline">\((x_i,y_j)\in (X,Y)(\Omega)\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span>, <span class="math inline">\(j=1,2,\ldots\)</span>.</p>
<p>La tabla de la <strong>función de probabilidad conjunta</strong> contiene suficiente información para obtener las <strong>funciones de probabilidad</strong> de las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
<p>Dichas variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> se denominan <strong>distribuciones marginales</strong> y sus correspondientes <strong>funciones de probabilidad</strong>, <strong>funciones de probabilidad marginales</strong> <span class="math inline">\(P_X\)</span> de la variable <span class="math inline">\(X\)</span> y <span class="math inline">\(P_Y\)</span> de la variable <span class="math inline">\(Y\)</span>.</p>
<p>Veamos cómo obtener <span class="math inline">\(P_X\)</span> y <span class="math inline">\(P_Y\)</span> a partir de la tabla <span class="math inline">\(P_{XY}\)</span>.</p>
<p><l class="prop">Proposición. Expresión de las funciones de probabilidad marginales. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria <strong>bidimensional discreta</strong> con <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}(x_i,y_j)\)</span>, con <span class="math inline">\((x_i,y_j)\in (X,Y)(\Omega)\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span>, <span class="math inline">\(j=1,2,\ldots\)</span>.</p>
<p>Las <strong>funciones de probabilidad marginales</strong> <span class="math inline">\(P_X(x_i)\)</span> y <span class="math inline">\(P_Y(y_j)\)</span> se calculan usando las expresiones siguientes:</p>
<p><span class="math display">\[
\begin{array}{rl}
P_X(x_i)  &amp; = \sum_{j=1} P_{XY}(x_i,y_j),\  i=1,2,\ldots,\\ P_Y(y_j) &amp;  = \sum_{i=1} P_{XY}(x_i,y_j),\ \ j=1,2,\ldots
\end{array}
\]</span></p>
<p>Si consideramos la funciòn <span class="math inline">\(P_{XY}\)</span> como una tabla bidimensional en la que en la primera fila están los valores de la variable <span class="math inline">\(Y\)</span> (<span class="math inline">\(y_1,y_2,\ldots\)</span>) y en la primera columna están los valores de la variable <span class="math inline">\(X\)</span> (<span class="math inline">\(x_1,x_2,\ldots\)</span>). Para obtener la <strong>función de probabilidad marginal</strong> de la variable <span class="math inline">\(X\)</span> en el valor <span class="math inline">\(x_i\)</span>, <span class="math inline">\(P_X(x_i)\)</span>, hay que sumar todos los valores de <span class="math inline">\(P_{XY}(x_i,y_j)\)</span> correspondientes a la fila <span class="math inline">\(i\)</span>-ésima y para obtener la <strong>función de probabilidad marginal</strong> de la variable <span class="math inline">\(Y\)</span> en el valor <span class="math inline">\(y_j\)</span>, <span class="math inline">\(P_Y(y_j)\)</span>, hay que sumar todos los valores de <span class="math inline">\(P_{XY}(x_i,y_j)\)</span> correspondientes a la columna <span class="math inline">\(j\)</span>-ésima.</p>
<div id="ejemplo" class="section level4">
<h4><span class="header-section-number">5.3.2.1</span> Ejemplo</h4>
<div class="example">
<p><strong>Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado</strong></p>
<p>Hallemos la función de probabilidad marginal para la suma de los resultados <span class="math inline">\(S\)</span>:</p>
<div class="example-sol">
<p>Usando la expresión de la probabilidad marginal tenemos que</p>
<p><span class="math display">\[
\begin{array}{rl}
P_S(2) &amp; = P_{SP}(2,1)=\frac{1}{36},\\
P_S(3) &amp; = P_{SP}(3,2)=\frac{2}{36},\\
P_S(4) &amp; = P_{SP}(4,3)+P_{SP}(4,4)=\frac{2}{36}+\frac{1}{36}=\frac{3}{36}=\frac{1}{12},\\
P_S(5) &amp; = P_{SP}(5,4)+P_{SP}(5,6)=\frac{2}{36}+\frac{2}{36}=\frac{4}{36}=\frac{1}{9},\\
P_S(6) &amp; = P_{SP}(6,5)+P_{SP}(6,8)+P_{SP}(6,9)=\frac{2}{36}+\frac{2}{36}+\frac{1}{36}=\frac{5}{36},\\
P_S(7) &amp; = P_{SP}(7,6)+P_{SP}(7,10)+P_{SP}(7,12)=\frac{2}{36}+\frac{2}{36}+\frac{2}{36}=\frac{6}{36}=\frac{1}{6},\\
P_S(8) &amp; = P_{SP}(8,12)+P_{SP}(8,15)+P_{SP}(8,16)=\frac{2}{36}+\frac{2}{36}+\frac{1}{36}=\frac{5}{36},\\
P_S(9) &amp; = P_{SP}(9,18)+P_{SP}(9,20)=\frac{2}{36}+\frac{2}{36}=\frac{4}{36}=\frac{1}{9},\\
P_S(10) &amp; = P_{SP}(10,24)+P_{SP}(10,25)=\frac{2}{36}+\frac{1}{36}=\frac{3}{36}=\frac{1}{12},\\
P_S(11) &amp; = P_{SP}(11,30)=\frac{2}{36},\\
P_S(12) &amp; = P_{SP}(12,36)=\frac{1}{36}.
\end{array}
\]</span></p>
<p>La <strong>función de probabilidad marginal</strong> de la suma <span class="math inline">\(S\)</span> queda resumida en la tabla siguiente:</p>
<div class="center">
<table>
<colgroup>
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(S\)</span></th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P_S\)</span></td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\frac{3}{36}\)</span></td>
<td><span class="math inline">\(\frac{4}{36}\)</span></td>
<td><span class="math inline">\(\frac{5}{36}\)</span></td>
<td><span class="math inline">\(\frac{6}{36}\)</span></td>
<td><span class="math inline">\(\frac{5}{36}\)</span></td>
<td><span class="math inline">\(\frac{4}{36}\)</span></td>
<td><span class="math inline">\(\frac{3}{36}\)</span></td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Para hallar la <strong>función de probabilidad marginal</strong> de la suma basta sumar las filas de la tabla que nos daba la <strong>función de probabilidad conjunta</strong>:</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb379-1" data-line-number="1">marginal.suma =<span class="st"> </span><span class="kw">apply</span>(tabla.func.prob.conjunta,<span class="dv">1</span>,sum)</a>
<a class="sourceLine" id="cb379-2" data-line-number="2">marginal.suma</a></code></pre></div>
<pre><code>##          2          3          4          5          6          7          8 
## 0.02777778 0.05555556 0.08333333 0.11111111 0.13888889 0.16666667 0.13888889 
##          9         10         11         12 
## 0.11111111 0.08333333 0.05555556 0.02777778</code></pre>
<p>De la misma manera, para hallar la <strong>función de probabilidad marginal</strong> del producto basta sumar las columnas de la tabla anterior:</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb381-1" data-line-number="1">marginal.producto =<span class="st"> </span><span class="kw">apply</span>(tabla.func.prob.conjunta,<span class="dv">2</span>,sum)</a>
<a class="sourceLine" id="cb381-2" data-line-number="2">marginal.producto</a></code></pre></div>
<pre><code>##          1          2          3          4          5          6          8 
## 0.02777778 0.05555556 0.05555556 0.08333333 0.05555556 0.11111111 0.05555556 
##          9         10         12         15         16         18         20 
## 0.02777778 0.05555556 0.11111111 0.05555556 0.02777778 0.05555556 0.05555556 
##         24         25         30         36 
## 0.05555556 0.02777778 0.05555556 0.02777778</code></pre>
</div>
</div>
</div>
</div>
</div>
<div id="variables-aleatorias-bidimensionales-continuas" class="section level2">
<h2><span class="header-section-number">5.4</span> Variables aleatorias bidimensionales continuas</h2>
<div id="definición-2" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Definición</h3>
<p>Recordemos la definición de <strong>variable continua unidimensional</strong>: <span class="math inline">\(X\)</span> es continua si existe una función <span class="math inline">\(f_X:\mathbb{R}\longrightarrow \mathbb{R}\)</span>, llamada <strong>función de densidad</strong> no negativa <span class="math inline">\(f_X(x)\geq 0\)</span>, para todo <span class="math inline">\(x\in\mathbb{R}\)</span> tal que para cualquier intervalo <span class="math inline">\((a,b)\)</span>, la probabilidad de que <span class="math inline">\(X\)</span> esté en <span class="math inline">\((a,b)\)</span> se calcula de la forma siguiente:</p>
<p><span class="math display">\[
P(X\in B)=P(a&lt; X &lt; b)=\int_B f_{X}(x)\,du=\int_a^b f_{X}(x)\,dx.
\]</span></p>
<p>La generalización natural es, entonces:</p>
<p><l class="definition">Definición de variable aleatoria bidimensional continua. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Diremos que <span class="math inline">\((X,Y)\)</span> es continua si existe una función
<span class="math inline">\(f_{XY}:\mathbb{R}^2\longrightarrow \mathbb{R}\)</span> llamada <strong>función de densidad</strong> no negativa <span class="math inline">\(f_{XY}(x,y)\geq 0\)</span> para todo <span class="math inline">\((x,y)\in\mathbb{R}^2\)</span> tal que dado cualquier región <span class="math inline">\(B\)</span> del plano, la probabilidad de que <span class="math inline">\((X,Y)\)</span> esté en <span class="math inline">\(B\)</span> se calcula de la forma siguiente:
<span class="math display">\[
P((X,Y)\in B)=\int\int_B f_{XY}(x,y)\,dx\,dy.
\]</span></p>
<div id="ejemplos" class="section level4">
<h4><span class="header-section-number">5.4.1.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: cálculo probabilidad distribución bidimensional</strong></p>
<p>Consideremos la siguiente <strong>función de densidad</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
1, &amp; \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
En este caso, si consideramos <span class="math inline">\(B=\left[-1,\frac{1}{2}\right]\times \left[-1,\frac{1}{2}\right]\)</span>, la probabilidad de que <span class="math inline">\((X,Y)\)</span> esté en <span class="math inline">\(B\)</span> se calcularía de la forma siguiente:</p>
<div class="example-sol">
<p><span class="math display">\[
\begin{array}{rl}
P((X,Y)\in B)&amp;=\int\int_{B} f_{XY}(x,y)\, dx\, dy=\int_{-1}^{\frac{1}{2}}\int_{-1}^{\frac{1}{2}} f_{XY}(x,y)\, dx\, dy \\
&amp;=\int_0^{\frac{1}{2}}\int_0^{\frac{1}{2}} 1\, dx\,dy=\int_0^{\frac{1}{2}} 1\, dx\int_0^{\frac{1}{2}} 1\, dy=\frac{1}{2}\cdot\frac{1}{2}=\frac{1}{4}.
\end{array}
\]</span></p>
<p>En la figura siguiente hemos dibujado en morado la región donde <span class="math inline">\(f_{XY}\)</span> no es cero, es decir <span class="math inline">\([0,1]\times [0,1]\)</span>, la región <span class="math inline">\(B\)</span> en verde y la región intersección de las dos anteriores que es donde tenemos que integrar la <strong>función de densidad</strong> dada.</p>
<div class="center">
<p><img src="Images/VaUniformeBidi.png" /><!-- --></p>
</div>
</div>
</div>
</div>
</div>
<div id="propiedades-de-la-función-de-densidad" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Propiedades de la función de densidad</h3>
<p>Sea <span class="math inline">\((X,Y)\)</span> una <strong>variable aleatoria bidimensional continua</strong> con <strong>función de densidad</strong> <span class="math inline">\(f_{XY}\)</span>. Esta función verifica las propiedades siguientes:</p>
<ul>
<li>La integral de dicha función sobre todo el plano vale 1:</li>
</ul>
<p><span class="math display">\[
\int\int_{\mathbb{R}^2} f_{XY}(x,y)\,dx\,dy =1.
\]</span></p>
<p>Para ver dicha propiedad, basta considerar <span class="math inline">\(B=\mathbb{R}^2\)</span>, tener en cuenta que el suceso <span class="math inline">\((X,Y)\in \mathbb{R}^2\)</span> es el total <span class="math inline">\(\Omega\)</span> y aplicar la definición de <span class="math inline">\(f_{XY}\)</span>:</p>
<p><span class="math display">\[
P((X,Y)\in \mathbb{R}^2)=1= \int\int_{\mathbb{R}^2} f_{XY}(x,y)\,dx\,dy.
\]</span></p>
<ul>
<li>La relación que hay entre la <strong>función de distribución</strong> <span class="math inline">\(F_{XY}\)</span> y la <strong>función de densidad</strong> <span class="math inline">\(f_{XY}\)</span> es la siguiente:</li>
</ul>
<p><span class="math display">\[
F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^y f_{XY}(u,v)\,du\,dv.
\]</span></p>
<p>Para ver dicha propiedad, basta considerar <span class="math inline">\(B=(-\infty,x]\times (-\infty,y]\)</span> y aplicar la definición de <strong>función de distribución</strong>:</p>
<p><span class="math display">\[
F_{XY}(x,y)=P((X,Y)\in (-\infty,x]\times (-\infty,y])=\int_{-\infty}^x\int_{-\infty}^y f_{XY}(u,v)\,du\,dv.
\]</span></p>
<ul>
<li>La relación que hay entre la <strong>función de densidad</strong> <span class="math inline">\(f_{XY}\)</span> y la <strong>función de distribución</strong> <span class="math inline">\(F_{XY}\)</span> es la siguiente:</li>
</ul>
<p><span class="math display">\[
f_{XY}(x,y)=\frac{\partial^2 F_{XY}(x,y)}{\partial x\partial y}.
\]</span></p>
<p>Dicha propiedad se deduce de la anterior, derivando primero respecto a <span class="math inline">\(x\)</span> y después respecto a <span class="math inline">\(y\)</span> para eliminar las dos integrales.</p>
<ul>
<li>Las <strong>funciones de densidad marginales</strong> de las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, <span class="math inline">\(f_X(x)\)</span> y <span class="math inline">\(f_Y(y)\)</span> respectivamente, se calculan de la forma siguiente:</li>
</ul>
<p><span class="math display">\[
f_X(x)=\int_{-\infty}^\infty f_{XY}(x,y)\, dy,\ f_Y(y)=\int_{-\infty}^\infty f_{XY}(x,y)\, dx
\]</span></p>
<div id="ejemplos-1" class="section level4">
<h4><span class="header-section-number">5.4.2.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: continuación ejemplo anterior</strong></p>
<p>Comprobemos las propiedades usando la <strong>función de densidad</strong> del ejemplo anterior:
<span class="math inline">\(f_{XY}(x,y)=\begin{cases} 1, &amp; \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\ 0, &amp; \mbox{en caso contrario.} \end{cases}\)</span></p>
<div class="example-sol">
<ul>
<li>La integral de <span class="math inline">\(f_{XY}\)</span> sobre todo el plano vale 1:</li>
</ul>
<p><span class="math display">\[
\begin{array}{rcl}
\int\int_{\mathbb{R}^2} f_{XY}(x,y)\,dx\, dy &amp;=&amp;\int_0^1\int_0^1 1\, dx\, dv\\
&amp;=&amp;\int_0^1 1\, dx\int_0^1 1\, dy=1\cdot 1=1.
\end{array}
\]</span></p>
<ul>
<li>Vamos a calcular la función de distribución <span class="math inline">\(F_{XY}\)</span>. Para ello dividimos el plano en 5 zonas tal como muestra la figura siguiente:</li>
</ul>
<div class="center">
<p><img src="Images/VaUniformeBidi2.png" /><!-- --></p>
</div>
<p>Sea <span class="math inline">\((x,y)\)</span> un punto cualquiera de <span class="math inline">\(\mathbb{R}^2\)</span>. De cara a calcular <span class="math inline">\(F_{XY}(x,y)\)</span> tenemos que averiguar el conjunto intersección siguiente: <span class="math inline">\(([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])\)</span> ya que el dominio donde <span class="math inline">\(f_{XY}\)</span> es no nula es <span class="math inline">\([0,1]\times [0,1]\)</span> y la función de distribución <span class="math inline">\(F_{XY}(x,y)\)</span> valdrá:</p>
<p><span class="math display">\[
\begin{array}{rl}
F_{XY}(x,y)&amp;=\int_{-\infty}^x\int_{-\infty}^y f_{XY}(u,v)\,du\,dv\\ &amp;=
\int\int_{([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])} f_{XY}(u,v)\,du\,dv.
\end{array}
\]</span></p>
<ul>
<li>Caso <span class="math inline">\((x,y)\in \mbox{Zona A}\)</span> o <span class="math inline">\(x&lt;0\)</span> o <span class="math inline">\(y&lt;0\)</span> En este caso: <span class="math inline">\(([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])=\emptyset.\)</span> Ver figura siguiente donde la zona morada <span class="math inline">\(([0,1]\times [0,1]\)</span>) no se interseca con la zona verde (<span class="math inline">\((-\infty,x]\times (-\infty,y]\)</span>).</li>
</ul>
<p>Por tanto en este caso, <span class="math inline">\(F_{XY}(x,y)=0\)</span>.</p>
<div class="center">
<p><img src="Images/VaUniformeBidi3.png" /><!-- --></p>
</div>
<ul>
<li>Caso <span class="math inline">\((x,y)\in \mbox{Zona B}\)</span>, o <span class="math inline">\((x,y)\in [0,1]\times [0,1]\)</span>. En este caso: <span class="math inline">\(([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])=[0,x]\times [0,y].\)</span> Ver figura siguiente.</li>
</ul>
<p>Por tanto en este caso,
19</p>
<p><span class="math display">\[
F_{XY}(x,y)=\int_0^x \int_0^y 1\,du\,dv =\int_0^x 1\, du\int_0^y 1\, dy =x\cdot y.
\]</span></p>
<div class="center">
<p><img src="Images/VaUniformeBidi4.png" /><!-- --></p>
</div>
<p>Dejamos como ejercicio los otros casos. En resumen:
<span class="math display">\[
F_{XY}(x,y)=\begin{cases}
0, &amp; \mbox{ si }x&lt;0, \mbox{ o }y&lt;0,\\
x y, &amp; \mbox{ si }(x,y)\in [0,1]\times [0,1],\\
x, &amp; \mbox{ si }0\leq x\leq 1,\ y&gt;1,\\
y, &amp; \mbox{ si }x&gt;1,\ 0\leq y\leq 1,\\
1, &amp; \mbox{ si } x&gt;1,\ y&gt;1.
\end{cases}
\]</span>
¿Os suena?</p>
<p>Ver el primer ejemplo que pusimos del tema. Es la misma variable aleatoria bidimensional.
Ahora sabemos que se trata de una <strong>variable aleatoria bidimensional continua</strong>.</p>
<p>Comprobemos ahora que si derivamos dos veces la expresión de <span class="math inline">\(F_{XY}\)</span>, primero respecto <span class="math inline">\(x\)</span> y después respecto <span class="math inline">\(y\)</span>, obtendremos la <strong>función de densidad</strong> <span class="math inline">\(f_{XY}\)</span>.</p>
<p>Si derivamos respecto <span class="math inline">\(x\)</span> obtenemos:</p>
<p><span class="math display">\[
\frac{\partial F_{XY}(x,y)}{\partial x}=\begin{cases}
0, &amp; \mbox{ si }x&lt;0, \mbox{ o }y&lt;0,\\
y, &amp; \mbox{ si }(x,y)\in [0,1]\times [0,1],\\
1, &amp; \mbox{ si }0\leq x\leq 1,\ y&gt;1,\\
0, &amp; \mbox{ si }x&gt;1,\ 0\leq y\leq 1,\\
0, &amp; \mbox{ si } x&gt;1,\ y&gt;1.
\end{cases}
\]</span>
Si ahora derivamos respecto <span class="math inline">\(y\)</span> obtenemos:</p>
<p><span class="math display">\[
\frac{\partial^2 F_{XY}(x,y)}{\partial y\partial x}=\begin{cases}
0, &amp; \mbox{ si }x&lt;0, \mbox{ o }y&lt;0,\\
1, &amp; \mbox{ si }(x,y)\in [0,1]\times [0,1],\\
0, &amp; \mbox{ si }0\leq x\leq 1,\ y&gt;1,\\
0, &amp; \mbox{ si }x&gt;1,\ 0\leq y\leq 1,\\
0, &amp; \mbox{ si } x&gt;1,\ y&gt;1,
\end{cases}
\]</span>
expresión que coincide con la <strong>función de densidad</strong> <span class="math inline">\(f_{XY}(x,y)\)</span>.</p>
<p>Hallemos para finalizar las <strong>funciones de densidad marginales</strong>. Empecemos con <span class="math inline">\(f_X(x)\)</span>:
<span class="math display">\[
f_X(x)=\int_{-\infty}^\infty  f_{XY}(x,y)\, dy.
\]</span>
Recordemos que la región donde no se anulaba la <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span> era el cuadrado <span class="math inline">\([0,1]\times [0,1]\)</span>. Por tanto, fijado <span class="math inline">\(x\)</span>, el valor de <span class="math inline">\(f_X(x)\)</span> es no nulo si la recta vertical <span class="math inline">\(X=x\)</span> interseca dicho cuadrado. Y esto ocurre siempre que <span class="math inline">\(x\in (0,1)\)</span>. Por tanto,
<span class="math display">\[
f_X(x)=\begin{cases}
\int_{0}^1  f_{XY}(x,y)\, dy=\int_{0}^1  1\, dy=1, &amp; \mbox{ si }x\in (0,1),\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
Por tanto la variable <span class="math inline">\(X\)</span> sigue la distribución uniforme en el intervalo <span class="math inline">\([0,1]\)</span>.</p>
<p>Dejamos como ejercicio comprobar que la variable <span class="math inline">\(Y\)</span> también sigue la distribución uniforme en el mismo intervalo.</p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: otra función de densidad bidimensional</strong></p>
<p>Consideremos la variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> con <strong>función de densidad</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
c\cdot \mathrm{e}^{-x}\cdot\mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario,}
\end{cases}
\]</span>
donde <span class="math inline">\(c\)</span> es un valor que se tiene que hallar para que <span class="math inline">\(f_{XY}\)</span> sea función de densidad. Calcular <span class="math inline">\(c\)</span> y comprobar todas las propiedades de la función de densidad.</p>
<div class="example-sol">
<p>Para hallar <span class="math inline">\(c\)</span>, hemos de imponer que la integral de la función anterior debe ser 1 sobre todo el plano <span class="math inline">\(\mathbb{R}^2\)</span>.</p>
<p>Primero fijémonos en como es la región de integración (zona morada de la figura). Fijado un valor <span class="math inline">\(x\geq 0\)</span>, el valor <span class="math inline">\(y\)</span> va desde <span class="math inline">\(y=0\)</span> hasta <span class="math inline">\(y=x\)</span>. Por tanto, para calcular el valor de <span class="math inline">\(c\)</span>, hay que hacer lo siguiente:</p>
<div class="center">
<p><img src="Images/Ejemplo2Bidi.png" /><!-- --></p>
</div>
<p><span class="math display">\[
\begin{array}{rl}
1 &amp;=  \int\int_{\mathbb{R}^2}f_{XY}(x,y)\, dx\, dy=\int_{x=0}^{x=\infty}\int_{y=0}^{y=x} c \cdot\mathrm{e}^{-x}\cdot\mathrm{e}^{-y} \, dy\, dx \\
  &amp;=  c\cdot \int_{x=0}^{x=\infty}\mathrm{e}^{-x}\cdot\int_{y=0}^{y=x}\mathrm{e}^{-y}\, dy\, dx = c \cdot  \int_{x=0}^{x=\infty}\mathrm{e}^{-x}\cdot\left[-\mathrm{e}^{-y}\right]_{y=0}^{y=x}\, dx \\
  &amp;=  c \cdot\int_{x=0}^{x=\infty}\mathrm{e}^{-x}\cdot\left(1-\mathrm{e}^{-x}\right)\, dx =c \cdot\int_{x=0}^{x=\infty}\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx 
  \\ &amp; =  c \cdot\left[-\mathrm{e}^{-x}+\frac{1}{2}\mathrm{e}^{-2x}\right]_{x=0}^{x=\infty} = c\left(1-\frac{1}{2}\right)=\frac{c}{2}.
\end{array}
\]</span></p>
<p>El valor de <span class="math inline">\(c\)</span> es <span class="math inline">\(c=2\)</span>.</p>
<p>Vamos a calcular seguidamente su función de distribución.</p>
<p>Fijémonos que, en este caso, si <span class="math inline">\(x&lt;0\)</span> o <span class="math inline">\(y&lt;0\)</span>, <span class="math inline">\(F_{XY}(x,y)=0\)</span>, ya que el dominio <span class="math inline">\(B=(-\infty,x]\times (-\infty,y]\)</span> no interseca la zona morada del gráfico anterior.</p>
<p>Suponemos entonces que <span class="math inline">\(x\geq 0\)</span> e <span class="math inline">\(y\geq 0\)</span>.</p>
<p>Vamos a considerar dos casos:</p>
<ul>
<li><p><span class="math inline">\(x\leq y\)</span>. Ver zona verde del gráfico siguiente.</p></li>
<li><p><span class="math inline">\(x\geq y\)</span>. Ver zona morada del gráfico siguiente.</p></li>
</ul>
<div class="center">
<p><img src="Images/Ejemplo2Bidi2.png" /><!-- --></p>
</div>
<ul>
<li>Caso <span class="math inline">\(x\leq y\)</span> (zona verde de la figura adjunta). En este caso, si hacemos la intersección de la región <span class="math inline">\(B=(-\infty,x]\times (-\infty,y]\)</span> (zona azul) con la zona morada o región donde <span class="math inline">\(f_{XY}(x,y)\neq 0\)</span> obtenemos el triángulo <span class="math inline">\(T_{x,y}=\{(u,v)\in\mathbb{R}^2,\ 0\leq u\leq x,\ 0\leq v\leq u\}.\)</span> Ver figura adjunta.</li>
</ul>
<p>Por tanto,
<span class="math display">\[
\begin{array}{lcr}
F_{XY}(x,y) &amp; = &amp; \int_{u=0}^{u=x}\int_{v=0}^{v=u} f_{XY}(u,v)\,dv\,du= 2 \cdot\int_{u=0}^{u=x} \mathrm{e}^{-u}\int_{v=0}^{v=u}  \mathrm{e}^{-v}\,dv\,du\\ &amp;  = &amp; 
2 \cdot\int_{u=0}^{u=x} \mathrm{e}^{-u}\cdot\left[-\mathrm{e}^{-v}\right]_{v=0}^{v=u}\, du =  2 \cdot\int_{u=0}^{u=x} \mathrm{e}^{-u} \cdot (1-\mathrm{e}^{-u})\, du 
\\ &amp; = &amp; 2 \int_{u=0}^{u=x} \left(\mathrm{e}^{-u}-\mathrm{e}^{-2u}\right)\, du=2\cdot \left[-\mathrm{e}^{-u}+\frac{1}{2}\cdot\mathrm{e}^{-2u}\right]_{u=0}^{u=x}  \\ &amp; = &amp;
2\cdot\left(-\mathrm{e}^{-x}+\frac{1}{2}\cdot\mathrm{e}^{-2x}+1-\frac{1}{2}\right) =1-2\cdot\mathrm{e}^{-x}+\mathrm{e}^{-2x}.
\end{array}
\]</span></p>
<div class="center">
<p><img src="Images/Ejemplo2Bidi3.png" /><!-- --></p>
</div>
<ul>
<li>Caso <span class="math inline">\(x\geq y\)</span> (zona morada de la figura adjunta). En este caso, si hacemos la intersección de la región <span class="math inline">\(B=(-\infty,x]\times (-\infty,y]\)</span> (zona azul) con la zona morada o región donde <span class="math inline">\(f_{XY}(x,y)\neq 0\)</span> obtenemos el trapecio <span class="math inline">\(T_{x,y}=\{(u,v)\in\mathbb{R}^2,\ 0\leq v\leq y,\ v\leq u\leq x\}.\)</span> Ver figura adjunta.</li>
</ul>
<p>Por tanto,</p>
<p><span class="math display">\[
\begin{array}{rl}
F_{XY}(x,y) &amp;=  \int_{v=0}^{v=y}\int_{u=v}^{u=x} f_{XY}(u,v)\,dv\,du= 2\cdot\int_{v=0}^{v=y} \mathrm{e}^{-v}\int_{u=v}^{u=x} \mathrm{e}^{-u}\,du\,dv \\
&amp;=  2 \cdot\int_{v=0}^{v=y} \mathrm{e}^{-v}\cdot\left[-\mathrm{e}^{-u}\right]_{u=v}^{u=x}\, dv  = 2 \cdot\int_{v=0}^{v=y} \mathrm{e}^{-v}\cdot (\mathrm{e}^{-v}-\mathrm{e}^{-x})\, du \\ 
&amp;=  2 \cdot\int_{v=0}^{v=y} \left(\mathrm{e}^{-2v}-\mathrm{e}^{-v-x}\right)\, du=2 \cdot\left[-\frac{1}{2}\mathrm{e}^{-2v}+\mathrm{e}^{-v-x}\right]_{v=0}^{v=y}  
\\ &amp;=  2\cdot\left(-\frac{1}{2}\cdot\mathrm{e}^{-2y}+\mathrm{e}^{-x-y}+\frac{1}{2}-\mathrm{e}^{-x}\right) \\&amp;=  1-2\cdot\mathrm{e}^{-x}-\mathrm{e}^{-2y}+2\cdot\mathrm{e}^{-x-y}.
\end{array}
\]</span></p>
<div class="center">
<p><img src="Images/Ejemplo2Bidi4.png" /><!-- --></p>
</div>
<p>En resumen:
<span class="math display">\[
F_{XY}(x,y)=\begin{cases}
1-2\cdot\mathrm{e}^{-x}+\mathrm{e}^{-2x}, &amp; \mbox{si }x\geq 0,\ y\geq 0,\ x\leq y,\\
1-2\cdot\mathrm{e}^{-x}-\mathrm{e}^{-2y}+2\cdot\mathrm{e}^{-x-y}, &amp; \mbox{si }x\geq 0,\ y\geq 0,\ x\geq y,\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span></p>
<p>Comprobemos a continuación que si derivamos dos veces la expresión de <span class="math inline">\(F_{XY}\)</span>, primero respecto <span class="math inline">\(x\)</span> y después respecto <span class="math inline">\(y\)</span>, obtendremos la <strong>función de densidad</strong> <span class="math inline">\(f_{XY}\)</span>.</p>
<p>Si derivamos respecto <span class="math inline">\(x\)</span> obtenemos:
<span class="math display">\[
\frac{\partial F_{XY}(x,y)}{\partial x}=\begin{cases}
2\cdot\mathrm{e}^{-x}-2\cdot\mathrm{e}^{-2x}, &amp; \mbox{si }x\geq 0,\ y\geq 0,\ x\leq y,\\
2\cdot\mathrm{e}^{-x}-2\cdot\mathrm{e}^{-x-y}, &amp; \mbox{si }x\geq 0,\ y\geq 0,\ x\geq y,\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
Si ahora derivamos respecto <span class="math inline">\(y\)</span> obtenemos:
<span class="math display">\[
\frac{\partial^2 F_{XY}(x,y)}{\partial y\partial x}=\begin{cases}
0, &amp; \mbox{si }x\geq 0,\ y\geq 0,\ x\leq y,\\
2\cdot\mathrm{e}^{-x-y}, &amp; \mbox{si }x\geq 0,\ y\geq 0,\ x\geq y,\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
expresión que coincide con la <strong>función de densidad</strong> <span class="math inline">\(f_{XY}(x,y)\)</span>.</p>
<p>Hallemos las <strong>funciones de densidad marginales</strong>. Fijémonos que basta tener en cuenta los casos en que <span class="math inline">\(x\geq 0\)</span> e <span class="math inline">\(y\geq 0\)</span> ya que en caso contrario tanto <span class="math inline">\(f_X(x)\)</span> como <span class="math inline">\(f_Y(y)\)</span> son nulas.</p>
<p><span class="math display">\[
\begin{array}{rl}
f_X(x) &amp;=   \int_{-\infty}^{\infty} f_{XY}(x,y)\, dy =\int_{y=0}^{y=x}2\cdot\mathrm{e}^{-x-y}\, dy = 2\cdot\left[-\mathrm{e}^{-x-y}\right]_{y=0}^{y=x} \\ &amp;=   2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right),\mbox{ si }x\geq 0,
\end{array}
\]</span></p>
<p><span class="math display">\[
\begin{array}{rl}
f_Y(y) &amp; =  \int_{-\infty}^{\infty} f_{XY}(x,y)\, dx =\int_{x=y}^{x=\infty}2\cdot\mathrm{e}^{-x-y}\, dx = 2\cdot\left[-\mathrm{e}^{-x-y}\right]_{x=y}^{x=\infty}\\ &amp;= 2\cdot\mathrm{e}^{-2y}, \mbox{ si }y\geq 0.
\end{array}
\]</span></p>
<p>Vemos que la variable <span class="math inline">\(Y\)</span> corresponde a una distribución exponencial de parámetro <span class="math inline">\(\lambda =2\)</span>.</p>
<p>Dibujemos la <strong>función de densidad conjunta</strong> y la <strong>función de distribución conjunta</strong> con <code>R</code>. Primero las definimos:</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb383-1" data-line-number="1">fun.den.con =<span class="st"> </span><span class="cf">function</span>(x,y){<span class="kw">ifelse</span>(x<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>y<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&gt;=</span>y,</a>
<a class="sourceLine" id="cb383-2" data-line-number="2">                                   <span class="dv">2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">-</span>y),<span class="dv">0</span>)}</a>
<a class="sourceLine" id="cb383-3" data-line-number="3">fun.dist.con =<span class="st"> </span><span class="cf">function</span>(x,y){<span class="kw">ifelse</span>(x<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>y<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span>y,</a>
<a class="sourceLine" id="cb383-4" data-line-number="4">                    <span class="dv">1-2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x)<span class="op">+</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>x),<span class="kw">ifelse</span>(x<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>y<span class="op">&gt;=</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&gt;=</span>y,</a>
<a class="sourceLine" id="cb383-5" data-line-number="5">                    <span class="dv">1-2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x)<span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>y)<span class="op">+</span><span class="dv">2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">-</span>y),<span class="dv">0</span>))}</a></code></pre></div>
<p>A continuación las dibujamos para <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> entre <span class="math inline">\(-1\)</span> y <span class="math inline">\(4\)</span>:</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb384-1" data-line-number="1">x=<span class="kw">seq</span>(<span class="dt">from=</span><span class="op">-</span><span class="dv">1</span>,<span class="dt">to=</span><span class="dv">4</span>,<span class="dt">by=</span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb384-2" data-line-number="2">y=<span class="kw">seq</span>(<span class="dt">from=</span><span class="op">-</span><span class="dv">1</span>,<span class="dt">to=</span><span class="dv">4</span>,<span class="dt">by=</span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb384-3" data-line-number="3">z.fun.den.con=<span class="kw">outer</span>(x,y,fun.den.con)</a>
<a class="sourceLine" id="cb384-4" data-line-number="4">z.fun.dist.con =<span class="st"> </span><span class="kw">outer</span>(x,y,fun.dist.con)</a>
<a class="sourceLine" id="cb384-5" data-line-number="5"><span class="kw">persp</span>(x,y,z.fun.den.con,<span class="dt">theta=</span><span class="dv">50</span>,<span class="dt">phi=</span><span class="dv">40</span>,<span class="dt">col=</span><span class="st">&quot;green&quot;</span>,<span class="dt">shade=</span><span class="fl">0.25</span>,<span class="dt">ticktype=</span><span class="st">&quot;detailed&quot;</span>)</a></code></pre></div>
<p><img src="curso-probabilidad-udemy_files/figure-html/unnamed-chunk-130-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
</div>
<div id="la-distribución-gaussiana-bidimensional" class="section level3">
<h3><span class="header-section-number">5.4.3</span> La distribución gaussiana bidimensional</h3>
<p>Vamos a generalizar la distribución normal a dos dimensiones.</p>
<p><l class="definition">Definición de distribución gaussiana bidimensional. </l>
Diremos que la distribución de la variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> es <strong>gaussiana bidimensional</strong> dependiendo del parámetro <span class="math inline">\(\rho\)</span> si su <strong>función de densidad conjunta</strong> es:
<span class="math display">\[
f_{XY}(x,y)=\frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\cdot\rho\cdot x\cdot y+y^2)}{2\cdot(1-\rho^2)}},\ -\infty &lt;x,y&lt;\infty.
\]</span></p>
<p>Propiedades de la <strong>función de densidad de la variable gaussiana bidimensional</strong>:</p>
<ul>
<li><p>Para cualquier punto <span class="math inline">\((x,y)\in\mathbb{R}^2\)</span>, la <strong>función de densidad</strong> es no nula: <span class="math inline">\(f_{XY}(x,y)&gt;0\)</span>.</p></li>
<li><p>La <strong>función de densidad</strong> tiene un único máximo absoluto en el punto <span class="math inline">\((0,0)\)</span> que vale <span class="math inline">\(f_{XY}(0,0)=\frac{1}{2\pi\sqrt{1-\rho^2}}.\)</span> Por tanto, para <span class="math inline">\(\rho=0\)</span>, dicho máximo alcanza el mínimo valor posible y si <span class="math inline">\(\rho\to \pm 1\)</span>, dicho máximo tiende a <span class="math inline">\(\infty\)</span>.</p></li>
<li><p>Las densidades marginales <span class="math inline">\(f_X(x)\)</span> y <span class="math inline">\(f_Y(y)\)</span> son normales <span class="math inline">\(N(0,1)\)</span>.</p></li>
</ul>
<div class="dem">
<p>Veámoslo con <span class="math inline">\(f_X(x)\)</span>. Por simetría, quedaría deducido para <span class="math inline">\(f_Y(y)\)</span>:
<span class="math display">\[
\begin{array}{rl}
f_X(x) &amp; =\frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\int_{-\infty}^\infty \mathrm{e}^{-\frac{(x^2-2\cdot\rho \cdot x \cdot y+y^2)}{2\cdot(1-\rho^2)}}\, dy =
\frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2\cdot(1-\rho^2)}}\int_{-\infty}^\infty \mathrm{e}^{-\frac{(-2\cdot\rho x\cdot y+y^2)}{2\cdot(1-\rho^2)}}\, dy \\ &amp; = \frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2\cdot(1-\rho^2)}} \int_{-\infty}^\infty \mathrm{e}^{-\frac{(y-\rho x)^2}{2(1-\rho^2)}} \mathrm{e}^{\frac{\rho^2 \cdot x^2}{2\cdot(1-\rho^2)}}\, dy \\ &amp; =\frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2}} \int_{-\infty}^\infty \mathrm{e}^{-\frac{(y-\rho x)^2}{2(1-\rho^2)}}\, dy,  \mbox{ hacemos el cambio $z=\frac{y-\rho x}{\sqrt{1-\rho^2}}$}\\ &amp; = \frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2}} \int_{-\infty}^\infty \mathrm{e}^{-\frac{z^2}{2}}\sqrt{1-\rho^2}\, dy =\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}},
\end{array}
\]</span>
función que coincide con la <strong>función de densidad</strong> de la variable <span class="math inline">\(N(0,1)\)</span>.</p>
<p>En el último paso hemos usado que
<span class="math display">\[
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty \mathrm{e}^{-\frac{z^2}{2}}\, dz=1,
\]</span>
ya que correspondería al área de una <strong>función de densidad</strong> de una distribución <span class="math inline">\(N(0,1)\)</span>.</p>
</div>
<div id="la-distribución-gaussiana-bidimensional-en-r" class="section level4">
<h4><span class="header-section-number">5.4.3.1</span> La distribución gaussiana bidimensional en <code>R</code></h4>
<div class="example">
<p>En <code>R</code> existe el paquete <code>bivariate</code> para trabajar con algunas distribuciones conjuntas; en particular, con la <strong>distribución normal bidimensional</strong>.</p>
<p>La función que nos la densidad de la <strong>distribución normal bidimensional</strong> es <code>nbvpdf</code> y tiene 5 parámetros: la <strong>media</strong> de <span class="math inline">\(X\)</span> (<span class="math inline">\(\mu_X\)</span>), la <strong>media</strong> de <span class="math inline">\(Y\)</span> (<span class="math inline">\(\mu_Y\)</span>), la <strong>desviación típica</strong> de <span class="math inline">\(X\)</span> (<span class="math inline">\(\sigma_X\)</span>), la <strong>desviación típica</strong> de <span class="math inline">\(Y\)</span> (<span class="math inline">\(\sigma_Y\)</span>) y un concepto que veremos más adelante, la <strong>correlación</strong> entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> (<span class="math inline">\(\rho_{XY}\)</span>).</p>
<div class="example-sol">
<p>En el ejemplo que estamos tratando, los valores de los parámetros anteriores son: <span class="math inline">\(\mu_X=\mu_Y=0\)</span>, <span class="math inline">\(\sigma_X=\sigma_Y=1\)</span> y <span class="math inline">\(\rho_{XY}=\rho.\)</span></p>
<p>Vamos a hacer un gráfico de la <strong>distribución normal bidimensional</strong> para <span class="math inline">\(\rho=\frac{1}{2}.\)</span></p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb385-1" data-line-number="1"><span class="kw">library</span>(bivariate)</a>
<a class="sourceLine" id="cb385-2" data-line-number="2">f =<span class="st"> </span><span class="kw">nbvpdf</span> (<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb385-3" data-line-number="3"><span class="kw">plot</span>(f,<span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="curso-probabilidad-udemy_files/figure-html/unnamed-chunk-131-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
</div>
</div>
<div id="independencia-de-variables-aleatorias" class="section level2">
<h2><span class="header-section-number">5.5</span> Independencia de variables aleatorias</h2>
<div id="independencia-de-variables-aleatorias-discretas" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Independencia de variables aleatorias discretas</h3>
<p>Recordemos que dos sucesos <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> son independientes si <span class="math inline">\(P(A\cap B)=P(A)\cdot P(B)\)</span>.</p>
<p>¿Cómo trasladar dicho concepto al caso de variables aleatorias?</p>
<p>En el caso de <strong>variables aleatorias discretas bidimensionales</strong> vimos que, dada una variable aleatoria bidimensional discreta <span class="math inline">\((X,Y)\)</span> con <span class="math inline">\((X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,j=1,2,\ldots\}\)</span>, los sucesos de la forma <span class="math inline">\(\{X=x_i,\  Y=y_j\}\)</span> determinaban cómo se distribuían los valores de la variable <span class="math inline">\((X,Y)\)</span>. De ahí la definición siguiente:</p>
<p><l class="definition">Definición de independencia para variables aleatorias bidimensionales discretas. </l>
Sean <span class="math inline">\((X,Y)\)</span> una <strong>variable aleatoria bidimensional discreta</strong> con <span class="math inline">\((X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,j=1,2,\ldots\}\)</span> y <strong>función de probabilidad</strong> <span class="math inline">\(P_{XY}\)</span> y <strong>funciones de probabilidad marginales</strong> <span class="math inline">\(P_X\)</span> y <span class="math inline">\(P_Y\)</span>. Entonces <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes si:
<span class="math display">\[
P_{XY}(x_i,y_j)=P_X(x_i)\cdot P_Y(y_k),\ i=1,2,\ldots,j=1,2,\ldots
\]</span>
o dicho de otra forma:
<span class="math display">\[
P(X=x_i,\ Y=y_k)=P(X=x_i)\cdot P(Y=y_k),\ i=1,2,\ldots,j=1,2,\ldots
\]</span></p>
<div class="example">
<p><strong>Ejemplo: suma y el producto de los resultados de dos lanzamientos de un dado</strong></p>
<p>Consideramos la variable aleatoria <span class="math inline">\((S,P)\)</span> donde <span class="math inline">\(S\)</span> representa la suma de los valores obtenidos al lanzar dos veces un dado y <span class="math inline">\(P\)</span>, su producto.</p>
<div class="example-sol">
<p>En este caso <span class="math inline">\(S\)</span> y <span class="math inline">\(P\)</span> no son independientes ya que recordemos que por ejemplo <span class="math inline">\(P_{SP}(3,2)=\frac{2}{36}\)</span>, <span class="math inline">\(P_S(3)=\frac{2}{36}\)</span> y <span class="math inline">\(P_P(2)=\frac{2}{36}\)</span>, ya que en este último caso, sólo hay dos posibles resultados en los que el producto dé 2: el <span class="math inline">\((1,2)\)</span> y el <span class="math inline">\((2,1)\)</span>.</p>
<p>Entonces no se cumple que <span class="math inline">\(P_{SP}(3,2)=P_S(3)\cdot P_P(2)\)</span>, ya que <span class="math inline">\(\frac{2}{36}\neq \frac{2}{36}\cdot \frac{2}{36}\)</span>.</p>
<p>De ahí que no sean independientes ya que la condición anterior se debería cumplir para todos los valores <span class="math inline">\(x_i\)</span> e <span class="math inline">\(y_k\)</span> y hemos encontrado un contraejemplo en donde no se cumple.</p>
</div>
</div>
<p><l class="observ">Observación. </l>
Si la tabla de la <strong>función de probabilidad conjunta</strong> de <span class="math inline">\((X,Y)\)</span> contiene algún <span class="math inline">\(0\)</span>, <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> no pueden ser independientes. ¿Podéis decir por qué?</p>
<div class="example">
<p><strong>Ejemplo: un caso de imdependencia</strong></p>
<p>Veamos un caso de independencia. Consideramos el experimento aleatorio de lanzar un dado dos veces. Sea <span class="math inline">\(X\)</span> el resultado del primer lanzamiento e <span class="math inline">\(Y\)</span>, el resultado del segundo lanzamiento.</p>
<p>Veamos que, en este caso, <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes.</p>
<div class="example-sol">
<p>El valor de <span class="math inline">\((X,Y)(\Omega)=\{(1,1),(1,2),\ldots,(6,6)\}\)</span>, en total 36 resultados.</p>
<p>La <strong>función de probabilidad conjunta</strong> en un valor cualquiera <span class="math inline">\((i,j)\)</span> con <span class="math inline">\(i,j\in\{1,2,3,4,5,6\}\)</span> es:
<span class="math inline">\(P_{XY}(i,j)=\frac{1}{36}\)</span> ya que la probabilidad que salga <span class="math inline">\(i\)</span> en el primer lanzamiento es <span class="math inline">\(\frac{1}{6}\)</span> y la probabilidad de que salga <span class="math inline">\(j\)</span> en el segundo lanzamiento, también. Por tanto, la probabilidad de que salga <span class="math inline">\(i\)</span> en el primer lanzamiento y <span class="math inline">\(j\)</span> en el segundo es: <span class="math inline">\(\frac{1}{6}\cdot \frac{1}{6}=\frac{1}{36}.\)</span></p>
Las <strong>funciones de densidad marginales</strong> de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son:
<div class="center">
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span> o <span class="math inline">\(Y\)</span></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P_X\)</span> o <span class="math inline">\(P_Y\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Por tanto, para todo <span class="math inline">\((i,j)\)</span> con <span class="math inline">\(i,j\in\{1,2,3,4,5,6\}\)</span> se cumplirá:
<span class="math display">\[
P_{XY}(i,j)=\frac{1}{36}=\frac{1}{6}\cdot \frac{1}{6}=P_X(i)\cdot P_Y(j).
\]</span>
Deducimos que son independientes.</p>
<p>Para comprobar si dos variables aleatorias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes o no en <code>R</code> en general, una vez calculada la tabla de la <strong>función de probabilidad</strong>, podemos calcular la tabla de <strong>independencia teórica</strong> <span class="math inline">\(P_T(x_i,y_j)\)</span> y compararlas. Ésta segunda tabla se define de la forma siguiente:
<span class="math display">\[
P_T(x_i,y_j)=P_X(x_i)\cdot P_Y(y_j),
\]</span>
donde <span class="math inline">\(P_X\)</span> y <span class="math inline">\(P_Y\)</span> son las distribuciones marginales.</p>
<p>La tabla de <strong>independencia teórica </strong> en el caso de la suma y el producto se calcularían de la forma siguiente:</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb386-1" data-line-number="1">tabla.ind.teor =<span class="st">  </span>marginal.suma<span class="op">%*%</span><span class="kw">t</span>(marginal.producto)</a>
<a class="sourceLine" id="cb386-2" data-line-number="2">tabla.ind.teor =<span class="st"> </span><span class="kw">as.data.frame</span>(tabla.ind.teor)</a>
<a class="sourceLine" id="cb386-3" data-line-number="3"><span class="kw">rownames</span>(tabla.ind.teor)=<span class="kw">rownames</span>(tabla.func.prob.conjunta)</a>
<a class="sourceLine" id="cb386-4" data-line-number="4"><span class="kw">colnames</span>(tabla.ind.teor)=<span class="kw">colnames</span>(tabla.func.prob.conjunta)</a></code></pre></div>
<p>Si comparamos los resultados de la tabla de <strong>independencia teórica</strong> mostrada a continuación con los resultados de la tabla de la <strong>función de probabilidad conjunta</strong>, veréis que no son iguales. Por tanto, <span class="math inline">\(S\)</span> y <span class="math inline">\(P\)</span> no son <strong>independientes</strong>.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
<th align="right">6</th>
<th align="right">8</th>
<th align="right">9</th>
<th align="right">10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
</tr>
<tr class="even">
<td>3</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.005</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
<td align="right">0.005</td>
<td align="right">0.007</td>
<td align="right">0.005</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
</tr>
<tr class="even">
<td>5</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.006</td>
<td align="right">0.009</td>
<td align="right">0.006</td>
<td align="right">0.012</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
</tr>
<tr class="odd">
<td>6</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.008</td>
<td align="right">0.012</td>
<td align="right">0.008</td>
<td align="right">0.015</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
</tr>
<tr class="even">
<td>7</td>
<td align="right">0.005</td>
<td align="right">0.009</td>
<td align="right">0.009</td>
<td align="right">0.014</td>
<td align="right">0.009</td>
<td align="right">0.019</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.009</td>
</tr>
<tr class="odd">
<td>8</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.008</td>
<td align="right">0.012</td>
<td align="right">0.008</td>
<td align="right">0.015</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
</tr>
<tr class="even">
<td>9</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.006</td>
<td align="right">0.009</td>
<td align="right">0.006</td>
<td align="right">0.012</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
</tr>
<tr class="odd">
<td>10</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
<td align="right">0.005</td>
<td align="right">0.007</td>
<td align="right">0.005</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
</tr>
<tr class="even">
<td>11</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.005</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">12</th>
<th align="right">15</th>
<th align="right">16</th>
<th align="right">18</th>
<th align="right">20</th>
<th align="right">24</th>
<th align="right">25</th>
<th align="right">30</th>
<th align="right">36</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
</tr>
<tr class="even">
<td>3</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
<td align="right">0.005</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
</tr>
<tr class="even">
<td>5</td>
<td align="right">0.012</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.006</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
</tr>
<tr class="odd">
<td>6</td>
<td align="right">0.015</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.008</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
</tr>
<tr class="even">
<td>7</td>
<td align="right">0.019</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.009</td>
<td align="right">0.009</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
</tr>
<tr class="odd">
<td>8</td>
<td align="right">0.015</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.008</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
<td align="right">0.008</td>
<td align="right">0.004</td>
</tr>
<tr class="even">
<td>9</td>
<td align="right">0.012</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.006</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
</tr>
<tr class="odd">
<td>10</td>
<td align="right">0.009</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
<td align="right">0.005</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
<td align="right">0.005</td>
<td align="right">0.002</td>
</tr>
<tr class="even">
<td>11</td>
<td align="right">0.006</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="right">0.003</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
<td align="right">0.002</td>
<td align="right">0.001</td>
</tr>
</tbody>
</table>
<p>lo cual finaliza nuestros cálculos en <code>R</code>.</p>
</div>
</div>
</div>
<div id="independencia-de-variables-aleatorias-continuas" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Independencia de variables aleatorias continuas</h3>
<p>La definición dada para <strong>variables aleatorias discretas</strong> se traslada de forma natural a las <strong>variables aleatorias continuas</strong>:</p>
<p><l class="definition">Definición de independencia para variables aleatorias bidimensionales continuas. </l>
Sean <span class="math inline">\((X,Y)\)</span> una <strong>variable aleatoria bidimensional continua</strong> con <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span> y <strong>funciones de densidad marginales</strong> <span class="math inline">\(f_X\)</span> y <span class="math inline">\(f_Y\)</span>. Entonces <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes si:
<span class="math display">\[
f_{XY}(x,y)=f_X(x)\cdot f_Y(y),\ \mbox{para todo $x,y\in\mathbb{R}$.}
\]</span></p>
<div id="ejemplos-2" class="section level4">
<h4><span class="header-section-number">5.5.2.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: densidad uniforme en el cuadrado unidad</strong></p>
<p>Recordemos el ejemplo siguiente visto donde teníamos una <strong>variable aleatoria bidimensional continua</strong> <span class="math inline">\((X,Y)\)</span> con
<strong>función de densidad conjunta</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
1, &amp; \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
y con densidad marginales:
<span class="math display">\[
f_{X}(x)=\begin{cases}
1, &amp; \mbox{ si }0\leq x\leq 1,\\
0, &amp; \mbox{en caso contrario.}
\end{cases}\quad f_{Y}(y)=\begin{cases}
1, &amp; \mbox{ si }0\leq y\leq 1,\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span></p>
<p>Veamos que son independientes.</p>
<div class="example-sol">
<p>Consideremos dos casos:</p>
<ul>
<li><p><span class="math inline">\((x,y)\in [0,1]\times [0,1]\)</span>. En este caso:
<span class="math display">\[
f_{XY}(x,y) =1 =1\cdot 1=f_X(x)\cdot f_Y(y).
\]</span></p></li>
<li><span class="math inline">\((x,y)\not\in [0,1]\times [0,1]\)</span>. En este caso:
<span class="math display">\[
f_{XY}(x,y) =0 = f_X(x)\cdot f_Y(y),
\]</span>
ya que si <span class="math inline">\((x,y)\not\in [0,1]\times [0,1]\)</span>, o <span class="math inline">\(x\not\in [0,1]\)</span> o <span class="math inline">\(y\not\in [0,1]\)</span>. Por tanto <span class="math inline">\(f_X(x)=0\)</span> o <span class="math inline">\(f_Y(y)=0\)</span>. En cualquier caso, <span class="math inline">\(f_X(x)\cdot f_Y(y)=0\)</span>.</li>
</ul>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: otra función de densidad (continuación)</strong></p>
<p>Recordemos el ejemplo siguiente visto donde teníamos una <strong>variable aleatoria bidimensional continua</strong> <span class="math inline">\((X,Y)\)</span> con <strong>función de densidad conjunta</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
2 \cdot \mathrm{e}^{-x}\cdot\mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario,}
\end{cases}
\]</span>
y con densidad marginales:
<span class="math display">\[
f_X(x)  = 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right),\mbox{ si }x\geq 0, \quad
f_Y(y)  =  2\mathrm{e}^{-2y}, \mbox{ si }y\geq 0.
\]</span></p>
<p>En este caso no son independientes ya que claramente <span class="math inline">\(f_{XY}(x,y)\neq f_X(x)\cdot f_Y(y)\)</span>.</p>
<div class="example-sol">
<p>En este caso, recordemos que la <strong>función de densidad conjunta</strong> de <span class="math inline">\((X,Y)\)</span> es:
<span class="math display">\[
f_{XY}(x,y)=\frac{1}{2\cdot \pi\cdot \sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\cdot \rho \cdot x\cdot y+y^2)}{2\cdot (1-\rho^2)}},\ -\infty &lt;x,y&lt;\infty.
\]</span>
Las <strong>funciones de densidad marginales</strong> de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> correspondían a <span class="math inline">\(N(0,1)\)</span>:
<span class="math display">\[
\begin{array}{rl}
f_X(x) &amp; =\frac{1}{\sqrt{2\pi}}\cdot \mathrm{e}^{-\frac{x^2}{2}},\ -\infty &lt;x&lt;\infty,\\ f_Y(y) &amp; =\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{y^2}{2}},\ -\infty &lt;y&lt;\infty.
\end{array}
\]</span></p>
<p>¿Para qué valor(es) de <span class="math inline">\(\rho\)</span> las variables normales estándar <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes?</p>
<p>o, ¿para qué valor(es) de <span class="math inline">\(\rho\)</span> se cumple?</p>
<p><span class="math display">\[
f_X(x)\cdot f_Y(y)=\frac{1}{2\cdot\pi}\mathrm{e}^{-\frac{x^2+y^2}{2}} = \frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\cdot\rho x \cdot y+y^2)}{2\cdot (1-\rho^2)}}.
\]</span>
La respuesta es claramente para <span class="math inline">\(\rho=0\)</span>.</p>
<p>Por tanto, <span class="math inline">\(\rho\)</span> se puede interpretar como un parámetro de independencia, cuánto más cercano a cero esté, más cerca de la independencia estarán las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
</div>
</div>
<div id="relación-de-la-independencia-y-la-función-de-distribución" class="section level3">
<h3><span class="header-section-number">5.5.3</span> Relación de la independencia y la función de distribución</h3>
<p>El siguiente resultado nos da la relación entre la <strong>independencia de variables aleatorias</strong> y su <strong>función de distribución conjunta</strong>:</p>
<p><l class="prop">Teorema. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Entonces
<span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes si, y sólo si, la <strong>función de distribución conjunta</strong> es el producto de las <strong>funciones de distribución marginales</strong> en todo valor <span class="math inline">\((x,y)\in\mathbb{R}^2\)</span>:
<span class="math display">\[
F_{XY}(x,y)=F_X(x)\cdot F_Y(y),\ (x,y)\in\mathbb{R}^2.
\]</span></p>
<div class="example">
<p><strong>Ejemplo</strong></p>
<p>Consideramos el experimento aleatorio de lanzar un dado dos veces. Sea <span class="math inline">\(X\)</span> el resultado del primer lanzamiento e <span class="math inline">\(Y\)</span>, el resultado del segundo lanzamiento.</p>
<p>Recordemos que, en este caso, <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes.</p>
<div class="example-sol">
<p>En primer lugar notemos que si <span class="math inline">\(x&lt;1\)</span> o <span class="math inline">\(y&lt;1\)</span>, <span class="math inline">\(F_{XY}(x,y)=0\)</span> ya que el suceso <span class="math inline">\(\{X\leq x,\ Y\leq y\}\)</span> es vacío.</p>
<p>De la misma forma como <span class="math inline">\(x&lt;1\)</span> o <span class="math inline">\(y&lt;1\)</span>, o el suceso <span class="math inline">\(\{X\leq x\}\)</span> o el suceso <span class="math inline">\(\{Y\leq y\}\)</span> son vacíos. Por tanto, o <span class="math inline">\(F_X(x)=0\)</span> o <span class="math inline">\(F_Y(y)=0\)</span>.</p>
<p>En cualquier caso, se cumple <span class="math inline">\(F_{XY}(x,y)=0=F_X(x)\cdot F_Y(y)\)</span>.</p>
<p>Podemos suponer, por tanto, que <span class="math inline">\(x\geq 1\)</span> e <span class="math inline">\(y\geq 1\)</span>.</p>
<p>Sea <span class="math inline">\((x,y)\in \mathbb{R}^2\)</span> con <span class="math inline">\(x\geq 1\)</span> e <span class="math inline">\(y\geq 1\)</span>. Podemos suponer tal que existen dos valores <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span> en <span class="math inline">\(\{1,2,\ldots\}\)</span> con <span class="math inline">\(i\leq x &lt; i+1\)</span> y <span class="math inline">\(j\leq y &lt;j+1\)</span>.</p>
<p>El valor de la <strong>función de distribución conjunta</strong> en <span class="math inline">\((x,y)\)</span> es:
<span class="math display">\[
F_{XY}(x,y)=\begin{cases}
\frac{i\cdot j}{36}, &amp; \mbox{si }i\leq 6, \ j\leq 6, \\
\frac{6 \cdot i}{36}, &amp; \mbox{si }i\leq 6,\ j\geq 6,\\
\frac{6\cdot j}{36}, &amp; \mbox{si }i\geq 6,\ j\leq 6,\\
1, &amp; \mbox{ si }i\geq 6,\ j\geq 6,
\end{cases}
\]</span></p>
<p>ya que:</p>
<p><span class="math display">\[
\begin{array}{rl}
F_{XY}(x,y) &amp; =P(X\leq i,\ Y\leq j)=P(\{(k,l)\in \{1,2,3,4,5,6\}^2,\ |\ k\leq i,\ l\leq j\})\\ &amp; =P(\{(1,1),\ldots,(1,j),\ldots,(i,1),\ldots,(i,j)\})
\\
&amp; =\begin{cases}
\frac{i\cdot j}{36}, &amp; \mbox{si }i\leq 6, \ j\leq 6, \\
\frac{6\cdot i}{36}, &amp; \mbox{si }i\leq 6,\ j\geq 6,\\
\frac{6\cdot j}{36}, &amp; \mbox{si }i\geq 6,\ j\leq 6,\\
1, &amp; \mbox{ si }i\geq 6,\ j\geq 6,
\end{cases},
\end{array}
\]</span>
ya que claramente el cardinal del conjunto
<span class="math display">\[\{(1,1),\ldots,(1,j),\ldots,(i,1),\ldots,(i,j)\}\]</span>
es</p>
<p><span class="math display">\[
\begin{cases}
i\cdot j, &amp; \mbox{si }i\leq 6, \ j\leq 6, \\
\cdot  i, &amp; \mbox{si }i\leq 6,\ j\geq 6,\\
6\cdot j, &amp; \mbox{si }i\geq 6,\ j\leq 6,\\
36, &amp; \mbox{ si }i\geq 6,\ j\geq 6.
\end{cases}
\]</span></p>
<p>Hallemos ahora la función de distribución de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> que consiste en el resultado del lanzamiento de un dado.</p>
<p>Dado <span class="math inline">\(x\in\mathbb{R}\)</span> con <span class="math inline">\(x\geq 1\)</span>, existe un <span class="math inline">\(i\)</span> con <span class="math inline">\(i\in\{1,2,\ldots,\}\)</span> con <span class="math inline">\(i\leq x &lt;i+1\)</span>. En este caso, el valor de <span class="math inline">\(F_X(x)\)</span> es:</p>
<p><span class="math display">\[
F_X(x)=\begin{cases}
\frac{i}{6}, &amp;\mbox{si }i\leq 6,\\
1, &amp; \mbox{si }i\geq 6,
\end{cases}
\]</span>
ya que:</p>
<p><span class="math display">\[
\begin{array}{rl}
F_X(x) = &amp; F_X(i)=P(X\leq i)=P(\{k\in\{1,2,3,4,5,6\},\ |\ k\leq i\})
\\ = &amp; 
\begin{cases}
\frac{i}{6}, &amp;\mbox{si }i\leq 6,\\
1, &amp; \mbox{si }i\geq 6,
\end{cases}
\end{array}
\]</span>
\begin
ya que el cardinal del conjunto <span class="math inline">\(\{k\in\{1,2,3,4,5,6\},\ |\ k\leq i\}\)</span> es <span class="math inline">\(\begin{cases} i, &amp;\mbox{si }i\leq 6,\\ 6, &amp; \mbox{si }i\geq 6. \end{cases}\)</span></p>
<p>La función de distribución de <span class="math inline">\(Y\)</span> es de la misma forma.</p>
<p>Por último, comprobemos que se verifica que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>, si <span class="math inline">\(x\geq 1\)</span> e <span class="math inline">\(y\geq 1\)</span>.</p>
<p>Sea <span class="math inline">\((x,y)\in\mathbb{R}^2\)</span> y sean los enteros <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span> tales que <span class="math inline">\(i\leq x&lt;i+1\)</span> y <span class="math inline">\(j\leq y&lt;j+1\)</span>. Consideremos 4 casos:</p>
<ul>
<li><p><span class="math inline">\(i\leq 6, \ j\leq 6\)</span>. En este caso:
<span class="math display">\[
F_{XY}(x,y)=\frac{i\cdot j}{36}=\frac{i}{6}\cdot \frac{j}{6}=F_X(x)\cdot F_Y(y).
\]</span></p></li>
<li><p><span class="math inline">\(i\leq 6,\ j\geq 6\)</span>. En este caso:
<span class="math display">\[
F_{XY}(x,y)=\frac{6i}{36}=\frac{i}{6}\cdot 1=F_X(x)\cdot F_Y(y).
\]</span></p></li>
<li><p><span class="math inline">\(i\geq 6,\ j\leq 6\)</span>. En este caso:
<span class="math display">\[
F_{XY}(x,y)=\frac{6j}{36}=1\cdot \frac{j}{6}=F_X(x)\cdot F_Y(y).
\]</span></p></li>
<li><p><span class="math inline">\(i\geq 6,\ j\geq 6\)</span>. En este caso:
<span class="math display">\[
F_{XY}(x,y)=1=1\cdot 1=F_X(x)\cdot F_Y(y).
\]</span></p></li>
</ul>
<p>En resumen, para todo <span class="math inline">\((x,y)\in \mathbb{R}^2\)</span> se verifica que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>, tal como queríamos ver.</p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo</strong></p>
<p>Recordemos la variable aleatoria bidimensional continua con <strong>función de densidad conjunta</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
1, &amp; \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
Su <strong>función de distribución conjunta</strong> es:</p>
<div class="example-sol">
<p><span class="math display">\[
F_{XY}(x,y)=\begin{cases}
0, &amp; \mbox{si }x&lt;0,\mbox{ o }y&lt;0,\\
x\cdot y, &amp; \mbox{si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
x, &amp; \mbox{si }0\leq x\leq 1,\ y&gt; 1, \\
y, &amp; \mbox{si }0\leq y\leq 1,\ x&gt; 1, \\
1, &amp; x\geq 1,\ y\geq 1.
\end{cases}
\]</span></p>
<p>Recordemos también que las <strong>distribuciones marginales</strong> de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> eran uniformes en el intervalo <span class="math inline">\([0,1]\)</span>. Por tanto, las <strong>funciones de distribución marginales</strong> son:
<span class="math display">\[
F_X(x)=\begin{cases}
0, &amp; \mbox{si }x\leq 0, \\
x, &amp; \mbox{si }0\leq x\leq 1, \\
1, &amp; \mbox{si }x\geq 1. \\
\end{cases},\quad 
F_Y(y)=\begin{cases}
0, &amp; \mbox{si }y\leq 0, \\
y, &amp; \mbox{si }0\leq y\leq 1, \\
1, &amp; \mbox{si }y\geq 1. \\
\end{cases}
\]</span>
Recordemos que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes. Verifiquemos que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>.</p>
<p>Distinguiremos cinco casos:</p>
<ul>
<li><p><span class="math inline">\(x&lt;0\)</span> o <span class="math inline">\(y&lt;0\)</span>. En este caso, <span class="math inline">\(F_{XY}(x,y)=0\)</span> y, o <span class="math inline">\(F_X(x)=0\)</span>, si <span class="math inline">\(x&lt;0\)</span>, o <span class="math inline">\(F_Y(y)=0\)</span>, si <span class="math inline">\(y&lt;0\)</span>. En cualquier caso, se cumple que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>.</p></li>
<li><p><span class="math inline">\(0\leq x\leq 1,\ 0\leq y\leq 1\)</span>. En este caso, <span class="math inline">\(F_{XY}(x,y)=xy\)</span>, <span class="math inline">\(F_X(x)=x\)</span> y <span class="math inline">\(F_Y(y)=y\)</span>. Claramente, se cumple que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>.</p></li>
<li><p><span class="math inline">\(0\leq x\leq 1,\ y&gt; 1\)</span>. En este caso, <span class="math inline">\(F_{XY}(x,y)=x\)</span>, <span class="math inline">\(F_X(x)=x\)</span> y <span class="math inline">\(F_Y(y)=1\)</span>. Claramente, se cumple que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>.</p></li>
<li><p><span class="math inline">\(x &gt;1,\ 0\leq y\leq 1\)</span>. En este caso, <span class="math inline">\(F_{XY}(x,y)=y\)</span>, <span class="math inline">\(F_X(x)=1\)</span> y <span class="math inline">\(F_Y(y)=y\)</span>. Claramente, se cumple que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>.</p></li>
<li><p><span class="math inline">\(x\geq 1,\ y\geq 1\)</span>. En este caso, <span class="math inline">\(F_{XY}(x,y)=1\)</span>, <span class="math inline">\(F_X(x)=1\)</span> y <span class="math inline">\(F_Y(y)=1\)</span>. Claramente, se cumple que <span class="math inline">\(F_{XY}(x,y)=F_X(x)\cdot F_Y(y)\)</span>.</p></li>
</ul>
</div>
</div>
</div>
</div>
<div id="momentos-conjuntos-y-valores-esperados-conjuntos" class="section level2">
<h2><span class="header-section-number">5.6</span> Momentos conjuntos y valores esperados conjuntos</h2>
<p>El <strong>valor esperado</strong> de una variable aleatoria <span class="math inline">\(X\)</span> se identifica con el <em>centro de masa de la distribución de <span class="math inline">\(X\)</span></em>.</p>
<p>La <strong>varianza</strong> proporciona una medida de la <em>extensión de la distribución</em>.</p>
<p>En el caso de dos variables aleatorias, estamos interesados en cómo <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> varían juntas.</p>
<p>En particular, nos interesa saber si la variación de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> está correlacionada. Por ejemplo, si <span class="math inline">\(X\)</span> aumenta, ¿Y tiende a aumentar o disminuir?</p>
<p>Los momentos conjuntos de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, que se definen como valores esperados de las funciones de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, proporcionan esta información.</p>
<div id="valor-esperado-de-una-función-de-dos-variables-aleatorias" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Valor esperado de una función de dos variables aleatorias</h3>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional.</p>
<p>Sea <span class="math inline">\(P_{XY}\)</span> su <strong>función de probabilidad conjunta</strong> en el caso en que <span class="math inline">\((X,Y)\)</span> sea <strong>discreta</strong> y <span class="math inline">\(f_{XY}\)</span> su <strong>función de densidad conjunta</strong> en el caso en que <span class="math inline">\((X,Y)\)</span> sea <strong>continua</strong>.</p>
<p>Sea <span class="math inline">\(Z=g(X,Y)\)</span> una <strong>variable aleatoria unidimensional</strong> función de las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. Por ejemplo:</p>
<ul>
<li>Suma de las dos variables <span class="math inline">\(g(x,y)=x+y\)</span>: <span class="math inline">\(Z=X+Y\)</span>.</li>
<li>Producto de las dos variables <span class="math inline">\(g(x,y)=x\cdot y\)</span>: <span class="math inline">\(Z=X\cdot Y\)</span>.</li>
<li>Suma de los cuadrados de las variables <span class="math inline">\(g(x,y)=x^2+y^2\)</span>: <span class="math inline">\(Z=X^2+Y^2\)</span>.</li>
</ul>
<p>Hay que tener en cuenta que <span class="math inline">\(Z\)</span>, como <strong>variable aleatoria unidimensional</strong> tiene una <strong>función de probabilidad</strong> <span class="math inline">\(P_Z\)</span> en el caso en que <span class="math inline">\((X,Y)\)</span> sea discreta y una <strong>función de densidad</strong> <span class="math inline">\(f_Z\)</span> en el caso en que <span class="math inline">\((X,Y)\)</span> sea continua.</p>
<p>El siguiente resultado nos dice cómo calcular el <strong>valor esperado</strong> de <span class="math inline">\(Z\)</span> sin tener que calcular <span class="math inline">\(P_Z\)</span> o <span class="math inline">\(f_Z\)</span>, sólo usando la información de la <strong>variable aleatoria conjunta</strong> <span class="math inline">\((X,Y)\)</span>:</p>
<p><l class="prop">Proposición. </l>
El valor esperado de <span class="math inline">\(Z\)</span> se puede hallar usando la expresión siguiente:</p>
<ul>
<li><p>en el caso en que <span class="math inline">\((X,Y)\)</span> sea discreta con <span class="math inline">\((X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots, j=1,2,\ldots\}\)</span>,
<span class="math display">\[
E(Z)  = E(g(X,Y))  =\sum_{x_i}\sum_{y_j}g(x_i,y_j)\cdot P(x_i,y_j),
\]</span></p></li>
<li><p>en el caso en que <span class="math inline">\((X,Y)\)</span> sea continua:
<span class="math display">\[
E(Z)=E(g(X,Y))=\int_{-\infty}^\infty \int_{-\infty}^\infty g(x,y)\cdot f_{XY}(x,y)\, dx\, dy.
\]</span></p></li>
</ul>
<div id="ejemplos-3" class="section level4">
<h4><span class="header-section-number">5.6.1.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: suma y producto de dos dados (continuación)</strong></p>
<p>Consideremos el ejemplo de la variable <span class="math inline">\((S,P)\)</span> que nos daba la suma y el producto de los resultados cuando lanzábamos dos veces un dado.</p>
<p>Vamos a calcular <span class="math inline">\(E(S+P)\)</span>.</p>
<div class="example-sol">
<p>Recordemos que ya hemos calculado <span class="math inline">\(P_{SP}\)</span>. La expresión de <span class="math inline">\(E(S+P)\)</span> es:</p>
<p><span class="math display">\[
\begin{array}{rl}
E(S+P) &amp; = (2+1)\cdot P_{SP}(2,1)+(3+2)\cdot P_{SP}(3,2)+(4+3)\cdot P_{SP}(4,3)  \\ &amp;
\quad +(4+4)\cdot P_{SP}(4,4) + (5+4)\cdot P_{SP}(5,4)+(5+6)\cdot P_{SP}(5,6)\\ &amp; 
\quad +(6+5)\cdot P_{SP}(6,5)+(6+8)\cdot P_{SP}(6,8)+ (6+9)\cdot P_{SP}(6,9) \\ &amp;
\quad + (7+6)\cdot P_{SP}(7,6)+(7+10)\cdot P_{SP}(7,10)+(7+12)\cdot P_{SP}(7,12)\\ &amp; 
\quad + (8+12)\cdot P_{SP}(8,12)+(8+15)\cdot P_{SP}(8,15)+(8+16)\cdot P_{SP}(8,16)\\ &amp; 
\quad +(9+18)\cdot P_{SP}(9,18)+ (9+20)\cdot P_{SP}(9,20)\\ &amp; 
\quad +(10+24)\cdot P_{SP}(10,24) +(10+25)\cdot P_{SP}(10,25)\\ &amp;
\quad +(11+30)\cdot P_{SP}(11,30)  + (12+36)\cdot P_{SP}(12,36) \\ &amp; 
=  3\cdot \frac{1}{36}+5\cdot\frac{2}{36}+7\cdot \frac{2}{36}+8\cdot \frac{1}{36}+9\cdot \frac{2}{36}+11\cdot\frac{2}{36}+11\cdot \frac{2}{36}+14\cdot\frac{2}{36}
\\ &amp;  \quad  +15\cdot\frac{1}{36} + 13\cdot\frac{2}{36}+17\cdot\frac{2}{36}+19\cdot\frac{2}{36}+20\cdot\frac{2}{36}+23\cdot\frac{2}{36}+24\cdot\frac{1}{36}
\\ &amp; \quad+27\cdot\frac{2}{36}+29\cdot\frac{2}{36} + 34\cdot\frac{2}{36}+35\cdot\frac{1}{36}+41\cdot\frac{2}{36}+48\cdot\frac{1}{36}\\
&amp; =\frac{693}{36}= 19.25.
\end{array}
\]</span></p>
<p>Hallar el valor esperado de la suma <span class="math inline">\(E(S+P)\)</span> una vez hallada la tabla de la <strong>función de probabilidad conjunta</strong>, en <code>R</code> es bastante sencillo usando la función <code>outer</code>:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb387-1" data-line-number="1">valores.suma =<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">rownames</span>(tabla.func.prob.conjunta))</a>
<a class="sourceLine" id="cb387-2" data-line-number="2">valores.producto =<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">colnames</span>(tabla.func.prob.conjunta))</a>
<a class="sourceLine" id="cb387-3" data-line-number="3">suma.valores =<span class="st"> </span><span class="kw">outer</span>(valores.suma,valores.producto,<span class="st">&quot;+&quot;</span>)</a>
<a class="sourceLine" id="cb387-4" data-line-number="4">(<span class="dt">valor.esperado.suma =</span> <span class="kw">sum</span>(suma.valores<span class="op">*</span>tabla.func.prob.conjunta))</a></code></pre></div>
<pre><code>## [1] 19.25</code></pre>
</div>
</div>
<p><l class="observ">Observación:</l>
En <code>R</code> para hallar el valor esperado de una función <span class="math inline">\(g(X,Y)\)</span>, <span class="math inline">\(E(g(X,Y))\)</span> de las variables aleatorias <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, basta sustituir el valor <code>+</code> en el script anterior por <code>FUN=g</code>, definiendo previamente la función <code>g</code>.</p>
<div class="example">
<p><strong>Ejemplo: otra densidad (continuación)</strong></p>
Recordemos el ejemplo donde <span class="math inline">\((X,Y)\)</span> era una variable aleatoria bidimensional continua con <strong>función de densidad conjunta</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
2\cdot \mathrm{e}^{-x}\cdot\mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario.}
\end{cases}
\]</span>
Calculemos <span class="math inline">\(E(X\cdot Y)\)</span>:
<div class="example-sol">
<p><span class="math display">\[
\begin{array}{rl}
E(X\cdot Y) &amp; =\displaystyle \int_{x=0}^{x=\infty} \int_{y=0}^{y=x} 2\cdot x\cdot y \mathrm{e}^{-x}\cdot\mathrm{e}^{-y}\, dy\, dx\\
&amp; =\displaystyle  2\cdot\int_{x=0}^{x=\infty} x \cdot\mathrm{e}^{-x} \cdot\int_{y=0}^{y=x}  y \cdot\mathrm{e}^{-y}\, dy\, dx\\
&amp; =\displaystyle  2\int_{x=0}^{x=\infty}x\cdot \mathrm{e}^{-x} \left[-\mathrm{e}^{-y}\cdot (y+1)\right]_{y=0}^{y=x}\, dx\\
&amp; =\displaystyle  2\cdot\int_{x=0}^{x=\infty}x \cdot\mathrm{e}^{-x} \cdot\left(1-\mathrm{e}^{-x}(x+1)\right)\, dx \\ 
&amp;= \displaystyle 2\cdot\int_{x=0}^{x=\infty}x\cdot\left( \mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)-x^2\cdot\mathrm{e}^{-2x}\, dx \\ 
&amp; =\displaystyle  2\cdot\left[-\mathrm{e}^{-x}(x+1)+\frac{1}{4}\cdot\mathrm{e}^{-2 x}(1+2x)+\frac{1}{4} \cdot\mathrm{e}^{-2 x} \left(2 x^2+2
   x+1\right)\right]_{x=0}^{x=\infty} \\
   &amp;= \displaystyle 2\cdot \left(1-\frac{1}{4}-\frac{1}{4}\right)=1.
\end{array}
\]</span>
En el último cálculo hemos usado integración por partes para integrar <span class="math inline">\(\int x\mathrm{e}^{-x}\,dx\)</span>, <span class="math inline">\(\int x\mathrm{e}^{-2x}\,dx\)</span> y <span class="math inline">\(\int x^2\mathrm{e}^{-2x}\, dx\)</span>.</p>
</div>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Hallar <span class="math inline">\(E(X+Y)\)</span> para el ejemplo anterior.</p>
</div>
</div>
</div>
<div id="valor-esperado-de-una-función-de-dos-variables-aleatorias-independientes" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Valor esperado de una función de dos variables aleatorias independientes</h3>
<p>El siguiente resultado nos simplifica el cálculo del <strong>valor esperado de una función de dos variables aleatorias</strong> en el caso en que sean <strong>independientes</strong>:</p>
<p><l class="prop">Proposición: cálculo del valor esperado de una función de dos variables aleatorias en el caso de independencia. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensionaltal que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes.
Sea <span class="math inline">\(Z=g(X,Y)\)</span> una variable aleatoria unidimensional función de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> en la que podemos “separar” las variables <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> en la función <span class="math inline">\(g\)</span>. Es decir, existen dos funciones <span class="math inline">\(g_x\)</span> y <span class="math inline">\(g_y\)</span> tal que <span class="math inline">\(g(x,y)=g_x(x)\cdot g_y(y)\)</span> para todo valor <span class="math inline">\(x,y\in\mathbb{R}\)</span>. En este caso, el valor esperado de <span class="math inline">\(Z\)</span> se puede calcular como:
<span class="math display">\[
E(Z)=E(g(X,Y))=E_X(g_x(X))\cdot E_Y(g_y(Y)).
\]</span></p>
<p>Es decir, el cálculo de <span class="math inline">\(E(g(X,Y))\)</span> que es una suma doble en el caso de que <span class="math inline">\((X,Y)\)</span> sea <strong>discreta</strong> o una integral doble en el caso en que <span class="math inline">\((X,Y)\)</span> sea continua se transforma en el producto de dos sumas simples (caso <strong>discreto</strong>) o el producto de dos integrales simples (caso <strong>continuo</strong>):</p>
<p><span class="math display">\[
\begin{array}{rl}
E(Z) &amp; =E(g(X,Y))=\displaystyle\left(\sum_{x_i} g_x(x_i)\cdot P_X(x_i)\right)\cdot \left(\sum_{y_j} g_y(y_j)\cdot P_Y(y_j)\right),\\ &amp;\ \quad \mbox{caso discreto},\\
E(Z) &amp; =E(g(X,Y))=\displaystyle\left(\int_{-\infty}^\infty g_x(x)\cdot f_X(x)\, dx\right)\cdot \left(\int_{-\infty}^\infty g_y(y)\cdot f_Y(y)\right), \\  &amp;\ \quad \mbox{caso continuo}.
\end{array}
\]</span></p>
<p>Un caso particular de aplicación de la proposición anterior es el calculo de <span class="math inline">\(E(X\cdot Y)\)</span> cuando <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes. En este caso <span class="math inline">\(g(x,y)=x\cdot y\)</span>, <span class="math inline">\(g_x(x)=x\)</span>, y <span class="math inline">\(g_y(y)=y\)</span>.</p>
<p>Podemos escribir, por tanto:
<span class="math display">\[
E(X\cdot Y)=E_X(X)\cdot E_Y(Y).
\]</span></p>
<div id="ejemplos-4" class="section level4">
<h4><span class="header-section-number">5.6.2.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: lanzar dos veces un dado (continuación)</strong></p>
<p>Recordemos el experimento aleatorio que consiste en lanzar un dado dos veces. Sea <span class="math inline">\(X\)</span> el resultado del primer lanzamiento e <span class="math inline">\(Y\)</span>, el resultado del segundo lanzamiento.</p>
<p>Hemos visto que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes.</p>
Las marginales de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> recordemos que son las siguientes:
<div class="center">
<table style="width:100%;">
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(X\)</span> o <span class="math inline">\(Y\)</span></th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P_X(i)\)</span> o <span class="math inline">\(P_Y(i)\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
<td><span class="math inline">\(\frac{1}{6}\)</span></td>
</tr>
</tbody>
</table>
</div>
Calculemos <span class="math inline">\(E(X\cdot Y)\)</span> usando la proposición anterior:
<div class="example-sol">
<p><span class="math display">\[
E(X\cdot Y)=\displaystyle E_X(X)\cdot E_Y(Y)=\left(\sum_{i=1}^6 i\cdot \frac{1}{6}\right)\cdot \left(\sum_{i=1}^6 i\cdot \frac{1}{6}\right)=\left(\frac{21}{6}\right)^2 = 12.25.
\]</span>
Dejamos como ejercicio el cálculo de <span class="math inline">\(E(X\cdot Y)\)</span> usando la <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}\)</span> y comprobar que da el mismo resultado.</p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: densidad uniforme cuadrado unidad</strong></p>
<p>Recordemos la variable aleatoria bidimensional continua con <strong>función de densidad conjunta</strong>:
<span class="math display">\[
f_{XY}(x,y)=\displaystyle \begin{cases}
1, &amp; \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
donde vimos que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> eran independientes y de distribución uniforme en el intervalo <span class="math inline">\([0,1]\)</span>.</p>
<p>Calculemos <span class="math inline">\(E(X\cdot Y)\)</span> usando la proposición:</p>
<div class="example-sol">
<p><span class="math display">\[
\begin{array}{rl}
E(X\cdot Y)= &amp; \displaystyle E_X(X)\cdot E_Y(Y)=\int_0^1 x\cdot 1\, dx\cdot \int_0^1 y\cdot 1\, dy\\
&amp; =\left[\frac{x^2}{2}\right]_{x=0}^{x=1}\cdot \left[\frac{y^2}{2}\right]_{y=0}^{y=1}=\frac{1}{2}\cdot \frac{1}{2}=\frac{1}{4}.
\end{array}
\]</span>
Dejamos como ejercicio el cálculo de <span class="math inline">\(E(X\cdot Y)\)</span> usando la <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span> y comprobar que da el mismo resultado.</p>
</div>
</div>
</div>
</div>
<div id="momentos-conjuntos" class="section level3">
<h3><span class="header-section-number">5.6.3</span> Momentos conjuntos</h3>
<p>A continuación vamos a definir el momento de orden <span class="math inline">\((k,l)\)</span> para una variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> para intentar obtener información de su comportamiento conjunto:</p>
<p><l class="definition">Definición de momento conjunto. </l>
Sean <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional con <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}\)</span> en el caso discreto y <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span> en el caso continuo. Dados <span class="math inline">\(k\)</span> y <span class="math inline">\(l\)</span> números enteros positivos, definimos el <strong>momento conjunto de orden <span class="math inline">\((k,l)\)</span></strong> para la variable <span class="math inline">\((X,Y)\)</span> como:
<span class="math display">\[
E\left(X^k Y^l\right)=\begin{cases}
\displaystyle \sum_{x_i}\sum_{y_j} x_i^k y_j^l P_{XY}(x_i,y_j), &amp; \mbox{ caso discreto,} \\\displaystyle
\int_{-\infty}^\infty\int_{-\infty}^\infty x^k y^l f_{XY}(x,y)\, dx\, dy. &amp; \mbox{ caso continuo.}
\end{cases}
\]</span></p>
<p><l class="observ">Observación.</l>
Si consideramos <span class="math inline">\(l=0\)</span>, los momentos conjuntos de orden <span class="math inline">\((k,0)\)</span> coinciden con los momentos de orden <span class="math inline">\(k\)</span> de la variable aleatoria <span class="math inline">\(X\)</span>.</p>
<p>De la misma forma, considerando <span class="math inline">\(k=0\)</span>, los momentos conjuntos de orden <span class="math inline">\((0,l)\)</span> coinciden con los momentos de orden <span class="math inline">\(l\)</span> de la variable aleatoria <span class="math inline">\(Y\)</span>.</p>
<p>Para <span class="math inline">\(l=1\)</span> y <span class="math inline">\(k=1\)</span> obtenemos el momento de orden <span class="math inline">\((1,1)\)</span> ya visto anteriormente: <span class="math inline">\(E(X\cdot Y)\)</span>, denominado <strong>correlación entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span></strong>. Si dicha correlación es cero, <span class="math inline">\(E(X\cdot Y)=0\)</span>, se dice que las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son <strong>ortogonales</strong>.</p>
</div>
<div id="momentos-conjuntos-centrados-en-las-medias" class="section level3">
<h3><span class="header-section-number">5.6.4</span> Momentos conjuntos centrados en las medias</h3>
<p>A continuación definamos los <strong>momentos conjuntos centrados en las medias</strong>:</p>
<p><l class="definition">Definición de momento conjunto. </l>
Sean <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional con <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}\)</span> en el caso discreto y <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span> en el caso continuo. Sean <span class="math inline">\(\mu_X=E(X)\)</span> y <span class="math inline">\(\mu_Y=E(Y)\)</span> los <strong>valores esperados</strong> de las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, respectivamente. Dados <span class="math inline">\(k\)</span> y <span class="math inline">\(l\)</span> números enteros positivos, definimos el <strong>momento conjunto de orden <span class="math inline">\((k,l)\)</span> centrado en las medias</strong> para la variable <span class="math inline">\((X,Y)\)</span> como:
<span class="math display">\[
E\left((X-\mu_X)^k\cdot  (Y-\mu_Y)^l\right)=\begin{cases}
\sum_{x_i}\sum_{y_j} (x_i-\mu_X)^k \cdot (y_j-\mu_Y)^l\cdot  P_{XY}(x_i,y_j), &amp; \\\ \qquad \mbox{ caso discreto,}&amp; \\
\int_{-\infty}^\infty\int_{-\infty}^\infty (x-\mu_X)^k\cdot  (y-\mu_Y)^l\cdot  f_{XY}(x,y)\, dx\, dy. &amp; \\ \ \qquad\mbox{ caso continuo.} &amp;
\end{cases}
\]</span></p>
</div>
<div id="covariancia-entre-las-variables" class="section level3">
<h3><span class="header-section-number">5.6.5</span> Covariancia entre las variables</h3>
<p>El <strong>momento conjunto centrado en las medias para <span class="math inline">\(k=1\)</span> y <span class="math inline">\(l=1\)</span></strong> se denomina <strong>covariancia</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\mathrm{Cov}(X,Y)=E((X-\mu_X)\cdot (Y-\mu_Y)).
\]</span>
La covariancia puede calcularse a partir de la <strong>correlación</strong> entre las variables:
<span class="math display">\[
\mathrm{Cov}(X,Y)=E((X-\mu_X) \cdot (Y-\mu_Y))=E(X\cdot Y)-\mu_X\cdot \mu_Y,
\]</span></p>
<p>ya que, usando las propiedades de la esperanza, tenemos:
<span class="math display">\[
\begin{array}{rl}
E((X-\mu_X)\cdot (Y-\mu_Y)) &amp; =E(X\cdot Y-\mu_Y \cdot X-\mu_X \cdot Y+\mu_X\cdot \mu_Y)\\ &amp; =E(X\cdot Y)-\mu_Y\cdot E(X)-\mu_X \cdot E(Y)+\mu_X\cdot \mu_Y \\ &amp;  = E(X\cdot Y)-\mu_Y\cdot \mu_X-\mu_X \cdot \mu_Y+\mu_X\cdot \mu_Y \\ &amp; = E(X\cdot Y)-\mu_X\cdot \mu_Y.
\end{array}
\]</span></p>
<p><l class="observ">Observación. </l>
Si las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son <strong>independientes</strong>, su <strong>covarianza</strong> es nula ya que vimos que <span class="math inline">\(E(X\cdot Y)=\mu_X\cdot \mu_y\)</span>.</p>
<p>La <strong>covarianza</strong> es una medida de lo relacionadas están las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:</p>
<ul>
<li><p>Si cuando <span class="math inline">\(X\geq \mu_X\)</span>, también ocurre que <span class="math inline">\(Y\geq \mu_Y\)</span> o viceversa, cuando <span class="math inline">\(X\leq \mu_X\)</span>, también ocurre que <span class="math inline">\(Y\leq \mu_Y\)</span>, el valor <span class="math inline">\((X-\mu_X)(Y-\mu_Y)\)</span> será positivo y la <strong>covarianza</strong> será positiva.</p></li>
<li><p>Si por el contrario, cuando <span class="math inline">\(X\geq \mu_X\)</span>, también ocurre que <span class="math inline">\(Y\leq \mu_Y\)</span> o viceversa, cuando <span class="math inline">\(X\leq \mu_X\)</span>, también ocurre que <span class="math inline">\(Y\geq \mu_Y\)</span>, el valor <span class="math inline">\((X-\mu_X)(Y-\mu_Y)\)</span> será negativo y la <strong>covarianza</strong> será negativa.</p></li>
<li><p>En cambio, si a veces ocurre una cosa y a veces ocurre otra, la <strong>covarianza</strong> va cambiando de signo y puede tener un valor cercano a 0.</p></li>
</ul>
<div id="propiedades-de-la-covarianza" class="section level4">
<h4><span class="header-section-number">5.6.5.1</span> Propiedades de la covarianza</h4>
<ul>
<li>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Entonces la <strong>varianza de la suma/resta</strong> se calcula usando la expresión siguiente:
<span class="math display">\[
\mathrm{Var}(X\pm Y)=\mathrm{Var}(X)+\mathrm{Var}(Y)\pm 2 \mathrm{Cov}(X,Y).
\]</span></li>
</ul>
<div class="dem">
<p><strong>Demostración</strong></p>
<p>La varianza de la suma/resta de las variables es, usando la propiedad de la <strong>varianza</strong>:
<span class="math display">\[
\mathrm{Var}(X\pm Y)=E\left((X\pm Y)^2\right)-\left(E(X\pm Y)\right)^2.
\]</span>
Desarrollando las expresiones anteriores, obtenemos:
<span class="math display">\[
\begin{array}{rl}
\mathrm{Var}(X\pm Y) &amp; =E\left(X^2+Y^2\pm 2XY\right)-\left(E(X)\pm E(Y)\right)^2 \\ &amp; =
E(X^2)+E(Y^2)\pm 2\cdot E(X\cdot Y) \\ &amp;\qquad\qquad - \left(E(X)^2+E(Y)^2\pm 2\cdot E(X)\cdot E(Y)\right)
\\ &amp; = E(X^2)-E(X)^2+E(Y^2)-E(Y)^2\\ &amp;\qquad\qquad \pm 2\cdot (E(X\cdot Y)-E(X)\cdot E(Y)) \\ &amp; = \mathrm{Var}(X)+\mathrm{Var}(Y)\pm 2\cdot \mathrm{Cov}(X,Y),
\end{array}
\]</span>
tal como queríamos ver.</p>
</div>
<p>Una consecuencia de la propiedad anterior es el resultado siguiente:</p>
<p><l class="prop">Proposición: si las variables son independientes, la varianza de la suma es la suma de varianzas. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional donde las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son <strong>independientes</strong>.
Entonces:
<span class="math display">\[
\mathrm{Var}(X+Y)=\mathrm{Var}(X)+\mathrm{Var}(Y).
\]</span></p>
<div class="dem">
<p><strong>Demostración</strong></p>
<p>La demostración es muy sencilla: basta aplicar la fórmula de la varianza de la suma y tener en cuenta que, como <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes, su covarianza es cero: <span class="math inline">\(\mathrm{Cov}(X,Y)=0\)</span>.</p>
</div>
</div>
</div>
<div id="coeficiente-de-correlación-entre-las-variables" class="section level3">
<h3><span class="header-section-number">5.6.6</span> Coeficiente de correlación entre las variables</h3>
<p>La <strong>covarianza</strong> depende de las unidades en las que están las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> ya que si <span class="math inline">\(a&gt;0\)</span> y <span class="math inline">\(b&gt;0\)</span>, entonces:
<span class="math display">\[
\mathrm{Cov}(a\cdot X,b\cdot Y)=a\cdot b\cdot \mathrm{Cov}(X,Y).
\]</span>
Por tanto, si queremos “medir” la relación que existe entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> tendremos que “normalizar” la <strong>covarianza</strong> definiendo el <strong>coeficiente de correlación</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:</p>
<p><l class="definition">Definición del coeficiente de correlación. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Se define el <strong>coeficiente de correlación</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> como:
<span class="math display">\[
\rho_{XY}=\frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)}\cdot\sqrt{\mathrm{Var}(Y)}}=\frac{E(X\cdot Y)-\mu_X\cdot \mu_Y}{\sqrt{E\left(X^2\right)-\mu_X^2}\cdot \sqrt{E\left(Y^2\right)-\mu_Y^2}}.
\]</span></p>
<p><l class="observ">Observación. </l>
Si las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son <strong>independientes</strong>, su <strong>coeficiente de correlación</strong> <span class="math inline">\(\rho_{XY}=0\)</span> es nulo ya que su <strong>covarianza</strong> lo es.</p>
<p>Notemos también que la <strong>correlación</strong> no tiene unidades y es invariante a cambios de escala.</p>
<p>Además, la <strong>covarianza</strong> de las <strong>variables tipificadas</strong> <span class="math inline">\(\frac{X-\mu_X}{\sigma_X}\)</span> y <span class="math inline">\(\frac{Y-\mu_Y}{\sigma_Y}\)</span> coincide con la <strong>correlación</strong> de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
<p>El <strong>coeficiente de correlación</strong> es un valor normalizado ya que siempre está entre -1 y 1: <span class="math inline">\(-1\leq\rho_{XY}\leq 1\)</span>.</p>
<div class="dem">
<p>Para demostrar de este hecho, sean <span class="math inline">\(\mu_X=E(X)\)</span>, <span class="math inline">\(\mu_Y=E(Y)\)</span>, <span class="math inline">\(\sigma_X=\sqrt{\mathrm{Var}(X)}\)</span> y <span class="math inline">\(\sigma_Y=\sqrt{\mathrm{Var}(Y)}\)</span>.</p>
<p>Consideremos la variable <span class="math inline">\(Z=\left(\frac{X-\mu_X}{\sigma_X}\pm \frac{Y-\mu_Y}{\sigma_Y}\right)^2\)</span>. Como <span class="math inline">\(Z\geq 0\)</span>, tenemos que <span class="math inline">\(E(Z)\geq 0\)</span>. Desarrollemos el valor de <span class="math inline">\(E(Z)\)</span>:</p>
<p><span class="math display">\[
\begin{array}{rl}
E(Z) &amp; = E\left(\frac{X-\mu_X}{\sigma_X}\pm \frac{Y-\mu_Y}{\sigma_Y}\right)^2 = E\left(\left(\frac{X-\mu_X}{\sigma_X}\right)^2+\left(\frac{Y-\mu_Y}{\sigma_Y}\right)^2\pm 2\left(\frac{X-\mu_X}{\sigma_X}\right)\cdot  \left(\frac{Y-\mu_Y}{\sigma_Y}\right)\right) \\ &amp; =
E\left(\left(\frac{X-\mu_X}{\sigma_X}\right)^2\right)+E\left(\left(\frac{Y-\mu_Y}{\sigma_Y}\right)^2\right)\pm 2\cdot  E\left(\left(\frac{X-\mu_X}{\sigma_X}\right) \cdot \left(\frac{Y-\mu_Y}{\sigma_Y}\right)\right) \\ &amp; =
\frac{1}{\sigma_X^2}E\left(\left(X-\mu_X\right)^2\right)+\frac{1}{\sigma_Y^2}E\left(\left(Y-\mu_Y\right)^2\right)\pm \frac{2}{\sigma_X\cdot \sigma_Y}E\left(\left(X-\mu_X\right) \left(Y-\mu_Y\right)\right) \\ &amp; = \frac{1}{\sigma_X^2}\sigma_X^2+
\frac{1}{\sigma_Y^2}\sigma_Y^2 \pm\frac{2}{\sigma_X\cdot \sigma_Y} \mathrm{Cov}(X,Y) = 1+1\pm 2\cdot \frac{\mathrm{Cov}(X,Y)}{\sigma_X\sigma_Y}=2\cdot (1\pm\rho_{XY})
\end{array}
\]</span></p>
<p>Ahora, como <span class="math inline">\(E(Z)\geq 0\)</span>, tenemos que <span class="math inline">\(1\pm \rho_{XY}\geq 0\)</span>, lo que significa que, por un lado <span class="math inline">\(1+\rho_{XY}\geq 0\)</span> y, por otro, <span class="math inline">\(1-\rho_{XY}\geq 0\)</span>. De la primera inecuación, deducimos que <span class="math inline">\(\rho_{XY}\geq -1\)</span> y de la segunda, <span class="math inline">\(\rho_{XY}\leq 1\)</span>.</p>
<p>En resumen, <span class="math inline">\(-1\leq\rho_{XY}\leq 1\)</span>, tal como queríamos ver.</p>
</div>
<div id="ejemplos-5" class="section level4">
<h4><span class="header-section-number">5.6.6.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: otra densidad (continuación)</strong></p>
<p>Hallemos el <strong>coeficiente de correlación</strong> para el ejemplo de la variable aleatoria bidimensional continua con <strong>función de densidad conjunta</strong>:</p>
<p><span class="math display">\[
f_{XY}(x,y)=\begin{cases}
2\cdot  \mathrm{e}^{-x}\cdot \mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario,}
\end{cases}
\]</span>
Recordemos los cálculos realizados anteriormente:</p>
<div class="example-sol">
<ul>
<li><p><span class="math inline">\(E(X\cdot Y)=1.\)</span></p></li>
<li><p><span class="math inline">\(f_X(x)=2\cdot \left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\)</span>, si <span class="math inline">\(x\geq 0\)</span>. Su esperanza es:</p></li>
</ul>
<p><span class="math display">\[
\begin{array}{rl}
E(X)&amp;=\int_0^\infty x\cdot 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx=2 \left[\frac{1}{4} \mathrm{e}^{-2 x} (2 x+1)-\mathrm{e}^{-x}(x+1)\right]_0^\infty \\
&amp; = 2\left(1-\frac{1}{4}\right)=\frac{3}{2}.
\end{array}
\]</span></p>
<p>Calculemos a continuación su varianza: <span class="math inline">\(\mathrm{Var}(X)=E\left(X^2\right)-\mu_X^2\)</span>. El valor de <span class="math inline">\(E\left(X^2\right)\)</span> es:
<span class="math display">\[
\begin{array}{rl}
E\left(X^2\right) &amp; =\displaystyle \int_0^\infty x^2 \cdot 2\cdot \left(\mathrm{e}^{-x}-\mathrm{e}^{-2\cdot x}\right)\, dx\\
&amp;=\displaystyle 2 \cdot  \left[\frac{1}{4} \cdot \mathrm{e}^{-2 \cdot x} \cdot  (2\cdot x^2+2\cdot x+1)- \mathrm{e}^{-x} \cdot (x^2+2\cdot x+2)\right]_0^\infty \\ &amp; = 2\cdot \left(2-\frac{1}{4}\right)=\frac{7}{2}.
\end{array}
\]</span></p>
<p>El valor de la varianza de <span class="math inline">\(X\)</span> es: <span class="math inline">\(\mathrm{Var}(X)=\frac{7}{2}-\left(\frac{3}{2}\right)^2 = \frac{5}{4}.\)</span></p>
<ul>
<li>La variable <span class="math inline">\(Y\)</span> era exponencial de parámetro <span class="math inline">\(\lambda =2\)</span>. Por tanto, <span class="math inline">\(E(Y)=\frac{1}{2}\)</span>, <span class="math inline">\(\mathrm{Var}(Y)=\frac{1}{4}\)</span>.</li>
</ul>
<p>El <strong>coeficiente de correlación</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> es:
<span class="math display">\[
\rho_{XY}=\frac{E(X\cdot Y)-\mu_X\cdot \mu_Y}{\sqrt{\mathrm{Var}(X)}\cdot\sqrt{\mathrm{Var}(Y)}}=\frac{1-\frac{3}{2}\cdot \frac{1}{2}}{\sqrt{\frac{5}{4}}\cdot\sqrt{\frac{1}{4}}}=\frac{\sqrt{5}}{5}\approx 0.447.
\]</span>
Vemos que la <strong>correlación</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> es positiva pero no demasiado ya que su valor no está cercano a 1.</p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: normal bidimensional</strong></p>
<p>Recordemos que la <strong>función de densidad</strong> de la variable aleatoria <strong>normal bidimensional</strong> es:
<span class="math inline">\(f_{XY}(x,y)=\frac{1}{2\cdot \pi\cdot \sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\cdot \rho \cdot x\cdot y+y^2)}{2\cdot (1-\rho^2)}},\ -\infty &lt;x,y&lt;\infty.\)</span></p>
<p>Las <strong>variables aleatorias marginales</strong> son normales estándar o <span class="math inline">\(N(0,1)\)</span>.</p>
<p>Hallemos el <strong>coeficiente de correlación <span class="math inline">\(\rho_{XY}\)</span></strong> en este caso.</p>
<div class="example-sol">
<p>Calculemos <span class="math inline">\(E(X\cdot Y)\)</span>:</p>
<p><span class="math display">\[
\begin{array}{rl}
E(X\cdot Y) &amp; = \displaystyle\int_{-\infty}^\infty x y \frac{1}{2\cdot\cdot\pi\cdot\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho\cdot x\cdot y+y^2)}{2(1-\rho^2)}}\, dy\, dx \\
&amp; = \displaystyle\frac{1}{2\pi\sqrt{1-\rho^2}}\int_{x=-\infty}^{x=\infty}x\cdot  \mathrm{e}^{-\frac{x^2}{2\cdot(1-\rho^2)}}\int_{y=-\infty}^{y=\infty}y \mathrm{e}^{-\frac{(-2\cdot\rho\cdot  x\cdot y+y^2)}{2\cdot(1-\rho^2)}}\, dy\, dx \\ &amp; = \displaystyle\frac{1}{2\cdot\pi\cdot\sqrt{1-\rho^2}}\int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}\cdot{2(1-\rho^2)}}  \mathrm{e}^{\frac{\rho^2\cdot x^2}{2\cdot(1-\rho^2)}} \int_{y=-\infty}^{y=\infty}y \mathrm{e}^{-\frac{(y-\rho y)^2}{2\cdot(1-\rho^2)}}\, dy\, dx,\\ &amp;\ \qquad\mbox{ cambio de variable en la segunda integral } z=\frac{y-\rho x}{\sqrt{1-\rho^2}},\\
&amp; = \displaystyle\frac{1}{2\pi\sqrt{1-\rho^2}}\int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}{2}}  \int_{z=-\infty}^{z=\infty} \left(z \sqrt{1-\rho^2}+\rho x\right) \sqrt{1-\rho^2}\mathrm{e}^{-\frac{z^2}{2}}\, dz\, \\
&amp; = \displaystyle\frac{1}{2\pi} \int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}{2}}\left(\sqrt{1-\rho^2}\int_{z=-\infty}^{z=\infty} z\cdot \mathrm{e}^{-\frac{z^2}{2}}\, dz +\rho\cdot x \int_{z=-\infty}^{z=\infty}\mathrm{e}^{-\frac{z^2}{2}}\, dz \right)\, dx
\end{array}
\]</span></p>
<p>Ahora, usando que el valor esperado de una variable <span class="math inline">\(N(0,1)\)</span> es cero tenemos que:
<span class="math inline">\(\int_{z=-\infty}^{z=\infty} z \mathrm{e}^{-\frac{z^2}{2}}\, dz =0,\)</span> y usando que la integral de la <strong>función de densidad</strong> de la <span class="math inline">\(N(0,1)\)</span> (<span class="math inline">\(\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{z^2}{2}}\)</span>) sobre todo <span class="math inline">\(\mathbb{R}\)</span> es 1, tenemos que:
<span class="math inline">\(\int_{z=-\infty}^{z=\infty} \mathrm{e}^{-\frac{z^2}{2}}\, dz =\sqrt{2\pi}.\)</span></p>
<p>Por tanto,
<span class="math display">\[
E(X\cdot Y)=\frac{\rho}{2\pi} \int_{x=-\infty}^{x=\infty} x^2  \mathrm{e}^{-\frac{x^2}{2}}\sqrt{2\pi}\, dx=\frac{\rho}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} x^2  \mathrm{e}^{-\frac{x^2}{2}}\, dx.
\]</span>
Por último, usando que la varianza de la distribución <span class="math inline">\(Z=N(0,1)\)</span> es 1, tenemos que <span class="math inline">\(\mathrm{Var}(Z)=E\left(Z^2\right)-E(Z)^2\)</span>. Como <span class="math inline">\(E(Z)=0\)</span>, deducimos que <span class="math inline">\(E\left(Z^2\right)=1\)</span>:
<span class="math display">\[
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty x^2\mathrm{e}^{-\frac{x^2}{2}}\, dx=1,\ \Rightarrow \int_{-\infty}^\infty x^2\mathrm{e}^{-\frac{x^2}{2}}\, dx=\sqrt{2\pi}.
\]</span>
El valor de <span class="math inline">\(E(X\cdot Y)\)</span> es:
<span class="math display">\[
E(X\cdot Y)=\frac{\rho}{\sqrt{2\pi}}\sqrt{2\pi}=\rho.
\]</span></p>
<p>La correlación entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> es precisamente <span class="math inline">\(\rho\)</span>.</p>
<p>Ahora, usando que <span class="math inline">\(\mu_X=\mu_Y=0\)</span> y <span class="math inline">\(\sigma_X=\sigma_Y=1\)</span> ya que recordemos que las marginales son <span class="math inline">\(N(0,1)\)</span>, el <strong>coeficiente de correlación</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> es:
<span class="math display">\[
\rho_{XY}=\frac{E(X\cdot Y)-\mu_X\cdot \mu_Y}{\sqrt{\mathrm{Var}(X)}\cdot\sqrt{\mathrm{Var}(Y)}}=\frac{\rho-0\cdot 0}{1\cdot 1}=\rho.
\]</span>
Por tanto, <span class="math inline">\(\rho\)</span> es el <strong>coeficiente de correlación</strong> entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> y mide lo correlacionadas que están dichas variables.</p>
</div>
</div>
</div>
</div>
<div id="incorrelación-e-independencia" class="section level3">
<h3><span class="header-section-number">5.6.7</span> Incorrelación e independencia</h3>
<p>Hemos visto que si dos variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son <strong>independientes</strong>, entonces son <strong>incorreladas</strong>, es decir, la <strong>covarianza</strong> es 0 (<span class="math inline">\(E(X\cdot Y)=E(X)\cdot E(Y)\)</span>).</p>
<p>El recíproco, sin embargo, es falso. Veamos un ejemplo de variables <strong>incorreladas</strong> que no son independientes.</p>
<div class="example">
<p><strong>Ejemplo de variables aleatorias incorreladas pero no independientes</strong></p>
<p>Consideremos la variable aleatoria bidimensional continua con <strong>función de densidad</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
\frac{3}{8}(x^2+y^2), &amp; \mbox{si }(x,y)\in [-1,1]\times [-1,1],\\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span></p>
<p>Dejamos como ejercicio comprobar que es una <strong>función de densidad</strong>. Es decir, que es positiva y que la integral sobre todo el plano vale 1.</p>
<div class="example-sol">
<p>Calculemos las <strong>densidades marginales</strong>:</p>
<p><span class="math display">\[
\begin{array}{rl}
f_X(x) &amp; = \int_{-1}^{1} \frac{3}{8}\cdot (x^2+y^2)\, dy = \frac{3}{8}\cdot\left[x^2\cdot y+\frac{y^3}{3}\right]_{-1}^1 =\frac{3}{8}\cdot\left(2 \cdot x^2+\frac{2}{3}\right)=\frac{3}{4}
\cdot x^2+\frac{1}{4}, \\
f_Y(y) &amp; = \int_{-1}^{1} \frac{3}{8}\cdot(x^2+y^2)\, dx = \frac{3}{8}\cdot\left[\frac{x^3}{3}+y^2 x\right]_{-1}^1 =\frac{3}{8}\cdot\left(\frac{2}{3}+2 y^2+\right)=\frac{3}{4}\cdot y^2+\frac{1}{4}.
\end{array}
\]</span></p>
<p>Los valores esperados de cada variable <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son:</p>
<p><span class="math display">\[
\begin{array}{rl}
E(X) &amp; =\int_{-1}^1 x \cdot\left(\frac{3}{4} \cdot x^2+\frac{1}{4}\right)\, dx =0, \mbox{al integrar una función impar,}\\
E(Y) &amp; =\int_{-1}^1 x \left(\frac{3}{4}\cdot y^2+\frac{1}{4}\right)\, dx =0, \mbox{al integrar una función impar.}
\end{array}
\]</span></p>
<p>El valor de la <strong>correlación</strong> entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> es:</p>
<p><span class="math display">\[
\begin{array}{rl}
E(X\cdot Y) &amp; =\int_{-1}^1\int_{-1}^1 x \cdot y \cdot \frac{3}{8}\cdot (x^2+y^2)\, dy\, dx\\ &amp; =\frac{3}{8}\cdot\left(\int_{-1}^1\int_{-1}^1 x^3 \cdot y\, dy \, dx+\int_{-1}^1\int_{-1}^1 x\cdot y^3\, dy \, dx\right) \\ &amp; = \frac{3}{8} \left(\int_{x=-1}^{x=1}x^3 \left[\frac{y^2}{2}\right]_{y=-1}^{y=1}\, dx + \int_{y=-1}^{y=1}y^3 \left[\frac{x^2}{2}\right]_{x=-1}^{x=1}\right)=0.
\end{array}
\]</span></p>
<p>El <strong>coeficiente de correlación</strong> entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> es: <span class="math inline">\(\rho_{XY}=E(X\cdot Y)-E(X)\cdot E(Y)=0-0\cdot 0=0\)</span>. Por tanto, son <strong>incorreladas</strong>.</p>
<p>En cambio no son <strong>independientes</strong> ya que claramente si <span class="math inline">\((x,y)\in [-1,1]\times [-1,1]\)</span>,</p>
<p><span class="math display">\[
f_{XY}(x,y)=\frac{3}{8}(x^2+y^2) \neq f_X(x)\cdot f_Y(y)=\left(\frac{3}{4} x^2+\frac{1}{4}\right)\cdot \left(\frac{3}{4} y^2+\frac{1}{4}\right).
\]</span></p>
</div>
</div>
</div>
</div>
<div id="variables-aleatorias-condicionales-y-valor-esperado-condicional" class="section level2">
<h2><span class="header-section-number">5.7</span> Variables aleatorias condicionales y valor esperado condicional</h2>
<p>Muchas <strong>variables aleatorias bidimensionales</strong> de interés práctico no son independientes.</p>
<p>Por ejemplo, la salida <span class="math inline">\(Y\)</span> de un canal de comunicación debe depender de la entrada <span class="math inline">\(X\)</span> para transmitir información.</p>
<p>En esta sección vamos a introducir variables aleatorias <span class="math inline">\(Y\)</span> cuya distribución depende de otras <span class="math inline">\(X\)</span>. Dichas variables se denominan <strong>variables aleatorias condicionales</strong>.</p>
<p>También nos interesa el valor esperado de la <strong>variable condicional</strong> <span class="math inline">\(Y\)</span> suponiendo que conocemos <span class="math inline">\(X=x\)</span>.</p>
<div id="variables-aleatorias-condicionales-discretas" class="section level3">
<h3><span class="header-section-number">5.7.1</span> Variables aleatorias condicionales discretas</h3>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Sea <span class="math inline">\(B\)</span> un subconjunto de los números reales <span class="math inline">\(\mathbb{R}\)</span>. Recordemos que la <strong>probabilidad condicional</strong> del suceso <span class="math inline">\(\{Y\in B\}\)</span> suponiendo que <span class="math inline">\(X=x\)</span> se definía de la forma siguiente:
<span class="math display">\[
P(Y\in B|X=x)=\frac{P(Y\in B,\ X=x)}{P(X=x)}, \mbox{ siempre que }P(X=x)&gt;0.
\]</span></p>
<p>La definición anterior motiva la definición siguiente de <strong>variable aleatoria condicional discreta</strong>:</p>
<p><l class="definition">Definición de variable aleatoria condicional discreta. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional discreta con conjunto de valores <span class="math inline">\((X,Y)(\Omega)=\{(x_i,y_j)\ i=1,2,\ldots, j=1,2,\ldots\}\)</span> y <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}\)</span>. Sean <span class="math inline">\(x_i\)</span> un valor de <span class="math inline">\(X(\Omega)\)</span> con <span class="math inline">\(P(X=x_i)&gt;0\)</span>. Entonces definimos la <strong>función de probabilidad</strong> de la <strong>variable aleatoria condicional discreta</strong> <span class="math inline">\(Y|X=x_i\)</span> como:
<span class="math display">\[
P_{Y|X=x_i}(y_j)=P(Y=y_j|X=x_i)=\frac{P(X=x_i,\ Y=y_j)}{P(X=x_i)}=\frac{P_{XY}(x_i,y_j)}{P_X(x_i)}.
\]</span></p>
<p>¡<l class="observ">Observación. </l>
La <strong>función de probabilidad</strong> de la <strong>variable aleatoria condicional <span class="math inline">\(Y|X=x_i\)</span></strong> depende únicamente de la <strong>función de probabilidad conjunta</strong> de la variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span>.</p>
<l class="observ">Observación. </l>
Al ser <span class="math inline">\(Y|X=x_i\)</span> una variable aleatoria unidimensional, su <strong>función de probabilidad</strong> tiene que verificar que la suma de todos sus valores tiene que dar 1. Es decir:
<span class="math display">\[
\sum_{y_j} P(Y=y_j|X=x_i)=1.
\]</span>
Veámoslo:
<div class="dem">
<p><span class="math display">\[
\begin{array}{rl}
\sum_{y_j} P(Y=y_j|X=x_i) &amp;=\displaystyle \sum_{y_j} \frac{P_{XY}(x_i,y_j)}{P_X(x_i)}=\frac{1}{P_X(x_i)}\sum_{y_j} P_{XY}(x_i,y_j) \\ 
&amp;=\frac{1}{P_X(x_i)}\cdot P_X(x_i)=1.
\end{array}
\]</span></p>
</div>
<p><l class="observ">Observación. </l>
Si <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes, la distribución de <span class="math inline">\(Y|X=x_iY\)</span> es la misma que la de <span class="math inline">\(Y\)</span>, es decir, la <strong>variable aleatoria condicional <span class="math inline">\(Y|X=x_i\)</span></strong> coincide con <span class="math inline">\(Y\)</span>. Es decir, condicionar con <span class="math inline">\(X=x_i\)</span> no tiene ningún efecto sobre <span class="math inline">\(Y\)</span>.</p>
<div class="dem">
<p>Efectivamente, veamos que <span class="math inline">\(P_{Y|X=x_i}(y_j)=P_Y(y_j)\)</span> para todo valor <span class="math inline">\(y_j\)</span> de <span class="math inline">\(Y(\Omega)\)</span>:</p>
<p><span class="math display">\[
\begin{array}{rl}
P_{Y|X=x_i}(y_j) &amp;=\frac{P_{XY}(x_i,y_j)}{P_X(x_i)} \stackrel{\mbox{Por ser independientes}}{=}\frac{P_Y(y_j)\cdot P_X(x_i)}{P_X(x_i)}\\
&amp; =P_Y(y_j).
\end{array}
\]</span></p>
</div>
<p><l class="observ">Observación. </l>
La definición de la <strong>función de probabilidad</strong> de la <strong>variable aleatoria condicional <span class="math inline">\(X|Y=y_j\)</span></strong> se definiría de forma similar:</p>
<p><span class="math display">\[
P_{X|Y=y_j}(x_i)=P(X=x_i|Y=y_j)=\frac{P(X=x_i,\ Y=y_j)}{P(Y=y_j)}=\frac{P_{XY}(x_i,y_j)}{P_Y(y_j)}, 
\]</span>
para todo <span class="math inline">\(x_i\in X(\Omega)\)</span>.</p>
<p><l class="observ">Observación.</l>
Si tenemos la tabla de la <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}\)</span>, para hallar la <strong>función de distribución de la variable <span class="math inline">\(Y|X=x_i\)</span></strong> es equivalente a considerar la fila del valor <span class="math inline">\(x_i\)</span> a la tabla y dividir todos los valores de la fila por la suma de los valores en dicha fila:</p>
<div class="center">
<table>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(Y|X=x_i\)</span></th>
<th><span class="math inline">\(y_1\)</span></th>
<th><span class="math inline">\(y_2\)</span></th>
<th><span class="math inline">\(\ldots\)</span></th>
<th><span class="math inline">\(y_N\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P_{Y|X=x_i}\)</span></td>
<td><span class="math inline">\(\frac{P_{XY}(x_i,y_1)}{P_X(x_i)}\)</span></td>
<td><span class="math inline">\(\frac{P_{XY}(x_i,y_2)}{P_X(x_i)}\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(\frac{P_{XY}(x_i,y_N)}{P_X(x_i)}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p><l class="observ">Observación.</l>
De la misma manera, si tenemos la tabla de la <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}\)</span>, para hallar la <strong>función de distribución de la variable <span class="math inline">\(X|Y=y_j\)</span></strong> es equivalente a considerar la columna del valor <span class="math inline">\(y=y_j\)</span> a la tabla y dividir todos los valores de la columna por la suma de los valores en dicha columna:</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(X|Y=y_j\)</span></th>
<th><span class="math inline">\(P_{X|Y=y_j}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x_1\)</span></td>
<td><span class="math inline">\(\frac{P_{XY}(x_1,y_j)}{P_Y(y_j)}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x_M\)</span></td>
<td><span class="math inline">\(\frac{P_{XY}(x_M,y_j)}{P_Y(y_j)}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="ejemplos-6" class="section level4">
<h4><span class="header-section-number">5.7.1.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado</strong></p>
<p>Vamos a hallar la <strong>variable aleatoria condicional <span class="math inline">\(S|P=12\)</span></strong>.</p>
<p>Tenemos calculada la tabla de la <strong>función de probabilidad conjunta <span class="math inline">\(P_{SP}\)</span></strong>.</p>
<p>Si <span class="math inline">\(P=12\)</span>, los únicos valores <span class="math inline">\(x_i\)</span> de <span class="math inline">\(S(\Omega)\)</span> para los que se verifica <span class="math inline">\(P_{SP}(x_i,12)\neq 0\)</span> son 7 y 8.</p>
<p>Además si calculamos <span class="math inline">\(P_P(12)\)</span>, obtenemos <span class="math inline">\(P(P=12)=\frac{4}{36}\)</span> ya que hay 4 casos en que el producto da 12: <span class="math inline">\((3,4), (4,3), (2,6)\)</span> y <span class="math inline">\((6,2)\)</span>.</p>
<p>Por tanto, la tabla de la <strong>función de probabilidad condicional</strong> de la variable <span class="math inline">\(S|P=12\)</span> es:</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(S|P=12\)</span></th>
<th><span class="math inline">\(P_{S|P=12}\)</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(7\)</span></td>
<td><span class="math inline">\(\frac{\frac{2}{36}}{\frac{4}{36}}=\frac{1}{2}\)</span></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(8\)</span></td>
<td><span class="math inline">\(\frac{\frac{2}{36}}{\frac{4}{36}}=\frac{1}{2}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="example">
<p><strong>Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado</strong></p>
<p>Vamos a hallar la <strong>variable aleatoria condicional <span class="math inline">\(P|S=8\)</span></strong>.</p>
<div class="example-sol">
<p>Si <span class="math inline">\(S=8\)</span>, los únicos valores <span class="math inline">\(y_j\)</span> de <span class="math inline">\(P(\Omega)\)</span> para los que se verifica <span class="math inline">\(P_{SP}(8,y_j)\neq 0\)</span> son 12 y 15 y 16.</p>
<p>El valor de <span class="math inline">\(P_S(8)\)</span> recordemos que valía: <span class="math inline">\(P_S(8)=\frac{5}{36}\)</span>.</p>
<p>Por tanto, la tabla de la <strong>función de probabilidad condicional</strong> de la variable <span class="math inline">\(P|S=8\)</span> es:</p>
<div class="center">
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(P|S=8\)</span></th>
<th><span class="math inline">\(12\)</span></th>
<th><span class="math inline">\(15\)</span></th>
<th><span class="math inline">\(16\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P_{P|S=8}\)</span></td>
<td><span class="math inline">\(\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}\)</span></td>
<td><span class="math inline">\(\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}\)</span></td>
<td><span class="math inline">\(\frac{\frac{1}{36}}{\frac{5}{36}}=\frac{1}{5}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Para hallar la <strong>variable aleatoria condicional</strong> <span class="math inline">\(S|P=12\)</span> hemos de condicionar por la columna <span class="math inline">\(P=12\)</span> en la tabla de la <strong>función de probabilidad conjunta</strong>:</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb389-1" data-line-number="1">prob.cond.p12=tabla.func.prob.conjunta[,valores.producto<span class="op">==</span><span class="dv">12</span>]<span class="op">/</span></a>
<a class="sourceLine" id="cb389-2" data-line-number="2"><span class="st">  </span><span class="kw">sum</span>(tabla.func.prob.conjunta[,valores.producto<span class="op">==</span><span class="dv">12</span>])</a>
<a class="sourceLine" id="cb389-3" data-line-number="3">prob.cond.p12</a></code></pre></div>
<pre><code>##   2   3   4   5   6   7   8   9  10  11  12 
## 0.0 0.0 0.0 0.0 0.0 0.5 0.5 0.0 0.0 0.0 0.0</code></pre>
<p>El problema es que aparecen valores con <strong>función de probabilidad marginal</strong> nulos. Para eliminarlos hacemos lo siguiente:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb391-1" data-line-number="1">prob.cond.p12.buena =<span class="st"> </span>prob.cond.p12[prob.cond.p12<span class="op">!=</span><span class="dv">0</span>]</a>
<a class="sourceLine" id="cb391-2" data-line-number="2">prob.cond.p12.buena</a></code></pre></div>
<pre><code>##   7   8 
## 0.5 0.5</code></pre>
<p>Para hallar la <strong>función de probabilidad marginal</strong> <span class="math inline">\(P|S=8\)</span>, haríamos lo siguiente:</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb393-1" data-line-number="1">prob.cond.s8=tabla.func.prob.conjunta[valores.suma<span class="op">==</span><span class="dv">8</span>,]<span class="op">/</span></a>
<a class="sourceLine" id="cb393-2" data-line-number="2"><span class="st">  </span><span class="kw">sum</span>(tabla.func.prob.conjunta[valores.suma<span class="op">==</span><span class="dv">8</span>,])</a>
<a class="sourceLine" id="cb393-3" data-line-number="3">(<span class="dt">prob.cond.s8.buena =</span> prob.cond.s8[prob.cond.s8<span class="op">!=</span><span class="dv">0</span>])</a></code></pre></div>
<pre><code>##  12  15  16 
## 0.4 0.4 0.2</code></pre>
</div>
</div>
</div>
</div>
<div id="variables-aleatorias-condicionales-continuas" class="section level3">
<h3><span class="header-section-number">5.7.2</span> Variables aleatorias condicionales continuas</h3>
<p>La definición en el caso continua se hace cambiando la <strong>función de probabilidad</strong> por la <strong>función de densidad</strong>:</p>
<p><l class="definition">Definición de variable aleatoria condicional discreta. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional continua con <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span>. Sean <span class="math inline">\(x\in\mathbb{R}\)</span> con <span class="math inline">\(f_X(x)&gt;0\)</span>. Entonces definimos la <strong>función de densidad</strong> de la <strong>variable aleatoria condicional continua</strong> <span class="math inline">\(Y|X=x\)</span> como:
<span class="math display">\[
f_{Y|X=x}(y)=\frac{f_{XY}(x,y)}{f_X(x)}.
\]</span></p>
<p><l class="observ">Observación. </l>
La <strong>función de densidad</strong> de la <strong>variable aleatoria condicional continua<span class="math inline">\(Y|X\)</span></strong> depende únicamente de la <strong>función de densidad conjunta</strong> de la variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span>.</p>
<p><l class="observ">Observación. </l>
Al ser <span class="math inline">\(Y|X=x\)</span> una variable aleatoria unidimensional, su <strong>función de densidad</strong> tiene que verificar que la integral de dicha función sobre todo <span class="math inline">\(\mathbb{R}\)</span> tiene que ser 1. Es decir:</p>
<p><span class="math display">\[
\int_{-\infty}^\infty f_{Y|X=x}(y)\, dy=1.
\]</span></p>
Veámoslo:
<div class="dem">
<p><span class="math display">\[
\begin{array}{rl}
\int_{-\infty}^\infty f_{Y|X=x}(y)\, dy &amp; =\int_{-\infty}^\infty \frac{f_{XY}(x,y)}{f_X(x)}\, dy=\frac{1}{f_X(x)}\int_{-\infty}^\infty f_{XY}(x,y)\, dy\\
&amp; = \frac{1}{f_X(x)}\cdot f_X(x) =1.
\end{array}
\]</span></p>
</div>
<p><l class="observ">Observación. </l>
Si <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes, <span class="math inline">\(Y|X=x =Y\)</span>, es decir, la <strong>variable aleatoria condicional <span class="math inline">\(Y|X=x\)</span></strong> coincide con <span class="math inline">\(Y\)</span>. Es decir, condicionar con <span class="math inline">\(X=x\)</span> no tiene ningún efecto sobre <span class="math inline">\(Y\)</span>.</p>
<div class="dem">
<p>Efectivamente, veamos que <span class="math inline">\(f_{Y|X=x}(y)=f_Y(y)\)</span> para todo valor <span class="math inline">\(y\in\mathbb{R}.\)</span></p>
<p><span class="math display">\[
f_{Y|X=x}(y) =\displaystyle \frac{f_{XY}(x,y)}{f_X(x)} \stackrel{\mbox{Al ser independientes}}{=}\frac{f_Y(y)\cdot f_X(x)}{f_X(x)}=f_Y(y).
\]</span></p>
</div>
<p><l class="observ">Observación. </l>
La definición de la <strong>función de densidad</strong> de la <strong>variable aleatoria condicional <span class="math inline">\(X|Y=y\)</span></strong> se definiría de forma similar:
<span class="math display">\[
f_{X|Y=y}(x)=\frac{f_{XY}(x,y)}{f_Y(y)},
\]</span>
para todo <span class="math inline">\(x\in\mathbb{R}\)</span>.</p>
<div id="ejemplos-7" class="section level4">
<h4><span class="header-section-number">5.7.2.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo: otra función de densidad (continuación)</strong></p>
<p>Recordemos el ejemplo de la variable aleatoria bidimensional continua con <strong>función de densidad</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
2 \cdot \mathrm{e}^{-x}\cdot \mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario,}
\end{cases}
\]</span>
Dado un valor <span class="math inline">\(x_0\geq 0\)</span> cualquiera, vamos a hallar la <strong>función de densidad</strong> de la <strong>variable aleatoria condicional</strong> <span class="math inline">\(Y|X=x_0\)</span>.</p>
<div class="example-sol">
<p>Fijémonos que, fijado un valor <span class="math inline">\(x_0\)</span>, los valores <span class="math inline">\(y\)</span> para los cuales <span class="math inline">\(f_{XY}(x_0,y)\neq 0\)</span> cumplen <span class="math inline">\(0\leq y\leq x_0\)</span>.
Por tanto,</p>
<p><span class="math display">\[
f_{Y|X=x_0}(y)=\frac{f_{XY}(x_0,y)}{f_X(x_0)}=\frac{2\cdot \mathrm{e}^{-x_0}\cdot \mathrm{e}^{-y}}{f_X(x_0)},
\]</span>
si <span class="math inline">\(0\leq y\leq x_0\)</span>, y <span class="math inline">\(f_{Y|X=x_0}(y)=0\)</span>, en caso contrario.</p>
<p>Recordemos que la <strong>densidad marginal</strong> de la variable <span class="math inline">\(X\)</span> era: <span class="math inline">\(f_X(x_0)=2\left(\mathrm{e}^{-x_0}-\mathrm{e}^{-2x_0}\right)\)</span>.</p>
<p>La <strong>función de densidad marginal</strong> de la variable <span class="math inline">\(Y|X=x_0\)</span> es:</p>
<p><span class="math display">\[
f_{Y|X=x_0}(y)=\frac{2\cdot \mathrm{e}^{-x_0}\cdot \mathrm{e}^{-y}}{2\cdot \left(\mathrm{e}^{-x_0}-\mathrm{e}^{-2\cdot x_0}\right)}=\frac{e^{-y}}{1-\mathrm{e}^{-x_0}},
\]</span></p>
<p>si <span class="math inline">\(0\leq y\leq x_0\)</span>, y <span class="math inline">\(f_{Y|X=x_0}(y)=0\)</span>, en caso contrario.</p>
<p>Sea ahora <span class="math inline">\(y_0&gt;0\)</span>. Calculemos ahora la <strong>densidad marginal</strong> de la variable <span class="math inline">\(X|Y=y_0\)</span>.</p>
<p>Fijémonos que, fijado un valor <span class="math inline">\(y_0\)</span>, los valores <span class="math inline">\(x\)</span> para los cuales <span class="math inline">\(f_{XY}(x,y_0)\neq 0\)</span> cumplen <span class="math inline">\(y_0\leq x\leq \infty\)</span>. Por tanto,</p>
<p><span class="math display">\[
f_{X|Y=y_0}(x)=\frac{f_{XY}(x,y_0)}{f_Y(y_0)}=\frac{2\cdot \mathrm{e}^{-x}\cdot \mathrm{e}^{-y_0}}{f_Y(y_0)},
\]</span>
si <span class="math inline">\(y_0\leq x\leq \infty\)</span>, y <span class="math inline">\(f_{X|Y=y_0}(x)=0\)</span>, en caso contrario.</p>
<p>Recordemos que la variable <span class="math inline">\(Y\)</span> era exponencial de parámetro <span class="math inline">\(\lambda=2\)</span>. Por tanto, <span class="math inline">\(f_Y(y_0)=2\mathrm{e}^{-2y_0}\)</span>.</p>
<p>La <strong>función de densidad marginal</strong> de la variable <span class="math inline">\(X|Y=y_0\)</span> es:</p>
<p><span class="math display">\[
f_{X|Y=y_0}(x)=\frac{2\cdot \mathrm{e}^{-x}\cdot \mathrm{e}^{-y_0}}{2\cdot \mathrm{e}^{-2\cdot y_0}}=\frac{\mathrm{e}^{-x}}{\mathrm{e}^{-y_0}},
\]</span>
si <span class="math inline">\(y_0\leq x\leq \infty\)</span>, y <span class="math inline">\(f_{X|Y=y_0}(x)=0\)</span>, en caso contrario.</p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: normal bidimensional</strong></p>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional normal bidimensional con <strong>densidad conjunta</strong>:</p>
<p><span class="math display">\[
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty &lt;x,y&lt;\infty.
\]</span>
Sea <span class="math inline">\(x\in\mathbb{R}\)</span>. Hallemos la <strong>función de densidad</strong> de la <strong>variable aleatoria condicionada</strong> <span class="math inline">\(Y|X=x\)</span>.</p>
<div class="example-sol">
<p>Recordemos que las <strong>marginales</strong> eran <span class="math inline">\(N(0,1)\)</span>. Por tanto, <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}.\)</span></p>
<p>La <strong>función de densidad</strong> de la variable condicional <span class="math inline">\(Y|X=x\)</span> es:</p>
<p><span class="math display">\[
\begin{array}{rl}
f_{Y|X=x}(y) &amp; =  \frac{f_{XY}(x,y)}{f_X(x)}=\frac{\frac{1}{2\cdot \pi\cdot \sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\cdot \rho \cdot x\cdot y+y^2)}{2(1-\rho^2)}}}{\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}}\\
&amp; =\frac{1}{\sqrt{2\cdot \pi\cdot  (1-\rho^2)}}\mathrm{e}^{-\frac{(y-\rho\cdot  x)^2}{2\cdot (1-\rho^2)}},\ y\in\mathbb{R}.
\end{array}
\]</span>
Concluimos que la <strong>variable aleatoria condicional <span class="math inline">\(Y|X=x\)</span></strong> es una normal de parámetros <span class="math inline">\(\mu_{Y|X=x}=\rho x\)</span> y <span class="math inline">\(\sigma_{Y|X=x}^2 =1-\rho^2\)</span>.</p>
<p><l class="obrv"> Observaciones</l></p>
<p>Tenemos dos observaciones con respecto al resultado obtenido:</p>
<ul>
<li><p>La varianza de la <strong>variable aleatoria condicional</strong> no depende de la <span class="math inline">\(x\)</span> que se ha fijado. Sólo depende del parámetro <span class="math inline">\(\rho\)</span>. La <span class="math inline">\(x\)</span> sólo influye en la media de dicha variable.</p></li>
<li><p>En el caso en que <span class="math inline">\(\rho=0\)</span>, que significa que <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes, la distribución condicional de <span class="math inline">\(Y|X=x\)</span> es una <span class="math inline">\(N(0,1)\)</span>, distribución que coincide con la distribución de la <strong>variable aleatoria marginal</strong> <span class="math inline">\(Y\)</span>.</p></li>
</ul>
</div>
</div>
</div>
</div>
<div id="valores-esperados-condicionales" class="section level3">
<h3><span class="header-section-number">5.7.3</span> Valores esperados condicionales</h3>
<p><l class="definition">Definición de valor esperado condicional.</l>
Dada una variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span>, definimos el <strong>valor esperado de la variable <span class="math inline">\(Y\)</span> dado que <span class="math inline">\(X=x\)</span></strong> como <span class="math inline">\(E(Y|x)\)</span>, es decir, el valor esperado de la <strong>variable aleatoria condicional <span class="math inline">\(Y|X=x\)</span></strong>:
<span class="math display">\[
E(Y|x)=\begin{cases}
\displaystyle\sum_{y_j} y_j \cdot P_{Y|X=x}(y_j), &amp; \mbox{ caso discreto,}\\
\displaystyle\int_{-\infty}^\infty y \cdot f_{Y|X=x}(y)\,dy, &amp; \mbox{ caso continuo.}
\end{cases}
\]</span></p>
<p>Tenemos el siguiente resultado relacionado con los valores esperados: el valor esperado respecto <span class="math inline">\(x\)</span> del valor esperado de la <strong>variable condicional <span class="math inline">\(Y|X=x\)</span></strong> coincide con el valor esperado de la variable <span class="math inline">\(Y\)</span>:</p>
<p><l class="prop">Proposición. </l>
Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Sean <span class="math inline">\(E(Y|x)\)</span> el <strong>valor esperado condicional de <span class="math inline">\(Y\)</span></strong> respecto <span class="math inline">\(x\)</span>. Entonces el valor esperado de la <em>variable aleatoria</em> <span class="math inline">\(E(Y|X)\)</span> como función de la variable <span class="math inline">\(X\)</span> es el valor esperado de la variable <span class="math inline">\(Y\)</span>:
<span class="math display">\[
E_X(E(Y|X))=E(Y).
\]</span></p>
<div class="dem">
<p><strong>Demostración</strong></p>
<p>Haremos la demostración en el caso continuo. Dejamos como ejercicio la demostración para el caso discreto.</p>
<p>Sea <span class="math inline">\(f_{XY}\)</span> la <strong>función de densidad conjunta</strong> y <span class="math inline">\(f_X\)</span> y <span class="math inline">\(f_Y\)</span> las <strong>funciones de densidad marginales</strong>.</p>
<p>El valor de <span class="math inline">\(E_X(E(Y|X))\)</span> es:
<span class="math display">\[
\begin{array}{rl}
E_X(E(Y|X)) &amp; =\int_{x=-\infty}^{x=\infty} E(Y|x)f_X(x)\, dx=\int_{x=-\infty}^{x=\infty}\int_{y=-\infty}^{y=\infty} y f_{Y|X=x}(y)\, dy f_X(x)\, dx \\ &amp; = \int_{x=-\infty}^{x=\infty}\int_{y=-\infty}^{y=\infty} y \frac{f_{XY}(x,y)}{f_X(x)}f_X(x)\, dy\, dx = \int_{y=-\infty}^{y=\infty} y \int_{x=-\infty}^{x=\infty}f_{XY}(x,y)\, dx\, dy \\ &amp;  = \int_{y=-\infty}^{y=\infty} y f_Y(y)\, dy = E(Y),
\end{array}
\]</span>
tal como queríamos ver.</p>
</div>
</div>
<div id="relación-con-el-problema-de-la-regresión-general" class="section level3">
<h3><span class="header-section-number">5.7.4</span> Relación con el problema de la regresión general</h3>
<p>El problema de la <strong>regresión general</strong> es el siguiente:</p>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional. Queremos hallar una función <span class="math inline">\(g\)</span> tal que la variable <span class="math inline">\(\hat{Y}=g(X)\)</span> explique mejor la variable <span class="math inline">\(Y\)</span>.</p>
<p>Dicho de forma más explícita, queremos hallar una función <span class="math inline">\(g\)</span> tal que minimice el error cometido al aproximar <span class="math inline">\(Y\)</span> por <span class="math inline">\(\hat{Y}=g(X)\)</span>. Dicho error se definede forma natural como el valor esperado de la variable <span class="math inline">\((Y-g(X))^2\)</span>:</p>
<p><span class="math display">\[
\min_g E\left((Y-g(X))^2\right).
\]</span></p>
<p>El siguiente resultado nos dice cuál es la función <span class="math inline">\(g\)</span>:</p>
<p><l class="prop">Proposición: </l>
La función <span class="math inline">\(g\)</span> solución del problema de <strong>regresión general</strong> es la siguiente: <span class="math inline">\(g(x)=E(Y|X=x)\)</span>.</p>
<p>Es decir, la función <span class="math inline">\(g\)</span> asigna a cada valor <span class="math inline">\(x\)</span> de la variable aleatoria <span class="math inline">\(X\)</span>, el valor esperado de la <strong>variable condicional</strong> <span class="math inline">\(Y|X=x\)</span>.</p>
<p>En resumen, la función <span class="math inline">\(g(x)=E(Y|X=x)\)</span> es la función que minimiza el error. A la curva <span class="math inline">\(y=g(x)\)</span> se la denomina <strong>curva general de regresión de <span class="math inline">\(Y\)</span> sobre <span class="math inline">\(X\)</span></strong>.</p>
</div>
<div id="valores-esperados-condicionales.-caso-general" class="section level3">
<h3><span class="header-section-number">5.7.5</span> Valores esperados condicionales. Caso general</h3>
<p>Podemos generalizar los valores esperados condicionales en el sentido que en lugar de hallar <span class="math inline">\(E(Y|X=x)\)</span>, hallar <span class="math inline">\(E(g(Y)|X=x)\)</span>, donde <span class="math inline">\(g\)</span> es una función de la variable aleatoria <span class="math inline">\(Y\)</span>:</p>
<p><l class="definition">Definición de valor esperado condicional.</l></p>
<p>Dada una variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> y una función <span class="math inline">\(g\)</span>, definimos el <strong>valor esperado de la variable <span class="math inline">\(g(Y)\)</span> dado que <span class="math inline">\(X=x\)</span></strong> como <span class="math inline">\(E(g(Y)|x)\)</span>, es decir, el valor esperado de la <strong>variable aleatoria condicional <span class="math inline">\(g(Y)|X=x\)</span></strong>:</p>
<p><span class="math display">\[
E(g(Y)|x)=\begin{cases}
\sum_{y_j} g(y_j) P_{Y|X=x}(y_j), &amp; \mbox{ caso discreto,}\\
\int_{-\infty}^\infty g(y) f_{Y|X=x}(y)\,dy, &amp; \mbox{ caso continuo.}
\end{cases}
\]</span></p>
<p><l class="observ">Observación:</l> cuando <span class="math inline">\(g(y)=y^k\)</span>, tenemos definidos los <strong>momentos condicionados de orden <span class="math inline">\(k\)</span></strong> de la variable <span class="math inline">\(Y|X=x\)</span>.</p>
<div id="ejemplos-8" class="section level4">
<h4><span class="header-section-number">5.7.5.1</span> Ejemplos</h4>
<div class="example">
<p><strong>Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado</strong></p>
<p>Vamos a hallar el valor esperado de la <strong>variable aleatoria condicional <span class="math inline">\(P|S=8\)</span></strong>.</p>
<div class="example-sol">
<p>Recordemos su <strong>función de probabilidad</strong>:</p>
<div class="center">
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(P|S=8\)</span></th>
<th><span class="math inline">\(12\)</span></th>
<th><span class="math inline">\(15\)</span></th>
<th><span class="math inline">\(16\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(P_{P|S=8}\)</span></td>
<td><span class="math inline">\(\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}\)</span></td>
<td><span class="math inline">\(\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}\)</span></td>
<td><span class="math inline">\(\frac{\frac{1}{36}}{\frac{5}{36}}=\frac{1}{5}\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Su valor esperado es:
<span class="math display">\[
E(P|S=8)=12\cdot \frac{2}{5}+15\cdot \frac{2}{5}+16\cdot \frac{1}{5}=\frac{70}{5}=14.
\]</span>
El valor medio del producto de los resultados al lanzar un dado dos veces cuando la suma de dichos resultados es 8 vale 14.</p>
<p>El valor esperado de la variable <span class="math inline">\(E(P|S=8)\)</span> es:</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb395-1" data-line-number="1">valores.cond.s8=<span class="kw">as.integer</span>(<span class="kw">names</span>(prob.cond.s8.buena))</a>
<a class="sourceLine" id="cb395-2" data-line-number="2"><span class="kw">sum</span>(valores.cond.s8<span class="op">*</span>prob.cond.s8.buena)</a></code></pre></div>
<pre><code>## [1] 14</code></pre>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: otra densidad (continuación)</strong></p>
<p>Recordemos el ejemplo de la variable aleatoria bidimensional continua con <strong>función de densidad</strong>:</p>
<p><span class="math display">\[
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario,}
\end{cases}
\]</span></p>
<p>Ya sebemos que si fijamos <span class="math inline">\(x_0&gt;0\)</span>, la <strong>función de densidad</strong> de la <strong>variable aleatoria condicionada</strong> <span class="math inline">\(Y|X=x_0\)</span> es:</p>
<p><span class="math display">\[
f_{Y|X=x_0}(y)=\begin{cases}
\frac{e^{-y}}{1-\mathrm{e}^{-x_0}}, &amp; \mbox{ si }0\leq y\leq x_0, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span></p>
<p>Hallemos su valor esperado:</p>
<div class="example-sol">
<p><span class="math display">\[
E(Y|X=x_0)=\int_0^{x_0} y \frac{e^{-y}}{(1-\mathrm{e}^{-x_0})}\, dy=\frac{1}{(1-\mathrm{e}^{-x_0})}\left[-\mathrm{e}^{-y} (y+1)\right]_0^{x_0} = \frac{1-\mathrm{e}^{-x_0}(1+x_0)}{1-\mathrm{e}^{-x_0}}.
\]</span></p>
<p>Verifiquemos la propiedad vista anteriormente <span class="math inline">\(E_X(E(Y|x))=E(Y)\)</span>. Recordemos que la <strong>función de densidad marginal</strong> de la variable <span class="math inline">\(X\)</span> era: <span class="math inline">\(f_X(x)=2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\)</span>, para <span class="math inline">\(x&gt;0\)</span>:</p>
<p><span class="math display">\[
\begin{array}{rl}
E_X(E(Y|x)) &amp; =\int_0^\infty E(Y|x)\cdot f_X(x)\, dx = \int_0^\infty \frac{1-\mathrm{e}^{-x}(1+x)}{1-\mathrm{e}^{-x}}\cdot 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx 
\\ &amp; =  2\int_0^\infty \frac{1-\mathrm{e}^{-x}(1+x)}{1-\mathrm{e}^{-x}} \mathrm{e}^{-x}\left(1-\mathrm{e}^{-x}\right)\, dx = 2 \int_0^\infty \left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}(1+x)\right)\, dx \\ &amp; = 2\left[-\mathrm{e}^{-x}+\mathrm{e}^{-2 x}
   \left(\frac{x}{2}+\frac{3}{4}\right)\right]_0^\infty = 2 \left(1-\frac{3}{4}\right)=\frac{1}{2}.
\end{array}
\]</span></p>
<p>Recordemos que la variable <span class="math inline">\(Y\)</span> era exponencial de parámetro <span class="math inline">\(\lambda=2\)</span>. Por tanto <span class="math inline">\(E(Y)=\frac{1}{\lambda}=\frac{1}{2}\)</span>, valor que coincide con el hallado, tal como queríamos ver.</p>
</div>
</div>
</div>
</div>
</div>
<div id="variables-aleatorias-definidas-como-función-de-dos-variables-aleatorias-conjuntas" class="section level2">
<h2><span class="header-section-number">5.8</span> Variables aleatorias definidas como función de dos variables aleatorias conjuntas</h2>
<p>Dado un experimento aleatorio, a veces estaremos interesados en una o más funciones de las variables asociadas con el experimento.</p>
<p>Por ejemplo, si consideramos el experimento aleatorio de lanzar un dado dos veces y definimos la <strong>variable aleatoria bidimensional</strong> <span class="math inline">\((X_1,X_2)\)</span> como la variable que nos da el resultado de cada lanzamiento, podemos expresar la suma y el producto como <span class="math inline">\(S=X_1+X_2\)</span>, <span class="math inline">\(P=X_1\cdot X_2\)</span>.</p>
<p>Otros ejemplos podrían ser considerar el experimento aleatoria de realizar mediciones repetidas de la misma cantidad aleatoria. Entonces, podríamos estar interesados en el valor máximo y mínimo en el conjunto, así como la media muestral y la varianza muestral.</p>
<p>En esta sección presentamos métodos para determinar las probabilidades de eventos que involucran <strong>funciones de dos variables aleatorias</strong>.</p>
<p>Daremos métodos de cómo hallar la <strong>función de distribución</strong> y la <strong>función de probabilidad</strong> (caso discreto) o la <strong>función de densidad</strong> (caso continuo) de la variable aleatoria definida como función de la <strong>variable aleatoria bidimensional</strong>.</p>
<div id="variable-aleatoria-función-de-la-variable-aleatoria-bidimensional" class="section level3">
<h3><span class="header-section-number">5.8.1</span> Variable aleatoria función de la variable aleatoria bidimensional</h3>
<p><l class="prop">Proposición.</l></p>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional con <strong>función de probabilidad</strong> <span class="math inline">\(P_{XY}\)</span> (caso discreto) o <strong>función de densidad</strong> (caso continuo). Sea <span class="math inline">\(g\)</span> una función y definimos la <strong>variable aleatoria unidimensional</strong> <span class="math inline">\(Z\)</span> como <span class="math inline">\(Z=g(X,Y)\)</span>. Entonces la función de distribución de <span class="math inline">\(Z\)</span> es:
<span class="math display">\[
\begin{array}{rl}
F_Z(z) &amp; = \displaystyle P(Z\leq z)=\sum\sum_{(x_i,y_j),\ |\ g(x_i,y_j)\leq z} P_{XY}(x_i,y_j),\ z\in\mathbb{R},\\ &amp;\ \qquad\mbox{ (caso discreto),}\\
F_Z(z) &amp; = \displaystyle  P(Z\leq z)=\int\int_{(x,y)\in\mathbb{R}^2,\ |\ g(x,y)\leq z} f_{XY}(x,y)\,dy\, dx, \ z\in\mathbb{R},\\ &amp;\ \qquad\mbox{ (caso continuo).}
\end{array}
\]</span></p>
</div>
<p><l class="observ">Observación.</l></p>
<p>En el caso discreto, la variable aleatoria será discreta con valores <span class="math inline">\(Z(\Omega)=\{z_{ij}=g(x_i,y_j),\ |\ (x_i,y_j)\in (X,Y)(\Omega)\}\)</span>.
Hay que tener en cuenta que en dicho conjunto puede haber repeticiones, es decir, pueden existir dos parejas <span class="math inline">\((i,j)\)</span> y <span class="math inline">\((i&#39;,j&#39;)\)</span> tal que <span class="math inline">\(z_{ij}=z_{i&#39;j&#39;}\)</span>.</p>
<p>La expresión de la <strong>función de probabilidad</strong> en el caso discreto se complica mucho debido a dichas repeticiones y es mejor hallarla en cada caso concreto.</p>
<p>La última observación se puede aplicar también en el caso continuo: la expresión de la <strong>función de densidad</strong> se halla en cada caso concreto.</p>
<div class="example">
<p><strong>Ejemplo del lanzamiento de un dado dos veces.</strong></p>
<p>Consideremos el experimento aleatorio de lanzar dos veces un dado.</p>
<p>Sea <span class="math inline">\((X,Y)\)</span> la <strong>variable aleatoria</strong> bidimensional discreta ya estudiada anteriormente donde <span class="math inline">\(X\)</span> nos da el resultado del primer lanzamiento e <span class="math inline">\(Y\)</span>, el resultado del segundo lanzamiento.</p>
<p>Vimos que <span class="math inline">\((X,Y)(\Omega)=\{(i,j),\ i=1,2,3,4,5,6,\ j=1,2,3,4,5,6\}\)</span> con <strong>función de probabilidad conjunta</strong> <span class="math inline">\(P_{XY}(i,j)=\frac{1}{36}\)</span>, <span class="math inline">\(i=1,2,3,4,5,6,\ j=1,2,3,4,5,6.\)</span></p>
<p>Anteriormente hemos estudiado la suma <span class="math inline">\(S\)</span> de los resultados. En este caso podemos interpretar <span class="math inline">\(S=g(X,Y)\)</span> donde <span class="math inline">\(g(x,y)=x+y\)</span>.</p>
<p>Como la función <span class="math inline">\(S\)</span> ya ha sido estudiada y el producto se ha dejado como ejercicio, estudiaremos la siguiente variable aleatoria función de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>: <span class="math inline">\(Z=X^2+Y^2\)</span>.</p>
<p>Realizaremos los cálculos con ayuda de <code>R</code> ya que hacerlos a mano es bastante tedioso.</p>
<p>Los valores de <span class="math inline">\(Z(\Omega)\)</span> son: <span class="math inline">\(Z(\Omega)=\{z_{ij}=i^2+j^2,\ i=1,2,3,4,5,6,\ j=1,2,3,4,5,6\}\)</span>. Observad que hay parejas <span class="math inline">\((i,j)\)</span> que dan lugar a los mismos valores, por ejemplo <span class="math inline">\(1^2+2^2 = 2^2+1^2\)</span>, y, en general, si <span class="math inline">\(i\neq j\)</span>, <span class="math inline">\(z_{ij}=i^2+j^2=z_{ji}=j^2+i^2\)</span>.</p>
<div class="example-sol">
<p>Para hallar el conjunto <span class="math inline">\(Z(\Omega)\)</span> usamos la función <code>outer</code> de <code>R</code>:</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb397-1" data-line-number="1">g=<span class="cf">function</span>(x,y){x<span class="op">^</span><span class="dv">2</span><span class="op">+</span>y<span class="op">^</span><span class="dv">2</span>}  <span class="co">## definimos la función g</span></a>
<a class="sourceLine" id="cb397-2" data-line-number="2"><span class="kw">sort</span>(<span class="kw">unique</span>(<span class="kw">as.vector</span>(<span class="kw">outer</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,g))))</a></code></pre></div>
<pre><code>##  [1]  2  5  8 10 13 17 18 20 25 26 29 32 34 37 40 41 45 50 52 61 72</code></pre>
<p>Vemos que hay 21 valores distintos de la variable <span class="math inline">\(Z\)</span>.</p>
<p>Para hallar la <strong>función de probabilidad</strong> de <span class="math inline">\(Z\)</span> hemos de calcular para cada valor <span class="math inline">\(z_k\)</span>, las parejas <span class="math inline">\((i,j)\)</span> tal que <span class="math inline">\(i^2+j^2=z_k\)</span>:</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb399-1" data-line-number="1">valores.variable.Z =<span class="st"> </span><span class="kw">sort</span>(<span class="kw">unique</span>(<span class="kw">as.vector</span>(<span class="kw">outer</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,g))))  </a>
<a class="sourceLine" id="cb399-2" data-line-number="2">matriz.valores =<span class="st"> </span><span class="kw">outer</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,g) <span class="co">## aplicamos la función g a </span></a>
<a class="sourceLine" id="cb399-3" data-line-number="3"><span class="co">##  todas las parejas (i,j), i,j=1,2,3,4,5,6</span></a>
<a class="sourceLine" id="cb399-4" data-line-number="4">frecuencias =<span class="st"> </span><span class="kw">c</span>()  <span class="co">## vector donde guardaremos las frecuencias de los valores de Z</span></a>
<a class="sourceLine" id="cb399-5" data-line-number="5"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(valores.variable.Z)){</a>
<a class="sourceLine" id="cb399-6" data-line-number="6">  z=valores.variable.Z[i]</a>
<a class="sourceLine" id="cb399-7" data-line-number="7">  frecuencias=<span class="kw">c</span>(frecuencias,<span class="kw">length</span>(matriz.valores[matriz.valores<span class="op">==</span>z]))</a>
<a class="sourceLine" id="cb399-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb399-9" data-line-number="9">frecuencias</a></code></pre></div>
<pre><code>##  [1] 1 2 1 2 2 2 1 2 2 2 2 1 2 2 2 2 2 1 2 2 1</code></pre>
<p>La <strong>función de probabilidad</strong> de <span class="math inline">\(Z\)</span> es:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb401-1" data-line-number="1">función.probabilidad.Z=<span class="kw">data.frame</span>(<span class="kw">rbind</span>(valores.variable.Z,<span class="kw">round</span>(frecuencias<span class="op">/</span><span class="dv">36</span>,<span class="dv">3</span>)))</a>
<a class="sourceLine" id="cb401-2" data-line-number="2"><span class="kw">rownames</span>(función.probabilidad.Z)=<span class="kw">c</span>(<span class="st">&quot;Z&quot;</span>,<span class="st">&quot;P_Z&quot;</span>)</a>
<a class="sourceLine" id="cb401-3" data-line-number="3">función.probabilidad.Z</a></code></pre></div>
<pre><code>##        X1    X2    X3     X4     X5     X6     X7     X8     X9    X10    X11
## Z   2.000 5.000 8.000 10.000 13.000 17.000 18.000 20.000 25.000 26.000 29.000
## P_Z 0.028 0.056 0.028  0.056  0.056  0.056  0.028  0.056  0.056  0.056  0.056
##        X12    X13    X14    X15    X16    X17    X18    X19    X20    X21
## Z   32.000 34.000 37.000 40.000 41.000 45.000 50.000 52.000 61.000 72.000
## P_Z  0.028  0.056  0.056  0.056  0.056  0.056  0.028  0.056  0.056  0.028</code></pre>
</div>
</div>
<div class="example">
<p><strong>Ejemplo variables aleatorias continuas</strong></p>
<p>Recordemos la variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> con <strong>función de densidad</strong>:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
2\cdot  \mathrm{e}^{-x}\cdot \mathrm{e}^{-y}, &amp; 0\leq y\leq x &lt; \infty,\\
0, &amp; \mbox{ en caso contrario,}
\end{cases}
\]</span>
Consideremos la variable aleatoria <span class="math inline">\(Z=X+Y\)</span>. Vamos a calcular la <strong>función de densidad</strong> de <span class="math inline">\(Z\)</span>.</p>
<p>En primer lugar, los valores de <span class="math inline">\(Z\)</span> para los que <span class="math inline">\(f_Z(z)\neq 0\)</span> cumplen <span class="math inline">\(z\geq 0\)</span> ya que <span class="math inline">\(X\geq 0\)</span> e <span class="math inline">\(Y\geq 0\)</span>.</p>
<p>Calculemos la <strong>función de distribución</strong> de la variable <span class="math inline">\(Z\)</span>. Sean <span class="math inline">\(z\in\mathbb{R}\)</span> con <span class="math inline">\(z\geq 0\)</span>:</p>
<div class="example-sol">
<p><span class="math display">\[
\begin{array}{rl}
F_Z(z) &amp; =  P(Z\leq z)=P(X+Y\leq z)\\
&amp; =\displaystyle \int\int_{\{(x,y)\mathbb{R}^2,\ |\ x+y\leq z\}\cap \{(x,y)\in \mathbb{R}^2,\ |\ 0\leq y\leq x&lt;\infty\}} 2\cdot  \mathrm{e}^{-x}\cdot \mathrm{e}^{-y}\, dy\, dx
\end{array}
\]</span></p>
El gráfico siguiente muestra en color violeta la región de integración para hallar <span class="math inline">\(F_Z(z)\)</span> dado un <span class="math inline">\(z\geq 0\)</span>.
<div class="center">
<p><img src="Images/EjSumaXY.png" /><!-- --></p>
</div>
<p>El valor de <span class="math inline">\(F_Z(z)\)</span> es: (fijémonos que primero fijamos la <span class="math inline">\(y\)</span> y para cada <span class="math inline">\(y\)</span> la <span class="math inline">\(x\)</span> va desde la recta <span class="math inline">\(x=y\)</span> hasta la recta <span class="math inline">\(x=z-y\)</span>)</p>
<p><span class="math display">\[
\begin{array}{rl}
F_Z(z) &amp; =\displaystyle\int_{y=0}^{y=\frac{z}{2}}\int_{x=y}^{x=z-y}2 \cdot\mathrm{e}^{-x}\cdot\mathrm{e}^{-y}\, dx\, dy = 2 \cdot\int_{y=0}^{y=\frac{z}{2}} \mathrm{e}^{-y} \cdot\left[-\mathrm{e}^{-x}\right]_{x=y}^{x=z-y}\, dy \\ &amp; 
\displaystyle = 2 \cdot\cdot\int_{y=0}^{y=\frac{z}{2}} \mathrm{e}^{-y}\cdot \left(\mathrm{e}^{-y}-\mathrm{e}^{y-z}\right)\, dy = 2 \cdot\int_{y=0}^{y=\frac{z}{2}} \left(\mathrm{e}^{-2y}-\mathrm{e}^{-z} \right)\, dy  \\
&amp; = 2\cdot\left[-\frac{1}{2}\mathrm{e}^{-2y}-\mathrm{e}^{-z} \cdot y\right]_{y=0}^{y=\frac{z}{2}}  = \displaystyle 2\cdot\left(\frac{1}{2}-\frac{1}{2}\mathrm{e}^{-z}-\frac{z}{2}\mathrm{e}^{-z}\right) \\ 
&amp; = 1-\mathrm{e}^{-z}\cdot(1+z),\ z\geq 0.
\end{array}
\]</span>
La <strong>función de densidad</strong> de <span class="math inline">\(Z\)</span> es:</p>
<p><span class="math display">\[
f_Z(z)=F&#39;_Z(z)=z\cdot\mathrm{e}^{-z},\ z\geq 0,
\]</span>
y <span class="math inline">\(f_Z(z)=0\)</span> en caso contrario.</p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo de la suma de dos normales</strong></p>
<p>Consideremos el caso en que la variable aleatoria <span class="math inline">\((X,Y)\)</span> tenga distribución <strong>normal bidimensional</strong>.</p>
<p>Recordemos que su <strong>función de densidad conjunta</strong> era:
<span class="math display">\[
f_{XY}(x,y)=\frac{1}{2\cdot \pi\cdot \sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\cdot \rho\cdot  x\cdot y+y^2)}{2\cdot (1-\rho^2)}},\ -\infty &lt;x,y&lt;\infty.
\]</span>
Consideremos <span class="math inline">\(S=X+Y\)</span>. Estudiemos qué distribución tiene <span class="math inline">\(S\)</span>.</p>
<p>Dado un valor <span class="math inline">\(z\in\mathbb{R}\)</span>, la <strong>función de distribución</strong> de <span class="math inline">\(S\)</span> en <span class="math inline">\(s\)</span> es:</p>
<div class="example-sol">
<p><span class="math display">\[
\begin{array}{rl}
F_S(s) &amp; =P(S\leq s)=\displaystyle \int\int_{\{(x,y)\in\mathbb{R}^2,\ |\ x+y\leq s\}}\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx \\
&amp; =\displaystyle  \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty}\int_{y=-\infty}^{y=s-x}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx \\
&amp; = \displaystyle  \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}} \int_{y=-\infty}^{y=s-x}\mathrm{e}^{-\frac{(-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx  \\ &amp;\ \qquad\mbox{hacemos el siguiente cambio  en la segunda integral $t=y+x$}\\
&amp; = \displaystyle  \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}} \int_{t=-\infty}^{t=s}\mathrm{e}^{-\frac{(-2\rho x(t-x)+(t-x)^2)}{2(1-\rho^2)}}\, dt\, dx 
\end{array}
\]</span></p>
<p><span class="math display">\[
\begin{array}{rl}
F_S(s) 
&amp; =  \displaystyle \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{(1+\rho)x^2}{1-\rho^2}}\int_{t=-\infty}^{t=s} \mathrm{e}^{-\frac{(t^2-2(1+\rho) t x)}{2(1-\rho^2)}}\, dt\, dx \\
&amp; = \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{(1+\rho)x^2}{1-\rho^2}}\int_{t=-\infty}^{t=s} \mathrm{e}^{-\frac{(t-(1+\rho)x)^2}{2(1-\rho^2)}} \mathrm{e}^{\frac{(\rho+1)^2 x^2}{2(1-\rho^2)}}\, dt\, dx  \\
&amp; = \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot \sqrt{2\pi (1-\rho^2)} F_X(s)\, dx, \\ 
&amp; \mbox{ donde $F_X(s)$ es la función de distribución}\\
&amp; \mbox{de una variable $X$ normal de parámetros} \\ 
&amp; \mbox{ $\mu =(1+\rho)x$ y $\sigma^2=1-\rho^2$.} \\ 
&amp; = \frac{1}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot F_X(s)\, dx.
\end{array}
\]</span></p>
<p>Para calcular la <strong>función de densidad</strong> <span class="math inline">\(f_S(s)\)</span> aplicamos la expresión <span class="math inline">\(f_S(s)=F&#39;_S(s)\)</span> y la derivación bajo el signo integral:</p>
<p><span class="math display">\[
\begin{array}{rl}
f_S(s) &amp; = \frac{1}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot f_X(s)\, dx = \frac{1}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot \frac{1}{\sqrt{2\pi (1-\rho^2)}}\mathrm{e}^{-\frac{(s-(1+\rho)x)^2}{2(1-\rho^2)}}\, dx \\ &amp; = \frac{\mathrm{e}^{-\frac{s^2}{2(1-\rho^2)}}}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{(2(1+\rho) x^2-2(1+\rho)xs)}{2(1-\rho^2)}}\, dx= \frac{\mathrm{e}^{-\frac{s^2}{2(1-\rho^2)}}}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{\left(x-\frac{s}{2}\right)^2}{1-\rho}}\mathrm{e}^{\frac{s^2}{4(1-\rho)}}\, dx
\end{array}
\]</span></p>
<p>En la última integral hacemos el cambio <span class="math inline">\(u=x-\frac{z}{2}\)</span>:
<span class="math display">\[
f_S(s)  =\frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{1-\rho^2}} \int_{u=-\infty}^{u=\infty} \mathrm{e}^{-\frac{u^2}{1-\rho}}\, du.
\]</span>
A continuación usando que <span class="math inline">\(f_Z(z)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\)</span> es la función de densidad de la distribución <span class="math inline">\(Z=N(0,1)\)</span>, podemos escribir: <span class="math inline">\(\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}=1,\ \Rightarrow \int_{-\infty}^\infty \mathrm{e}^{-\frac{x^2}{2}}=\sqrt{2\pi}.\)</span></p>
<p>Si en la última integral hacemos el cambio <span class="math inline">\(v=\sqrt{\frac{2}{1-\rho}}u\)</span>, obtenemos:</p>
<p><span class="math display">\[
\begin{array}{rl}
f_S(s)  &amp; = \frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{1-\rho^2}}\int_{v=-\infty}^{v=\infty}\mathrm{e}^{-\frac{v^2}{2}} \sqrt{\frac{1-\rho}{2}}\, dv= \frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{2(1+\rho)}}\int_{v=-\infty}^{v=\infty}\mathrm{e}^{-\frac{v^2}{2}} \, dv \\ &amp; = \frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{2(1+\rho)}} \sqrt{2\pi}= \frac{1}{\sqrt{2\pi 2(1+\rho)}}\mathrm{e}^{-\frac{s^2}{4(1+\rho)}},\ s\in\mathbb{R}.
\end{array}
\]</span></p>
<p>Dicha función de densidad corresponde a una distribución normal de parámetros <span class="math inline">\(\mu =0\)</span> y <span class="math inline">\(\sigma = \sqrt{2(1+\rho)}\)</span>.</p>
<p>En resumen, la distribución de la suma de dos normales es una normal de parámetros <span class="math inline">\(S=N(\mu=0,\sigma = \sqrt{2(1+\rho)})\)</span>.</p>
</div>
</div>
</div>
<div id="transformaciones-lineales-de-variables-aleatorias" class="section level3">
<h3><span class="header-section-number">5.8.2</span> Transformaciones lineales de variables aleatorias</h3>
<p>Consideremos una variable aleatoria bidimensional continua <span class="math inline">\((X,Y)\)</span> con <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span>.</p>
<p>Definimos la variable aleatoria bidimensional continua <span class="math inline">\((U,V)\)</span> a partir de una transformación lineal de la variable <span class="math inline">\((X,Y)\)</span>. Es decir, existe una matriz <span class="math inline">\(\mathbf{M}=\begin{pmatrix}a &amp; b\\ c&amp; d\end{pmatrix}\)</span> y un vector <span class="math inline">\(\mathbf{n}=\begin{pmatrix}\alpha\\\beta \end{pmatrix}\)</span> tal que:</p>
<p><span class="math display">\[
\begin{array}{rl}
\begin{pmatrix}U\\ V\end{pmatrix} &amp; =\mathbf{M}\cdot \begin{pmatrix}X\\ Y\end{pmatrix}+\mathbf{n}=\begin{pmatrix}a &amp; b\\ c&amp; d\end{pmatrix}\cdot\begin{pmatrix}X\\ Y\end{pmatrix}+\begin{pmatrix}\alpha\\\beta \end{pmatrix},\\  &amp; \Rightarrow \left.\begin{array}{rl}U &amp; = aX+bY+\alpha,\\ V &amp; =cX+dY+\beta.\end{array}\right\}
\end{array}
\]</span></p>
<p>Para que <span class="math inline">\((U,V)\)</span> sea una variable aleatoria bidimensional, necesitamos que la matriz <span class="math inline">\(\mathbf{M}\)</span> sea no singular, o <span class="math inline">\(\mathrm{det}(\mathbf{M})\neq 0\)</span>.</p>
<p>Nos preguntamos cuál es la relación entre la <strong>función de densidad</strong> de la variable <span class="math inline">\((U,V)\)</span>, <span class="math inline">\(f_{UV}\)</span> y la <strong>función de densidad</strong> de la variable <span class="math inline">\((X,Y)\)</span>, <span class="math inline">\(f_{XY}\)</span>. La expresión siguiente nos da dicha relación:</p>
<p><span class="math display">\[
f_{UV}(u,v)=\frac{1}{|\mathrm{det}(\mathbf{M})|}f_{XY}\left(\mathbf{M}^{-1}\begin{pmatrix}u-\alpha\\ v-\beta\end{pmatrix}\right), \ (u,v)\in\mathbb{R}^2.
\]</span></p>
<p><l class="observ">Observación. </l>
Si la variable <span class="math inline">\((X,Y)\)</span> tiene una región <span class="math inline">\(D\)</span> donde <span class="math inline">\(f_{XY}(x,y)\neq 0\)</span>, para todo <span class="math inline">\((x,y)\in D\)</span>, antes de aplicar la expresión anterior para hallar la <strong>función de densidad</strong> de la variable <span class="math inline">\((U,V)\)</span> hemos de calcular cómo se transforma <span class="math inline">\(D\)</span> con la matriz <span class="math inline">\(\mathbf{M}\)</span>. Es decir, hay que hallar la región</p>
<p><span class="math display">\[
D&#39;=\mathbf{M}(D)=\{(u,v)\in\mathbb{R}^2,\ \mbox{existe $(x,y)\in D$ con } (u,v)=\mathbf{M}(x,y)+\mathbf{n}\}.
\]</span></p>
<div class="example">
<p><strong>Ejemplo: transformación lineal</strong></p>
<p>Consideremos la variable <span class="math inline">\((X,Y)\)</span> continua con función de densidad:
<span class="math display">\[
f_{XY}(x,y)=\begin{cases}
\frac{1}{2}(1+x+y), &amp; \mbox{ si }(x,y)\in R, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
donde <span class="math inline">\(R\)</span> es el rombo de vértices <span class="math inline">\((1,0)\)</span>, <span class="math inline">\((0,1)\)</span>, <span class="math inline">\((-1,0)\)</span> y <span class="math inline">\((0,-1)\)</span>, ver figura adjunta.</p>
<p>Otra forma de definir la función anterior es:</p>
<p><span class="math display">\[
f_{XY}(x,y)=\begin{cases}
\frac{1}{2}(1+x+y), &amp; -1\leq x\leq 0,\ -1-x\leq y\leq x+1, \\
\frac{1}{2}(1+x+y), &amp; 0\leq x\leq 0,\ x-1\leq y\leq 1-x, \\
0, &amp; \mbox{en caso contrario.}
\end{cases}
\]</span>
Dejamos como ejercicio al lector comprobar que la función anterior es una <strong>función de densidad</strong>.</p>
<div class="center">
<p><img src="Images/EjTranLineal.png" /><!-- --></p>
</div>
<div class="example-sol">
<p>Consideramos la variable aleatoria bidimensional <span class="math inline">\((U,V)\)</span> definida a partir de la variable <span class="math inline">\((X,Y)\)</span>:</p>
<p><span class="math display">\[
\begin{pmatrix}U\\ V\end{pmatrix}=\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}\cdot\begin{pmatrix}X\\ Y\end{pmatrix},\ \Rightarrow \left.\begin{array}{rl}U &amp; = X-Y,\\ V &amp; =X+Y.\end{array}\right\}
\]</span>
La región <span class="math inline">\(R\)</span> se transforma en el cuadrado <span class="math inline">\(C\)</span> de vértices <span class="math inline">\((1,1)\)</span>, <span class="math inline">\((-1,1)\)</span>, <span class="math inline">\((-1,-1)\)</span> y <span class="math inline">\((1,-1)\)</span> ya que si aplicamos la matriz a los vértices del rombo, obtenemos los vértices de cuadrado:
<span class="math display">\[
\begin{array}{rl}
\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}\cdot \begin{pmatrix}1\\ 0\end{pmatrix} &amp; =\begin{pmatrix}1\\ 1\end{pmatrix},\qquad 
\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}\cdot \begin{pmatrix}0\\ 1\end{pmatrix}=\begin{pmatrix}-1\\ 1\end{pmatrix},\\ 
\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}\cdot \begin{pmatrix}-1\\ 0\end{pmatrix} &amp; =\begin{pmatrix}-1\\ -1\end{pmatrix},\qquad 
\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}\cdot \begin{pmatrix}0\\ -1\end{pmatrix}=\begin{pmatrix}1\\ -1\end{pmatrix}.
\end{array}
\]</span>
Ver la figura adjunta.</p>
<p>Para hallar la <strong>función de densidad</strong> <span class="math inline">\(f_{UV}\)</span> necesitamos escribir <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> en función de <span class="math inline">\(U\)</span> y <span class="math inline">\(V\)</span>:
<span class="math display">\[
\begin{pmatrix}X\\ Y\end{pmatrix}=\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}^{-1}\cdot\begin{pmatrix}U\\ V\end{pmatrix}=\begin{pmatrix}\frac{1}{2} &amp; \frac{1}{2}\\ -\frac{1}{2}&amp; \frac{1}{2}\end{pmatrix}\cdot\begin{pmatrix}U\\ V\end{pmatrix},\ \Rightarrow \left.\begin{array}{rl}X &amp; = \frac{1}{2}(U+V),\\ Y &amp; =\frac{1}{2}(-U+V).\end{array}\right\}
\]</span></p>
<div class="center">
<p><img src="Images/EjTranLineal2.png" /><!-- --></p>
</div>
<p>La <strong>función de densidad</strong> <span class="math inline">\(f_{UV}\)</span> es,
<span class="math display">\[
\begin{array}{rl}
f_{UV}(u,v) &amp; =\frac{1}{\left|\mathrm{det}\begin{pmatrix}1 &amp; -1\\ 1&amp; 1\end{pmatrix}\right|}\cdot f_{XY}\left(\frac{1}{2}(u+v),\frac{1}{2}(-u+v)\right) \\ &amp; =\frac{1}{2}\cdot \frac{1}{2}\cdot \left(1+\frac{1}{2}(-u+v)+\frac{1}{2}(u+v)\right)=\frac{1}{4}(1+v),
\end{array}
\]</span>
para <span class="math inline">\((u,v)\)</span> perteneciente al cuadrado <span class="math inline">\(C\)</span> de vértices <span class="math inline">\((1,1)\)</span>, <span class="math inline">\((-1,1)\)</span>, <span class="math inline">\((-1,-1)\)</span> y <span class="math inline">\((1,-1)\)</span>, o si se quiere para <span class="math inline">\(-1\leq u\leq 1\)</span>, <span class="math inline">\(-1\leq v\leq 1\)</span>, y <span class="math inline">\(f_{UV}(u,v)=0\)</span>, en caso contrario.</p>
<p>Observamos que es más cómodo trabajar con las variables <span class="math inline">\((u,v)\)</span> en vez de trabajar con las variables <span class="math inline">\((x,y)\)</span> por dos razones:</p>
<ul>
<li>La región donde la <strong>función de densidad</strong> no es nula es más simple, ya que trabajar con un cuadrado simplifica mucho más los cálculos que trabajar con un rombo a la hora de hallar la <strong>función de distribución</strong>, <strong>densidades marginales</strong>, <strong>densidades condicionadas</strong>, <strong>valores esperados</strong>, etc.</li>
<li>La expresión de la <strong>función de densidad</strong> también es más simple, ya que sólo depende de la segunda variable <span class="math inline">\(v\)</span>; sin embargo, la <strong>función de densidad</strong> inicial <span class="math inline">\(f_{XY}\)</span> dependía de las dos variables <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</li>
</ul>
</div>
</div>
<div class="example">
<p><strong>Ejemplo</strong></p>
<p>Consideremos el caso en que la variable aleatoria <span class="math inline">\((X,Y)\)</span> tenga distribución <strong>normal bidimensional</strong>.</p>
<p>Recordemos que su <strong>función de densidad conjunta</strong> era:
<span class="math display">\[
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty &lt;x,y&lt;\infty.
\]</span>
Recordemos que las <strong>distribuciones marginales</strong> son distribuciones <span class="math inline">\(N(0,1)\)</span>.</p>
<p>La idea es hallar la <strong>función de densidad conjunta</strong> de una distribución normal bidimensional para la que sus <strong>distribuciones marginales</strong> sean dos normales <span class="math inline">\(N(\mu_1,\sigma_1)\)</span> y <span class="math inline">\(N(\mu_2,\sigma_2)\)</span>.</p>
<div class="example-sol">
<p>Recordemos que si <span class="math inline">\(Z=N(0,1)\)</span>, entonces <span class="math inline">\(\sigma_1\cdot Z+\mu_1 =N(\mu_1,\sigma_1)\)</span>. Este hecho, motiva que consideremos el cambio lineal siguiente a las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\begin{pmatrix}U\\ V\end{pmatrix}=\begin{pmatrix}\sigma_1 &amp; 0\\ 0&amp; \sigma_2\end{pmatrix}\cdot\begin{pmatrix}X\\ Y\end{pmatrix}+\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix},\ \Rightarrow \left.\begin{array}{rl}U &amp; = \sigma_1\cdot X+\mu_1,\\ V &amp; =\sigma_2\cdot Y+\mu_2.\end{array}\right\}
\]</span></p>
<p>La función de densidad conjunta <span class="math inline">\(f_{UV}\)</span> es:
<span class="math display">\[
\begin{array}{rl}
f_{UV}(u,v) &amp; = \frac{1}{\left|\begin{pmatrix}\sigma_1 &amp; 0\\ 0&amp; \sigma_2\end{pmatrix}\right|} f_{XY}\left(\frac{u-\mu_1}{\sigma_1},\frac{v-\mu_2}{\sigma_2}\right)
=\frac{1}{\sigma_1\cdot \sigma_2}f_{XY}\left(\frac{u-\mu_1}{\sigma_1},\frac{v-\mu_2}{\sigma_2}\right)\\ &amp; =
\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{\left(\left(\frac{u-\mu_1}{\sigma_1}\right)^2-2\rho \left(\frac{u-\mu_1}{\sigma_1}\right)\left(\frac{v-\mu_2}{\sigma_2}\right)+\left(\frac{v-\mu_2}{\sigma_2}\right)^2\right)}{2(1-\rho^2)}},
\end{array}
\]</span>
para <span class="math inline">\((u,v)\in\mathbb{R}^2\)</span>.</p>
<p>Si llamamos <span class="math inline">\(\mathbf{\Sigma}\)</span> a la matriz <span class="math inline">\(\mathbf{\Sigma}=\begin{pmatrix}\sigma_1^2 &amp; \rho\sigma_1\sigma_2\\ \rho\sigma_1\sigma_2 &amp; \sigma_2^2\end{pmatrix}\)</span>, llamada <strong>matriz de covarianzas</strong> de la distribución normal <span class="math inline">\((U,V)\)</span> la <strong>función de densidad</strong> anterior puede escribirse como:
<span class="math display">\[
f_{UV}(u,v)=\frac{1}{2\pi \sqrt{\left|\mathrm{\Sigma}\right|}}\mathrm{e}^{-\frac{1}{2}(\mathbf{u}-\mathbf{\mu})^\top \mathbf{\Sigma}^{-1}(\mathbf{u}-\mathbf{\mu})},\ \mbox{donde $\mathbf{u}=\begin{pmatrix}u \\ v\end{pmatrix}$ y $\mathbf{\mu}=\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix}$.}
\]</span>
La variable aleatoria bidimensional <span class="math inline">\((X,Y)\)</span> es la <strong>variable aleatoria tipificada</strong> con respecto de la variable <span class="math inline">\((U,V)\)</span>.</p>
</div>
</div>
</div>
<div id="transformaciones-generales-de-variables-aleatorias" class="section level3">
<h3><span class="header-section-number">5.8.3</span> Transformaciones generales de variables aleatorias</h3>
<p>Consideremos una variable aleatoria bidimensional continua <span class="math inline">\((X,Y)\)</span> con <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span>.</p>
<p>Definimos la variable aleatoria bidimensional continua <span class="math inline">\((U,V)\)</span> a partir de una transformación general de la variable <span class="math inline">\((X,Y)\)</span>. Es decir, existen dos funciones de dos variables <span class="math inline">\(g_1\)</span> y <span class="math inline">\(g_2\)</span> tal que:
<span class="math display">\[
U  = g_1 (X,Y),\quad 
V  = g_2 (X,Y).
\]</span>
Vamos a suponer que las funciones <span class="math inline">\(g_1\)</span> y <span class="math inline">\(g_2\)</span> son invertibles, es decir, dados <span class="math inline">\((u,v)\)</span>, podemos encontrar <span class="math inline">\((x,y)\)</span> tal que <span class="math inline">\(x=h_1(u,v)\)</span> e <span class="math inline">\(y=h_2(u,v)\)</span>. Las funciones <span class="math inline">\(h_1\)</span> y <span class="math inline">\(h_2\)</span> son las inversas de las funciones <span class="math inline">\(g_1\)</span> y <span class="math inline">\(g_2\)</span>, respectivamente.</p>
<p>La <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{UV}\)</span> se puede expresar de la forma siguiente en función de la <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{XY}\)</span>:</p>
<p><span class="math display">\[
\begin{array}{rl}
f_{UV}(u,v) &amp; =\left|\mathrm{det}\begin{pmatrix}\frac{\partial h_1}{\partial u} &amp; \frac{\partial h_1}{\partial v}\\ \frac{\partial h_2}{\partial u} &amp; \frac{\partial h_2}{\partial v}\end{pmatrix}\right|f_{XY}(h_1(u,v),h_2(u,v))\\ &amp; =\frac{1}{\left|\mathrm{det}\begin{pmatrix}\frac{\partial g_1}{\partial x} &amp; \frac{\partial g_1}{\partial y}\\ \frac{\partial g_2}{\partial x} &amp; \frac{\partial g_2}{\partial y}\end{pmatrix}\right|_{x=h_1(u,v),y=h_2(u,v)}}f_{XY}(h_1(u,v),h_2(u,v)).
\end{array}
\]</span></p>
<p>A la matriz <span class="math inline">\(\begin{pmatrix}\frac{\partial g_1}{\partial x} &amp; \frac{\partial g_1}{\partial y}\\ \frac{\partial g_2}{\partial x} &amp; \frac{\partial g_2}{\partial y}\end{pmatrix}\)</span> se le llama <strong>matriz jacobiana del cambio</strong> y a la matriz <span class="math inline">\(\begin{pmatrix}\frac{\partial h_1}{\partial u} &amp; \frac{\partial h_1}{\partial v}\\ \frac{\partial h_2}{\partial u} &amp; \frac{\partial h_2}{\partial v}\end{pmatrix}\)</span>, <strong>matriz jacobiana del cambio inverso</strong>.</p>
<div class="example">
<p><strong>Ejemplo: cambio a polares</strong></p>
<p>Sea <span class="math inline">\((X,Y)\)</span> una variable aleatoria bidimensional cuya <strong>función de densidad conjunta</strong> es:</p>
<p><span class="math display">\[
f_{XY}(x,y)=
\begin{cases}
\frac{2}{\pi}\left(x^2 + y^2\right), &amp; \mbox{si }(x,y)\in D_1, \\
0, &amp; \mbox{en caso contrario,}
\end{cases}
\]</span>
donde <span class="math inline">\(D_1\)</span> es el disco de radio <span class="math inline">\(1\)</span>:
<span class="math display">\[
D_1 = \{(x,y)\in\mathbb{R}^2,\ | \ x^2+y^2\leq 1\}.
\]</span>
El cambio a polares consiste en considerar las coordenadas polares <span class="math inline">\((r,\alpha)\)</span> de un punto cualquiera <span class="math inline">\((x,y)\)</span> del plano, ver figura adjunta. El cambio que pasa de <span class="math inline">\((r,\alpha)\)</span> a <span class="math inline">\((x,y)\)</span> (fijaos que es el cambio inverso, según nuestra notación o <span class="math inline">\(h_1\)</span>y <span class="math inline">\(h_2\)</span>, respectivamente) es:
<span class="math display">\[
x=h_1(r,\alpha)=r\cdot \cos\alpha,\quad y=h_2(r,\alpha)=r\cdot \sin\alpha.
\]</span></p>
<div class="center">
<p><img src="Images/Polares.png" /><!-- --></p>
</div>
<div class="example-sol">
<p>Fijémonos que, con el cambio a polares, el disco unidad <span class="math inline">\(D_1\)</span> se transforma en el rectángulo <span class="math inline">\([0,1]\times [0,2\pi]\)</span>.</p>
<p>Hallemos el <strong>jacobiano del cambio inverso</strong>:
<span class="math display">\[
\mathrm{det}\begin{pmatrix}\frac{\partial h_1}{\partial u} &amp; \frac{\partial h_1}{\partial v}\\ \frac{\partial h_2}{\partial u} &amp; \frac{\partial h_2}{\partial v}\end{pmatrix} =\mathrm{det}\begin{pmatrix}\cos\alpha &amp; -r\sin\alpha\\ \sin\alpha &amp; r\cdot\cos\alpha\end{pmatrix} = r.
\]</span>
La <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{r\alpha}\)</span> en las nuevas variables (polares) es:
<span class="math display">\[
f_{r\alpha}(r,\alpha)=r\cdot \frac{2}{\pi}\left((r\cos\alpha)^2+(r\sin\alpha)^2\right)=\frac{2}{\pi}\cdot r^3,
\]</span>
si <span class="math inline">\((r,\alpha)\in [0,1]\times [0,2\pi]\)</span>.</p>
<p>Podemos comentar que, gracias al cambio a polares, en este caso, es mucho más sencillo y cómodo trabajar con las variables <span class="math inline">\((r,\alpha)\)</span> en vez de trabajar con las variables <span class="math inline">\((x,y)\)</span> por dos razones:</p>
<ul>
<li>La región donde la <strong>función de densidad</strong> no es nula es más simple, ya que trabajar con un rectángulo simplifica mucho más los cálculos que trabajar con un disco a la hora de hallar la <strong>función de distribución</strong>, <strong>densidades marginales</strong>, <strong>densidades condicionadas</strong>, <strong>valores esperados</strong>, etc.</li>
</ul>
<p>Por ejemplo, comprobar que el área de la <strong>función de densidad conjunta</strong> <span class="math inline">\(f_{r\alpha}\)</span> da <span class="math inline">\(1\)</span> es trivial:
<span class="math display">\[
\int_{r=0}^{r=1}\int_{\alpha =0}^{\alpha =2\pi}\frac{2}{\pi} r^3\, d\alpha\, dr = \frac{2}{\pi}\cdot 2\pi \left[\frac{r^4}{4}\right]_{r=0}^{r=1}=4\cdot \frac{1}{4}=1.
\]</span></p>
<ul>
<li>La expresión de la <strong>función de densidad</strong> también es más simple, ya que sólo depende de la primera variable <span class="math inline">\(r\)</span>; sin embargo, la <strong>función de densidad</strong> inicial <span class="math inline">\(f_{XY}\)</span> dependía de las dos variables <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</li>
</ul>
</div>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="variables-aleatorias-complementos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vectores-aleatorios.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/joanby/probabilidad/edit/master/5.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["curso-probabilidad-udemy.pdf", "curso-probabilidad-udemy.epub"],
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
