<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Tema 2 Variables Aleatorias | Probabilidad y variables aleatorias para ML con R y Python</title>
  <meta name="description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Tema 2 Variables Aleatorias | Probabilidad y variables aleatorias para ML con R y Python" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7" />
  <meta property="og:image" content="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7Images/cover.jpg" />
  <meta property="og:description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="github-repo" content="https://github.com/joanby/probabilidad" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tema 2 Variables Aleatorias | Probabilidad y variables aleatorias para ML con R y Python" />
  
  <meta name="twitter:description" content="Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos." />
  <meta name="twitter:image" content="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7Images/cover.jpg" />

<meta name="author" content="Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir" />


<meta name="date" content="2019-12-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="Images/apple-icon-120x120.png" />
  <link rel="shortcut icon" href="Images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="probabilidad.html"/>
<link rel="next" href="distribuciones-notables.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso completo de Probabilidad y Variables Aleatorias con R y Python</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><i class="fa fa-check"></i>Pre requisitos: Teoría de conjuntos y combinatoria</a><ul>
<li class="chapter" data-level="0.1" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#teoría-de-conjuntos"><i class="fa fa-check"></i><b>0.1</b> Teoría de conjuntos</a><ul>
<li class="chapter" data-level="0.1.1" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#conjuntos-básicos"><i class="fa fa-check"></i><b>0.1.1</b> Conjuntos básicos</a></li>
<li class="chapter" data-level="0.1.2" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#características-y-propiedades-básicas-de-los-conjuntos"><i class="fa fa-check"></i><b>0.1.2</b> Características y propiedades básicas de los conjuntos</a></li>
<li class="chapter" data-level="0.1.3" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#operaciones-con-conjuntos"><i class="fa fa-check"></i><b>0.1.3</b> Operaciones con conjuntos</a></li>
<li class="chapter" data-level="0.1.4" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#más-propiedades-y-definiciones"><i class="fa fa-check"></i><b>0.1.4</b> Más propiedades y definiciones</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#combinatoria"><i class="fa fa-check"></i><b>0.2</b> Combinatoria</a><ul>
<li class="chapter" data-level="0.2.1" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#número-binomial."><i class="fa fa-check"></i><b>0.2.1</b> Número binomial.</a></li>
<li class="chapter" data-level="0.2.2" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#variaciones."><i class="fa fa-check"></i><b>0.2.2</b> Variaciones.</a></li>
<li class="chapter" data-level="0.2.3" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#variaciones-con-repetición."><i class="fa fa-check"></i><b>0.2.3</b> Variaciones con repetición.</a></li>
<li class="chapter" data-level="0.2.4" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#permutaciones"><i class="fa fa-check"></i><b>0.2.4</b> Permutaciones</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html"><a href="pre-requisitos-teoría-de-conjuntos-y-combinatoria.html#para-acabar"><i class="fa fa-check"></i><b>0.3</b> Para acabar</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>1</b> Probabilidad</a><ul>
<li class="chapter" data-level="1.1" data-path="probabilidad.html"><a href="probabilidad.html#probabilidades-básicas"><i class="fa fa-check"></i><b>1.1</b> Probabilidades Básicas</a><ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad.html"><a href="probabilidad.html#operaciones-con-sucesos"><i class="fa fa-check"></i><b>1.1.1</b> Operaciones con sucesos</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad.html"><a href="probabilidad.html#propiedades"><i class="fa fa-check"></i><b>1.1.2</b> Propiedades</a></li>
<li class="chapter" data-level="1.1.3" data-path="probabilidad.html"><a href="probabilidad.html#definición-de-probabilidad"><i class="fa fa-check"></i><b>1.1.3</b> Definición de probabilidad</a></li>
<li class="chapter" data-level="1.1.4" data-path="probabilidad.html"><a href="probabilidad.html#propiedades-1"><i class="fa fa-check"></i><b>1.1.4</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.2</b> Probabilidad condicionada</a><ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad.html"><a href="probabilidad.html#atención"><i class="fa fa-check"></i><b>1.2.1</b> ¡Atención!</a></li>
<li class="chapter" data-level="1.2.2" data-path="probabilidad.html"><a href="probabilidad.html#propiedades-2"><i class="fa fa-check"></i><b>1.2.2</b> Propiedades</a></li>
<li class="chapter" data-level="1.2.3" data-path="probabilidad.html"><a href="probabilidad.html#teorema-de-la-probabilidad-total"><i class="fa fa-check"></i><b>1.2.3</b> Teorema de la probabilidad total</a></li>
<li class="chapter" data-level="1.2.4" data-path="probabilidad.html"><a href="probabilidad.html#clasificación-o-diagnósticos"><i class="fa fa-check"></i><b>1.2.4</b> Clasificación o Diagnósticos</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad.html"><a href="probabilidad.html#bayes"><i class="fa fa-check"></i><b>1.3</b> Bayes</a><ul>
<li class="chapter" data-level="1.3.1" data-path="probabilidad.html"><a href="probabilidad.html#fórmula-de-bayes"><i class="fa fa-check"></i><b>1.3.1</b> Fórmula de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="probabilidad.html"><a href="probabilidad.html#independencia-de-sucesos"><i class="fa fa-check"></i><b>1.4</b> Independencia de sucesos</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probabilidad.html"><a href="probabilidad.html#sucesos-independientes"><i class="fa fa-check"></i><b>1.4.1</b> Sucesos independientes</a></li>
<li class="chapter" data-level="1.4.2" data-path="probabilidad.html"><a href="probabilidad.html#sucesos-independientes-vs-disjuntos"><i class="fa fa-check"></i><b>1.4.2</b> Sucesos independientes vs disjuntos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>2</b> Variables Aleatorias</a><ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#introducción-a-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.1</b> Introducción a las variables aleatorias</a><ul>
<li class="chapter" data-level="2.1.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#definición-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.1.1</b> Definición de variable aleatoria</a></li>
<li class="chapter" data-level="2.1.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>2.1.2</b> Tipos de variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.2</b> Variables aleatorias discretas</a><ul>
<li class="chapter" data-level="2.2.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#distribuciones-de-probabilidad-para-v.a.-discretas."><i class="fa fa-check"></i><b>2.2.1</b> Distribuciones de probabilidad para v.a. discretas.</a></li>
<li class="chapter" data-level="2.2.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#valores-esperados-o-esperanza"><i class="fa fa-check"></i><b>2.2.2</b> Valores esperados o esperanza</a></li>
<li class="chapter" data-level="2.2.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#medidas-de-la-variabilidad"><i class="fa fa-check"></i><b>2.2.3</b> Medidas de la variabilidad</a></li>
<li class="chapter" data-level="2.2.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#transformaciones-lineales."><i class="fa fa-check"></i><b>2.2.4</b> Transformaciones lineales.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.3</b> Variables aleatorias continuas</a><ul>
<li class="chapter" data-level="2.3.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#propiedades-3"><i class="fa fa-check"></i><b>2.3.1</b> Propiedades</a></li>
<li class="chapter" data-level="2.3.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#función-de-densidad"><i class="fa fa-check"></i><b>2.3.2</b> Función de densidad</a></li>
<li class="chapter" data-level="2.3.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#utilidad-de-la-función-de-densidad"><i class="fa fa-check"></i><b>2.3.3</b> Utilidad de la función de densidad</a></li>
<li class="chapter" data-level="2.3.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#esperanza-y-varianza-para-variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.3.4</b> Esperanza y varianza para variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#transformaciones-de-variables-aleatorias"><i class="fa fa-check"></i><b>2.4</b> Transformaciones de variables aleatorias</a></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#desigualdades-de-markov-y-de-chebychev"><i class="fa fa-check"></i><b>2.5</b> Desigualdades de Markov y de Chebychev</a><ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#desigualdad-de-markov"><i class="fa fa-check"></i><b>2.5.1</b> Desigualdad de Markov</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#desigualdad-de-chebychev"><i class="fa fa-check"></i><b>2.5.2</b> Desigualdad de Chebychev</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html#cuantiles-de-variables-aleatorias"><i class="fa fa-check"></i><b>2.6</b> Cuantiles de variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a><ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a><ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-de-bernoulli"><i class="fa fa-check"></i><b>3.1.1</b> Distribución de Bernoulli</a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-binomial"><i class="fa fa-check"></i><b>3.1.2</b> Distribución binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-geométrica"><i class="fa fa-check"></i><b>3.1.3</b> Distribución geométrica</a></li>
<li class="chapter" data-level="3.1.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-binomial-negativa"><i class="fa fa-check"></i><b>3.1.4</b> Distribución binomial negativa</a></li>
<li class="chapter" data-level="3.1.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-de-poisson"><i class="fa fa-check"></i><b>3.1.5</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-hipergeométrica"><i class="fa fa-check"></i><b>3.1.6</b> Distribución hipergeométrica</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#cuantiles-de-distribuciones-notables-discretas"><i class="fa fa-check"></i><b>3.2</b> Cuantiles de distribuciones notables discretas</a></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.3</b> Distribuciones continuas</a><ul>
<li class="chapter" data-level="3.3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-uniforme"><i class="fa fa-check"></i><b>3.3.1</b> Distribución uniforme</a></li>
<li class="chapter" data-level="3.3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-exponencial"><i class="fa fa-check"></i><b>3.3.2</b> Distribución exponencial</a></li>
<li class="chapter" data-level="3.3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-normal-o-gaussiana"><i class="fa fa-check"></i><b>3.3.3</b> Distribución normal o Gaussiana</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html"><i class="fa fa-check"></i><b>4</b> Variables Aleatorias. Complementos</a><ul>
<li class="chapter" data-level="4.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#momentos-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.1</b> Momentos de variables aleatorias</a><ul>
<li class="chapter" data-level="4.1.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#momento-de-orden-n"><i class="fa fa-check"></i><b>4.1.1</b> Momento de orden <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="4.1.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#momento-central-de-orden-n"><i class="fa fa-check"></i><b>4.1.2</b> Momento central de orden <span class="math inline">\(n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#asimetría-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>4.2</b> Asimetría de una variable aleatoria</a></li>
<li class="chapter" data-level="4.3" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#curtosis-o-apuntamiento-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>4.3</b> Curtosis o apuntamiento de una variable aleatoria</a></li>
<li class="chapter" data-level="4.4" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#métodos-de-transformación"><i class="fa fa-check"></i><b>4.4</b> Métodos de transformación</a><ul>
<li class="chapter" data-level="4.4.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#función-generatriz-de-momentos"><i class="fa fa-check"></i><b>4.4.1</b> Función generatriz de momentos</a></li>
<li class="chapter" data-level="4.4.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#función-característica"><i class="fa fa-check"></i><b>4.4.2</b> Función característica</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#fiabilidad"><i class="fa fa-check"></i><b>4.5</b> Fiabilidad</a><ul>
<li class="chapter" data-level="4.5.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#tiempo-medio-de-vida"><i class="fa fa-check"></i><b>4.5.1</b> Tiempo medio de vida</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#generación-de-muestras-de-variables-aleatorias-por-ordenador"><i class="fa fa-check"></i><b>4.6</b> Generación de muestras de variables aleatorias por ordenador</a><ul>
<li class="chapter" data-level="4.6.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#método-de-transformación"><i class="fa fa-check"></i><b>4.6.1</b> Método de transformación</a></li>
<li class="chapter" data-level="4.6.2" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#método-de-rechazo"><i class="fa fa-check"></i><b>4.6.2</b> Método de rechazo</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#entropía"><i class="fa fa-check"></i><b>4.7</b> Entropía</a><ul>
<li class="chapter" data-level="4.7.1" data-path="variables-aleatorias-complementos.html"><a href="variables-aleatorias-complementos.html#entropía-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>4.7.1</b> Entropía de una variable aleatoria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html"><i class="fa fa-check"></i><b>5</b> Vectores aleatorios bidimensionales</a><ul>
<li class="chapter" data-level="5.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#dos-variables-aleatorias"><i class="fa fa-check"></i><b>5.1</b> Dos variables aleatorias</a><ul>
<li class="chapter" data-level="5.1.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#definición"><i class="fa fa-check"></i><b>5.1.1</b> Definición</a></li>
<li class="chapter" data-level="5.1.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#representación-del-dominio-de-una-variable-aleatoria-bidimensional"><i class="fa fa-check"></i><b>5.1.2</b> Representación del dominio de una variable aleatoria bidimensional</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#función-de-distribución-conjunta"><i class="fa fa-check"></i><b>5.2</b> Función de distribución conjunta</a><ul>
<li class="chapter" data-level="5.2.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#definición-1"><i class="fa fa-check"></i><b>5.2.1</b> Definición</a></li>
<li class="chapter" data-level="5.2.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#propiedades-4"><i class="fa fa-check"></i><b>5.2.2</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-bidimensionales-discretas"><i class="fa fa-check"></i><b>5.3</b> Variables aleatorias bidimensionales discretas</a><ul>
<li class="chapter" data-level="5.3.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#función-de-probabilidad-conjunta"><i class="fa fa-check"></i><b>5.3.1</b> Función de probabilidad conjunta</a></li>
<li class="chapter" data-level="5.3.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>5.3.2</b> Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-bidimensionales-continuas"><i class="fa fa-check"></i><b>5.4</b> Variables aleatorias bidimensionales continuas</a><ul>
<li class="chapter" data-level="5.4.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#definición-2"><i class="fa fa-check"></i><b>5.4.1</b> Definición</a></li>
<li class="chapter" data-level="5.4.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#propiedades-de-la-función-de-densidad"><i class="fa fa-check"></i><b>5.4.2</b> Propiedades de la función de densidad</a></li>
<li class="chapter" data-level="5.4.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#la-distribución-gaussiana-bidimensional"><i class="fa fa-check"></i><b>5.4.3</b> La distribución gaussiana bidimensional</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.5</b> Independencia de variables aleatorias</a><ul>
<li class="chapter" data-level="5.5.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#independencia-de-variables-aleatorias-discretas"><i class="fa fa-check"></i><b>5.5.1</b> Independencia de variables aleatorias discretas</a></li>
<li class="chapter" data-level="5.5.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#independencia-de-variables-aleatorias-continuas"><i class="fa fa-check"></i><b>5.5.2</b> Independencia de variables aleatorias continuas</a></li>
<li class="chapter" data-level="5.5.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#relación-de-la-independencia-y-la-función-de-distribución"><i class="fa fa-check"></i><b>5.5.3</b> Relación de la independencia y la función de distribución</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#momentos-conjuntos-y-valores-esperados-conjuntos"><i class="fa fa-check"></i><b>5.6</b> Momentos conjuntos y valores esperados conjuntos</a><ul>
<li class="chapter" data-level="5.6.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valor-esperado-de-una-función-de-dos-variables-aleatorias"><i class="fa fa-check"></i><b>5.6.1</b> Valor esperado de una función de dos variables aleatorias</a></li>
<li class="chapter" data-level="5.6.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valor-esperado-de-una-función-de-dos-variables-aleatorias-independientes"><i class="fa fa-check"></i><b>5.6.2</b> Valor esperado de una función de dos variables aleatorias independientes</a></li>
<li class="chapter" data-level="5.6.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#momentos-conjuntos"><i class="fa fa-check"></i><b>5.6.3</b> Momentos conjuntos</a></li>
<li class="chapter" data-level="5.6.4" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#momentos-conjuntos-centrados-en-las-medias"><i class="fa fa-check"></i><b>5.6.4</b> Momentos conjuntos centrados en las medias</a></li>
<li class="chapter" data-level="5.6.5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#covariancia-entre-las-variables"><i class="fa fa-check"></i><b>5.6.5</b> Covariancia entre las variables</a></li>
<li class="chapter" data-level="5.6.6" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#coeficiente-de-correlación-entre-las-variables"><i class="fa fa-check"></i><b>5.6.6</b> Coeficiente de correlación entre las variables</a></li>
<li class="chapter" data-level="5.6.7" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#incorrelación-e-independencia"><i class="fa fa-check"></i><b>5.6.7</b> Incorrelación e independencia</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-condicionales-y-valor-esperado-condicional"><i class="fa fa-check"></i><b>5.7</b> Variables aleatorias condicionales y valor esperado condicional</a><ul>
<li class="chapter" data-level="5.7.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-condicionales-discretas"><i class="fa fa-check"></i><b>5.7.1</b> Variables aleatorias condicionales discretas</a></li>
<li class="chapter" data-level="5.7.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-condicionales-continuas"><i class="fa fa-check"></i><b>5.7.2</b> Variables aleatorias condicionales continuas</a></li>
<li class="chapter" data-level="5.7.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valores-esperados-condicionales"><i class="fa fa-check"></i><b>5.7.3</b> Valores esperados condicionales</a></li>
<li class="chapter" data-level="5.7.4" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#relación-con-el-problema-de-la-regresión-general"><i class="fa fa-check"></i><b>5.7.4</b> Relación con el problema de la regresión general</a></li>
<li class="chapter" data-level="5.7.5" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#valores-esperados-condicionales.-caso-general"><i class="fa fa-check"></i><b>5.7.5</b> Valores esperados condicionales. Caso general</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variables-aleatorias-definidas-como-función-de-dos-variables-aleatorias-conjuntas"><i class="fa fa-check"></i><b>5.8</b> Variables aleatorias definidas como función de dos variables aleatorias conjuntas</a><ul>
<li class="chapter" data-level="5.8.1" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#variable-aleatoria-función-de-la-variable-aleatoria-bidimensional"><i class="fa fa-check"></i><b>5.8.1</b> Variable aleatoria función de la variable aleatoria bidimensional</a></li>
<li class="chapter" data-level="5.8.2" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#transformaciones-lineales-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.8.2</b> Transformaciones lineales de variables aleatorias</a></li>
<li class="chapter" data-level="5.8.3" data-path="vectores-aleatorios-bidimensionales.html"><a href="vectores-aleatorios-bidimensionales.html#transformaciones-generales-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.8.3</b> Transformaciones generales de variables aleatorias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html"><i class="fa fa-check"></i><b>6</b> Vectores aleatorios</a><ul>
<li class="chapter" data-level="6.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#varias-variables-aleatorias"><i class="fa fa-check"></i><b>6.1</b> Varias variables aleatorias</a><ul>
<li class="chapter" data-level="6.1.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#definición-3"><i class="fa fa-check"></i><b>6.1.1</b> Definición</a></li>
<li class="chapter" data-level="6.1.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#representación-del-dominio-de-una-variable-aleatoria-n-dimensional"><i class="fa fa-check"></i><b>6.1.2</b> Representación del dominio de una variable aleatoria <span class="math inline">\(n\)</span>-dimensional</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#función-de-distribución-conjunta-1"><i class="fa fa-check"></i><b>6.2</b> Función de distribución conjunta</a><ul>
<li class="chapter" data-level="6.2.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#definición-4"><i class="fa fa-check"></i><b>6.2.1</b> Definición</a></li>
<li class="chapter" data-level="6.2.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-5"><i class="fa fa-check"></i><b>6.2.2</b> Propiedades</a></li>
<li class="chapter" data-level="6.2.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#ejemplos-9"><i class="fa fa-check"></i><b>6.2.3</b> Ejemplos</a></li>
<li class="chapter" data-level="6.2.4" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#ejemplo-con-r"><i class="fa fa-check"></i><b>6.2.4</b> Ejemplo con <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#variables-aleatorias-n-dimensionales-discretas"><i class="fa fa-check"></i><b>6.3</b> Variables aleatorias <span class="math inline">\(n\)</span>-dimensionales discretas</a><ul>
<li class="chapter" data-level="6.3.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#función-de-probabilidad-conjunta-1"><i class="fa fa-check"></i><b>6.3.1</b> Función de probabilidad conjunta</a></li>
<li class="chapter" data-level="6.3.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-de-la-función-de-probabilidad-conjunta-1"><i class="fa fa-check"></i><b>6.3.2</b> Propiedades de la función de probabilidad conjunta</a></li>
<li class="chapter" data-level="6.3.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#funciones-de-distribución-marginales"><i class="fa fa-check"></i><b>6.3.3</b> Funciones de distribución marginales</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#variables-aleatorias-n-dimensionales-continuas"><i class="fa fa-check"></i><b>6.4</b> Variables aleatorias <span class="math inline">\(n\)</span>-dimensionales continuas</a><ul>
<li class="chapter" data-level="6.4.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#definición-5"><i class="fa fa-check"></i><b>6.4.1</b> Definición</a></li>
<li class="chapter" data-level="6.4.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-de-la-función-de-densidad-1"><i class="fa fa-check"></i><b>6.4.2</b> Propiedades de la función de densidad</a></li>
<li class="chapter" data-level="6.4.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#la-distribución-gaussiana-n-dimensional"><i class="fa fa-check"></i><b>6.4.3</b> La distribución gaussiana <span class="math inline">\(n\)</span>-dimensional</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#independencia-de-variables-aleatorias-1"><i class="fa fa-check"></i><b>6.5</b> Independencia de variables aleatorias</a><ul>
<li class="chapter" data-level="6.5.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#independencia-de-variables-aleatorias-discretas-1"><i class="fa fa-check"></i><b>6.5.1</b> Independencia de variables aleatorias discretas</a></li>
<li class="chapter" data-level="6.5.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#independencia-de-variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>6.5.2</b> Independencia de variables aleatorias continuas</a></li>
<li class="chapter" data-level="6.5.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#relación-de-la-independencia-y-la-función-de-distribución-1"><i class="fa fa-check"></i><b>6.5.3</b> Relación de la independencia y la función de distribución</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#momentos-conjuntos-y-valores-esperados-conjuntos-1"><i class="fa fa-check"></i><b>6.6</b> Momentos conjuntos y valores esperados conjuntos</a><ul>
<li class="chapter" data-level="6.6.1" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#valor-esperado-de-una-función-de-n-variables-aleatorias"><i class="fa fa-check"></i><b>6.6.1</b> Valor esperado de una función de <span class="math inline">\(n\)</span> variables aleatorias</a></li>
<li class="chapter" data-level="6.6.2" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#ejemplos-15"><i class="fa fa-check"></i><b>6.6.2</b> Ejemplos</a></li>
<li class="chapter" data-level="6.6.3" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedad-del-valor-esperado-de-la-suma-de-variables"><i class="fa fa-check"></i><b>6.6.3</b> Propiedad del valor esperado de la suma de variables</a></li>
<li class="chapter" data-level="6.6.4" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#valor-esperado-de-una-función-de-n-variables-aleatorias-independientes"><i class="fa fa-check"></i><b>6.6.4</b> Valor esperado de una función de <span class="math inline">\(n\)</span> variables aleatorias independientes</a></li>
<li class="chapter" data-level="6.6.5" data-path="vectores-aleatorios.html"><a href="vectores-aleatorios.html#propiedades-de-la-covarianza-1"><i class="fa fa-check"></i><b>6.6.5</b> Propiedades de la covarianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><i class="fa fa-check"></i><b>7</b> Ley de los grandes números y Teorema Central del Límite</a><ul>
<li class="chapter" data-level="7.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#muestras-aleatorias-simples"><i class="fa fa-check"></i><b>7.1</b> Muestras aleatorias simples</a><ul>
<li class="chapter" data-level="7.1.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#la-distribución-de-la-media-muestral"><i class="fa fa-check"></i><b>7.1.1</b> La distribución de la media muestral</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-de-sucesiones-de-variables-aleatorias"><i class="fa fa-check"></i><b>7.2</b> Convergencia de sucesiones de variables aleatorias</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-casi-segura"><i class="fa fa-check"></i><b>7.2.1</b> Convergencia casi segura</a></li>
<li class="chapter" data-level="7.2.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-en-probabilidad"><i class="fa fa-check"></i><b>7.2.2</b> Convergencia en probabilidad</a></li>
<li class="chapter" data-level="7.2.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-en-ley-o-en-distribución"><i class="fa fa-check"></i><b>7.2.3</b> Convergencia en ley o en distribución</a></li>
<li class="chapter" data-level="7.2.4" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#relaciones-entre-las-distintas-convergencias"><i class="fa fa-check"></i><b>7.2.4</b> Relaciones entre las distintas convergencias</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#leyes-de-los-grandes-números"><i class="fa fa-check"></i><b>7.3</b> Leyes de los grandes números</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#leyes-débiles-de-los-grandes-números"><i class="fa fa-check"></i><b>7.3.1</b> Leyes débiles de los grandes números</a></li>
<li class="chapter" data-level="7.3.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#convergencia-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>7.3.2</b> Convergencia de los momentos muestrales</a></li>
<li class="chapter" data-level="7.3.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#leyes-fuertes-de-los-grandes-números"><i class="fa fa-check"></i><b>7.3.3</b> Leyes fuertes de los grandes números</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-central-del-límite"><i class="fa fa-check"></i><b>7.4</b> Teorema Central del Límite</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-central-del-límite-1"><i class="fa fa-check"></i><b>7.4.1</b> Teorema Central del Límite</a></li>
<li class="chapter" data-level="7.4.2" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-central-del-límite-en-la-práctica"><i class="fa fa-check"></i><b>7.4.2</b> Teorema Central del Límite en la práctica</a></li>
<li class="chapter" data-level="7.4.3" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#teorema-de-moivre-laplace"><i class="fa fa-check"></i><b>7.4.3</b> Teorema de Moivre-Laplace</a></li>
<li class="chapter" data-level="7.4.4" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#aproximación-de-una-suma-de-variables-poisson"><i class="fa fa-check"></i><b>7.4.4</b> Aproximación de una suma de variables Poisson</a></li>
<li class="chapter" data-level="7.4.5" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#corrección-de-continuidad-de-fisher"><i class="fa fa-check"></i><b>7.4.5</b> Corrección de continuidad de Fisher</a></li>
<li class="chapter" data-level="7.4.6" data-path="ley-de-los-grandes-números-y-teorema-central-del-límite.html"><a href="ley-de-los-grandes-números-y-teorema-central-del-límite.html#simulación-del-teorema-central-del-límite"><i class="fa fa-check"></i><b>7.4.6</b> Simulación del Teorema Central del Límite</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7" target="blank">Curso en Udemy</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probabilidad y variables aleatorias para ML con R y Python</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variables-aleatorias" class="section level1">
<h1><span class="header-section-number">Tema 2</span> Variables Aleatorias</h1>
<div id="introducción-a-las-variables-aleatorias" class="section level2">
<h2><span class="header-section-number">2.1</span> Introducción a las variables aleatorias</h2>
<ul>
<li>Hasta ahora nuestros sucesos han sido de varios tipos: <span class="math inline">\(\{C,+\}\)</span> en
la moneda, nombres de periódicos, ángulos en una ruleta, número de
veces que sale cara en el lanzamiento de una moneda etc.</li>
<li>Necesitamos estandarizar de alguna manera todos estos sucesos. Una
solución es asignar a cada suceso un cierto conjunto de
números reales, es decir, convertir todos los sucesos en
<em>sucesos de números reales</em> para trabajar con ellos de forma
unificada.</li>
<li>Para conseguirlo utilizaremos unas funciones que
transformen los elementos del espacio muestral en números; esta funciones son las
variables aleatorias.</li>
</ul>
<div id="definición-de-variable-aleatoria" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Definición de variable aleatoria</h3>
<p>Comenzaremos dando una definición poco rigurosa, pero suficiente, de variable aleatoria.</p>
<p><l class="definition"> <strong>Variable Aleatoria (definición práctica)</strong> </l></p>
<p>Una variable aleatoria (v.a.) es una aplicación que toma valores numéricos determinados por el resultado de un experimento aleatorio</p>
<p><l class="observ"><strong>Notación</strong>:</l></p>
<ul>
<li>Normalmente representaremos las v.a. por letras mayúsculas <span class="math inline">\(X,Y,Z\ldots\)</span></li>
<li>Los valores que “<em>toman</em>” las v.a. los representaremos por letras minúsculas (las mismas en principio) <span class="math inline">\(x,y,z\ldots\)</span></li>
</ul>
<div class="example">
<p><strong>Ejemplo: Dado seis caras</strong></p>
<p>Lanzamos un dado convencional de parchís el espacio muestral del experimento es</p>
<p><span class="math display">\[\Omega=\{1,2, 3, 4,  5, 6\}.\]</span></p>
<div class="example-sol">
<p>Una v.a <span class="math inline">\(X:\Omega\to\mathbb{R}\)</span>
sobre este espacio queda definida por</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}
X(1)&amp;=1,X(2)=2,X(3)=3,\\
X(4)&amp;=4,X(5)=5,X(6)=6.
\end{split}
\end{equation*}\]</span></p>
<ul>
<li>Ahora el suceso <span class="math inline">\(A=\{2, 4, 6\}\)</span>, es decir “salir
número par”, es equivalente a <span class="math inline">\(\{X=2,X=4,X=6\}\)</span>.</li>
<li>El suceso <span class="math inline">\(B=\{1,2,3\}\)</span>, es decir “salir un número
inferior o igual a <span class="math inline">\(3\)</span>” es en términos de la v.a. <span class="math inline">\(\{X=1,X=2,X=3\}\)</span> o también <span class="math inline">\(\{X\leq 3\}\)</span>.</li>
</ul>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: Juego lanzamiento anilla</strong></p>
<p>Consideremos el experimento lanzar una anilla al cuello de una botella. Si acertamos a
ensartar la anilla en la botella el resultado del experimento es <em>éxito</em> y
<em>fracaso</em> en caso contrario.</p>
<div class="example-sol">
<p>El espacio muestral asociado a este experimento será
<span class="math inline">\(\Omega=\{\mbox{éxito, fracaso}\}\)</span>. Construyamos la siguiente variable aleatoria:</p>
<p><span class="math display">\[X:\{\mbox{éxito, fracaso}\}\to\mathbb{R}\]</span></p>
<p>definida por</p>
<p><span class="math display">\[X(\mbox{éxito})=1 \mbox{ y } X(\mbox{fracaso})=0.\]</span></p>
</div>
</div>
</div>
<div id="tipos-de-variables-aleatorias" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Tipos de variables aleatorias</h3>
<p>Hay dos tipos fundamentales de variables aleatorias, las discretas y las continuas.</p>
<p>Damos a continuación una definición informal.</p>
<p><l class="definition"><strong>Variables Aleatorias Discretas y Continuas</strong> </l></p>
<ul>
<li>Una variable aleatoria es <strong>discreta</strong> si sólo puede tomar una cantidad numerable de valores con probabilidad positiva.</li>
<li>Las variables aleatorias <strong>continuas</strong> toman valores en intervalos.</li>
<li>También existen las variables aleatorias <strong>mixtas</strong>; con una parte discreta y otra continua.</li>
</ul>
<div class="example">
<p><strong>Ejemplo: Tipos de variables aleatorias</strong></p>
<p>Son <strong>variables aleatorias discretas</strong>:</p>
<ul>
<li>Número de artículos defectuosos en un cargamento.</li>
<li>Número de clientes que llegan a una ventanilla de un banco en una hora.</li>
<li>Número de errores detectados en las cuentas de una compañía.</li>
<li>Número de reclamaciones de una póliza de un seguro médico.</li>
</ul>
<p>Son <strong>variables aleatorias continuas</strong>:</p>
<ul>
<li>Renta anual de una familia.</li>
<li>Cantidad de petróleo importado por un país.</li>
<li>Variación del precio de las acciones de una compañía de telecomunicaciones.</li>
<li>Porcentaje de impurezas en un lote de productos químicos.</li>
</ul>
</div>
</div>
</div>
<div id="variables-aleatorias-discretas" class="section level2">
<h2><span class="header-section-number">2.2</span> Variables aleatorias discretas</h2>
<div id="distribuciones-de-probabilidad-para-v.a.-discretas." class="section level3">
<h3><span class="header-section-number">2.2.1</span> Distribuciones de probabilidad para v.a. discretas.</h3>
<ul>
<li>Pasamos ahora a describir el comportamiento de la v.a.
Para ello utilizaremos distintas funciones que nos darán algunas probabilidades de la variable aleatoria.</li>
<li>En el caso discreto estas funciones son la de probabilidad, y la función de distribución o de probabilidad acumulada.</li>
<li>En el caso discreto la función de probabilidad es la que nos da las probabilidades de los sucesos elementales de la v.a. que definimos a continuación.</li>
</ul>
<p><l class="definition"> <strong>Función de Probabilidad</strong></l></p>
<p>La <strong>función de probabilidad</strong> (<em>probability mass function</em> o incluso abusando de notación <em>probability density function</em>) de una variable aleatoria discreta <span class="math inline">\(X\)</span> a la que denotaremos por <span class="math inline">\(P_{X}(x)\)</span> está definida por
<span class="math display">\[P_{X}(x)=P(X=x),\]</span>
es decir la probabilidad de que <span class="math inline">\(X\)</span> tome el valor <span class="math inline">\(x\)</span>.</p>
<p>Si <span class="math inline">\(X\)</span> no asume ese valor <span class="math inline">\(x\)</span>, entonces <span class="math inline">\(P_{X}(x)=0\)</span>.</p>
<p><l class="definition"> <strong>Dominio de una variable aleatoria discreta</strong> </l></p>
<p>El conjunto <span class="math display">\[D_X=\{ x\in\mathbb{R} \mid P_X(x)&gt;0\}\]</span> recibe el nombre de
<strong>dominio</strong> de la v.a. y son los valores posibles de esta variable.</p>
<p>En el caso discreto lo más habitual es que <span class="math inline">\(X(\Omega)=D_X\)</span>.</p>
<div class="example">
<p><strong>Ejemplo: Juego del parchís</strong></p>
<p>Lanzamos un dado de parchís una vez, en esta ocasión representaremos los
sucesos elementales por el número de puntos de la cara obtenida, tenemos que
<span class="math display">\[\Omega=\{\mbox{1-puntos,2-puntos,3-puntos,4-puntos,5-puntos,6-puntos}\},\]</span>
y la variable aleatoria <span class="math inline">\(X:\Omega\to \mathbb{R}\)</span> viene definida por</p>
<p><span class="math display">\[X(\mbox{i-puntos})=i\mbox{ para } i=1,2,3,4,5,6.\]</span></p>
<div class="example-sol">
<p>Supongamos que el dado está bien balanceado. Entonces
<span class="math display">\[P_{X}(1)=P_{X}(2)=P_{X}(3)=P_{X}(4)=P_{X}(5)=P_{X}(6)=\frac16.\]</span>
Concretamente:
<span class="math display">\[
P_{X}(x)=
  \left\{
  \begin{array}{ll}
   \frac16 &amp; \mbox{si } x=1,2,3,4,5,6\\
  0 &amp; \mbox{en otro caso. }
  \end{array}
  \right.
\]</span></p>
<p>Su dominio es <span class="math display">\[D_X=\{1,2,3,4,5,6\}.\]</span></p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: Lanzamiento moneda</strong></p>
<p>Sea <span class="math inline">\(X\)</span> la v.a. asociada al lanzamiento de una moneda. Su espacio muestral es <span class="math inline">\(\Omega=\{c,+\}\)</span>, la v.a. queda definida por:</p>
<p><span class="math display">\[X(\omega)=\left\{\begin{array}{ll} 1 &amp; \mbox{si } \omega=c, \\
0 &amp; \mbox{si }\omega=+.\end{array}\right.\]</span></p>
<div class="example-sol">
<p>Su función de probabilidad es:</p>
<p><span class="math display">\[P_{X}(x)=P(X=x)=\left\{\begin{array}{ll} \frac12, &amp; \mbox{si } x=0,1,\\
0, &amp; \mbox{en otro caso.}\end{array}\right.\]</span></p>
<p>Finalmente su dominio es <span class="math inline">\(D_X=\{0,1\}.\)</span></p>
</div>
</div>
<div class="example">
<p><strong>Ejemplo: Urna con bolas</strong></p>
<p>Tenemos una urna con tres bolas rojas, una negra y dos blancas. Realizamos una extracción y observamos el color de la bola entonces un espacio muestral es
<span class="math display">\[\Omega=\{roja, blanca, negra\}.\]</span></p>
<div class="example-sol">
<p>Una variable aleatoria asociada al experimento es:</p>
<p><span class="math display">\[X(\omega)=\left\{\begin{array}{ll} 1, &amp; \mbox{si } \omega=roja,  \\
2, &amp; \mbox{si }\omega=negra, \\ 3, &amp; \mbox{si } \omega=blanca. \end{array}\right.\]</span></p>
<p>La función de probabilidad es</p>
<p><span class="math display">\[P_{X}(x)=\left\{\begin{array}{ll} \frac36, &amp; \mbox{si } x=1,\\[1ex]
\frac16, &amp; \mbox{si } x=2,\\[1ex] \frac26, &amp; \mbox{si } x=3,\\[1ex] 0, &amp; \mbox{en otro
caso.}\end{array}\right.\]</span></p>
<p>El dominio de la v.a. <span class="math inline">\(X\)</span> es <span class="math inline">\(D_X=\{1,2,3\}.\)</span></p>
</div>
</div>
<p><l class="prop"> <strong>Propiedades básicas de la función de probabilidad</strong> </l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. discreta <span class="math inline">\(X:\Omega:\to\mathbb{R}\)</span> con dominio <span class="math inline">\(D_X\)</span>. Su función de probabilidad <span class="math inline">\(P_{X}\)</span> verifica las siguientes propiedades:</p>
<ul>
<li><span class="math inline">\(0\leq P_{X}(x)\leq 1\)</span>, para todo <span class="math inline">\(x\in\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\sum\limits_{x\in D_X} P_{X}(x)=1\)</span>.</li>
</ul>
<div class="example">
<p><strong>Ejemplo: Lanzamiento moneda</strong></p>
<p>Lanzamos al aire tres veces, de forma independiente, una moneda perfecta. El espacio muestral de este experimento es
<span class="math display">\[\Omega=\{ccc,cc+,c+c,+cc,c++,+c+,++c,+++\}\]</span> (expresados en orden de aparición).</p>
<div class="example-sol">
<p>Este espacio tiene todos los sucesos elementales equiprobables.</p>
<p>Consideremos la variable aleatoria asociada a este experimento:</p>
<p><span class="math display">\[X=\mbox{ número de caras en los tres lanzamientos}.\]</span></p>
<p>Su función de probabilidad es:</p>
<p><span class="math display">\[
\begin{array}{l}
P(X=0)=P(\{+++\})=\frac18,\\ P(X=1)=P(\{c++,+c+,++c\})=\frac38,\\
    P(X=2)=P(\{cc+,c+c,+cc\})=\frac38,\\
    P(X=3)=P(\{ccc\})=\frac18.
\end{array}
\]</span></p>
<p>Podemos reescribir la función de probabilidad de <span class="math inline">\(X\)</span> de forma simplificada:</p>
<p><span class="math display">\[P_{X}(x)=\left\{\begin{array}{ll} \frac18, &amp; \mbox{si } x=0, 3,\\[1ex]
\frac38, &amp; \mbox{si } x=1,2,\\[1ex] 0, &amp; \mbox{en otro caso.}\end{array}\right.\]</span></p>
<p>Efectivamente los valores de la función de distribución suman 1:</p>
<p><span class="math display">\[\sum_{x=0}^3 P_X(x)= \frac18+\frac38+\frac38+\frac18=1.\]</span></p>
</div>
</div>
<p><l class="definition"> <strong>Distribución de Probabilidad</strong></l></p>
<p>La función de <em>distribución de probabilidad</em> (acumulada) de la v.a. <span class="math inline">\(X\)</span> (de cualquier tipo; discreta o continua) <span class="math inline">\(F_{X}(x)\)</span> representa la probabilidad de que <span class="math inline">\(X\)</span> tome un menor o igual que <span class="math inline">\(x\)</span>, es decir,</p>
<p><span class="math display">\[F_{X}(x)=P(X\leq x).\]</span></p>
<p>Esta función también se denomina función de <em>distribución de
probabilidad o simplemente función de distribución</em> de una v.a., y en inglés
<em>cumulative distribution function</em> por lo que se abrevia con el acrónimo <code>cdf</code>.</p>
<p><l class="definition"> <strong>Propiedades de la Función de Distribución</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. y <span class="math inline">\(F_{X}\)</span> su función de distribución:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(X&gt;x)=1-P(X\leq x)=1-F_{X}(x).\)</span></li>
<li>Sea a y b tales que <span class="math inline">\(a&lt;b\)</span>, <span class="math inline">\(P(a&lt;X\leq b)=P(X\leq b)-P(X\leq a)=F_{X}(b)-F_{X}(a).\)</span></li>
</ol>
<div class="dem">
<p><strong>Demostración</strong>:</p>
<p>Tenemos que el complementario de <span class="math inline">\(X\)</span> mayor que <span class="math inline">\(x\)</span> es: <span class="math inline">\(\overline{\left\{X&gt;x\right\}}=\left\{X&gt;x\right\}^c=\left\{X\leq x\right\}\)</span>. Además,</p>
<p><span class="math display">\[P(X&gt;x)=1-P(\overline{\left\{X&gt;x\right\}})=1-P(X\leq x)=1-F_{X}(x),\]</span></p>
<p>lo que demuestra la primera propiedad.</p>
<p>Por otro lado, que <span class="math inline">\(X\)</span> se encuentre entre dos valores <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> es <span class="math inline">\(\left\{a&lt; X \leq b\right\}= \left\{X\leq b\right\}-\left\{X\leq a\right\}\)</span>. Ahora podemos hacer</p>
<p><span class="math display">\[\begin{eqnarray*}
P(a&lt;X\leq b)&amp;=&amp;P(\left\{X\leq b\right\}-\left\{X\leq a\right\})\\
&amp;=&amp; P(\left\{X\leq b\right\})-P(\left\{X\leq a\right\})\\
&amp;=&amp; F_{X}(b)-F_{X}(a).
\end{eqnarray*}\]</span></p>
</div>
<p><l class="definition"> <strong>Más propiedades de la Función de Distribución</strong></l></p>
<p>Sea <span class="math inline">\(F_{X}\)</span> la función de distribución de una v.a. <span class="math inline">\(X\)</span> entonces:</p>
<ul>
<li><span class="math inline">\(0\leq F_{X}(x)\leq 1\)</span>.</li>
<li>La función <span class="math inline">\(F_{X}\)</span> es no decreciente.</li>
<li>La función <span class="math inline">\(F_{X}\)</span> es continua por la derecha.</li>
<li>Si denotamos por <span class="math inline">\(F_X(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F(x)\)</span>,
entonces se cumple que <span class="math inline">\(P(X&lt; x_0)=F_X(x_0^{-})\)</span> y que <span class="math inline">\(P(X=x_0)=F_X(x_0)-F_X(x_0^{-})\)</span>.</li>
<li>Se cumple que <span class="math inline">\(\displaystyle \lim_{x\to\infty} F_{X}(x)=1\)</span>; <span class="math inline">\(\displaystyle \lim_{x\to-\infty}F_{X}(x)=0\)</span>.</li>
<li>Toda función <span class="math inline">\(F\)</span> verificando las propiedades anteriores es función de distribución de alguna v.a. <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(P(X&gt;x)=1-F_{X}(x)\)</span>.</li>
<li>Dados <span class="math inline">\(a,b\in \mathbb{R}\)</span> con <span class="math inline">\(a&lt;b\)</span>, <span class="math display">\[P(a&lt;X\leq b)=F_{X}(b)-F_{X}(a).\]</span></li>
</ul>
<p><strong>Advertencia desigualdades estrictas</strong></p>
<p>En las propiedades anteriores no se pueden cambiar en general las desigualdades de
estrictas o no estrictas.</p>
<p>Veamos que propiedades tenemos cuando se cambian estas
desigualdades.</p>
<p>Dada una <span class="math inline">\(F_{X}\)</span> una función de distribución de la v.a. <span class="math inline">\(X\)</span> y denotamos por <span class="math display">\[F_{X}(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F_{X}(x),\]</span>
entonces se cumplen las siguientes igualdades:</p>
<ul>
<li><span class="math inline">\(P(X=x)=F_{X}(x)-F_{X}(x^{-})\)</span>.</li>
<li><span class="math inline">\(P(a&lt; X&lt; b)=F_{X}(b^{-})-F_{X}(a)\)</span>.</li>
<li><span class="math inline">\(P(a\leq X&lt; b)=F_{X}(b^{-})-F_{X}(a^{-})\)</span>.</li>
<li><span class="math inline">\(P(X&lt;a)=F_{X}(a^{-})\)</span>.</li>
<li><span class="math inline">\(P(a\leq X\leq b)=F_{X}(b)-F_{X}(a^{-})\)</span>.</li>
<li><span class="math inline">\(P(X\geq a)=1-F_{X}(a^{-})\)</span>.</li>
<li>Si <span class="math inline">\(F_X\)</span> es continua en <span class="math inline">\(x\)</span> se tiene que <span class="math inline">\(P(X=x)=0\)</span>.
Así que si la v.a. es continua <span class="math inline">\(P(X\leq a)=P(X&lt; a)+P(X=a)=P(X&lt;a)\)</span> y propiedades similares.</li>
<li>Sea <span class="math inline">\(X\)</span> una variable aleatoria discreta que con dominio <span class="math inline">\(D_X\)</span> y
que tiene por función de probabilidad <span class="math inline">\(P_{X}(x)\)</span> entonces su función de distribución
<span class="math inline">\(F_{X}(x_0)\)</span> es
<span class="math display">\[F_{X}(x_0)=\sum_{x\leq x_0} P_{X}(x),\]</span>
donde <span class="math inline">\(\sum\limits_{x\leq x_0}\)</span> indica que sumamos todos los <span class="math inline">\(x \in D_X\)</span> tales que <span class="math inline">\(x\leq x_0\)</span>.</li>
</ul>
<div class="dem">
<p><strong>Demostración</strong>:</p>
<p>Si <span class="math inline">\(X\)</span> es continua <span class="math display">\[P(X=a)=F(a)-F(a^{-})=F(a)-F(a)=0,\]</span>
por lo tanto
<span class="math display">\[P(X\leq a)=P(X&lt;a)+P(X=a)= P(X&lt;a)+0= P(X&lt;a),\]</span>
lo que demuestra la primera propiedad.</p>
<p>Para demostrar la segunda basta hacer
<span class="math display">\[ 
F_{X}(x_0)= P(X\leq x_0)=P\left(\bigcup_{x\leq
x_0; x\in D_X} \{x\}\right)= \sum_{x\leq x_0}P(X=x)= \sum_{x\leq x_0}P_{X}(x).
\]</span></p>
</div>
<div class="example">
<p><strong>Ejemplo: dado (continuación)</strong></p>
<p>En el experimento del dado se tiene que:</p>
<p><span class="math display">\[P_{X}(x)=\left\{\begin{array}{ll} \frac16, &amp; \mbox{si } x=1,2,3,4,5,6,\\ 0, &amp; \mbox{en el resto de casos.}\end{array}\right.,\]</span></p>
<p>por lo tanto,
<span class="math display">\[F_{X}(x)=P(X\leq x)=\left\{\begin{array}{ll}
   0, &amp; \mbox{si } x&lt;1,\\[1ex]
   \frac16, &amp;\mbox{si } 1\leq x&lt;2,\\[1ex]
   \frac26, &amp;\mbox{si } 2\leq x&lt;3,\\[1ex]
   \frac36, &amp;\mbox{si } 3\leq x&lt;4,\\[1ex]
   \frac46, &amp;\mbox{si } 4\leq x&lt;5,\\[1ex]
   \frac56, &amp;\mbox{si } 5\leq x&lt;6,\\[1ex]
   1, &amp;\mbox{si } 6\leq x.\end{array}\right.\]</span></p>
<p>Calculemos más detalladamente algún valor de <span class="math inline">\(F_{X}\)</span>, por ejemplo:</p>
<p><span class="math display">\[\begin{eqnarray*}
F_{X}(3.5) &amp; = &amp; P(X\leq 3.5)=  P(\{X=1\}\cup\{X=2\}\cup \{X=3\})\\
&amp;=&amp; P(\{X=1\})+P(\{X=2\})+P(\{X=3\})\\
&amp;=&amp; \frac16+\frac16+\frac16=\frac36 =\frac12,
\end{eqnarray*}\]</span>
o de otra forma,
<span class="math display">\[\begin{eqnarray*}
F_{X}(3.5)&amp;=&amp;\sum_{x\leq 3.5} P_X(x)=\sum_{x=1}^3 P(X=x)\\&amp;=&amp;\sum_{x=1}^3 \frac16= 3 \cdot
   \frac16=\frac12.
\end{eqnarray*}\]</span></p>
</div>
<p><strong>Propiedades de la función de distribución</strong></p>
<p>Sea <span class="math inline">\(X\)</span> una variable con función de distribución <span class="math inline">\(F_{X}\)</span> entonces:</p>
<ul>
<li><span class="math inline">\(0\leq F_{X}(x)\leq 1\)</span>, para todo <span class="math inline">\(x\)</span>.</li>
<li>Si <span class="math inline">\(x&lt;x&#39;\)</span>, entonces <span class="math inline">\(F_{X}(x)\leq F_{X}(x&#39;),\)</span> es decir, es una función creciente, no necesariamente estrictamente creciente.</li>
<li><span class="math inline">\(\displaystyle \lim_{x\to -\infty}F_{X}(x)=0\)</span> y <span class="math inline">\(\displaystyle \lim_{x\to +\infty}F_{X}(x)=1\)</span>.</li>
<li>Es continua por la derecha: <span class="math inline">\(\displaystyle \lim_{x\to x_0^{+}}F_{X}(x)=F_{X}(x_0)\)</span>.</li>
</ul>
</div>
<div id="valores-esperados-o-esperanza" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Valores esperados o esperanza</h3>
<p>Al igual que en la estadística descriptiva se utilizan distintas medidas para
resumir los valores centrales y para medir la dispersión de una muestra, podemos definir
las correspondiente medidas para variables aleatorias.</p>
<p>A estas medidas se les suele añadir el adjetivo <strong>poblacionales</strong> mientras que a las que provienen de la muestra se las adjetiva como <strong>muestrales</strong>.</p>
<p>Por ejemplo podemos buscar un valor que resuma toda la variable. Este valor es el que “<em>esperamos</em>” que se resuma la v.a. o esperamos que las realizaciones de la v.a. queden cerca de él. Veamos su definición formal.</p>
<p><l class="definition"><strong>Esperanza de una variable aleatoria discreta </strong></l></p>
<p>El valor <strong>esperado o esperanza</strong> (<em>expected value</em> en inglés) <span class="math inline">\(E(X)\)</span> de una v.a. discreta <span class="math inline">\(X\)</span>, se define como</p>
<p><span class="math display">\[
E(X)=\sum_{x\in X(\Omega)} x P_{X}(x).
\]</span></p>
<p>En ocasiones se denomina <strong>media</strong> (<em>mean</em> en inglés) poblacional o simplemente media y muy frecuentemente se la denota <span class="math inline">\(\mu_{X}=E(X)\)</span> o simplemente <span class="math inline">\(\mu=E(X)\)</span>.</p>
<div class="example">
<p><strong>Ejemplo: lanzamiento de un dado <span class="math inline">\(n\)</span> veces</strong></p>
<p>Supongamos que lanzamos un dado <span class="math inline">\(n\)</span> veces y obtenemos unas frecuencias absolutas <span class="math inline">\(n_{i}\)</span> para el resultado <span class="math inline">\(i\)</span> con <span class="math inline">\(i=1,\ldots,6\)</span>. Sea <span class="math inline">\(X\)</span> la v.a. que nos representa el valor de una tirada del dado.</p>
<p>Calculemos la media aritmética (o media muestral) de los datos</p>
<p><span class="math display">\[
\overline{x}=\frac{1\cdot n_1+2\cdot  n_2+3\cdot  n_3+4\cdot  n_4+5\cdot  n_5+6 \cdot 
n_6}{n}=\sum_{x=1}^6 x\cdot \frac{n_{x}}{n}.
\]</span>
Si <span class="math inline">\(n\to \infty\)</span> se tiene que <span class="math inline">\(\displaystyle\lim_{n\to \infty} \frac{n_{x}}{n}=P_{X}(x).\)</span></p>
<p>Por lo tanto <span class="math inline">\(E(X)=\displaystyle \lim_{n\to\infty}\sum_{x=1}^6 x\cdot \frac{n_{x}}{n}.\)</span></p>
<p>Entonces el valor esperado en una v.a. discreta puede entenderse como el valor promedio que tomaría una v.a. en un número grande de repeticiones.</p>
</div>
<div class="example">
<p><strong>Ejemplo: Erratas en un texto</strong></p>
<p>Sea <span class="math inline">\(X\)</span> el número de erratas en una página de un texto, con dominio <span class="math inline">\(D_X=\{0,1,2\}\)</span>.</p>
<p>Resulta que</p>
<p><span class="math display">\[
P(X=0)=0.42,\ P(X=1)=0.4,\ P(X=2)=0.18.
\]</span></p>
<p>entonces</p>
<p><span class="math display">\[
E(X)=0\cdot 0.42+ 1\cdot 0.4 + 2 \cdot 0.18=0.76.
\]</span></p>
<p>Elegida una página del texto al azar esperamos encontrar <span class="math inline">\(0.76\)</span> errores por página.</p>
<p>Supongamos que el editor nos paga <span class="math inline">\(2\)</span> euros por cada página que
encontremos con <span class="math inline">\(1\)</span> error y <span class="math inline">\(3\)</span> euros por cada página con dos errores (y nada por las
páginas correctas) ¿Cuánto <em>esperamos</em> cobrar si analizamos una página?</p>
<p><span class="math display">\[0\cdot 0.42 + 2\cdot 0.4 + 3\cdot 0.18=1.34.\]</span></p>
</div>
<p><l class="definition"> <strong>Esperanzas de funciones de variables aleatorias discretas</strong> </l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. discreta con función de probabilidad <span class="math inline">\(P_{X}\)</span> y de distribución
<span class="math inline">\(F_{X}\)</span>. Entonces el <strong>valor esperado de una función</strong> <span class="math inline">\(g(x)\)</span> es :</p>
<p><span class="math display">\[E(g(X))=\sum_{x}g(x)\cdot P_{X}(x).\]</span></p>
<p><strong>Propiedades de los valores esperados</strong></p>
<ul>
<li><span class="math inline">\(E(k)=k\)</span> para cualquier constante <span class="math inline">\(k\)</span>.</li>
<li>Si <span class="math inline">\(a\leq X\leq b\)</span> entonces <span class="math inline">\(a\leq E(X)\leq b\)</span>.</li>
<li>Si <span class="math inline">\(X\)</span> es una v.a. discreta que toma valores enteros no negativos entonces
<span class="math inline">\(E(X)=\sum_{x=0}^{+\infty}(1- F_X(x)).\)</span></li>
</ul>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>La demostración de las propiedades anteriores se deja como ejercicio.</p>
</div>
<div class="example">
<p><strong>Ejemplo: paleta de colores aleatoria</strong></p>
<p>Supongamos que estamos sentados delante de nuestro ordenador con un amigo y
le decimos que en dos minutos podemos programar una paleta para poner colores a unos
gráficos.</p>
<p>Queremos que la paleta tenga dos botones con las opciones color rojo y color azul.
Como hemos programado a gran velocidad resulta que el programa tiene un error; cada vez que se abre la paleta los colores se colocan al azar (con igual probabilidad) en cada botón, así que no sabemos en qué color hemos de pinchar.</p>
<p>Además, como nos sobraron <span class="math inline">\(15\)</span> segundos
para hacer el programa y pensando en la comodidad del usuario, la paleta se cierra después de haber seleccionado un color y hay que volverla a abrir de nuevo.</p>
<p>La pregunta es: ¿cuál es el valor esperado del
número de veces que hemos pinchar el botón de color azul antes de obtener este color?</p>
<div class="example-sol">
<p>Llamemos <span class="math inline">\(X\)</span> al número de veces que pinchamos en el botón azul (y nos sale rojo) hasta
obtener el primer azul. La variable <span class="math inline">\(X\)</span> toma valores en los enteros no negativos. Su
función de probabilidad queda determinada por</p>
<p><span class="math display">\[
P_X(x)=P(X=x)=P(\stackrel{x \mbox{ veces}}{\overbrace{rojo, rojo,\ldots,rojo},azul})
=\left(\frac12\right)^{x+1}.
\]</span></p>
</div>
</div>
<p><strong>Series geométricas</strong></p>
<p>Una <strong>progresión geométrica</strong> de razón <span class="math inline">\(r\)</span> es una sucesión de la forma<br />
<span class="math display">\[
r^0, r^1,\ldots,r^n,\ldots.
\]</span>
La serie geométrica es la suma de todos los
valores de la progresión geométrica <span class="math inline">\(\displaystyle\sum_{k=0}^{+\infty} r^k\)</span>.</p>
<p><l class="prop"><strong>Propiedades</strong></l></p>
<ul>
<li><p>Las sumas parciales desde el término <span class="math inline">\(n_0\)</span> al <span class="math inline">\(n\)</span> de una progresión geométrica valen
<span class="math display">\[
\sum_{k=n_0}^n r^k=\frac{r^{n_0}- r^n r}{1-r}.
\]</span></p></li>
<li>Si <span class="math inline">\(|r|&lt;1\)</span> la serie geométrica es convergente y <span class="math display">\[\sum_{k=0}^{+\infty }
r^k=\frac1{1-r}\]</span>.</li>
<li><p>En el caso en que se comience en <span class="math inline">\(n_0\)</span> se tiene que
<span class="math display">\[\sum_{k=n_0}^{+\infty} r^k=\frac{r^{n_0}}{1-r}.\]</span></p></li>
<li><p>Si <span class="math inline">\(|r|&lt;1\)</span> también son convergentes las derivadas, respecto de <span class="math inline">\(r\)</span>, de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que</p></li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
\left(\sum_{k=0}^{+\infty} r^k\right)&#39;= &amp; \sum_{k=1}^{+\infty}k
r^{k-1} \left(\frac1{1-r}\right)&#39;=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{&#39;&#39;}=&amp; \sum_{k=2}^{+\infty}k (k-1)
r^{k-2}\left(\frac1{1-r}\right)^{&#39;&#39;}=\frac2{(1-r)^3}.
\end{eqnarray*}\]</span></p>
<div class="example">
<p><strong>Ejemplo: paleta de colores (continuación)</strong></p>
<p>Si seguimos con el ejemplo de la paleta de colores, su esperanza es:</p>
<p><span class="math display">\[\begin{eqnarray*}
E(X)&amp;=&amp;\sum_{x=0}^{+\infty} x\cdot P(X=x)=\sum_{x=0}^{+\infty} x\cdot
\left(\frac12\right)^{x+1}\\
&amp;= &amp; \left(\frac12\right)^2\sum_{x=1}^{+\infty} x\cdot
\left(\frac12\right)^{x-1}=\left(\frac12\right)^2
\frac1{\left(1-\frac12\right)^2}=1.
\end{eqnarray*}\]</span></p>
<p>Ahora calculemos su función de distribución</p>
<p><span class="math display">\[\begin{eqnarray*}
F_X(x)&amp;=&amp; P(X\leq x)=\sum_{k=0}^x P(X=k)=\sum_{k=0}^x
\left(\frac12\right)^{k+1}\\
&amp;=&amp; \frac{\frac12-\frac12^{x+1}\cdot
\frac12}{1-\frac12}=1-\left(\frac12\right)^{x+1}.
\end{eqnarray*}\]</span></p>
<p>Como la variable toma valores enteros positivos, podemos calcular su valor esperado
de esta otra manera</p>
<p><span class="math display">\[E(X)=\sum_{x=0}^{+\infty} (1-F_X(x))=\sum_{x=0}^{+\infty}\left(\frac12\right)^{x+1}=\frac12\cdot
\frac1{1-\frac12}=1.\]</span></p>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Calculad el valor esperado de la variable</p>
<p><span class="math display">\[
Y=\mbox{número de intentos para conseguir el color azul.}
\]</span></p>
</div>
<p><l class="definition"> <strong>Momentos de orden <span class="math inline">\(m\)</span></strong></l></p>
<p>Llamaremos <strong>momento de orden <span class="math inline">\(m\)</span></strong> respecto al punto <span class="math inline">\(C\)</span> a
<span class="math display">\[E\left((X-C)^m\right).\]</span></p>
<ul>
<li>Cuando <span class="math inline">\(C=0\)</span> los momentos reciben el nombre de <strong>momentos respecto al origen</strong>.</li>
<li>Cuando <span class="math inline">\(C=E(X)\)</span> reciben el nombre de <strong>momentos centrales o respecto de la media</strong>. Luego la esperanza es el momento de orden <span class="math inline">\(1\)</span> respecto al origen. Estos momentos son la versión poblacional de los momentos que vimos en el curso de estadística descriptiva, recibiendo estos último el nombre de momentos muestrales.</li>
</ul>
<p><strong>Resumen de conceptos</strong></p>
<ul>
<li>Hemos descrito el comportamiento aleatorio de una v.a. discreta mediante sus funciones de probabilidad <span class="math inline">\(P_{X}\)</span> y de distribución <span class="math inline">\(F_{X}\)</span>.</li>
<li>También tenemos un valor central; el valor esperado <span class="math inline">\(E(X)\)</span>.</li>
<li>Como medida básica nos queda definir una medida de lo lejos que están los datos del valor central <span class="math inline">\(E(X)\)</span> una de estas medidas es la varianza de <span class="math inline">\(X\)</span>.</li>
</ul>
</div>
<div id="medidas-de-la-variabilidad" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Medidas de la variabilidad</h3>
<p><l class="definition"> <strong>Varianza</strong> </l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. Llamaremos <strong>varianza</strong> de <span class="math inline">\(X\)</span> a</p>
<p><span class="math display">\[Var(X)=E((X-E(X))^2).\]</span></p>
<p>Por lo tanto, la varianza es el momento central de orden <span class="math inline">\(2\)</span>.</p>
<p>De forma frecuente se utiliza la notación <span class="math display">\[\sigma_{X}^2=Var(X).\]</span></p>
<p>A la raíz cuadrada positiva de la varianza
<span class="math display">\[\sigma_{X}=+\sqrt{Var(X)},\]</span></p>
<p>se la denomina desviación típica o estándar de <span class="math inline">\(X\)</span>.</p>
<p><l class="prop"> <strong>Propiedad</strong> </l></p>
<ul>
<li>Si <span class="math inline">\(X\)</span> es una v.a. discreta con función de probabilidad <span class="math inline">\(P_X\)</span> su varianza es
<span class="math display">\[\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\sum_{x}(x-E(X))^2 \cdot P_{X}(x).\]</span></li>
<li>Sea <span class="math inline">\(X\)</span> una v.a.
<span class="math display">\[Var(X)=E(X^2)-(E(X))^2=\sum_{x} x^2\cdot  P_{X}(X)-(E(X))^2\]</span></li>
</ul>
<div class="dem">
<p><strong>Demostración de b)</strong></p>
<p><span class="math display">\[\begin{eqnarray*}
Var(X)&amp;= &amp; \sum_{x}(x-E(X))^2 \cdot P_{X}(x) = \sum_{x}(x^2 -2 x E(X)+(E(X)^2)\cdot  P_{X}(x)\\
&amp;=&amp; \sum_{x}x^2 \cdot  P_{X}(x) -  E(X)\sum_{x}2 x\cdot  P_{X}(x) + (E(X)^2)\sum_{x} P_{X}(x)\\
&amp;=&amp; E(X^2)- 2 E(X)\cdot  E(X) + (E(X))^2=E(X^2)-(E(X))^2.
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><strong>Ejemplo: número de errores (continuación)</strong></p>
<p>Calculemos en el ejemplo anterior la varianza del número de errores.</p>
<div class="example-sol">
<p>Recordemos que:</p>
<p><span class="math display">\[
P(X=0)=0.42,\  P(X=1)=0.4, \  P(X=2)=0.18,
\]</span>
y que
<span class="math display">\[
E(X)=0.76.
\]</span>
Entonces:</p>
<p><span class="math display">\[
Var(X)=E(X^2)-(E(X))^2 = E(X^2)-(0.76)^2.
\]</span>
Ahora necesitamos calcular</p>
<p><span class="math display">\[E(X^2)= 0^2 (0.41)+ 1^2 (0.4)+ 2^2 (0.18)=0.4+0.72=1.12,\]</span>
y por lo tanto</p>
<p><span class="math display">\[Var(X)= E(X^2)-(0.76)^2=1.12-0.5776=0.542,\]</span>
y <span class="math display">\[\sqrt{Var(X)}=\sqrt{0.542}.\]</span></p>
<p>En resumen <span class="math inline">\(\sigma_{X}^2=0.542\)</span> y <span class="math inline">\(\sigma_{X}=\sqrt{0.542}.\)</span></p>
</div>
</div>
<p><strong>Más propiedades de la varianza</strong></p>
<ul>
<li><span class="math inline">\(Var(X)\geq 0\)</span>.</li>
<li><span class="math inline">\(Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0\)</span>.</li>
<li>El mínimo de <span class="math inline">\(E((X-C)^2)\)</span> se alcanza cuando <span class="math inline">\(C=E(X)\)</span> y es <span class="math inline">\(Var(X)\)</span>. Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.</li>
</ul>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Se deja como ejercicio la demostración de estas propiedades.</p>
</div>
</div>
<div id="transformaciones-lineales." class="section level3">
<h3><span class="header-section-number">2.2.4</span> Transformaciones lineales.</h3>
<p><l class="definition"> <strong>Transformación lineal</strong> </l></p>
<p>Un <strong>cambio de variable lineal</strong> o <strong>transformación lineal</strong> de una v.a. <span class="math inline">\(X\)</span> es otra v.a. <span class="math inline">\(Y= a+ b X\)</span> donde <span class="math inline">\(a,b\in\mathbb{R}\)</span>.</p>
<p><l class="prop"> <strong>Esperanza de una transformación lineal</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. con <span class="math inline">\(E(X)=\mu_{X}\)</span> y <span class="math inline">\(Var(X)=\sigma_{X}^2\)</span> y <span class="math inline">\(a,b\in\mathbb{R}\)</span>.
Entonces si <span class="math inline">\(Y=a+b X\)</span>:</p>
<ul>
<li><span class="math inline">\(E(Y)=E(a + b X)=a+ b\cdot E(X)= a + b\cdot \mu_{X}\)</span>.</li>
<li><span class="math inline">\(Var(Y)=Var(a+bX)=b^2\cdot Var(X)= b^2 \cdot \sigma_{X}^2\)</span>.</li>
<li><span class="math inline">\(\sigma_{Y}=\sqrt{Var(Y)}=\sqrt{b^2\cdot Var(X)}=|b|\cdot \sigma_{X}\)</span>.</li>
</ul>
<div class="dem">
<p><strong>Demostración</strong>:</p>
<p><span class="math display">\[\begin{eqnarray*}
E(Y)&amp;=&amp; E(a+bX)=\sum_{x}(a+b\cdot X)\cdot P_{X}(x)\\
&amp;=&amp; a \sum_{x} P_{X}(x) + b \sum_{x} x\cdot P_{X}(x)\\ 
&amp;=&amp; a + b\cdot E(X)=a + b \mu_{X}.
\end{eqnarray*}\]</span></p>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Las demostración de las demás propiedades se dejan como ejercicio.</p>
</div>
</div>
</div>
<div id="variables-aleatorias-continuas" class="section level2">
<h2><span class="header-section-number">2.3</span> Variables aleatorias continuas</h2>
<p>Como ya hemos dicho las variables aleatorias continuas toman valores en
intervalos o áreas.</p>
<p>Lo más habitual es que estas variables tengan función de distribución continua y
derivable (salvo a los más en una cantidad finita o numerable de puntos).</p>
<p>En lo que sigue supondremos que la función de distribución de variables
aleatorias continuas cumplen estas propiedades.</p>
<p>Notemos que si <span class="math inline">\(X\)</span> es una v.a. con función de distribución continua se tiene que
<span class="math inline">\(P(X=x_0)=F_X(x_0)-F(x_0^{-})=0\)</span>. Por lo que no tiene sentido definir <em>función de probabilidad</em>.</p>
<p>En general tendremos que <span class="math inline">\(P(X&lt;x_0)=P(X\leq x_0)\)</span>.</p>
<p>Por otra parte podemos utilizar una regla parecida del
cociente entre casos favorables y casos posibles de Laplace pero en
este caso el conteo se hace por la <em>medida</em> de los casos
posibles partida por la <em>medida</em> de los casos favorables.</p>
<p>Veamos un ejemplo de v.a. continua, que ampliaremos en el tema siguiente, en el que se utilizan todos estos conceptos.</p>
<div class="example">
<p><strong>Ejemplo: distancia de un dardo al centro de la diana</strong></p>
<p>Supongamos que lanzamos un dardo a una diana de radio <span class="math inline">\(1\)</span>, de forma que sea <em>equiprobable</em> cualquier distancia al centro (¡Cuidado! esto no es equivalente
a que cualquier punto de la diana sea <em>equiprobable</em>).</p>
<p>Consideremos la v.a. continua <span class="math inline">\(X=\)</span> distancia del dardo al centro de la diana.</p>
<div class="example-sol">
<p>Su función de distribución es</p>
<p><span class="math display">\[
F_{X}(x)=
\left\{
\begin{array}{ll}
0, &amp; \mbox{si } x\leq 0,\\
x, &amp; \mbox{si } 0&lt;x&lt;1,\\
1, &amp; \mbox{si } x\geq 1.
\end{array}
\right.
\]</span></p>
<ul>
<li>C.F. <em>longitud favorable</em> es <span class="math inline">\(x-0\)</span>.</li>
<li>C.P. <em>longitud posible</em> es <span class="math inline">\(1-0\)</span>.</li>
<li>Luego
<span class="math display">\[P(X\leq x)=\frac{C.F.}{C.P.}=\frac{x-0}{1-0}=x.\]</span></li>
</ul>
</div>
</div>
<p><img src="curso-probabilidad-udemy_files/figure-html/figUNIF-7.png" width="672" style="display: block; margin: auto;" /></p>
<div id="propiedades-3" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Propiedades</h3>
<p>En las variables continuas los sucesos del tipo <span class="math inline">\(\{X\leq x \}\)</span> y <span class="math inline">\(\{X&lt; x \}\)</span> tendrán la
misma probabilidad, y otros tipos de sucesos similares también, algunas de estas
propiedades se explicitan en la siguiente proposición.</p>
<p><l class="prop"><strong>Propiedades</strong></l></p>
<p>Dada una v.a. continua <span class="math inline">\(X\)</span> se tiene que:</p>
<ul>
<li><span class="math inline">\(P(X\leq b)=P(X&lt;b)\)</span>.</li>
<li><span class="math inline">\(P(X&lt;b)=P(X&lt;a)+P(a&lt;X&lt;b)\)</span>.</li>
<li><span class="math inline">\(P(a&lt;X&lt;b)=P(X&lt;b)-P(X&lt;a)\)</span>.</li>
</ul>
<div class="dem">
<p><strong>Demostración:</strong></p>
<p>La primera es evidente <span class="math inline">\(P(X\leq b)=P(X&lt;b)+P(X=b)=P(X&lt;b)\)</span>.</p>
<p>Para demostrar la segunda, tenemos</p>
<p><span class="math display">\[\{X\leq a\}\cap \{a&lt;X&lt;b\}=\emptyset,\]</span>
<span class="math display">\[\{X\leq a\}\cup \{a&lt;X&lt;b\}=\{X&lt;b\},\]</span>
entonces
<span class="math display">\[\begin{eqnarray*}
P(X&lt; b) &amp; = &amp; P(\{X\leq a\}\cup \{a&lt;X&lt;b\})\\
&amp; = &amp; P(X\leq a)+P(a&lt;X&lt;b) \\
&amp; = &amp; P(X&lt; a)+P(a&lt;X&lt;b).
\end{eqnarray*}\]</span></p>
</div>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>La demostración de la tercera propiedad es similar a la segunda pero aplicando la primera. La dejamos como ejercicio.</p>
</div>
<p><strong>Propiedades de la función de distribución</strong></p>
<p>Las propiedades anteriores y combinaciones de ellas se pueden
escribir utilizando la función de distribución de <span class="math inline">\(X\)</span>:</p>
<p><l class="prop"> <strong>Propiedades de la Función de Distribución</strong> </l></p>
<p>Dada una variable aleatoria continua se tiene que:</p>
<ul>
<li><span class="math inline">\(F_{X}(b)=F_{X}(a)+P(a&lt;X&lt;b)\)</span>.</li>
<li><span class="math inline">\(P(a&lt;X&lt;b)=F_{X}(b)-F_{X}(a)\)</span>.</li>
<li><span class="math inline">\(P(a\leq X\leq b)=F_{X}(b)-F_{X}(a)\)</span>.</li>
</ul>
<div class="exercise">
<p><strong>Ejercicio</strong>
Se deja la demostración como ejercicio.</p>
</div>
<div class="example">
<p><strong>Ejemplo: diana (continuación)</strong></p>
<p>En el ejemplo de la diana:</p>
<p><span class="math display">\[P(0.25&lt;X&lt;0.3)=F_{X}(0.3)-F_{X}(0.25)=0.3-0.25=0.05.\]</span></p>
</div>
</div>
<div id="función-de-densidad" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Función de densidad</h3>
<p><l class="definition"> <strong>Función de densidad</strong> </l></p>
<p>Una función <span class="math inline">\(f:\mathbb{R}\to\mathbb{R}\)</span> es una función de densidad sobre <span class="math inline">\(\mathbb{R}\)</span> si cumple que</p>
<ul>
<li><span class="math inline">\(f_{X}(x)\geq 0\)</span> para todo <span class="math inline">\(x \in\mathbb{R}.\)</span></li>
<li><span class="math inline">\(f\)</span> es continua salvo a lo sumo en una cantidad finita de puntos sobre
cada intervalo acotado de <span class="math inline">\(\mathbb{R}\)</span>.</li>
<li><span class="math inline">\(\displaystyle\int\limits_{-\infty}^{+\infty} f_{X}(x) dx=1.\)</span></li>
</ul>
<p><l class="definition"> <strong>Función de distribución de una variable aleatoria</strong> </l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. con función de distribución <span class="math inline">\(F_X\)</span>. Sea <span class="math inline">\(f:\mathbb{R}\to\mathbb{R}\)</span> una función de densidad tal que</p>
<p><span class="math display">\[F_X(x)=\displaystyle\int_{-\infty}^{x} f_X(t)\,dt,\mbox{ para todo } x\in\mathbb{R}.\]</span></p>
<p>Entonces <span class="math inline">\(X\)</span> es una variable aleatoria continua y <span class="math inline">\(f_X\)</span> es la densidad de la v.a. <span class="math inline">\(X\)</span>.</p>
<p>El conjunto <span class="math inline">\(D_X=\{x\in\mathbb{R}| f_x(x)&gt;0\}\)</span> recibe el nombre de <l class="definition"> soporte o dominio de la
variable aleatoria continua</l> y se interpreta como su conjunto de resultados posibles.</p>
<div class="example-sol">
<p><strong>Ejemplo: diana (continuación)</strong></p>
<p>En nuestro ejemplo, la función <span class="math inline">\(f\)</span> es una densidad</p>
<p><span class="math display">\[
f_{X}(x)=\left\{
\begin{array}{ll}
0, &amp; \mbox{si } x\leq 0,\\
1, &amp; \mbox{si } 0 &lt; x &lt; 1,\\
0, &amp; \mbox{si } 1\leq x,
\end{array}\right.
\]</span>
que es la densidad de <span class="math inline">\(X\)</span>. En efecto:</p>
<ul>
<li><p>Si <span class="math inline">\(x \leq 0\)</span>, entonces <span class="math inline">\(\displaystyle\int_{-\infty}^x f_X(t) dt = 0.\)</span></p></li>
<li><p>Si <span class="math inline">\(0\leq x\leq 1\)</span>, entonces <span class="math inline">\(\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^x 1\, dt = x.\)</span></p></li>
<li><p>Si <span class="math inline">\(x\geq 1\)</span>, entonces <span class="math inline">\(\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^1 1\, dt = 1.\)</span></p></li>
</ul>
<p>Por lo tanto, <span class="math inline">\(F_X(x)=\displaystyle\int_{-\infty}^x f_X(t) dt\)</span> para todo <span class="math inline">\(x\in\mathbb{R}.\)</span></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1"><span class="kw">curve</span>(<span class="kw">dunif</span>(x,<span class="dv">0</span>,<span class="dv">1</span>),<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>,<span class="fl">1.5</span>),<span class="dt">col=</span><span class="st">&quot;blue&quot;</span>,</a>
<a class="sourceLine" id="cb35-2" title="2">      <span class="dt">main=</span><span class="st">&quot;Densidad de la distribución uniforme en [0,1]&quot;</span>)</a></code></pre></div>
<p><img src="curso-probabilidad-udemy_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="utilidad-de-la-función-de-densidad" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Utilidad de la función de densidad</h3>
<p>La función de densidad nos permite calcular diversas probabilidades.</p>
<p><l class="prop"><strong>Propiedades de la función de densidad</strong> </l></p>
<ul>
<li><p>Sea <span class="math inline">\(X\)</span> una v.a. continua con función de distribución <span class="math inline">\(F_X\)</span> y de
densidad <span class="math inline">\(f_X\)</span>, entonces
<span class="math display">\[\begin{eqnarray*}
P(a&lt; X&lt; b) &amp;=&amp;  P(a&lt;X\leq b)= P(a\leq X&lt; b)=\\
 &amp; &amp; P(a\leq X\leq b)= \displaystyle\int_{a}^b f_X(x) dx.
\end{eqnarray*}\]</span></p></li>
<li><p>Si <span class="math inline">\(A\)</span> es un subconjunto de <span class="math inline">\(\mathbb{R}\)</span> entonces</p></li>
</ul>
<p><span class="math display">\[
P(X\in A)=\displaystyle\int_{A} f(x) dx=\displaystyle\int_{A\cap D_X} f(x) dx.
\]</span></p>
<p><l class="prop"><strong>Propiedades de la función de densidad</strong> </l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. continua con función de distribución <span class="math inline">\(F_X\)</span> y de densidad <span class="math inline">\(f_X\)</span>, entonces:</p>
<ul>
<li>Si <span class="math inline">\(f_x\)</span> es continua en un punto <span class="math inline">\(x\)</span>, <span class="math inline">\(F_X\)</span> es derivable en ese punto y
<span class="math inline">\(F_X&#39;(x)=f_X(x).\)</span></li>
<li><span class="math inline">\(P(X=x)=0\)</span> para todo <span class="math inline">\(x\in\mathbb{R}.\)</span></li>
</ul>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Comprobar estas propiedades en el ejemplo de la diana.</p>
</div>
<div class="example">
<p><strong>Ejemplo: tiempo ejecución de un proceso.</strong></p>
<p>Sea <span class="math inline">\(X=\)</span> tiempo de ejecución de un proceso. Se supone que <span class="math inline">\(X\)</span> sigue una distribución uniforme en dos unidades de tiempo, si tarda más el proceso se cancela.</p>
<p>Calculemos la función de densidad y de distribución de la v.a <span class="math inline">\(X\)</span>.</p>
<div class="example-sol">
<p>Entonces</p>
<p><span class="math display">\[
F_{X}(x)=P(X\leq x)=\frac{\mbox{Casos Favorables}}{\mbox{Casos Posibles}}=\frac{x}2.
\]</span></p>
<p>Luego su función de distribución es:</p>
<p><span class="math display">\[
F_{X}(x)=\left\{\begin{array}{ll}
0, &amp; \mbox{si } x\leq 0,\\[1ex]
\frac{x}2, &amp; \mbox{si } 0&lt;x&lt;2,\\[1ex]
1, &amp; \mbox{si } 2\leq x.
\end{array}\right.
\]</span></p>
<p>Su función de densidad por su lado es:
<span class="math display">\[
f_{X}(x)=F_{X}&#39;(x)=\left\{\begin{array}{ll}
0, &amp; \mbox{si } x\leq 0,\\[1ex]
\frac12, &amp; \mbox{si } 0&lt;x\leq 2,\\[1ex]
0, &amp; \mbox{si } 2\leq x.
\end{array}\right.
\]</span></p>
<p>Efectivamente</p>
<ul>
<li><span class="math inline">\(f_{X}(x)\geq 0,\)</span> y tiene un conjunto finito de discontinuidades: <span class="math inline">\(\{0,2\}\)</span>.</li>
<li><p><span class="math inline">\(F_X(x)=\int_{-\infty}^x f_X(t) dt,\)</span> para todo <span class="math inline">\(x\in \mathbb{R}\)</span>. (Ejercicio: resolverlo gráficamente.)</p></li>
<li><p><span class="math inline">\(\displaystyle\int\limits_{-\infty}^{+\infty}f_{X}(x)dx= \int\limits_0^2\frac12dx=\left[\frac{x}2\right]_0^2=\frac22-\frac02=1.\)</span></p></li>
</ul>
</div>
</div>
<div class="exercise">
<p><strong>Ejercicio: tiempo de un proceso</strong></p>
<p>Calcular la probabilidad de que uno de nuestros procesos tarde
más de una unidad de tiempo en ser procesado. Calcular también la probabilidad de
que dure entre <span class="math inline">\(0.5\)</span> y <span class="math inline">\(1.5\)</span> unidades de tiempo.</p>
</div>
</div>
<div id="esperanza-y-varianza-para-variables-aleatorias-continuas" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Esperanza y varianza para variables aleatorias continuas</h3>
<p>Los mismos comentarios y definiciones que se dieron en la sección correspondiente del tema
de estadística descriptiva son aplicables aquí.</p>
<p>Así que sólo daremos las definiciones, la forma de cálculo y algunos ejemplos.</p>
<p>En lo que sigue, salvo que diagamos lo contrario, <span class="math inline">\(X\)</span> es una v.a. continua con función de densidad <span class="math inline">\(f_{X}(x)\)</span></p>
<p><l class="definition"> <strong>Esperanza v.a. continuas</strong> </l></p>
<ul>
<li>Su esperanza es:
<span class="math display">\[E(X)=\displaystyle\int\limits_{-\infty}^{+\infty} x\cdot f_{X}(x)dx.\]</span></li>
<li>Si <span class="math inline">\(g(x)\)</span> es una función de la variable <span class="math inline">\(X\)</span> entonces:
<span class="math display">\[E(g(X))=\displaystyle\int\limits_{-\infty}^{+\infty} g(x)\cdot f_{X}(x)dx.\]</span></li>
</ul>
<p><l class="definition"> <strong>Varianza v.a. continuas</strong> </l></p>
<ul>
<li>Su varianza es:
<span class="math display">\[
Var(X)=\sigma_{X}^2=E((X-\mu_{X})^2)=
\displaystyle\int\limits_{-\infty}^{+\infty} (x-\mu_{X})^2 f_{X}(x)dx.
\]</span></li>
<li>Su desviación típica es: <span class="math display">\[\sigma_{X}=+\sqrt{\sigma_{X}^2}.\]</span></li>
</ul>
<p><l class="prop"> <strong>Propiedades</strong> </l></p>
<ul>
<li><span class="math inline">\(\sigma_{X}^2\geq 0\)</span>.</li>
<li><span class="math inline">\(Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0\)</span>.</li>
<li><span class="math inline">\(\displaystyle Var(x)=E(X^2)-\mu_{X}^2=\int\limits_{-\infty}^{+\infty}x^2 f_{X}(x)dx - \mu_{X}^2.\)</span></li>
<li>El mínimo de <span class="math inline">\(E((X-C)^2)\)</span> se alcanza cuando <span class="math inline">\(C=E(X)\)</span> y es <span class="math inline">\(Var(X)\)</span>.</li>
</ul>
<div class="example">
<p><strong>Ejemplo: diana (continuación)</strong></p>
<p>Calcular <span class="math inline">\(\mu_{X}\)</span> y <span class="math inline">\(\sigma_{X}^2\)</span> en el ejemplo de la diana.</p>
<div class="example-sol">
<p>Resultado
<span class="math display">\[\mu_{X}=\frac12,\ E(X^2)=\frac13,\ Var(X)=\frac1{12}.\]</span></p>
</div>
</div>
<p><l class="prop"><strong>Proposición</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. continua con <span class="math inline">\(E(X)=\mu_{X}\)</span> y <span class="math inline">\(Var(X)=\sigma_{X}^2\)</span> sea <span class="math inline">\(Y=a+b\cdot X\)</span>, donde
<span class="math inline">\(a,b\in\mathbb{R}\)</span>, es una nueva v.a. continua obtenida mediante una transformación lineal de <span class="math inline">\(X\)</span>.
Se verifican las mismas propiedades que en el caso discreto:</p>
<ul>
<li><span class="math inline">\(E(Y)=E(a+b\cdot X)=a+b\cdot E(X)\)</span>.</li>
<li><span class="math inline">\(Var(Y)=Var(a+b\cdot X)=b^2\cdot Var(X)\)</span>.</li>
<li><span class="math inline">\(\sigma_{Y}=|b|\cdot \sigma_{X}\)</span>.</li>
<li><span class="math inline">\(Z=\frac{X-\mu_{X}}{\sigma_{X}}\)</span> es una transformación
lineal de <span class="math inline">\(X\)</span> de forma que
<span class="math display">\[E(Z)=0 \mbox{ y } Var(Z)=1.\]</span></li>
</ul>
<div class="example">
<p><strong>Ejemplo: venta de vinos</strong></p>
<p>En una empresa de venta de vinos por internet, sea
<span class="math inline">\(X\)</span> el número de litros de vino del país vendidos en un año.
Supongamos que sabemos que <span class="math inline">\(E(X)=10000\)</span> y que <span class="math inline">\(Var(X)=100\)</span>.
Supongamos que los gastos fijos de distribución son
50.000 € y el beneficio por litro es de 10 € por botella.
Definimos <span class="math inline">\(T=10 X-50000\)</span> que será el beneficio después de gastos.</p>
<div class="example-sol">
<p>Entonces la esperanza del beneficio es
<span class="math display">\[E(T)=10 E(X)-50000 = 50000,\]</span>
y
<span class="math display">\[Var(T)=10^2 Var(X)= 10000.\]</span></p>
</div>
</div>
</div>
</div>
<div id="transformaciones-de-variables-aleatorias" class="section level2">
<h2><span class="header-section-number">2.4</span> Transformaciones de variables aleatorias</h2>
<p>Muchas variables aleatorias son funciones de otras v.a. En lo que sigue resumiremos diversas técnicas para dada una v.a. <span class="math inline">\(X\)</span> y una
transformación <span class="math inline">\(Y=h(X)\)</span> encontrar <span class="math inline">\(F_{Y}\)</span> a
partir de <span class="math inline">\(F_{X}\)</span>.</p>
<p><l class="prop"><strong>Tranformaciones de v.a. discretas</strong> </l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. discreta con <span class="math inline">\(X(\Omega)=\{x_1,x_2,\ldots,x_{n},..\}\)</span> y sea <span class="math inline">\(h:\mathbb{R}\to\mathbb{R}\)</span> una aplicación.
Entonces <span class="math inline">\(Y=h(X)\)</span> es también una v.a. discreta. Además si <span class="math inline">\(P_X\)</span>
y <span class="math inline">\(F_{X}\)</span> son las funciones de probabilidad y de distribución de
<span class="math inline">\(X\)</span> entonces</p>
<ul>
<li><span class="math inline">\(\displaystyle P_{Y}(y)=\sum_{x_{i}|h(x_{i})=y}P_X(x_{i}).\)</span></li>
<li><span class="math inline">\(\displaystyle F_{Y}(y)=\sum_{x_{i}|h(x_{i})\leq y} P_X(x_{i}).\)</span></li>
</ul>
<p>Desafortunadamente para variables no discretas, el resultado no es tan sencillo como la expresión anterior, pues la transformación de, por ejemplo, una v.a. continua puede ser continua, discreta, mixta, <span class="math inline">\(\ldots\)</span></p>
<p><l class="prop"><strong>Transformación de v.a. continuas en continuas</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. continua cuya función de densidad es <span class="math inline">\(f_{X}\)</span>. Sea
<span class="math inline">\(h:\mathbb{R}\to\mathbb{R}\)</span> una aplicación estrictamente monótona y derivable; por lo tanto, <span class="math inline">\(h&#39;(x)\not=0\)</span> para todo <span class="math inline">\(x\in\mathbb{R}\)</span>. Sea <span class="math inline">\(Y=h(X)\)</span> la transformación de <span class="math inline">\(X\)</span> por <span class="math inline">\(h\)</span>. Entonces <span class="math inline">\(Y\)</span> es una v.a. continua con función de densidad</p>
<p><span class="math display">\[f_{Y}(y)=\left.\frac{f_{X}(x)}
{\left|h&#39;(x)\right|}\right|_{x=h^{-1}(y)}.\]</span></p>
<p><l class="prop"><strong>Densidad de una transformación de una v.a. continua</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. continua cuya función de densidad es <span class="math inline">\(f_{X}\)</span>. Sea
<span class="math display">\[h:\mathbb{R}\to\mathbb{R},\]</span>
una aplicación, no necesariamente monótona tal que :</p>
<ul>
<li>sea derivable con derivada no nula,</li>
<li>la ecuación <span class="math inline">\(h(x)=y\)</span> tiene un número finito de soluciones
<span class="math inline">\(x_1,x_2,..,x_{n}\)</span>,</li>
</ul>
<p>entonces:</p>
<p><span class="math display">\[
\displaystyle f_{Y}(y)=\left.\sum_{k=1}^{n} \frac{f_{X}(x)}
{\left|h&#39;(x)\right|}\right|_{x=x_{k}}.
\]</span></p>
<p><strong>Método general de transformación de v.a.</strong></p>
<p>Cuando no podamos aplicar las propiedades anteriores intentaremos
calcular primero la función de distribución de la transformación
y luego su densidad.</p>
<p>Notemos que en general si <span class="math inline">\(Y=g(X)\)</span> es una v.a. transformación de la
v.a. <span class="math inline">\(X\)</span> entonces</p>
<p><span class="math display">\[
F_{Y}(y)=P(Y\leq y)=P(g(X)\leq y).
\]</span></p>
<p>Por ejemplo, si <span class="math inline">\(g\)</span> es estrictamente creciente y continua,</p>
<p><span class="math display">\[
F_{Y}(y)=P(g(X)\leq y)=P(X\leq g^{-1}(y))=F_{X}(g^{-1}(y)),
\]</span>
y si <span class="math inline">\(g\)</span> es estrictamente decreciente y continua,
<span class="math display">\[
F_{Y}(y)=P(g(X)\leq y)=P(X\geq g^{-1}(y))=1-F_{X}(g^{-1}(y)).
\]</span></p>
</div>
<div id="desigualdades-de-markov-y-de-chebychev" class="section level2">
<h2><span class="header-section-number">2.5</span> Desigualdades de Markov y de Chebychev</h2>
<p>En esta sección distintas desigualdades que acotan determinadas probabilidades de
una variable aleatoria.</p>
<p>Estas desigualdades sirven en algunos casos para acotar probabilidades de determinados sucesos.</p>
<p>También son útiles desde el punto de vista teórico, por ejemplo para justificar que la varianza es una medida de la dispersión de
los datos.</p>
<div id="desigualdad-de-markov" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Desigualdad de Markov</h3>
<p><l class="prop"><strong>Desigualdad de Markov</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. positiva con <span class="math inline">\(E(X)\)</span> finita. Entonces</p>
<p><span class="math display">\[P(X\geq a)\leq \frac{E(X)}{a},\mbox{ para todo }a&gt;0.\]</span></p>
<div class="dem">
<p><strong>Demostración</strong>:</p>
<p>Si <span class="math inline">\(X\)</span> es continua y solo toma valores positivos</p>
<p><span class="math display">\[\begin{eqnarray*}
E(X) &amp;=&amp; \int_{-\infty}^{+\infty} x\cdot  f_{X}(x) dx=  \int_0^{+\infty} x\cdot f_{X}(x) dx=  \int_0^{a} x\cdot  f_{X}(x) dx +\int_{a}^{+\infty} x\cdot f_{X}(x) dx \\
&amp; &amp;\geq   \int_{a}^{+\infty} x\cdot
f_{X}(x) dx \geq a \int_{a}^{+\infty}
f_{X}(x) dx = a \cdot  P(X\geq a),
\end{eqnarray*}\]</span>
de donde se sigue que
<span class="math display">\[P(X\geq a)\leq \frac{E(X)}{a}.\]</span></p>
</div>
<p><l class="prop"> <strong>Corolario</strong></l></p>
<p>Sea <span class="math inline">\(X\)</span> una v.a. con <span class="math inline">\(E(X)\)</span> finita entonces para todo <span class="math inline">\(a&gt;0\)</span></p>
<span class="math display">\[P(|X|\geq a )\leq \frac{E(|X|)}{a}.\]</span>
<div class="exercise">
<p><strong>Ejercicio</strong></p>
<p>Demuestra el corolario anterior a partir de la desigualdad de Markov.</p>
</div>
<p>La desigualdad de Chebychev también se denomina de Chebyshov y en inglés Chebyshev.</p>
</div>
<div id="desigualdad-de-chebychev" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Desigualdad de Chebychev</h3>
<p><l class="prop"><strong>Desigualdad de Chebychev</strong></l></p>
<p>La desigualdad de Chebychev también se denomina de Chebyshov y en inglés Chebyshev.</p>
<p>Sea <span class="math inline">\(X\)</span> una v.a.con <span class="math inline">\(E(X)=\mu\)</span> y <span class="math inline">\(Var(X)=\sigma^2\)</span> entonces para todo <span class="math inline">\(a&gt;0\)</span>,</p>
<p><span class="math display">\[P(|X-\mu|\geq a)\leq \frac{\sigma^2}{a^2}.\]</span></p>
<div class="dem">
<p><strong>Demostración</strong></p>
<p>Apliquemos la consecuencia de la desigualdad de Markov a la v.a.
no negativa <span class="math inline">\(Y^2=(X-\mu)^2\)</span>. Entonces</p>
<p><span class="math display">\[
P(Y^2\geq a^2) \leq 
\frac{E(Y^2)}{a^2}=\frac{E((X-\mu)^2)}{a^2}
= \frac{Var(X)}{a^2}=\frac{\sigma^2}{a^2}.
\]</span>
Por otra parte</p>
<p><span class="math display">\[
P(Y^2\geq a^2)=P(|Y|\geq a)= P(|X-\mu|\geq a),
\]</span>
hecho que, junto con la desigualdad anterior, demuestra el resultado.</p>
</div>
<p><l class="observ"> <strong>Utilidad básica de la desigualdad de Chebychev</strong></l></p>
<p>Supongamos que <span class="math inline">\(X\)</span> es una v.a. con <span class="math inline">\(Var(X)=0\)</span>. Entonces, aplicando la desigualdad anterior,
<span class="math display">\[P(|X-E(X)|\geq a )=0,\mbox{ para todo }a&gt;0,\]</span>
lo que implica que
<span class="math display">\[P(X=E(X))=1,\]</span>
por lo que probabilidad de que <span class="math inline">\(X\)</span> sea
constantemente <span class="math inline">\(E(X)\)</span> es 1, hecho que nos confirma la utilidad de la varianza como una
medida de la dispersión de los datos.</p>
<div class="example">
<p><strong>Ejemplo: tiempo de respuesta</strong></p>
<p>Se sabe que el tiempo de respuesta medio y la desviación típica de un sistema multiusuario son 15 y 3 unidades de tiempo, respectivamente. Entonces:
<span class="math display">\[
P(|X-15|\geq 5)\leq \frac9{25}=0.36.
\]</span></p>
</div>
<p>Si substituimos <span class="math inline">\(a\)</span> por <span class="math inline">\(a\cdot \sigma\)</span> en la
desigualdad de Chebychev, nos queda:</p>
<p><span class="math display">\[
P(|X-\mu|\geq a \sigma)\leq
\frac{\sigma^2}{(a\sigma)^2}=\frac1{a^2},
\]</span>
que es otra manera de expresar la desigualdad de Chebychev.</p>
<p><strong>Más formas de la desgualdad de Chebychev</strong></p>
<p>La desigualdad de Chebychev también se puede escribir de al menos dos maneras más:</p>
<p><span class="math display">\[
P(\mu-a\leq X\leq \mu+a)\geq 1-\frac{\sigma^2}{a^2},
\]</span>
y tomado como <span class="math inline">\(a=k\cdot \sigma\)</span>,
<span class="math display">\[
P(\mu-k\cdot \sigma\leq X\leq \mu+ k \cdot \sigma)\geq 1-\frac1{k^2}.
\]</span></p>
<p>Tomando la segunda expresión que hemos visto para la desigualdad de
Chebychev para distintos valores de <span class="math inline">\(k&gt;0\)</span>, tenemos la siguiente tabla:</p>
<table>
<thead>
<tr class="header">
<th>k</th>
<th><span class="math inline">\(P(|X-E(X)|\geq k \cdot \sigma)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(\leq 1\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(\leq 0.25\)</span></td>
</tr>
<tr class="odd">
<td>3</td>
<td><span class="math inline">\(\leq 0.111\)</span></td>
</tr>
<tr class="even">
<td>4</td>
<td><span class="math inline">\(\leq 0.0025\)</span></td>
</tr>
</tbody>
</table>
<p>Por ejemplo para <span class="math inline">\(k=2\)</span>, esta desigualdad se puede interpretar como que, dada una v.a. <span class="math inline">\(X\)</span> con cualquier distribución que tenga <span class="math inline">\(E(X)\)</span> y <span class="math inline">\(Var(X)\)</span> finitos, <em>la probabilidad de que un valor se aleje de la media <span class="math inline">\(\mu\)</span> más de <span class="math inline">\(a=2\)</span> desviaciones típicas es menor o igual que <span class="math inline">\(0.25\)</span></em>.</p>
<p>Es decir sólo el 25% de los valores estarán alejados de la media
más de <span class="math inline">\(2\sigma\)</span>, ¡<em>sea cual sea la distribución de la v.a.</em>!</p>
</div>
</div>
<div id="cuantiles-de-variables-aleatorias" class="section level2">
<h2><span class="header-section-number">2.6</span> Cuantiles de variables aleatorias</h2>
<p>Si <span class="math inline">\(X\)</span> es una v.a. con dominio <span class="math inline">\(D_X\)</span> y <span class="math inline">\(0&lt;p&lt;1\)</span>, llamaremos cuantil de orden <span class="math inline">\(p\)</span> al menor valor perteneciente al dominio <span class="math inline">\(x_p\in D_X\)</span> tal que:
<span class="math display">\[P(X\leq x_p)\geq p.\]</span></p>
<p>En <code>R</code>, cada distribución <span class="math inline">\(X\)</span> tiene la función <code>qX(p,...)</code> que devuelve precisamente el cuantil <span class="math inline">\(x_p\)</span> tal que <span class="math inline">\(P(X\leq x_p)\geq p.\)</span></p>
<p>Dada una variable aleatoria <span class="math inline">\(X\)</span>, si existe la inversa de la función de distribución de <span class="math inline">\(X\)</span>, <span class="math inline">\(F_X^{-1}\)</span>, el cuantil de orden <span class="math inline">\(p\)</span> sería el valor que tiene la función <span class="math inline">\(F_X^{-1}\)</span> en <span class="math inline">\(p\)</span>: <span class="math inline">\(x_p=F^{-1}(p)\)</span>.</p>
<p>En caso de no existir la inversa, dado <span class="math inline">\(p\)</span>, definimos el conjunto <span class="math inline">\(A_p\)</span> como:</p>
<p><span class="math display">\[
A_p =\{x\in\mathbb{R},\ |\ F_X(x)\geq p\}.
\]</span></p>
<p>Entonces el cuantil <span class="math inline">\(p\)</span> es el mínimo del conjunto <span class="math inline">\(A_p\)</span> considerando sólo valores del dominio de la variable: <span class="math inline">\(x_p =\displaystyle\min_{x\in D_X}(A_p)\)</span>. Este mínimo siempre existirá y nos da una fórmula explícita para calcular los cuantiles de cualquier variable aleatoria.</p>
<div class="example">
<p><strong>Ejemplo: variable aleatoria que nos da el resultado del lanzamiento de un dado</strong></p>
<p>Sea <span class="math inline">\(X\)</span> la variable aleatoria uniforme discreta que nos da el número de puntos obtenidos en el lanzamiento de un dado (seis caras numeradas del 1 al 6).</p>
<p>Su dominio es <span class="math inline">\(D_X=\{1,2,3,4,5,6\}\)</span> y su función de probabilidad es
<span class="math display">\[
P_X(x)=P(X=x)=
\left\{
\begin{array}{ll}
 \frac{1}{6}, &amp; \mbox{ si } x=1,2,3,4,5,6, \\
0, &amp; \mbox{ en otro caso. }.
\end{array}
\right.
\]</span>
Su función de distribución es:
<span class="math display">\[
F_X(x)= P(X\leq x)=
\left\{
\begin{array}{ll}
0, &amp; \mbox{ si } x&lt;1, \\
\frac{k}{6} &amp; \mbox{ si } k\leq x&lt; k+1 \mbox{ para } x= 1,2,3,4,6, \\
 1, &amp; \mbox{si  } x \geq 6.
\end{array}
\right.
\]</span></p>
<p>La función siguiente llamada <code>ddado</code> nos define la función de probabilidad de <span class="math inline">\(X\)</span> para un dado de <span class="math inline">\(n\)</span> caras:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" title="1">ddado=<span class="cf">function</span>(x,<span class="dt">n=</span><span class="dv">6</span>) {</a>
<a class="sourceLine" id="cb36-2" title="2">  <span class="kw">sapply</span>(x,<span class="dt">FUN=</span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb36-3" title="3">    <span class="cf">if</span>( x <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>n)){<span class="kw">return</span>(<span class="dv">1</span><span class="op">/</span>n)} <span class="cf">else</span> {<span class="kw">return</span>(<span class="dv">0</span>)}})</a>
<a class="sourceLine" id="cb36-4" title="4">  }</a></code></pre></div>
<p>Por ejemplo, el valor de <span class="math inline">\(P_X(0.5)\)</span> sería:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1"><span class="kw">ddado</span>(<span class="fl">1.5</span>,<span class="dt">n=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>y los valores de <span class="math inline">\(P_X(i)\)</span> para <span class="math inline">\(i=1,\ldots 10\)</span> sería:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" title="1"><span class="kw">ddado</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,<span class="dt">n=</span><span class="dv">6</span>)</a></code></pre></div>
<pre><code>##  [1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.0000000
##  [8] 0.0000000 0.0000000 0.0000000</code></pre>
<p>La función <code>pdado</code> nos da la función de distribución de <span class="math inline">\(X\)</span>:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" title="1">pdado=<span class="cf">function</span>(x,<span class="dt">n=</span><span class="dv">6</span>) </a>
<a class="sourceLine" id="cb41-2" title="2">  {</a>
<a class="sourceLine" id="cb41-3" title="3">  <span class="kw">sapply</span>(x,<span class="dt">FUN=</span><span class="cf">function</span>(y){ <span class="cf">if</span> (y<span class="op">&lt;</span><span class="dv">1</span>){ <span class="kw">return</span>(<span class="dv">0</span>)}<span class="cf">else</span>{<span class="cf">if</span>(y<span class="op">&gt;=</span>n){<span class="kw">return</span>(<span class="dv">1</span>)} <span class="cf">else</span></a>
<a class="sourceLine" id="cb41-4" title="4">  {<span class="kw">return</span>(<span class="kw">sum</span>(<span class="kw">ddado</span>(<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">floor</span>(y))),<span class="dt">n=</span>n)))}}})</a>
<a class="sourceLine" id="cb41-5" title="5">  }</a></code></pre></div>
<p>Los valores de <span class="math inline">\(F_X(i)\)</span> para <span class="math inline">\(i=0,\ldots, 11\)</span> serían:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" title="1"><span class="kw">pdado</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">11</span>,<span class="dv">6</span>)</a></code></pre></div>
<pre><code>##  [1] 0.0000000 0.1666667 0.3333333 0.5000000 0.6666667 0.8333333 1.0000000
##  [8] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000</code></pre>
<p>A continuación, construímos la función <code>qdado</code> que nos calcula el cuantil <span class="math inline">\(p\)</span>, para <span class="math inline">\(0\leq p\leq 1\)</span>, de la variable <span class="math inline">\(X\)</span> como el mínimo del conjunto <span class="math inline">\(A_p\)</span>:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" title="1">qdado=<span class="cf">function</span>(p,<span class="dt">n=</span><span class="dv">6</span>){</a>
<a class="sourceLine" id="cb44-2" title="2"><span class="kw">sapply</span>(p,<span class="dt">FUN=</span><span class="cf">function</span>(<span class="dt">pp=</span>p,<span class="dt">nn=</span>n) </a>
<a class="sourceLine" id="cb44-3" title="3">  {</a>
<a class="sourceLine" id="cb44-4" title="4">  <span class="cf">if</span>(pp<span class="op">&lt;</span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span>pp<span class="op">&gt;</span><span class="dv">1</span>) {<span class="kw">return</span>(<span class="ot">NA</span>)}</a>
<a class="sourceLine" id="cb44-5" title="5">  <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb44-6" title="6">  aux=pp<span class="op">&gt;=</span><span class="kw">pdado</span>(<span class="dv">1</span><span class="op">:</span>n,nn)</a>
<a class="sourceLine" id="cb44-7" title="7">  aux</a>
<a class="sourceLine" id="cb44-8" title="8">  <span class="kw">ifelse</span>(<span class="kw">all</span>(<span class="op">!</span>aux),<span class="kw">return</span>(<span class="dv">1</span>),<span class="kw">return</span>(<span class="kw">max</span>(<span class="kw">which</span>(pp<span class="op">&gt;=</span><span class="kw">pdado</span>(<span class="dv">1</span><span class="op">:</span>n,nn)))))}}</a>
<a class="sourceLine" id="cb44-9" title="9">)</a>
<a class="sourceLine" id="cb44-10" title="10">}</a></code></pre></div>
<p>Si <span class="math inline">\(p=1.5\)</span> o <span class="math inline">\(p=-1\)</span>, la función anterior nos devuelve <code>NA</code> ya que ni 1.5 ni -1 están entre 0 y 1:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" title="1"><span class="kw">qdado</span>(<span class="fl">1.5</span>)</a></code></pre></div>
<pre><code>## [1] NA</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1"><span class="kw">qdado</span>(<span class="op">-</span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] NA</code></pre>
<p>Los cuantiles <span class="math inline">\(x_{0.1}\)</span>, <span class="math inline">\(x_{0.5}\)</span> <span class="math inline">\(x_{0.6}\)</span> y <span class="math inline">\(x_1\)</span> son:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" title="1"><span class="kw">qdado</span>(<span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="dv">1</span>))</a></code></pre></div>
<pre><code>## [1] 1 3 3 6</code></pre>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probabilidad.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="distribuciones-notables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/joanby/probabilidad/edit/master/2.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["curso-probabilidad-udemy.pdf", "curso-probabilidad-udemy.epub"],
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
