--- 
title: "Probabilidad y variables aleatorias para ML con R y Python"
author: "Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: https://github.com/joanby/probabilidad
description: "Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos."
---




# {-}

Consulta el curso completo creado por Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir solamente en [Udemy](https://www.udemy.com/course/probabilidad-y-variables-aleatorias-para-ml-con-r-y-python/?couponCode=B85F8D52148DF5AAD8F7)

Puedes consultar todas las transparecias del curso en formato HTML desde nuestro [Gihub.io](https://joanby.github.io/probabilidad/)

Asienta las bases para convertirte en el Data Scientist del futuro con todo el contenido de estadística descriptiva del curso. En particular verás los mismos contenidos que explicamos en primero de carrera a matemáticos, ingenieros, economistas, biólogos, médicos o informáticos.

1. Probabilidad
2. Variables aleatorias
3. Distribuciones notables
4. Complementos avanzados
5. Variables bidimnsionales
6. Variables multidimensionales
7. Convergencia y Teorema Central del límite

Y todo con más de 30 horas de vídeo a demanda, cientos de ejercicios, tareas, talleres y trucos de los profesores para que te conviertas en un experto de la materia.

```{r, echo = FALSE}
run_shiny = FALSE

library(shiny)
library(reticulate)
``` 



<!--chapter:end:index.Rmd-->

# Pre requisitos: Teoría de conjuntos y combinatoria{-}

## Antes de empezar

###  Consideraciones 

Para aprender cálculo de probabilidades son necesarios conocimientos de:

1. Cálculo: Derivadas, integrales, límites, sumas de series...
2. Geometría básica y álgebra lineal : rectas, hiperplanos, volúmenes... Matrices, valores propios...
3. Teoría de conjuntos y combinatoria.....

Por experiencia sabemos que  la mayoría de estudiantes tienen más conocimientos de  cálculo, geometría y matrices.

Pero muchos  tienen  una falta de conocimientos  en teoría básica de conjuntos y combinatoria (matemática discreta).


###  Teoría de conjuntos

<l class="definition"> Definición de conjunto </l>

La definición de conjunto es una [idea o noción primitiva](https://es.wikipedia.org/wiki/Concepto_primitivo). Es decir es una idea básica del pensamiento humano: un conjunto es una colección de objetos: números, imágenes... cualquier cosa, jugadores de fútbol, palabras, colores ....


La teoría de conjuntos básicas es simple y natural y es la que necesitamos para este curso.

La teoría de conjuntos matemática es más complejas y presenta varias paradojas como la [paradoja de Russell](https://es.wikipedia.org/wiki/Paradoja_de_Russell).


La idea o noción práctica de conjunto es la de una  colección de objetos de un cierto tipo.

Estas colecciones o  conjuntos se pueden definir por:

* Compresión: reuniendo los objetos que cumplen una propiedad $p$
* Extensión:  dando una lista exhaustiva de  los miembros del conjunto



###  Conjuntos básicos

Los  conjuntos suelen tener un conjunto madre como por ejemplo 

* \(\mathbb{N}=\{0,1,2,\ldots\}\)
* $\mathbb{Z}=\{\ldots,-2,-1,0,1,2,\ldots\}$
* $\mathbb{Q}=\left\{\frac{p}{q}\quad\Big|\quad p,q\in \mathbb{Z} \mbox{ y } q \not= 0.\right\}$
* $\mathbb{R}=\{\mbox{Todos los puntos de una recta.}\}$
* $\mathbb{C}= \left\{a+b\cdot i\quad \big|\quad a,b\in \mathbb{R}\right\}\mbox{Los números complejos}\quad a+b\cdot i.$
* Alfabeto = $\{a,b,c,\ldots, A,B,C,\ldots\}.$
* Palabras = $\{paz, guerra, amor, probabilidad,\ldots\}.$

Recordemos que $i$ es la unidad imaginaria que cumple que $\sqrt{i}=-1$.


### Características y propiedades básicas de los conjuntos

* Si a cada objeto  $x$ de  $\Omega$ le llamaremos **elemento del conjunto** $\Omega$ y diremos que $x$ pertenece a $\Omega$.  Lo denotaremos por $x\in \Omega$.
* Un **conjunto de un elemento**, por ejemplo $\{1\}$ recibe el nombre de **conjunto elemental** (o **singleton** del inglés).
* Sea $A$ otro conjunto diremos que $A$ **es igual a** $B$  si todos los elementos $A$ están en $B$ y todos los elementos de $B$ están en $A$. Por ejemplo $A=\{1,2,3\}$ es igual a $B=\{3,1,2\}$.
* Si $A$ es otro conjunto tal que  si $x\in A$ entonces $x\in B$ diremos que $A$ es un subconjunto de o que está contenido en $B$. Lo denotaremos por $A\subseteq B.$
* El conjunto  que no tiene elementos se denomina conjunto vacío y se denota por el símbolo $\emptyset$.
* Dado $A$ un conjunto cualquiera  obviamente $\emptyset\subseteq A.$

Tomemos como conjunto base $\Omega=\{1,2,3\}$

* $\Omega$ es un conjunto de cardinal 3, se denota por $\#(\Omega)=3$  o por $|\Omega|=3$ 
*  El conjunto $\Omega$ tiene  $2^3=8$ subconjuntos.
  + el vacio $\emptyset$ y los elementales $\{1\},\{3\},\{3\}$
  + los subconjuntos de dos elementos: $\{1,2\},\{1,3\},\{2,3\}$
  + El conjunto total de tres elementos $\Omega=\{1,2,3\}.$

Dado un conjunto $\Omega$ podemos construir el **conjunto de todas sus partes** (todos sus subconjuntos) al que denotamos por $\mathcal{P}(\Omega)$. También se denomina de forma directa partes de $\Omega$.


<l class="prop"> Cardinal  de las partes de un conjunto </l>

El cardinal de la partes de un conjunto  es $\#(\mathcal{P}(\Omega))=2^{\#(\Omega)}.$


Por ejemplo $\#\left(\mathcal{P}(\{1,2,3\})\right)=2^{\#(\{1,2,3\})}=2^3=8.$


Efectivamente

$$\mathcal{P}(\{1,2,3\})=\{\emptyset,\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}.$$

Dado un subconjunto $A$ de  $\Omega$ podemos construir la función característica de $A$ 
$$\chi_A:\Omega \to \{0,1\}$$

dado un $\omega\in \Omega$ 

$$
\chi_A(\omega)=
\left\{
\begin{array}{ll}
1 &  \mbox{si }\omega \in A\\
0 &  \mbox{si }\omega \not\in A
\end{array}
\right.
$$


### Operaciones con conjuntos


#### Intersección.

Sea $\Omega$ un conjunto y $A$ y $B$ dos subconjuntos de $\Omega$.

El conjunto **intersección** de $A$ $B$ es el formado por todos los elementos que perteneces a $A$ \mbox{Y} $B$, se denota por $A\cap B$.

Más formalmente

$$
A\cap B=\left\{x\in\Omega \big| x\in A \mbox{ y } x\in B\right\}.
$$

#### Unión.

El conjunto **unión** de $A$ y $B$ es el formado por todos los elementos que perteneces a $A$ \mbox{O que } pertenecen a $B$, se denota por $A\cup B$.


Más formalmente

$$
A\cup B=\left\{x\in\Omega \big| x\in A \mbox{ o } x\in B\right\}.
$$

#### Diferencia.

El conjunto **diferencia** de $A$ y $B$ es el formado por todos los elementos que perteneces a $A$ \mbox{Y NO } pertenecen a $B$, se denota por $A-B=A-(A\cap B)$.

Más formalmente

$$
A- B=\left\{x\in\Omega \big| x\in A \mbox{ y } x\notin B\right\}.
$$


#### Complementario

El **complementario** de un  subconjunto  $A$ de $\Omega$  es $\Omega-A$ Y se denota por $A^c$ o $\overline{A}$.

Más formalmente

$$
A^c=\left\{x\in\Omega \big| x\not\in A\right\}.
$$


### Más propiedades y definiciones

Sea $\Omega$ un conjunto y $A$,$B$,$C$ tres subconjuntos de $\Omega$

* Se dice que dos conjuntos $A$ y $B$ **son disjuntos** si $A\cap B=\emptyset.$
* $\Omega^c=\emptyset$.
* $\emptyset^c=\Omega$.
* $A\cup B=B \cup A$ , $A\cap B=B\cap A$ conmutativas
* $(A\cup B) \cup C = A \cup( B \cup C)$ , $(A\cap B) \cap C = A \cap( B \cap C)$ asociativas
* $A\cup (B\cap C)=(A\cup B) \cap (A\cup C)$ , $A\cap (B\cup C)=(A\cap B) \cup (A\cap C)$ distributivas
* $\left(A^c\right)^c=A$ doble complementario
* $\left(A\cup B\right)^c=A^c \cap B^c$, $\left(A\cap B\right)^c=A^c \cup B^c$ [leyes de De Morgan](https://es.wikipedia.org/wiki/Leyes_de_De_Morgan)


### Con R, ejemplos.

Con R los conjuntos de pueden definir como vectores

```{r}
(Omega=c(1,2,3,4,5,6,7,8,9,10))
(A=c(1,2,3,4,5))
(B=c(1,4,5))
(C=c(4,6,7,8))
```
$A\cap B$

```{r}
intersect(A,B)
```

$A\cup B$

```{r}
union(A,B)
```

$B-C$

```{r}
setdiff(B,C)
```

$A^c=\Omega-A$

```{r}
setdiff(Omega,A)
```


### Con python

```{python}
Omega=set([1,2,3,4,5,6,7,8,9,10])
Omega
A=set([1,2,3,4,5])
A
B=set([1,4,5])
B
C=set([4,6,7,8])
C
A & B   ## intersección (&: and/y)
A | B   ## unión (|: or/o)
A - C   ## diferencia 
Omega-C ## complementario.
```



## Combinatoria

La combinatoria es una rama de la matemática discreta que entre otras cosas cuenta distintas configuraciones de objetos de un conjunto.

Por ejemplo si tenemos un equipo  de baloncesto con  7 jugadores ¿cuántos equipos de 5 jugadores distintos podemos formar?

### Número binomial.

**Número combinatorio o número binomial**

Nos da el número de subconjuntos de tamaño $k$ de un conjunto de tamaño $n$. Este número es

$$
{n\choose k} = \frac{n!}{k!\cdot (n-k)!}.
$$

Recordemos que 
$$
n!=1\cdot 2\cdot 3\cdots n.
$$

En nuestro caso  con 7 jugadores $n=7$   el número de equipos distintos de $k=5$ es

$$
{7\choose 5} = \frac{7!}{5!\cdot (7-5)!}=\frac{7!}{5!\cdot 2!}=
\frac{1\cdot 2\cdot 3 \cdot 4\cdot 5\cdot 6\cdot 7}{1\cdot 2\cdot 3 \cdot 4\cdot 5\cdot 1\cdot 2}=\frac{6\cdot 7}{2}=\frac{42}{2}=21.
$$


Puedo formar 21 equipos distintos.

<div class="exercise">
**Ejercicio**

Carga el paquete `gtools` de R y investiga la función `combinations(n, r, v, set, repeats.allowed)` para calcular todas las combinaciones anteriores.
</div>

### Variaciones.

**Variaciones**

Con los número $\{1,2,3\}$ ¿cuántos números de dos cifras distintas  podemos  formar sin repetir ninguna cifra? 

La podemos escribir

$$12,13,21,23,31,32$$


Luego hay seis casos.

Denotaremos las variaciones (sin repetición) de $k$ elementos (de orden $k$) de un conjunto de $n$ elementos por $V^n_k$ su valor es 

$$
V^n_k=\frac{n!}{(n-k)!}=(n-k+1)\cdot (n-k+2)\cdots n.
$$

En nuestro ejemplo  con  $n=3$ dígitos  podemos escribir las siguientes variaciones de orden $k=2$

$$
V_{k=2}^{n=3}=\frac{3!}{(3-2)!}=\frac{1\cdot 2\cdot 3}{1}=6.
$$

<div class="exercise">
**Ejercicio**

Carga el paquete `gtools` de R y investiga la función `permutations(n, r, v, set, repeats.allowed)` para calcular todas las variaciones anteriores.
</div>

### Variaciones con repetición.

**Variaciones con repetición**

¿Y repitiendo algún dígito? 

$$VR^n_k=n^k$$

Efectivamente en nuestro caso

$$11,12,13,21,22,23,31,32,33$$

$$
VR_{k=2}^{n=3}=n^k.
$$


### Permutaciones

Las permutaciones de un conjunto de cardinal $n$ son todas las variaciones de orden máximo $n$.
Las denotamos y valen:

$$
P_n=VR_n^n=n!
$$

Por ejemplo todos los números que se pueden escribir ordenando todos los dígitos $\{1,2,3\}$ sin repetir ninguno

```{r,warning=FALSE,message=FALSE}
library(combinat)
for(permutacion in permn(3)) print(permutacion)
```

Efectivamente 
$$
P_3=3!=1\cdot  2\cdot 3.
$$

<div class="exercise">
**Ejercicio**

Carga el paquete `combinat` de R e investiga la funcion  `permn` para calcular todas las permutaciones anteriores.
</div>

<div class="exercise">
**Ejercicio**

Investiga el paquete `itertools` y la función `comb` de `scipy.misc` de Python e investiga sus funciones para todas las formas de contar que hemos visto en este tema.
</div>

<div class="exercise">
**Ejercicio**

La función gamma de Euler, cobrará mucha importancia en el curso de estadística. Comprueba que la función `gamma(x+1)` da el mismo valor que la función `factorial(x)` en `R` para todo $x = \{1,2,3\cdots,10\}$.
</div>

## Para acabar


### Otros asuntos básicos

Evidentemente nos hemos dejado muchas otras propiedades básicas de teoría de conjuntos y de combinatoria como: 

* Números multinomiales.
* Combinaciones con repetición
* Propiedades de los números combinatorios.
* Binomio de Newton.
* Multinomio de Newton.

Si nos son necesarias las volveremos a repetir a lo largo del curso o  bien daremos enlaces para que las podáis estudiar en paralelo.

<div class="exercise"> 
**Nota**

Puedes repasar todos esos conceptos con ejercicios y más en el [Curso de estadística descriptiva con `R` y `Python`](https://www.udemy.com/course/estadistica-descriptiva?couponCode=JB_PROMO_OFF) con M. Santos y J.G. Gomila.

</div>


<!--chapter:end:0.Rmd-->

# Probabilidad

## Probabilidades Básicas

<l class="definition"> Experimento aleatorio</l>: experimento que  repetido  en las mismas condiciones puede dar resultados diferentes, pero que a largo plazo son predecibles 


<div class="example"> 
**Ejemplo**

Tirar un dado de 6 caras y anotar el número de puntos de la cara superior.
</div>

<l class="definition" >Suceso elemental</l>: cada uno de los posibles resultados del experimento aleatorio


<div class="example"> 
**Ejemplo** 

Los sucesos elementales del ejemplo anterior serían:

<div class="center">
```{r, echo=FALSE}
knitr::include_graphics(c("Images/proba1dibujos/dice/1.png", 
                          "Images/proba1dibujos/dice/2.png",
                          "Images/proba1dibujos/dice/3.png",
                          "Images/proba1dibujos/dice/4.png",
                          "Images/proba1dibujos/dice/5.png",
                          "Images/proba1dibujos/dice/6.png"))
```
</div>
</div>

### Definiciones básicas

<l class="definition"> Espacio muestral</l>: el conjunto  $\Omega$ formado por todos los sucesos elementales del experimento aleatorio


<div class="example"> 
**Ejemplo**

El espacio muestral del ejemplo anterior del dado es 
<div class="center">
$\Omega=\Big\{$`r knitr::include_graphics("Images/proba1dibujos/dice/1.png")`,
`r knitr::include_graphics("Images/proba1dibujos/dice/2.png")`,
`r knitr::include_graphics("Images/proba1dibujos/dice/3.png")`,
`r knitr::include_graphics("Images/proba1dibujos/dice/4.png")`,
`r knitr::include_graphics("Images/proba1dibujos/dice/5.png")`,
`r knitr::include_graphics("Images/proba1dibujos/dice/6.png")`$\Big\}$
</div>
pero por comodidad, a partir de ahora pondremos
$$\Omega = \{1,2,3,4,5,6\}$$
</div>

### Definiciones básicas


<l class="definition"> Suceso </l> : Cualquier subconjunto del espacio muestral.

 Alguno sucesos notables que merece la pena nombrar son:

* <l class="definition">Suceso seguro o cierto</l>: $\Omega$
* <l class="definition">Suceso imposible o vacio</l>: $\emptyset$
* <l class="definition">Partes de un conjunto</l>: $\mathcal{P}(\Omega)$: conjunto de todos los sucesos del experimento aleatorio (es decir, el conjunto de todos los subconjuntos de $\Omega$)

<div class="exercise">
**Ejercicio**

¿Cuantos elementos contiene el conjunto de partes de $\Omega$ del experimento anterior?
</div>

### Ejemplo $n$-grama

Se define un $n$-grama de una palabra como el conjunto de $n$ letras consecutivas de la misma (contando los blancos de inicio y final de palabra que marcamos como "\_"). 

<div class="example">

**Ejemplo**

Consideremos el experimento aleatorio que consiste en escoger al  azar un 3-grama de la palabra "\_Baleares\_". Vamos a escribir el espacio muestral y algunos sucesos elementales del mismo.

</div>

<div class="example-sol">

En este caso, si consideramos la palabra "\_Baleares\_", el espacio muestral del experimento sería:

$$\Omega=\{\_Ba, Bal, ale, lea, ear, are, res, es\_\}$$


Algunos sucesos serían: 

* 3-gramas que empiezan por  $a$: $\{ale,are\}$
* 3-gramas de inicio y final de palabra: $\{\_Ba,es\_\}$
* 3-gramas que contengan una $l$: $\{Bal,ale,lea\}$

</div>

### Operaciones con sucesos

Si tenemos dos sucesos $A,B\subseteq \Omega$, podemos definir:

* $\Omega$: *suceso* total o *seguro*
* $\emptyset$:suceso  *vacío* o *imposible*
* $A\cup B$: suceso *unión*; el que ocurre si sucede $A$ o $B$
* $A\cap B$: suceso *intersección*; el que ocurre si sucede $A$ y $B$
* $A^c$: suceso *complementario*  el que sucede si NO sucede $A$.
* $A- B=A\cap B^c$: suceso *diferencia*, que acontece  si sucede $A$ y NO sucede $B$.

<l class="definition"> Sucesos incompatibles</l>: $A$ y $B$ son *incompatibles* (o *disjuntos*) cuando  $A\cap B=\emptyset$.


### Ejemplo género

<div class="example">
**Ejemplo**

Supongamos que el sexo se divide entre Mujeres y Hombres. Vamos a definir el espacio muestral, los sucesos elementales y a realizar algunas operaciones entre ellos.
</div>

<div class="example-sol">
* Estudiantes de esta clase: $\Omega$
* Mujeres de esta clase: $A$
* Estudiantes que son zurdos $B$

Algunas operaciones entre los conjuntos:

* $A\cup B$: Est. que son mujeres o que son zurdos.
* $A\cap B$: Mujeres de esta clase que son zurdas.
* $A^c$: Hombres de esta clase.
* $A-B$: Mujeres de la clases que NO son zurdas.
* $B-A$: Hombres de la clase que son zurdos
* ¡Cuidado! No son incompatibles 
</div>

### Propiedades

<l class="definition">Conmutativas</l>: 

$$A\cup B=B\cup A, \quad A\cap B=B\cap A$$

<l class="definition">Asociativas</l>: 

$$A\cup(B\cup C)=(A\cup B)\cup C, \quad A\cap(B\cap C)=(A\cap B)\cap C$$

<l class="definition">Distributivas</l>: 

$$A\cap(B\cup C)=(A\cap B)\cup (A\cap C), \quad A\cup(B\cap C)=(A\cup B)\cap (A\cup C)$$



### Propiedades

| $A$ | $B\cap C$ | $A\cup (B\cap C)$ |
|:--:|:--:|:--:| 
| ![](Images/proba1dibujos/distr11.jpg){height="200px"} | ![](Images/proba1dibujos/distr12.jpg){height="200px"} | ![](Images/proba1dibujos/distr13.jpg){height="200px"} |

### Propiedades

| $A\cup B$ | $A\cup C$ | $(A\cup B)\cap (A\cup C)$ |
|:--:|:--:|:--:| 
| ![](Images/proba1dibujos/distr21.jpg){height="200px" .image-caption} | ![](Images/proba1dibujos/distr22.jpg){height="200px"} | ![](Images/proba1dibujos/distr23.jpg){height="200px"} |

### Propiedades 

<l class="definition"> Complementario del complementario </l> 
$$(A^c)^c=A$$

| $A$ | $A^c$ | $(A^c)^c$ |
|:--:|:--:|:--:| 
| ![](Images/proba1dibujos/dd2.jpg){height="200px"} | ![](Images/proba1dibujos/dd1.jpg){height="200px"} | ![](Images/proba1dibujos/dd3.jpg){height="200px"} |

### Propiedades 

<l class="definition">Leyes de De Morgan</l>

$$(A\cup B)^c=A^c\cap B^c$$

| $A\cup B$ | $(A\cup B)^c$ |
|:--:|:--:|
| ![](Images/proba1dibujos/demorgan6.jpg){height="200px"} | ![](Images/proba1dibujos/demorgan7.jpg){height="200px"} |

### Propiedades 

<l class="definition">Leyes de De Morgan</l>

$$(A\cup B)^c=A^c\cap B^c$$

| $A^c$ | $B^c$ | $A^c\cap B^c$
|:--:|:--:|:--:|
| ![](Images/proba1dibujos/demorgan8.jpg){height="200px"} | ![](Images/proba1dibujos/demorgan9.jpg){height="200px"} | ![](Images/proba1dibujos/demorgan10.jpg){height="200px"} |


### Propiedades 

<l class="definition">Leyes de De Morgan</l>

$$(A\cap B)^c=A^c\cup B^c$$

| $A\cap B$ | $(A\cap B)^c$ |
|:--:|:--:|
| ![](Images/proba1dibujos/demorgan1.jpg){height="200px"} | ![](Images/proba1dibujos/demorgan2.jpg){height="200px"} |

### Propiedades 

<l class="definition">Leyes de De Morgan</l>

$$(A\cap B)^c=A^c\cup B^c$$

| $A^c$ | $B^c$ | $A^c\cup B^c$
|:--:|:--:|:--:|
| ![](Images/proba1dibujos/demorgan3.jpg){height="200px"} | ![](Images/proba1dibujos/demorgan5.jpg){height="200px"} | ![](Images/proba1dibujos/demorgan4.jpg){height="200px"} |

### Definición de probabilidad

La probabilidad de un suceso es una puntuación (*score*) numérico entre 0 y 1 que mide la verosimilitud de que este evento se produzca.

Esta verosimilitud puede estar justificada por 

* Estimación personal

* Estimación de expertos

* La frecuencia con la que se da 

* Cálculo formal

### Definición de probabilidad

Sea $\Omega$ el espacio muestral de un experimento aleatorio. 
Supongamos que el número de posibles resultados, por el momento, es finito.

Una probabilidad sobre $\Omega$ es una aplicación $P:\mathcal{P}(\Omega)\to [0,1]$ con las siguientes propiedades:

1. $0\leq P(A)\leq 1$, para todo suceso $A$ 
2. $P(\Omega)=1$
3. Si $\{A_1,A_2,\ldots,A_n\}$ son sucesos disjuntos dos a dos, entonces

$$
P(A_1\cup A_2\cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots +P(A_n)
$$

Si $a\in \Omega$ es un suceso elemental cometeremos el abuso de notación de poner $P(a)$ en lugar de $P(\{a\})$

### Ejemplo: grupos sangíneos

<div class="example">
**Ejemplo**

En la página de la [Fundación Banco de Sangre y Tejidos de las Islas Baleares](http://www.donasang.org/que-es-la-sang/es_frequencies-dels-diferents-grups.html) podemos encontrar información sobre los porcentajes de tipos de sangre de los donantes de las Islas Baleares: 

$$A: 46\%; B: 7.5\%; AB: 3.5\%; O: 43\%$$

¿Cuál es la probabilidad de que un balear donante de sangre  no  sea del  tipo 0?
</div>

<div class="example-sol">
**Experimento aleatorio:** tipo de sangre de un paciente humano

$$\Omega=\{\mbox{A,B,AB,O}\}$$


**Probabilidad** de un suceso: se asimila al porcentaje observado de individuos

**Suceso:** $\{\mbox{O}\}^c=\{\mbox{A,B,AB}\}$

$$P(\{\mbox{O}\}^c)\!=\!P(\{\mbox{A,B,AB}\})\!=\!
P(\mbox{A})+P (\mbox{B})+P(\mbox{AB})\!=\!0.57$$
</div>

### Propiedades

<div class="prop"> Propiedades básicas de la probabilidad</div>
* $P(\emptyset)=0$

* $P(A-B)=P(A)-P(A\cap B)$ porque $P(A)=P(A-B)+P(A\cap B)$

<div class="center">
![](Images/proba1dibujos/A-B.jpg){height="200px"}
</div>

* Si $B\subseteq A$, entonces $0\leq P(B)\leq P(A)$

* $P(A^c)=1-P(A)$

### Propiedades

* $P(A\cup B)=P(A)+P(B)-P(A\cap B)$ porque

\begin{eqnarray*}
P(A)+P(B)-P(A\cap B) &=& P(A-B)+P(A\cap B)+\\
 & & P(B-A)+ P(A\cap  B)-P(A\cap  B)\\
&=& P(A-B)+P(A\cap B)+ P(B-A) \\
&=& P(A\cup B)
\end{eqnarray*}

<div class="center">
![](Images/proba1dibujos/A-B.jpg){height="200px"}
</div>

### Propiedades

* \begin{eqnarray*}
P(A\cup B\cup C)&=&P(A)+P(B)+P(C)  \\ &&-P(A\cap B)-P(A\cap C)-P(B\cap C)  +P(A\cap B\cap C)
\end{eqnarray*}

<div class="center">
![](Images/proba1dibujos/tresconjunts.jpg){height="200px"}
</div>

$$P(A\cup B\cup C)=P(1)+P(2)+P(3)+P(4)+P(5)+P(6)+P(7)$$

### Propiedades 

* Si $A=\{a_1,a_2,\ldots,a_k\}$, entonces
$$
P(A)=P(a_1)+P(a_2)+\cdots+P(a_k)
$$

* Si todos los sucesos elementales tienen la misma probabilidad,
$$
P(A)=\frac{|A|}{|\Omega|}\Big(=\frac{\mbox{casos favorables}}{\mbox{casos posibles}}\Big)
$$

### Ejemplo: Frecuencia de vocales 

<div class="example">
**Ejemplo**

Los porcentajes de vocales de un determinado idioma (de alfabeto latino) según la [Wikipedia](https://es.wikipedia.org/wiki/Frecuencia_de_aparici%C3%B3n_de_letras) son:

$$A: 18.7\%; E: 26.1\%; I: 25.7\%; O: 24.4\% U: 5.1\%$$

¿Cuál es la probabilidad que  una vocal escogida al azar de este idioma sea una E o una O?
</div>

<div class="example-sol">
El espacio muestral del experimento es $\Omega=\{A,E,I,O,U\}$.

El suceso que deseamos analizar es $\{E,0\}$.

Y su probabilidad es 

$$P(\{E,O\})=P(E)+P(O)=0.261+0.244=0.505.$$

</div>

### Ejemplo: Consumo de drogas

<div class="example">
Segun un árticulo de [El País](https://elpais.com/politica/2019/01/02/actualidad/1546426491_623324.html), en un control especial de la policía el $0.1\%$ de todos los conductores analizados en un control de tráfico dan  positivo en un el test  en cocaína, y  el $1\%$ da positivo  en cannabis. Un $1.05\%$ da positivo en alguno de los dos test. 

¿Cuál  es la probabilidad que un individuo analizado  en el control de drogas  escogido  al azar no de positivo  en ninguno de lo dos test?
</div>

<div class="example-sol">
Los sucesos elementales del enunciado del problema son:

* $A$: dar positivo  en cocaína; $P(A)=0.001$
* $B$: dar positivo en cannabis; $P(B)=0.01$

En este caso nos interesa estudiar los sucesos: 

* $A\cup B$: dar positivo en alguno de los dos test; $P(A\cup B)=0.0105$
* $(A\cup B)^c$: no dar positivo en ninguno de los test

de donde, por tanto:
$$P((A\cup B)^c)=1-P(A\cup B)=1-0.0105=0.9895.$$

</div>

### Ejemplos: Consumo de drogas

<div class="example">

**Ejemplo**

En un control especial de la policía el $0.1\%$ de todos los conductores analizados en un control de tráfico dan  positivo en un el test  en cocaína, y  el $1\%$ da positivo  en cannabis. Un $1.05\%$ da positivo en alguno de los dos test. 

¿Cuál  es la probabilidad que un analizado  al azar de positivo en los dos test en cocaína y cannabis?
</div>

<div class="example-sol">
Los sucesos elementales son:

* $A$: dar positivo en cocaína; $P(A)=0.001$
* $B$: dar positivo en cannabis; $P(B)=0.01$


En este caso nos interesa estudiar los sucesos: 

* $A\cup B$: dar positivo en algún de los dos test; $P(A\cup B)=0.0105$
* $A\cap B$: dar positivo en los dos test

de donde, por tanto:

$$\begin{array}{rl}
{P(A\cap B)} &{=P(A)+P(B)-P(A\cup B)}\\ &{=0.001+0.01-0.0105=0.0005}
\end{array}$$

</div>

### Ejemplo: Control de drogas

<div class="example">
**Ejemplo**

En un control especial de la policía el $0.1\%$ de todos los conductores analizados en un control de tráfico dan  positivo en un el test  en cocaína, y  el $1\%$ da positivo  en cannabis. Un $1.05\%$ da positivo en alguno de los dos test. 

¿Cuál es la probabilidad de  que un conductor analizado de  positivo en cocaína pero no en cannabis?
</div>

<div class="example-sol">
Los sucesos elementales son:

* $A$: dar positivo en cocaína; $P(A)=0.001$
* $B$: dar positivo en cannabis; $P(B)=0.01$

En este caso nos interesa estudiar los sucesos: 

* $A\cap B$: dar positivo en los dos test; $P(A\cap B)=0.0005$
* $B-A$: dar positivo en  cocaína pero no en cannabis

de donde, por tanto:

$$P(B-A) =P(B)-P(A\cap B) =0.01-0.0005=0.0095$$
</div>

## Probabilidad condicionada


### Probabilidad condicionada

<l class="definition"> Probabilidad condicionada</l>: Dados dos sucesos  $A$  y $B$, con $P(A)>0$, la  probabilidad $P(B|A)$ de $B$ condicionado a $A$ es la probabilidad

* de que suceda  $B$ suponiendo que pasa $A$ 
* de que si pasa $A$, entonces suceda $B$
* de que un resultado de $A$ también pertenezca a $B$

Se calcula a través de la definición:

$$
P(B|A)=\frac{P(A\cap B)}{P(A)}
$$


### Ejemplo: frecuencia género y gafas

<div class="example">
**Ejemplo**

En una clase de 20 hombres  y 30 mujeres, 15 hombres y 18 mujeres llevan gafas. Contestemos las siguientes preguntas:
</div>

<div class="example-sol">

* ¿Cuál es la probabilidad de que un alumno lleve gafas?

$$
\frac{33}{50}
$$

* ¿Cuál es la probabilidad de que un alumno sea mujer y lleve gafas?

$$
\frac{18}{50}
$$
</div>

### Ejemplo: sexo y gafas

<div class="example">
**Ejemplo**

En una clase de 20 hombres  y 30 mujeres, 15 hombres y 18 mujeres llevan gafas. Contestemos las siguientes preguntas:
</div>

<div class="example-sol">

* ¿Cuál es la probabilidad de que un chica lleve gafas?

$$
\frac{18}{30}=\frac{18/50}{30/50}=\frac{P(\mbox{mujer  y gafas})}{P(\mbox{mujer})}
$$


* Si escogemos un estudiante al azar ¿Cuál es la probabilidad que si es mujer, entonces lleve gafas?

$$
\frac{18}{30}
$$

</div>


### Ejemplo

<div class="example">
**Ejemplo**

En una clase de 20 hombres  y 30 mujeres, 15 hombres y 18 mujeres llevan gafas. Contestemos las siguientes preguntas:
</div>

<div class="example-sol">

*  ¿Cuál es la probabilidad de que un alumno que lleve gafas sea mujer?

$$
\frac{18}{33}=\frac{18/50}{33/50}=\frac{P(\mbox{mujer y gafas})}{P(\mbox{gafas})}
$$


* Si escogemos un estudiante al azar  ¿Cuál es la probabilidad de que si lleva gafas, entonces sea mujer?
$$
\frac{18}{33}
$$

</div>

### ¡Atención!

Hay que distinguir bien entre

* $P(A\cap B)$: probabilidad de $A$ $\color{red}{\text{y}}$ $B$

*Probabilidad de que sea mujer y  lleve gafas*

* $P(A|B)$: probabilidad de que $\color{red}{\text{si}}$ pasa $B$, $\color{red}{\text{entonces}}$ pase $A$.

*Probabilidad de que, si es mujer, lleve gafas*


Cuando utilizamos probabilidad condicional  $P(A|B)$ estamos restringiendo el espacio muestral a $B$

### Probabilidad condicionada. Propiedades

La probabilidad condicionada es una probabilidad

<div class="prop"> Proposición </div>

Sea $A\subseteq \Omega$ un suceso tal que $P(A)>0$. entonces

$$
\begin{array}{rccl}
P(-|A):& \mathcal{P}(\Omega) & \to & [0,1]\\
&B & \mapsto & P(B|A)
\end{array}
$$
satisface las propiedades de las probabilidades, como por ejemplo:

$$
\begin{array}{l}
P(B^c|A)=1-P(B|A)\\
P(B_1\cup B_2|A)=P(B_1|A)+P(B_2|A)-P(B_1\cap B_2|A)
\end{array}
$$

<div class="exercise">
**Ejercicio**

Escribid el resto de propiedades que cumpliría una probabilidad condicionada al evento $A$.
</div>

### Ejemplos

<div class="example">
**Ejemplo**

Un 15\% de los adultos son hipertensos, un 25\% de los adultos creen que son hipertensos, y un 9\% de los adultos son hipertensos y creen que lo son.

Si un adulto cree que es hipertenso, ¿cuál es la probabilidad que lo sea?
</div>

<div class="example-sol">
Sean los sucesos

* $A$: ser hipertenso; $P(A)=0.15$ 
* $B$: creer ser hipertenso; $P(B)=0.25$

entonces podemos definir el suceso:

* $A\cap B$: ser hipertenso y creerlo; $P(A\cap B)=0.09$

de donde, la probabilidad condicionada de ser hipertenso creyéndonos que lo somos es: 

$$P(A|B)=\dfrac{P(A\cap B)}{P(B)}=\dfrac{0.09}{0.25}=0.36$$
</div>

### Ejemplo

<div class="example">
**Ejemplo**

Un 15\% de los adultos son hipertensos, un 25\% de los adultos creen que son hipertensos, y un 9\% de los adultos son hipertensos y creen que lo son.

Si un adulto es hipertenso, ¿cuál es la probabilidad que crea que lo es?
</div>

<div class="example-sol">
Si tenemos los sucesos:

* $A$: ser hipertenso; 
* $B$: creer ser hipertenso

entonces buscamos la probabilidad $P(B|A)$:

$$
\begin{array}{rl}
P(B|A) & =\dfrac{P(A\cap B)}{P(A)}=\dfrac{0.09}{0.15}=
0.6
\end{array}
$$

</div>

### Ejemplos: dígitos de control

<div class="example">
**Ejemplo**

Un dígito de control de error toma  el valor 0  en el 99\% de los casos en que hay un error. Si la probabilidad de error en un mensaje es  del $0.5\%$. \blue{¿cuál  es la probabilidad de que el mensaje sea erróneo y el código de error tenga valor 0?
</div>

<div class="example-sol">

* $B$: mensaje con error; $P(B)=0.005$
* $A$: código de error vale 0;
* $P(A|B)=0.99$

entonces: 
$$P(A\cap B)=P(B)\cdot P(A|B)=0.005\cdot 0.99=0.00495$$
</div>

### Ejemplos

<div class="example">
**Ejemplo**

Un 50\% de  correos recibidos en un servidor llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* ¿Cuál  es la probabilidad que un correo  lleve adjunto si es SPAM?
* ¿Cuál es la probabilidad que un correo **no** tenga adjuntos si **no**  es SPAM?
</div>

### Ejemplos

<div class="example">
**Ejemplo**

Un 50\% de  correos recibidos en un servidor llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* ¿Cuál  es la probabilidad que un correo  lleve adjunto si es SPAM?

</div>

<div class="example-sol">

* $A$: llevar adjuntos; $P(A)=0.5$
* $S$: SPAM; $P(S)=0.65$
* $A^c\cap S^c=(A\cup S)^c$: no llevar adjunto y no ser SPAM; $P((A\cup S)^c)=0.15$

$$P(A|S)=\dfrac{P(A\cap S)}{P(S)}=?$$
</div>

### Ejemplos

<div class="example">
**Ejemplo**

Un 50\% de  correos recibidos en un servidor llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* ¿Cuál  es la probabilidad que un correo  lleve adjunto si es SPAM?

</div>

<div class="example-sol">

* $P(A)=0.5, P(S)=0.65, P(A^c\cap S^c)=P((A\cup S)^c)=0.15$

* $P(A\cup S)=1-P((A\cup S)^c)=0.85$
 
* $P(A\cap S)=P(A)+P(S)-P(A\cup S)=0.3$

$$P(A|S)=\dfrac{P(A\cap S)}{P(S)}=\dfrac{0.3}{0.65}\approx 0.46$$
</div>

### Ejemplos SPAM continuación

<div class="example">
**Ejemplo**

Un 50\% de  correos recibidos en un servidor llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* ¿Cuál  es la probabilidad de que un correo no lleve adjuntos si  no es SPAM?

</div>

<div class="example-sol">

* $P(A)=0.5, P(S)=0.65, P(A^c\cap S^c)=P((A\cup S)^c)=0.15$

$$P(A^c|S^c)=\dfrac{P(A^c\cap S^c)}{P(S^c)}=\dfrac{P(A^c\cap S^c)}{1-P(S)}=\dfrac{0.15}{0.35}\approx 0.43$$
</div>

### Teorema de la probabilidad total

<div class="prop">Teorema de la probabilidad total</div>

Dados dos sucesos $A$ y $B$ se tiene que 

$$
\begin{array}{rl}
P(B)&= P(B\cap A) +P(B\cap A^c)\\
& =P(A)\cdot P(B|A)+ P(A^c)\cdot P(B|A^c)
\end{array}
$$


### Teorema de la probabilidad total

<div class="prop">Partición del espacio espacio muestral</div>

Los sucesos $A_1,A_2,\ldots, A_n$ son  una **partición** del espacio muestral $\Omega$ de un determinado experimento aleatorio, si cumplen las condiciones siguientes:

1. $A_1\cup A_2\cup\ldots\cup A_n=\Omega$
2. $A_1,A_2,\ldots,A_n$ son incompatibles dos a dos ($A_i\cap A_j=\emptyset$)

<div class="prop">Teorema de la probabilidad total</div>
Sea $A_1,A_2,\ldots,A_n$ una partición de $\Omega$. Sea $B$ un suceso cualquiera. Entonces

$$
\begin{array}{rl}
P(B)&= P(B\cap A_1)+\cdots +P(B\cap A_n)\\
& =P(A_1)\cdot P(B|A_1)+\ldots+P(A_n)\cdot P(B|A_n)
\end{array}
$$



### Ejemplos

<div class="example">

**Ejemplo**

Un dígito de control de error toma  el valor 0  en un $99\%$ de los casos en que hay un error y en un $5\%$  de los mensajes sin error.
La probabilidad de error en un mensaje es  del $0.5\%$ 

¿Cuál es la probabilidad de  que un mensaje escogido al azar tenga el dígito de control a 0?
</div>

<div class="example-sol">
Sean los sucesos del enunciado:

* $B$: mensaje con error; $P(B)=0.005$
* $A$: código de error vale 0;

entonces obtenemos las probabilidades a partir del enunciado:

* $P(A|B)=0.99$
* $P(A|B^c)= 0.05$

y por tanto, 

$$
\begin{array}{rl}
P(A) & =P(B)\cdot P(A|B)+P(B^c)\cdot P(A|B^c)\\ &
=0.005\cdot 0.99+0.995\cdot 0.05=0.0547\end{array}
$$

</div>

### Clasificación o Diagnósticos

Consideremos alguna de las siguientes situaciones:

* Un algoritmo detecta si una transacción con tarjeta de crédito es fraude o no.
* Un algoritmo detecta si  tiene o no que mostrar un anuncio en una web.
* Un prueba de embarazo. 
* Una prueba médica  para  una enfermedad concreta.

Nos ceñiremos a la casuística más elemental  el algoritmo de clasificación o la diagnosis solo da dos resultado **Positivo** (sí tienes la enfermedad, sí es un fraude) o **Negativo** (en caso contrario). 

### Clasificación o Diagnósticos

En todas estas situaciones  podemos calcular lo que se llama **matriz de confusión** que representa todas las situaciones posibles. En el caso de estudiar una condición de tipo binario, 

| | El Test da Positivo  | El Test da Negativo  |
|:--:|:--:|:--:|
|Condición Positiva | Correcto | Error|
|Condición Negativa | Error | Correcto|

### Clasificación o Diagnósticos


En general los  modelos y algoritmos de clasificación suelen aportar puntuaciones (*scores*) que determinan el grado de pertenencia a  una clase, o que miden si dos objetos están en la misma clase.

Así  el resultado del clasificador o del diagnóstico  puede ser:


* **un número real**, en cuyo caso debe clasificador entre cada clase debe determinarse por un valor umbral  (*threshold*) por ejemplo para determinar si una persona está estresado podemos dar un *scores* entre 0 y 1 (1 máximo estrés 0 estrés nulo):
* **un resultado discreto** que indica directamente una de las clases (esto es necesario si es un algoritmo que debe decidir  qué hacer con el objeto.

### Clasificación o Diagnósticos

<!--<div class="center">
[![SiliconValley]](https://www.youtube.com/watch?v=pqTntG1RXSY "SiliconValley")
</div>-->


### Clasificación o Diagnósticos

<div class="definition"> Positivos y Negativos en Clasificación</div>
Consideremos un problema de predicción de clases binario, en la que los resultados se etiquetan positivos (P) o negativos (N). Hay cuatro posibles resultados a partir de un clasificador binario como el propuesto. 

* Si el resultado de una exploración es P y el valor dado es también P, entonces se conoce como un Verdadero Positivo (VP). 
* Sin embargo si el valor real es N entonces se conoce como un Falso Positivo (FP). 
* De igual modo, tenemos un Verdadero Negativo (VN) cuando tanto la exploración como el valor dado son N. 
* Un Falso Negativo (FN) cuando el resultado de la predicción es N pero el valor real es P.


### Clasificación o Diagnósticos


Un ejemplo aproximado de un problema real es el siguiente: consideremos una prueba diagnóstica que persiga determinar si una persona tiene una cierta enfermedad. 

* Un falso positivo en este caso ocurre cuando la prueba predice que el resultado es positivo, cuando la persona no tiene realmente la enfermedad. 
* Un falso negativo, por el contrario, ocurre cuando el resultado de la prueba es negativo, sugiriendo que no tiene la enfermedad cuando realmente sí la tiene.


### Clasificación o Diagnósticos

En un diagnósticos de una  cierta  condición (por ejemplo, test embarazo, test de enfermedad), tenemos dos tipos de sucesos:

* $T$: el test da positivo
* $M$: el sujeto satisface la condición

<l class="definition"> Falsos Positivos y Falsos Negativos</l>

* **Falsos positivos** $T\cap M^c$: El test da positivo, pero la condición no es da
* **Coeficiente de falsos positivos** $P(T|M^c)$
* **Falsos negativos** $T^c\cap M$: El test da negativo, pero la condición sí que se da
* **Coeficiente de falsos negativos**: $P(T^c|M)$

### Clasificación o Diagnósticos

<div class="example">
**Ejemplo**

Un test diseñado para diagnosticar una determinada enfermedad tiene un coeficiente de falsos negativos de 0.06, y un coeficiente de falsos positivos de 0.04. En un estudio masivo se observa que un 15\% de la población da positivo al test.

¿Cuál es la probabilidad que una persona escogida aleatoriamente  tenga esta enfermedad?
</div>

<div class="example-sol">

Los datos del problema son:

* $T$: dar positivo al test; $P(T)=0.15$
* $M$: tener la enfermedad
* $P(T)=0.15$, $P(T^c|M)=0.06$, $P(T|M^c)=0.04$
* ¿$P(M)$?
</div>

### Ejemplos

<div class="example-sol">
* $P(T)=0.15$, $P(T^c|M)=0.06$, $P(T|M^c)=0.04$

$$
P(T) =P(M)\cdot P(T|M)+P(M^c)\cdot P(T|M^c)
$$

donde

$$
\begin{array}{l}
P(T|M)=1-P(T^c|M)=0.94 \\[1ex]
P(M^c)=1-P(M)
\end{array}
$$

Por lo tanto

$$
\begin{array}{rl}
0.15 & = P(M)\cdot 0.94+(1-P(M))\cdot 0.04\\
 & =0.04+0.9P(M)\\[1ex]
P(M) & =\dfrac{0.11}{0.9}\approx 0.1222.
\end{array}
$$

</div>

## Bayes

### Fórmula de Bayes

<div class="definition"> Teorema de Bayes </div>

Sean $A$ y $B$ dos sucesos. Si $P(B)>0$, entonces


\begin{eqnarray*}
P(A|B) & = & \frac{P(A)\cdot P(B\big|A)}{P(B)}\\
&=& \frac{P(A)\cdot P(B\big|A)}{P(A)\cdot P(B\big|A)+P(A^c)\cdot P(B\big|A^c)}
\end{eqnarray*}

<div class="example">
**Ejercicio**

Demostrar el teorema de Bayes utilizando que

$$P(A|B) =\frac{P(A\cap B)}{P(B)}=\cdots$$
</div>




### Fórmula de Bayes

<div class="definition"> Teorema de Bayes </div>


Sea $A_1,A_2,\ldots,A_n$ una partición de $\Omega$. Sea $B$ un suceso tal que $P(B)>0$. entonces(para cualquier $i=1,2,\ldots,n$):


\begin{eqnarray*}
P(A_i|B) & =& \dfrac{P(A_i)\cdot P(B|A_i)}{P(B)}\\
& =& \dfrac{P(A_i)\cdot P(B|A_i)}{P(A_1)\cdot P(B|A_1)+\cdots+P(A_n)\cdot P(B|A_n)}
\end{eqnarray*}

</div>

<div class="example">
**Ejercicio**

Demostrar el teorema de Bayes utilizando que

$$P(A_i|B) =\dfrac{P(A_i\cap B)}{P(B)}=\cdots$$

</div>

### Ejemplos

<div class="example">
**Ejemplo**

Un test para detección de VIH da positivo un 99\% de los casos en los que  está presente y en un 5\% de los casos  en los que  el virus está ausente. En una población con un  $0.5\%$ de infectados por VIH, ¿cuál es la probabilidad que un individuo que  haya dado positivo en el test esté infectado?
</div>

<div class="example-sol">
Los sucesos del ejemplo son:

* $A$: individuo infectado
* $B$: el test da positivo

de donde podemos calcular:


\begin{eqnarray*}
P(A|B) & =& \dfrac{P(B|A)\cdot P(A)}{P(B|A)\cdot P(A)+P(B|A^c)\cdot P(A^c)}\\
&=&\dfrac{0.99\cdot 0.005}{0.005\cdot 0.99+0.995\cdot 0.05}=0.09
\end{eqnarray*}

</div>

### Ejemplos


<div class="example">
**Ejemplo**

Un test para detección de VIH da positivo un 99\% de los casos en los que  está presente y en un 5\% de los casos  en los que el virus está ausente. En una población con un  $0.5\%$ de infectados por VIH, ¿cuál es la probabilidad de que un individuo que haya dado **negativo** en el test **no** esté infectado?
</div>

<div class="example-sol">
Los sucesos del ejemplo son:

* $A$: individuo infectado
* $B$: el test da positivo

de donde podemos calcular:

$$
\begin{array}{rl} P(A^c|B^c)& =\dfrac{P(B^c|A^c)\cdot P(A^c)}{P(B^c|A)\cdot P(A)+P(B^c|A^c)\cdot P(A^c)}\\ & =\dfrac{0.95\cdot 0.995}{0.01\cdot 0.005+0.95\cdot 0.995}=0.999947\end{array}
$$

</div>

### Ejemplos

<div class="exercise">
**Ejercicio**

Se ha observado que  los cientes de una empresa de ventas por internet son de tres tipos, A, B y C, disjuntos dos a dos. La probabilidad que  ser de cualquiera de cada uno de los tipos es $1/3$, pero la probabilidad de compra de cada tipo es diferente:  si es de tipo A  compra un 50\% de las veces,  si de tipo B, un 75\% de las veces, y de tipo C, un 60\%.

Supongamos que llega un cliente ¿cuál es la  probabilidad de  que si ha comprado sea del tipo B?
</div>

<div class="example-sol">

* Los sucesos del ejercicio son $A$: el cliente es de tipo  A; $B$:  el cliente es de tipo B; $C$:  el cliente es de tipo C;

 $$P(A)=P(B)=P(C)=1/3$$


Buscamos estrudiar el suceso $E$: el cliente compra

$$P(E|A)=0.5, P(E|B)=0.75, P(E|C)=0.6$$

$$P(B|E)\!=\!\dfrac{P(E|B)\cdot P(B)}{P(E|A)\!\cdot\! P(A)\!+\!P(E|B)\!\cdot\! P(B)\!+\!P(E|C)\!\cdot\! P(C)}\!=\!\ldots$$
</div>

### Ejemplos

<div class="exercise">
**Ejercicio**

Un test de detección precoz de abandono de clientes de una  empresa de telefonía  da  positivo el 97.5\% de las ocasiones en las que, posteriormente, el cliente se da de baja, y un 12\% de las veces en que no se dio de baja. La probabilidad que un cliente escogido al azar se dé de baja es de un 2\%.


* ¿Cuál  es la probabilidad que un individuo escogido al azar de positivo  en el test?
* ¿Cuál  es la probabilidad que un individuo escogido al azar se de de  baja y dé positivo en el test?
* ¿Cuál  es la probabilidad que un individuo  que dé negativo en el test se dé de baja?

</div>


<div class="example-sol">
Definimos los sucesos y datos del ejercicio:

* $T$: Dar positivo al test
* $B$: darse de baja; $P(B)=0.02$
* $P(T|B)=0.975, P(T|B^c)=0.12$

</div>


### Ejemplos

<div class="exercise-sol">

$$P(B)=0.02, P(T|B)=0.975, P(T|B^c)=0.12$$

* ¿Cuál  es la probabilidad que un individuo escogido al azar de positivo  en el test?


\begin{eqnarray*}
P(T) &= & P(B)\cdot P(T|B)+P(B^c)\cdot P(T|B^c)\\
& = &0.02\cdot 0.975+0.98\cdot 0.12=0.1371
\end{eqnarray*}


* ¿Cuál  es la probabilidad que un individuo escogido al azar se de de  baja y dé positivo en el test?

$$P(B\cap T)= P(B)\cdot P(T|B)=0.02\cdot 0.975=0.0195$$


</div>

### Ejemplos

<div class="exercise-sol">

$$P(B)=0.02, P(T|B)=0.975, P(T|B^c)=0.12$$

* ¿Cuál  es la probabilidad que un individuo  que dé negativo en el test se dé de baja?


\begin{eqnarray*}
P(B|T^c) & = &\displaystyle \frac{P(B\cap T^c)}{P(T^c)}=
\frac{P(B)-P(B\cap T)}{1-P(T)}\\
& = & \displaystyle
\frac{0.02-0.0195}{1-0.1371}\approx 0.00058
\end{eqnarray*}


* O también se obtiene  así
$$
P(B|T^c)=\frac{P(T^c|B)\cdot P(B)}{P(T^c|B)\cdot P(B)+P(T^c|B^c)\cdot P(B^c)}
$$

donde


\begin{eqnarray*}
P(T^c|B)&=&1-P(T|B)=0.025,\\ P(T^c|B^c)&=&1-P(T|B^c)=0.88
\end{eqnarray*}


</div>

## Independencia de sucesos

### Sucesos independientes

<l class="definition"> Sucesos Independientes </l>

Diremos que  los sucesos $A$ y  $B$ son **independientes** si  $P(A\cap B)=P(A)\cdot P(B)$


$A_1,\ldots, A_n$ son sucesos **independientes** cuando, para  toda
subfamilia $A_{i_1},\ldots,A_{i_k}$,
$$
P(A_{i_1}\cap \cdots\cap A_{i_k})=P(A_{i_1})\cdots P(A_{i_k})
$$

<l class="prop"> Proposición </l>
Dados dos sucesos  $A$ y $B$ con  $P(A),P(B)>0$,  las siguientes afirmaciones son equivalentes:

1. $A$ y $B$ son independientes 
2. $P(A|B)=P(A)$
3. $P(B|A)=P(B)$
</l>

### Sucesos independientes

<l class="prop"> Proposición </l>

Las siguientes afirmaciones son equivalentes:

1. $A$ y $B$ son independientes.
2. $A^c$ y $B$ son independientes.
3. $A$ y $B^c$ son independientes.
4. $A^c$ y $B^c$ son independientes.

### Ejemplo billete avión

<div class="example">
**Ejemplo**

En la web de viajes WEBTravel, el 55\% de los clientes compra billete de avión, el $20\%$  alojamiento en hotel, y el $60\%$  billete de avión  o alojamiento en hotel. ¿Son los sucesos comprar billete de avión y  comprar alojamiento en hotel independientes?
</div>

<div class="example-sol">
Los sucesos y datos del ejemplo son:

* $A$: comprar billete de avión; $P(A)=0.55$
* $B$: comprar alojamiento; $P(B)=0.2$

por tanto, podemos calcular las probabilidades siguientes

\begin{eqnarray*}
P(A\cap B) & = &P(A)+P(B)-P(A\cup B)\\ 
& = &0.55+0.2-0.6=0.15\\ 
P(A)\cdot P(B) & = & 0.55\cdot 0.2=0.11
\end{eqnarray*}

Por tanto, concluimos que son dependientes, ya que $P(A\cap B)\neq P(A)\cdot P(B)$.

</div>

### Sucesos independientes vs disjuntos

<div class="exercise">
**Ejercicio**

1. Dos sucesos $A$ y $B$ disjuntos, ¿son necesariamente independientes?
2. Dos sucesos $A$ y $B$ independientes, ¿son necesariamente disjuntos?
3. $\emptyset$ y un suceso cualquiera $A$, ¿son necesariamente independientes? 
4. $\Omega$ y un suceso cualquiera $A$, ¿son necesariamente independientes? 
5. ¿Qué condiciones se tienen que dar para que un suceso $A$ sea independiente de si mismo?
</div>

<!--chapter:end:1.Rmd-->

# Variables Aleatorias

## Introducción a las variables aleatorias

* Hasta ahora nuestros sucesos han sido de varios tipos: $\{C,+\}$ en
la moneda, nombres de periódicos, ángulos en una ruleta, número de
veces que sale cara en el lanzamiento de una moneda etc\ldots.
* Necesitamos estandarizar de alguna manera todos estos sucesos. Una
solución es asignar a cada suceso un cierto conjunto de
números reales, es decir, convertir todos los sucesos en
*sucesos de números reales* para trabajar con ellos de forma
unificada.
* Para conseguirlo utilizaremos  unas funciones que
transformen los elementos del espacio muestral en números; esta funciones son las
variables aleatorias.


### Definición de variable aleatoria
 Comenzaremos dando una definición poco rigurosa, pero suficiente, de  variable aleatoria.

<l class="definition"> *Variable Aleatoria (definición práctica)* </l>


Una variable aleatoria (v.a.) es una aplicación que toma valores numéricos determinados por el resultado de un experimento aleatorio

<l class="observ">**Notación**:</l>

* Normalmente representaremos las v.a. por letras mayúsculas $X,Y,Z$\ldots
* Los valores que "*toman*" las v.a. los representaremos por letras minúsculas (las mismas en principio) $x,y,z\ldots$


### Ejemplo

<div class="example">
**Ejemplo**

Lanzamos un dado convencional de parchís el espacio muestral del experimento es

$$\Omega=\{1,2, 3, 4,  5, 6\}$$


</div>

<div class="example-sol">
Una v.a $X:\Omega\to\mathbb{R}$
sobre este espacio queda definida por 

\begin{equation*}
\begin{split}
X(1)&=1,X(2)=2,X(3)=3,\\
X(4)&=4,X(5)=5,X(6)=6.
\end{split}
\end{equation*}

* Ahora el suceso $A=\{2, 4, 6\}$, es decir "salir
número par", es equivalente a $\{X=2,X=4,X=6\}$.
* El suceso $B=\{1,2,3\}$, es decir "salir un número
inferior o igual a $3$" es  en términos de la v.a. $\{X=1,X=2,X=3\}$ o también $\{X\leq 3\}$.

</div>

### Ejemplo

<div class="example">
**Ejemplo**

Consideremos el experimento lanzar una anilla al cuello de una botella. Si acertamos a
ensartar la anilla en la botella el resultado del experimento es *éxito* y
*fracaso* en caso contrario. 
</div>

<div class="example-sol">
El espacio muestral asociado a este experimento será
$\Omega=\{\mbox{éxito, fracaso}\}$. Construyamos la siguiente variable aleatoria:

$$X:\{\mbox{éxito, fracaso}\}\to\mathbb{R}$$

definida por 

$$X(\mbox{éxito})=1 \mbox{ y } X(\mbox{fracaso})=0.$$

</div>


### Tipos de variables aleatorias

Hay dos tipos fundamentales de variables aleatorias, las discretas y las continuas.

Damos a continuación una definición informal.

<l class="definition">Variables Aleatórias Discretas y Continuas </l>

* Una variable aleatoria es **discreta** si sólo puede tomar una cantidad numerable de valores con probabilidad positiva.
* Las variables aleatorias **continuas**  toman  valores en intervalos.
* También existen las variables aleatorias **mixtas**; con una parte discreta y otra continua.


### Ejemplo

<div class="example">
**Ejemplo**

Son variables *aleatorias discretas*:
      
*  Número de artículos defectuosos en un cargamento.
*  Número de clientes que llegan a una ventanilla de un banco en una hora.
*  Número de errores detectados en las cuentas de una compañía.
*  Número de reclamaciones de una póliza de un seguro médico.
      
Son variables *aleatorias continuas*:
      
* Renta anual de una familia.
* Cantidad de petróleo importado por un país
* Variación del precio de las acciones de una compañía de telecomunicaciones.
* Porcentaje de impurezas en un lote de productos químicos.
      
</div>

## Variables aleatorias discretas

### Distribuciones de probabilidad para v.a. discretas.

* Pasamos ahora a describir el comportamiento  de la v.a. 
Para ello utilizaremos distintas
funciones que nos darán algunas probabilidades de la variable aleatoria.
* En el caso discreto estas funciones son la de probabilidad, y  la función de distribución o de probabilidad acumulada.
* En el caso discreto la función de probabilidad es la que nos da las probabilidades de los
sucesos elementales de la v.a. que definimos a continuación.



### Función de probabilidad para variables discretas


<l class="definition"> **Función de Probabilidad**</l>
La *función de probabilidad* (*probability mass function* o incluso abusando de notación *probability density function*)

de una variable aleatoria discreta $X$ a la que denotaremos por $P_{X}(x)$
está definida por

$$P_{X}(x)=P(X=x)$$

es decir la probabilidad de que $X$ tome el valor $x$.

Si $X$ no asume ese valor $x$, entonces
$P_{X}(x)=0$.

### Funcion probabilidad discretas

<l class="definition"> **Dominio de una variable aleatoria discreta** </l> 

El conjunto $$D_X=\{ x\in\mathbb{R} \mid P_X(x)>0\}$$ recibe el nombre de
*dominio* de la v.a. y son los valores posibles de esta variable. 

En el caso discreto lo más habitual es que $X(\Omega)=D_X$.



### Ejemplo

<div class="example">
**Ejemplo parchís**

Lanzamos un dado de parchís una vez, en esta ocasión representaremos los
sucesos elementales por el número de puntos de la cara obtenida, tenemos que
$$\Omega=\{\mbox{1-puntos,2-puntos,3-puntos,4-puntos,5-puntos,6-puntos}\}$$ 
y la variables aleatoria $X:\Omega\to \mathbb{R}$ viene definida por

$$X(\mbox{i-puntos})=i\mbox{ para } i=1,2,3,4,5,6.$$
</div>
  
<div class="example-sol ">

Supongamos que el dado está bien balanceado. Entonces
$$P_{X}(1)=P_{X}(2)=P_{X}(3)=P_{X}(4)=P_{X}(5)=P_{X}(6)=\frac16$$
Concretamente:
$$
P_{X}(x)=
  \left\{
  \begin{array}{ll}
   \frac16 & \mbox{si } x=1,2,3,4,5,6\\
  0 & \mbox{en otro caso }
  \end{array}
  \right.
$$
  
Su dominio es $$D_X=\{1,2,3,4,5,6\}.$$
</div>

### Ejemplo
<div class="example">
**Ejemplo lanzamiento moneda**


Sea $X$ la v.a. asociada al lanzamiento de una moneda. Su espacio muestral es  $\Omega=\{c,+\}$, la v.a. queda definida por:

$$X(\omega)=\left\{\begin{array}{ll} 1 & \mbox{si } \omega=c \\
0 & \mbox{si }\omega=+\end{array}\right.$$

</div>

<div class="example-sol">

Su función de probabilidad es:

$$P_{X}(x)=P(X=x)=\left\{\begin{array}{ll} \frac12 & \mbox{si } x=0,1\\
0 & \mbox{en otro caso}\end{array}\right.$$


Finalmente su dominio es $D_X=\{0,1\}.$
</div>

### Ejemplo 
<div class="example">
**Ejemplo urna con bolas**

Tenemos una urna con tres bolas rojas, una negra y dos blancas. Realizamos una extracción y observamos el color de la bola entonces un espacio muestral es
$$\Omega=\{roja, blanca, negra\}.$$ 
</div>

<div class="example-sol">

Una variable aleatoria asociada al experimento es:

$$X(\omega)=\left\{\begin{array}{ll} 1 & \mbox{si } \omega=roja  \\
2 & \mbox{si }\omega=negra \\ 3 & \mbox{si } \omega=blanca \end{array}\right.$$
</div>

### Ejemplo

<div class="example-sol">
La función de probabilidad es 

$$P_{X}(x)=\left\{\begin{array}{ll} \frac36 & \mbox{si } x=1\\
\frac16 & \mbox{si } x=2\\ \frac26 & \mbox{si } x=3\\ 0 & \mbox{en otro
caso}\end{array}\right.$$

El dominio de la v.a.  $X$ es $D_X=\{1,2,3\}.$

</div>

### Propiedades de la función de probabilidad.


<l class="prop"> Propiedades básicas de la función de porbabilidad </l>

Sea $X$ una v.a. discreta $X:\Omega:\to\mathbb{R}$ con dominio $D_X$. Su función de probabilidad $P_{X}$ verifica las siguientes propiedades:

* $0\leq P_{X}(x)\leq 1$ para todo $x\in\mathbb{R}$
* $\sum\limits_{x\in D_X} P_{X}(x)=1$


### Ejemplo

<div class="example">

**Ejemplo: Lanzamiento moneda** 

Lanzamos al aire tres veces, de forma independiente, una moneda perfecta. El espacio muestral de este experimento es
$$\Omega=\{ccc,cc+,c+c,+cc,c++,+c+,++c,+++\}$$ (expresados en orden de aparición).
</div>

<div class="example-sol">

Este espacio tiene todos los sucesos elementales
equiprobables. 

Consideremos la variable aleatoria asociada a este experimento:

$$X=\mbox{ número de caras en los tres lanzamientos}.$$ 

Su función de probabilidad es:

$$
\begin{array}{l}
P(X=0)=P(\{+++\})=\frac18\\ P(X=1)=P(\{c++,+c+,++c\})=\frac38\\
    P(X=2)=P(\{cc+,c+c,+cc\})=\frac38\\
    P(X=3)=P(\{ccc\})=\frac18
\end{array}
$$
</div>    
### Ejemplo
<div class="example-sol">

Podemos reescribir la función de probabilidad de $X$ de forma simplificada:
    
$$P_{X}(x)=\left\{\begin{array}{ll} \frac18 & \mbox{si } x=0, 3\\
\frac38 & \mbox{si } x=1,2\\ 0 & \mbox{en otro caso}\end{array}\right.$$



Efectivamente los valores de la función de distribución suman 1

$$\sum_{x=0}^3 P_X(x)= \frac18+\frac38+\frac38+\frac18=1.$$

</div>


### Función de distribución de variables aleatorias

<l class="definition"> **Distribución de Probabilidad**</l>

La función de *distribución de probabilidad* (acumulada) de la v.a. $X$ (de cualquier tipo;
discreta o continua) $F_{X}(x)$ representa la probabilidad de que $X$  tome un menor o igual que  $x$ es decir

$$F_{X}(x)=P(X\leq x)$$

Esta función también se denomina función de *distribución de
probabilidad o simplemente función de distribución* de una v.a., y en inglés
*cumulative distribution function* por lo que se abrevia con el acrónimo `cdf`.



### Propiedades


<l class="definition"> **Propiedades de la Función de Distribución**</l>

Sea $X$ una v.a. y $F_{X}$ su función
de distribución:

1. $P(X>x)=1-P(X\leq x)=1-F_{X}(x)$
2.  Sea a y b tales que $a<b$, $P(a<X\leq b)=P(X\leq b)-P(X\leq a)=F_{X}(b)-F_{X}(a)$



### Propiedades

<div class="dem"> 

**Demostración**:

Tenemos que el complementario de $X$ mayor que $x$ es:  $\overline{\left\{X>x\right\}}=\left\{X>x\right\}^c=\left\{X\leq x\right\}$. Además

$$P(X>x)=1-P(\overline{\left\{X>x\right\}})=1-P(X\leq x)=1-F_{X}(x)$$
    
lo que demuestra la primera propiedad

Por otro lado, que $X$ se encuentre entre dos valores $a$ y $b$ es $\left\{a< X \leq b\right\}= \left\{X\leq b\right\}-\left\{X\leq  a\right\}$

ahora podemos hacer 
    
\begin{eqnarray*}
P(a<X\leq b)&=&P(\left\{X\leq b\right\}-\left\{X\leq a\right\})\\
&=& P(\left\{X\leq b\right\})-P(\left\{X\leq a\right\})\\
&=& F_{X}(b)-F_{X}(a).
\end{eqnarray*}

</div>

### Propiedades

<l class="definition"> **Propiedades de la Función de Distribución**</l>

Sea $F_{X}$ la función de distribución  de una  v.a. $X$ entonces:
 
* $0\leq F_{X}(x)\leq 1$.
* La función $F_{X}$ es no decreciente.
* La función $F_{X}$ es continua por la derecha.
* Si denotamos por $F_X(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F(x)$,
entonces se cumple que $P(X< x_0)=F_X(x_0^{-})$ y que $P(X=x_0)=F_X(x_0)-F_X(x_0^{-})$.

### Propiedades

<l class="definition"> **Propiedades de la Función de Distribución**</l>

* Se cumple que $\displaystyle \lim_{x\to\infty} F_{X}(x)=1$; $\displaystyle \lim_{x\to-\infty}F_{X}(x)=0$.
*  Toda función $F$ verificando las propiedades anteriores es función de distribución de alguna v.a. $X$.
* $P(X>x)=1-F_{X}(x)$
* Dados $a,b\in \mathbb{R}$ con $a<b$ $$P(a<X\leq b)=F_{X}(b)-F_{X}(a).$$

### Advertencia desigualdades estrictas

En las propiedades anteriores no se pueden cambiar en general las desigualdades de
estrictas o no estrictas.

Veamos que propiedades tenemos cuando se cambian estas
desigualdades.


Dada una $F_{X}$ una función de distribución de la v.a. $X$ y denotamos por $$F_{X}(x_0^{-})=\displaystyle \lim_{x\to x_0^{-}} F_{X}(x),$$,

entonces  se cumplen las siguientes igualdades...

### Advertencia desigualdades estrictas

<l class="prop">Propiedades </l>

* $P(X=x)=F_{X}(x)-F_{X}(x^{-})$
* $P(a< X< b)=F_{X}(b^{-})-F_{X}(a)$
* $P(a\leq X< b)=F_{X}(b^{-})-F_{X}(a^{-})$
* $P(X<a)=F_{X}(a^{-})$
* $P(a\leq X\leq b)=F_{X}(b)-F_{X}(a^{-})$
* $P(X\geq a)=1-F_{X}(a^{-})$
          
### Propiedades

<l class="prop">Más propiedades de la función de distribución </l> 

* Si  $F_X$ es continua en $x$ se tiene que $P(X=x)=0$.
Así que si la v.a. es continua $P(X\leq a)=P(X< a)+P(X=a)=P(X<a)$ y propiedades similares.
*  Sea $X$ una variable aleatoria discreta que con dominio $D_X$ y
que tiene por función de probabilidad $P_{X}(x)$ entonces su función de distribución
$F_{X}(x_0)$ es
$$F_{X}(x_0)=\sum_{x\leq x_0} P_{X}(x)$$

donde $\sum_{x\leq x_0}$ indica que sumamos todos los $x \in D_X$ tales que $x\leq
x_0$
  


### Propiedades

<div class="dem"> 

**Demostración**:


Si $X$ es continua $$P(X=a)=F(a)-F(a^{-})=F(a)-F(a)=0$$
por lo tanto 

$$P(X\leq a)=P(X<a)+P(X=a)= P(X<a)+0= P(X<a).$$


lo que demuestra la primera propiedad.

Para demostrar la segunda basta hacer


$$ 
F_{X}(x_0)= P(X\leq x_0)=P\left(\bigcup_{x\leq
x_0; x\in D_X} \{x\}\right)= \sum_{x\leq x_0}P(X=x)= \sum_{x\leq x_0}P_{X}(x).
$$
  
</div>


### Ejemplo

<div class="example">
**Ejemplo**

En el experimento del dado se tiene que:

$$P_{X}(x)=\left\{\begin{array}{ll} \frac16 & \mbox{si } x=1,2,3,4,5,6\\ 0 & \mbox{en el resto de casos}\end{array}\right.,$$

por lo tanto

   $$F_{X}(x)=P(X\leq x)=\left\{\begin{array}{ll}
   0 & \mbox{si } x<1\\
   \frac16 &\mbox{si } 1\leq x<2\\
   \frac26 &\mbox{si } 2\leq x<3\\
   \frac36 &\mbox{si } 3\leq x<4\\
   \frac46 &\mbox{si } 4\leq x<5\\
   \frac56 &\mbox{si } 5\leq x<6\\
   1 &\mbox{si } 6\leq x\end{array}\right.$$

</div>

### Ejemplo

<div class="example-sol">
Calculemos más detalladamente algún valor de $F_{X}$, por ejemplo:

\begin{eqnarray*}
F_{X}(3.5) & = & P(X\leq 3.5)=  P(\{X=1\}\cup\{X=2\}\cup \{X=3\})\\
&=& P(\{X=1\})+P(\{X=2\})+P(\{X=3\})\\
&=& \frac16+\frac16+\frac16=\frac36 =\frac12,
\end{eqnarray*}

o de otra forma

\begin{eqnarray*}
F_{X}(3.5)&=&\sum_{x\leq 3.5} P_X(x)=\sum_{x=1}^3 P(X=x)\\&=&\sum_{x=1}^3 \frac16= 3 \cdot
   \frac16=\frac12.
\end{eqnarray*}

</div>


### Propiedades de la función de distribución

<l class="prop"> Propiedad</l>

Sea $X$ una variable con función de distribución $F_{X}$ entonces:
 
* $0\leq F_{X}(x)\leq 1$ para todo $x$
* Si $x<x'$ entonces $$F_{X}(x)\leq F_{X}(x').$$
Es una función creciente, no necesariamente estrictamente creciente.
* $\displaystyle \lim_{x\to -\infty}F_{X}(x)=0$ y $\displaystyle \lim_{x\to +\infty}F_{X}(x)=1$
* Es continua por la derecha $\displaystyle \lim_{x\to x_0^{+}}F_{X}(x)=F_{X}(x_0)$.
  



## Valores esperados  o esperanza


### Momentos de variables aleatorias discretas

* Al igual que en  la estadística descriptiva  se utilizan  distintas medidas para
resumir los valores centrales y para medir la dispersión de una muestra, podemos definir
las correspondiente medidas para variables aleatorias.

* A estas medidas se les suele añadir el adjetivo *poblacionales* mientras que a las que provienen de la muestra se las adjetiva como *muestrales*.


Por ejemplo  podemos buscar un valor que resuma toda la variable. Este valor es el que "*esperamos*" que se resuma la v.a. o esperamos que las realizaciones de la v.a. queden cerca de él. Veamos su definición formal.



### Esperanza  de un variable aleatoria discreta


<l class="definition">Esperanza de una variable aleatoria discreta </l>

El valor *esperado o esperanza* (*expected value* en inglés) $E(X)$ de una v.a. discreta $X$, se define como

$$
E(X)=\sum_{x\in X(\Omega)} x P_{X}(x)
$$


En ocasiones se le domina *media* (*mean* en inglés *mitjana* en catalán) poblacional o simplemente media y muy frecuentemente se la denota $\mu_{X}=E(X)$ o simplemente $\mu=E(X)$.


### Interpretación de la media aritmética para v.a. discretas

<div class="example">
**Ejemplo**

Supongamos que lanzamos un dado $n$ veces y obtenemos unas frecuencias absolutas $n_{i}$
para el resultado $i$ con $i=1,\ldots,6$. Sea $X$ la v.a. que nos representa el valor de
una tirada del dado.

Calculemos la media aritmética (o media muestral) de los datos

$$
\overline{x}=\frac{1\cdot n_1+2\cdot  n_2+3\cdot  n_3+4\cdot  n_4+5\cdot  n_5+6 \cdot 
n_6}{n}=\sum_{x=1}^6 x \frac{n_{x}}{n}.
$$

Si $n\to \infty$ se tiene que $\displaystyle\lim_{n\to \infty} \frac{n_{x}}{n}=P_{X}(x).$

Por lo tanto $E(X)=\displaystyle \lim_{n\to\infty}\sum_{x=1}^6x \frac{n_{x}}{n}.$

Entonces el valor esperado en una v.a. discreta puede entenderse como el valor promedio que
tomaría una v.a. en un número grande de repeticiones.

</div>



### Ejemplo

<div class="example">

**Ejemplo: Erratas en un texto**

Sea $X$= número  de erratas en una página de un texto con dominio $D_X=\{0,1,2\}$.

Resulta que

$$
P(X=0)=0.42, P(X=1)=0.4, P(X=2)=0.18.
$$
    
entonces
    
$$
E(X)=0\cdot 0.42+ 1\cdot 0.4 + 2 \cdot 0.18=0.76.
$$

Elegida una página del texto al azar esperamos encontrar $0.76$ errores por página.

Supongamos que en  el editor nos paga $2$ euros por cada página que
encontremos con $1$ error y $3$ euros por cada página con  dos errores (y nada por las
páginas correctas) ¿Cuánto esperamos cobrar si analizamos una página?

$$0\cdot 0.42 + 2\cdot 0.4 + 3\cdot 0.18=1.34$$
</div>


### Esperanzas de funciones de variables aleatorias discretas

<l class="definition"> **Esperanzas de funciones de variables aleatorias discretas** </l>

Sea $X$ una v.a. discreta con función de probabilidad $P_{X}$ y de distribución
$F_{X}$. Entonces el *valor esperado de una función* $g(x)$ es :

$$E(g(X))=\sum_{x}g(x) P_{X}(x).$$


### Propiedades de los valores esperados


<l class="prop"> Propiedades</l>
 
* $E(k)=k$ para cualquier constante $k$.
* Si $a\leq X\leq b$ entonces $a\leq E(X)\leq b$.
* Si $X$ es una v.a. discreta que toma valores enteros no negativos entonces
$E(X)=\sum_{x=0}^{+\infty}(1- F_X(x)).$
  
<div class="exercise">
**Ejercicio**

La demostración de las propiedades anteriores se deja como ejercicio.
</div>

### Ejemplo

<div class="example"> 
**Ejemplo: paleta de colores aleatoria**

Supongamos que estamos sentados delante de nuestro ordenador con un amigo y
le decimos que en dos minutos podemos programar una paleta  para poner colores a unos
gráficos. 

Queremos la que paleta tenga dos botones con las opciones color rojo y color azul.
Como hemos programado a gran velocidad resulta que el programa tiene un error; cada vez que
se abre la paleta los colores se colocan al azar (con igual probabilidad) en cada botón,
así que no sabemos en que color hemos de pinchar. 

Además, como nos sobraron $15$ segundos
para hacer el programa y pensando en la  comodidad del usuario, la paleta se cierra después de haber seleccionado  un
color y hay que volverla a abrir de nuevo.

La pregunta es ¿cuál es el valor esperado del
número de veces que hemos pinchar el botón de color azul antes de obtener este color?

</div>



### Ejemplo

<div class="example-sol"> 
Llamemos $X$ al número de veces que pinchamos en el botón azul (y nos sale rojo) hasta
obtener el primer azul. La variable $X$ toma valores en los enteros no negativos. Su
función de probabilidad queda determinada por

$$
P_X(x)=P(X=x)=P(\stackrel{x \mbox{veces}}{\overbrace{rojo, rojo,\ldots,rojo},azul})
=\left(\frac12\right)^{x+1}.
$$

</div>

### Propiedades de las series geométricas

<l class="prop">Series geométricas</l>

* Una *progresión geométrica* de razón $r$ es una sucesión de la  forma  
$$
r^0, r^1,\ldots,r^n,\ldots.
$$
* La serie geométrica es la suma de todos los
valores de la progresión geométrica $\displaystyle\sum_{k=0}^{+\infty} r^k$.
* Las sumas parciales desde el término $n_0$ al $n$ de una progresión geométrica valen 
$$
\sum_{k=n_0}^n r^k=\frac{r^{n_0}- r^n r}{1-r}.
$$
 
### Propiedades de las series geométricas

<l class="prop">Propiedades</l>

* Si $|r|<1$ la serie geométrica es convergente y $$\sum_{k=0}^{+\infty }
r^k=\frac1{1-r}$$. 
* En el caso en que se comience en $n_0$ se tiene que
$$\sum_{k=n_0}^{+\infty} r^k=\frac{r^{n_0}}{1-r}.$$

### Propiedades de las series geométricas

<l class="prop">Propiedades</l>


* Si $|r|<1$  también son convergentes las derivadas, respecto de $r$, de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que


\begin{eqnarray*}
\left(\sum_{k=0}^{+\infty} r^k\right)'= & \sum_{k=1}^{+\infty}k
r^{k-1} \left(\frac1{1-r}\right)'=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{''}=& \sum_{k=2}^{+\infty}k (k-1)
r^{k-2}\left(\frac1{1-r}\right)^{''}=\frac2{(1-r)^3}
\end{eqnarray*}.


### Ejemplo

<div class="example">

**Ejemplo (cont)**

Si seguimos con el ejemplo de la paleta de colores, su esperanza es:

\begin{eqnarray*}
E(X)&=&\sum_{x=0}^{+\infty} x P(X=x)=\sum_{x=0}^{+\infty} x
\left(\frac12\right)^{x+1}\\
&= & \left(\frac12\right)^2\sum_{x=1}^{+\infty} x
\left(\frac12\right)^{x-1}=\left(\frac12\right)^2
\frac1{\left(1-\frac12\right)^2}=1.
\end{eqnarray*}

Ahora calculemos su función de distribución

\begin{eqnarray*}
F_X(x)&=& P(X\leq x)=\sum_{k=0}^x P(X=k)=\sum_{k=0}^x
\left(\frac12\right)^{k+1}\\
&=& \frac{\frac12-\frac12^{x+1}
\frac12}{1-\frac12}=1-\left(\frac12\right)^{x+1}
\end{eqnarray*}.

</div>


### Ejemplo

<div class="example">

Como la variable toma valores enteros positivos, podemos calcular su valor esperado
de esta otra manera

$$E(X)=\sum_{x=0}^{+\infty} (1-F_X(x))=\sum_{x=0}^{+\infty}(\frac12)^{x+1}=\frac12
\frac1{1-\frac12}=1.$$

</div>

<div class="exercise">

**Ejercicio**

Calculad el valor esperado de la variable

$$
Y=\mbox{número de intentos para conseguir el color azul.}
$$
</div>




### Momentos de una variable aleatoria

<l class="definition"> Momentos de orden $m$</l>

Llamaremos  *momento de orden $m$* respecto al punto $C$ a 
$$E\left((X-C)^m\right)$$

* Cuando $C=0$ los momentos reciben el nombre de *momentos respecto al origen*.
* Cuando $C=E(X)$ reciben el nombre de *momentos centrales o respecto de la media*. Luego la esperanza es el momento de orden $1$ respecto al origen. Estos momentos son la versión poblacional de los momentos que vimos en el curso de estadística descriptiva, recibiendo estos último el nombre de momentos muestrales.


### Resumen conceptos

* Hemos descrito el comportamiento aleatorio de una v.a. discreta mediante sus funciones  de probabilidad $P_{X}$ y de distribución $F_{X}$.
* También tenemos un valor central; el valor esperado $E(X)$. 
* Como medida básica nos queda definir una medida de lo lejos que están los datos del valor central $E(X)$ una de estas medidas es la varianza de $X$.

## Medidas de la variabilidad


### Medidas de la variabilidad: la varianza


<l class="definition"> Varianza </l>

Sea $X$ una v.a. Llamaremos *varianza* de $X$ a

$$Var(X)=E((X-E(X))^2)$$

Por lo tanto la varianza es el momento central de orden $2$.

De forma frecuente se utiliza la notación $$\sigma_{X}^2=Var(X).$$
    
A la raíz cuadrada positiva de la varianza
$$\sigma_{X}=\sqrt{Var(X)}$$
   
se la denomina desviación típica  o estándar de $X$.




### Propiedades de la varianza
 
<l class="prop"> Propiedad </l>

* Si $X$ es una v.a. discreta con función de probabilidad $P_X$ su varianza es 
 $$\sigma_{X}^2=Var(X)=E((X-E(X))^2)=\sum_{x}(x-E(X))^2 P_{X}(x).$$
* Sea $X$ una v.a.
 $$Var(X)=E(X^2)-(E(X))^2=\sum_{x} x^2 P_{X}(X)-(E(X))^2$$
  


### Demostración

<div class="dem"> 

**Demostración de b)**


\begin{eqnarray*}
Var(X)&= & \sum_{x}(x-E(X))^2 P_{X}(x) = \sum_{x}(x^2 -2 x E(X)+(E(X)^2) P_{X}(x)\\
&=& \sum_{x}x^2P_{X}(x) -  E(X)\sum_{x}2 x P_{X}(x) + (E(X)^2)\sum_{x} P_{X}(x)\\
&=& E(X^2)- 2 E(X) E(X) + (E(X))^2=E(X^2)-(E(X))^2.
\end{eqnarray*}



</div>
### Ejemplo


<div class="example"> 
**Ejemplo**

Calculemos en  el ejemplo anterior la varianza del número de errores.
</div>

<div class="example-sol"> 

Recordemos que:
   
$$
P(X=0)=0.42,\quad P(X=1)=0.4, \quad P(X=2)=0.18
$$

y que

$$
E(X)=0.76
$$

Entonces:
    
$$
Var(X)=E(X^2)-(E(X))^2 = E(X^2)-(0.76)^2.
$$


</div>

### Ejemplo
<div class="example-sol">
  Ahora necesitamos calcular 
  
  $$E(X^2)= 0^2 (0.41)+ 1^2 (0.4)+ 2^2 (0.18)=0.4+0.72=1.12$$
  y por lo tanto
  
  $$Var(X)= E(X^2)-(0.76)^2=1.12-0.5776=0.542$$
  y $$\sqrt{Var(X)}=\sqrt{0.542}$$

  En resumen $\sigma_{X}^2=0.542$ y $\sigma_{X}=\sqrt{0.542}$
     

</div>

### Propiedades de la varianza
 
 
<l class="prop"> **Propiedades de la varianza**</l>

* $Var(X)\geq 0$
* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$
* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$. Esta propiedad es una de las que hace útil a la varianza como medida de dispersión.
  

<div class="exercise">
**Ejercicio**

Se deja como ejercicio la demostración de estas propiedades.

</div>




## Esperanza y varianza de transformaciones lineales.


### Transformaciones lineales. 

<l class="definition"> Transformación lineal </l>

Un **cambio de variable lineal** o **transformación lineal** de una v.a. $X$ es otra v.a. $Y= a+ b X$  donde $a,b\in\mathbb{R}$.

<l class="prop"> Esperanza de una transformación lineal</l>

Sea $X$ una v.a. con $E(X)=\mu_{X}$ y $Var(X)=\sigma_{X}^2$ y $a,b\in\mathbb{R}$.
Entonces si $Y=a+b X$:
 
* $E(Y)=E(a + b X)=a+ b E(X)= a + b \mu_{X}$.
* $Var(Y)=Var(a+bX)=b^2 Var(X)= b^2 \sigma_{X}^2$
* $\sigma_{Y}=\sqrt{Var(Y)}=\sqrt{b^2 Var(X)}=|b| \sigma_{X}$
  
    
### Demostración

<div class="dem">
**Demostración**:

\begin{eqnarray*}
E(Y)&=& E(a+bX)=\sum_{x}(a+b\cdot X)\cdot P_{X}(x)\\
&=& a \sum_{x} P_{X}(x) + b \sum_{x} x\cdot P_{X}(x)\\ 
&=& a + b\cdot E(X)=a + b \mu_{X}
\end{eqnarray*}

</div>

<div class="exercise">
**Ejercicio**

Las demostración de las demás propiedades se dejan como ejercicio.
</div>

## Variables aleatorias continuas

### Variables aleatorias continuas definición.

* Como ya hemos dicho las variables aleatorias continuas toman valores en
intervalos o áreas.
* Lo más habitual es que estas variables tengan función de distribución continua y
derivable (salvo  a los más en una cantidad finita o numerable de puntos:-)).
* En lo que sigue supondremos que la función de distribución de variables
aleatorias continuas cumplen estas propiedades.
* Notemos que si $X$ es una v.a. con función de distribución continua se tiene que
$P(X=x_0)=F_X(x_0)-F(x_0^{-})=0$. Por lo que no tiene sentido definir *función de probabilidad*.



### Variables aleatorias continuas

* En general tendremos que $P(X<x_0)=P(X\leq x_0)$.
* Por otra parte podemos utilizar una regla parecida del
cociente entre casos favorables y casos posibles de Laplace  pero en
este caso el conteo se hace por la *medida*  de los casos
posibles partida por la *medida* de los casos favorables.
* Veamos un ejemplo de v.a. continua, que ampliaremos en el tema siguiente, en el que se utilizan todos estos conceptos.




### Ejemplo: Distribución uniforme en $[0,1]$.

<div class="example"> 

**Ejemplo: distancia el dardo centro** 

Supongamos que lanzamos un dardo a una diana de radio $1$, de forma que sea *equiprobable* cualquier distancia al centro (¡Cuidado! esto no es equivalente
a que cualquier punto de la diana  sea *equiprobable*).

Consideremos la v.a. continua $X=$ distancia al centro.
</div>

<div class="example-sol">

Su función de distribución es 

$$
F_{X}(x)=
\left\{
\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
x & \mbox{si } 0<x<1\\
1 & \mbox{si } x\geq 1
\end{array}
\right.
.
$$

Ya que

* C.F. *longitud favorable* es $x-0$.
* C.P. *longitud posible* es $1-0$.
* Luego 
$$P(X\leq x)=\frac{C.F.}{C.P.}=\frac{x-0}{1-0}=x$$
</div>

### Gráfica de la función de distribución uniforme

```{r figUNIF, fig.align='center',echo=FALSE}
curve(punif(x,0,1),xlim=c(-1,2),col="blue",
      main="Función de distribución de una v.a. uniforme en el intervalo unidad.")
```

### Propiedades

En las variables continuas los sucesos del tipo $\{X\leq x \}$ y $\{X< x \}$ tendrán la
misma probabilidad, y otros tipos de sucesos similares también, algunas de estas
propiedades se explicitan en la siguiente proposición.

<l class="prop">Propiedades</l>

Dada una v.a. continua $X$ se tiene que:
 
* $P(X\leq b)=P(X<b)$
* $P(X<b)=P(X<a)+P(a<X<b)$
* $P(a<X<b)=P(X<b)-P(X<a)$
  
### Demostración  
  
<div class="dem">
**Demostración:**

La primera es evidente  $P(X\leq b)=P(X<b)+P(X=b)=P(X<b)$

Para demostrar la segunda, tenemos

$$\{X<a\}\cap \{a<X<b\}=\emptyset$$ 
$$\{X<a\}\cup \{a<X<b\}=\{X<b\}$$ 

entonces

\begin{eqnarray*}
P(X\leq b)= & P(\{X<a\}\cup \{a<X<b\})\\
& = P(X<a)+P(a<X<b)
\end{eqnarray*}


</div>

<div class="exercise">
**Ejercicio**

La demostración de la tercera propiedad es similar a la segunda pero aplicando la primera. Queda de ejercicio.
</div>


### Propiedades de la función de distribución

Las propiedades anteriores  y combinaciones de ellas se pueden
escribir utilizando la función de distribución de $X$:


<l class="prop"> Propiedades de la Función de Distribución </l>

Dada una variable aleatoria continua se tiene que:

* $F_{X}(b)=F_{X}(a)+P(a<X<b)$
* $P(a<X<b)=F_{X}(b)-F_{X}(a)$
* $P(a\leq X\leq b)=F_{X}(b)-F_{X}(a)$



<div class="exercise"> 

**Ejercicio**

Se deja la demostración como ejercicio 
</div>


### Ejemplo 

<div class="example"> **Ejemplo: lanzamiento de dardos**


En los dardos:
$$P(0.25<X<0.3)=F_{X}(0.3)-F_{X}(0.25)=$$
$$=0.3-0.25=0.05$$
</div>

### Función de densidad

<l class="definition"> **Función de densidad** </l> 

Una función $f:\mathbb{R}\to\mathbb{R}$ es una función de densidad sobre $\mathbb{R}$ si cumple que


* $f_{X}(x)\geq 0$ para todo $x \in\mathbb{R}.$
* $f$ es continua salvo a lo más en una cantidad finita de puntos sobre
cada intervalo acotado de $\mathbb{R}$.
* $\displaystyle\int\limits_{-\infty}^{+\infty} f_{X}(x) dx=1.$

### Función de densidad de una variable aleatoria.

<l class="definition"> **Función de densidad de una variable aleatoria** </l>

Sea $X$ una v.a. con función de distribución $F_X$. Sea $f:\mathbb{R}\to\mathbb{R}$ una función de densidad tal que

$$F_X(x)=\displaystyle\int_{-\infty}^{x} f_X(t) dt.\mbox{ para todo } x\in\mathbb{R}.$$

Entonces $X$ es una variable aleatoria continua y $f_X$ es la densidad de la v.a.  $X$.


###  Dominio de una variable aleatoria continua

El conjunto $D_X=\{x\in\mathbb{R}| f_x(x)>0\}$ recibe el nombre de <l class="definition"> soporte o dominio de la
variable aleatoria continua</l> y se interpreta su conjunto de resultados posibles.


<div class="example">
**Ejemplo**

En nuestra diana, la función $f$ es una densidad

$$
f_{X}(x)=\left\{
\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
1 & \mbox{si } 0 < x < 1\\
0 & \mbox{si } 1\leq x
\end{array}\right.
$$

que es la densidad de $X$, en efecto:

</div>

### Densidad diana

<div class="example-sol">

$$
f_{X}(x)=\left\{
\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
1 & \mbox{si } 0 < x < 1\\
0 & \mbox{si } 1\leq x
\end{array}\right.
$$

Si $x \leq 0$ entonces $\displaystyle\int_{-\infty}^x f_X(t) dt = 0.$

Si $0\leq x\leq 1$ entonces $\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^x 1 dt = x.$

Si $x\geq 1$  entonces $\displaystyle\int_{-\infty}^x f_X(t) dt = \int_0^1 1 dt = 1.$


Por lo tanto  $F_X(x)=\displaystyle\int_{-\infty}^x f_X(t) dt$ para todo $x\in\mathbb{R}.$

</div>

###  Densidad diana


<div class="example-sol">


```{r fig.align="center",  fig_caption="Función de densidad de una v.a. uniforme en el intervalo$(0,1)$"}
curve(dunif(x,0,1),xlim=c(-0.5,1.5),col="blue",
      main="Densidad de la distribución uniforme en [0,1]")
```
</div>

### Utilidad de la función de densidad

La función de densidad nos permite calcular diversas probabilidades.

<l class="prop">Propiedades de la función de densidad </l> 

Sea $X$ una v.a. continua con función de distribución $F_X$ y de
densidad $f_X$, entonces
 
* \begin{eqnarray*}
P(a< X< b) &=&  P(a<X\leq b)= P(a\leq X< b)=\\
 & & P(a\leq X\leq b)= \displaystyle\int_{a}^b f_X(x) dx.
\end{eqnarray*}

* Si $A$ es un conjunto  adecuado de $\mathbb{R}$ entonces 

$$
P(X\in A)=\displaystyle\int_{A} f(x) dx=\displaystyle\int_{A\cap D_X} f(x) dx.
$$

### Utilidad de la función de densidad

<l class="prop">Propiedades de la función de densidad </l> 

Sea $X$ una v.a. continua con función de distribución $F_X$ y de densidad $f_X$, entonces:

* Si $f_x$ es continua en un punto $x$, $F_X$ es derivable en ese punto y
$F_X'(x)=f_X(x).$
* $P(X=x)=0$ para todo $x\in\mathbb{R}.$
  

<div  class="exercise"> **Ejercicio**

Comprobar estas propiedades en el ejemplo de la diana. </div>

### Ejemplo tiempo ejecución de un proceso

<div  class="example">
**Ejemplo: Tiempo ejecución de un proceso.**

Sea $X=$ tiempo de ejecución de un proceso. Se supone que $X$ sigue una distribución uniforme en dos unidades de tiempo, si tarda más el proceso se cancela.

Calculemos la función de densidad y de distribución de la v.a $X$.

</div>

<div  class="example-sol">

Entonces

$$
F_{X}(x)=P(X\leq x)=\frac{CF}{CP}=\frac{x}2
$$


Luego su función de distribución es:

$$
F_{X}(x)=\left\{\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
\frac{x}2 & \mbox{si } 0<x<2\\
1 & \mbox{si } 2\leq x
\end{array}\right.
$$

### Ejemplo tiempo ejecución de un proceso


Su función de densidad por su lado es:
$$
f_{X}(x)=F_{X}'(x)=\left\{\begin{array}{ll}
0 & \mbox{si } x\leq 0\\
\frac12 & \mbox{si } 0<x\leq 2\\
0 & \mbox{si } 2\leq x
\end{array}\right.
$$

Efectivamente

* $f_{X}(x)\geq 0,$ y tiene un conjunto finito de discontinuidades.
* $F_X(x)=\int_{-\infty}^x f_X(t) dt.$ para todo $x\in \mathbb{R}$ <l class="exercise">(Ejercicio,
resolverlo gráficamente.)</l>
* $\int\limits_{-\infty}^{+\infty}f_{X}(x)dx=
\int\limits_0^2\frac12dx=\frac{x}2\mid_0^2=
=\frac22-\frac02=1.$

</div>

### Ejemplo tiempo ejecución de un proceso

<div  class="exercise">
**Ejercicio: Tiempo de un proceso:**

Calcular la probabilidad de que uno de nuestros procesos tarde
más de una unidad de tiempo en ser procesado. Calcular también la  probabilidad de
que dure entre $0.5$ y $1.5$ unidades de tiempo.
</div>

## Esperanza y varianza para variables aleatorias continuas

### Esperanza y varianza para variables aleatorias continuas

Los mismos comentarios y definiciones que se dieron en la sección correspondiente del tema
de estadística descriptiva son aplicables aquí.

Así que sólo daremos las definiciones, la forma de cálculo y algunos ejemplos.

En lo que sigue, salvo que diagamos lo contrario,  $X$  es una v.a. continua con función de densidad $f_{X}(x)$



### Esperanza y varianza para variables aleatorias continuas

<l class="definition"> Esperanza v.a. continuas </l>

* Su esperanza es:
$$E(X)=\displaystyle\int\limits_{-\infty}^{+\infty} xf_{X}(x)dx.$$
* Si $g(x)$ es una función de la variable $X$ entonces:
$$E(g(X))=\displaystyle\int\limits_{-\infty}^{+\infty} g(x)\cdot f_{X}(x)dx.$$

### Esperanza y varianza para variables aleatorias continuas

<l class="definition"> Varianza v.a. continuas </l>


* Su varianza es:
$$
Var(X)=\sigma_{X}^2=E((X-\mu_{X})^2)=
\displaystyle\int\limits_{-\infty}^{+\infty} (x-\mu_{X})^2 f_{X}(x)dx.
$$
* Su desviación típica es:  $$\sigma_{X}=+\sqrt{\sigma_{X}^2}.$$


### Propiedades

<l class="prop"> Propiedades </l>

* $\sigma_{X}^2\geq 0$
* $Var(cte)=E(cte^2)-(E(cte))^2= cte^2 - cte^2=0$
* $Var(x)=E(X^2)-\mu_{X}^2=\int\limits_{-\infty}^{+\infty}x^2 f_{X}(x)dx - \mu_{X}^2.$
* El mínimo de $E((X-C)^2)$ se alcanza cuando $C=E(X)$ y es $Var(X)$.



### Ejemplo

<div  class="example">

**Ejemplo: Dardo**

Calcular $\mu_{X}$ y $\sigma_{X}^2$ en el dardo.
</div>

<div  class="example-sol">
Resultado 
$$\mu_{X}=\frac12,$$ 
$$E(X^2)=\frac13,$$
$$Var(X)=\frac1{12}.$$

</div>


### Esperanza de trasformaciones lineales de v.a. continuas

<l class="prop"> Proposición</l>

Sea $X$ una v.a. continua con $E(X)=\mu_{X}$ y $Var(X)=\sigma_{X}^2$ sea $Y=a+b X$, donde
$a,b\in\mathbb{R}$, es una nueva v.a. continua obtenida mediante una transformación lineal de $X$.
Se verifican las mismas propiedades que en el caso discreto:

* $E(Y)=E(a+b X)=a+b E(X)$
* $Var(Y)=Var(a+b X)=b^2 Var(X)$
* $\sigma_{Y}=|b| \sigma_{X}$
* $Z=\frac{X-\mu_{X}}{\sigma_{X}}$ es una transformación
lineal de $X$ de forma que
$$E(Z)=0 \mbox{ y } Var(Z)=1$$





### Ejemplo

<div class="example"> 
**Ejemplo**

En una empresa de venta de vinos por internet, sea
$X=$ número de  litros de vino del país vendidos en un año.
Supongamos que sabemos que $E(X)=10000$ y que $Var(X)=100$
Supongamos que los gastos fijos de distribución son
50.000 &euro; y el beneficio por litro es de 10 &euro; por botella.
Definimos $T=10 X-50000$ que será el beneficio después de gastos.
</div>

<div class="example-sol"> 

Entonces la esperanza del beneficio es 
$$E(T)=10 E(X)-50000 = 50000$$
y
$$Var(T)=10^2 Var(X)= 10000$$
</div>

## Transformaciones de variables aleatorias


### Transformaciones de variables aleatorias

Muchas variables aleatorias son funciones de otras v.a. En lo que sigue resumiremos diversas técnicas para dada una v.a. $X$ y una
transformación $Y=h(X)$  encontrar $F_{Y}$ a
partir de $F_{X}$.


### Propiedad

<l class="prop">Tranformación de v.a. discretas </l>

Sea $X$ una v.a. discreta con $X(\Omega)=\{x_1,x_2,\ldots,x_{n},..\}$ y sea $h:\mathbb{R}\to\mathbb{R}$ una aplicación.
Entonces $Y=h(X)$ es también una v.a. discreta. Además si $P_X$
y $F_{X}$ son las funciones de probabilidad y de distribución de
$X$ entonces

 
* $\displaystyle P_{Y}(y)=\sum_{x_{i}|h(x_{i})=y}P_X(x_{i}).$
* $\displaystyle F_{Y}(y)=\sum_{x_{i}|h(x_{i})\leq y} P_X(x_{i}).$

### Propiedades

Desafortunadamente para variables no discetas el asunto  no es tan sencillo como el anterior, pues la transformación de, por ejemplo, una v.a. continua puede ser continua, discreta, mixta...

<l class="prop">Transformación de v.a. continuas en continuas</l>

Sea $X$ una v.a. continua cuya función de densidad es $f_{X}$. Sea
$h:\mathbb{R}\to\mathbb{R}$ una aplicación estrictamente monótona y derivable, tal
que $h'(x)\not=0$ para todo $x\in\mathbb{R}$. Sea $Y=h(X)$ la
transformación de $X$ por $h$. Entonces $Y$ es una v.a. continua con función
de densidad

$$f_{Y}(y)=\left.\frac{f_{X}(x)}
{\left|h'(x)\right|}\right|_{x=h^{-1}(y)}$$



### Propiedades


<l class="prop"> Densidad de una transformación de una v.a. continua</l>

Sea $X$ una v.a. continua cuya función de densidad es $f_{X}$.  Sea 
$$h:\mathbb{R}\to\mathbb{R}$$ 
una aplicación, no necesariamente monótona tal que :

* sea derivable con derivada no nula
* la ecuación $h(x)=y$ tiene un número finito de soluciones
$x_1,x_2,..,x_{n}$

entonces:

$$
\displaystyle f_{Y}(y)=\left.\sum_{k=1}^{n} \frac{f_{X}(x)}
{\left|h'(x)\right|}\right|_{x=x_{k}}.
$$


### Método general del transformación de v.a.

Cuando no podamos aplicar las propiedades anteriores intentaremos
calcular primero la función de distribución de la transformación
y luego su densidad.

Notemos que en general si $Y=g(X)$ es una v.a. transformación  de la
v.a. $X$ entonces

$$
F_{Y}(y)=P(Y\leq y)=P(g(X)\leq y).
$$

### Método general del transformación de variables aleatorias


Por ejemplo si $g$ es estrictamente creciente y cont.

$$
F_{Y}(y)=P(g(X)\leq y)=P(X\leq g^{-1}(y))=F_{X}(g^{-1}(y)).
$$

y si $g$ es estrictamente decreciente y cont.
$$
F_{Y}(y)=P(g(X)\leq y)=P(X\geq g^{-1}(y))=1-F_{X}(g^{-1}(y)).
$$



## Desigualdades   básicas: Markov y Chebychev



### Desigualdades de Markov y de Chebychev

* En esta sección distintas desigualdades que acotan determinadas probabilidades de
una variable aleatoria.
* Estas desigualdades sirven en algunos casos para acotar probabilidades de determinados sucesos.
* También son útiles desde el punto de vista teórico, por ejemplo para justificar que la varianza es una mediada de la dispersión de
los datos.




### Desigualdad de Markov

<l class="prop"> Desigualdad de Markov</l>

Sea $X$ una v.a. positiva con $E(X)$ finita. Entonces 

$$P(X\geq a)\leq \frac{E(X)}{a}\mbox{ para todo }a>0.$$

<div class="dem">
**Demostración**:

Si $X$ es continua  y solo toma valores positivos

\begin{eqnarray*}
E(X) &=& \int_{-\infty}^{+\infty} x f_{X}(x) dx=  \int_0^{+\infty} x f_{X}(x) dx=  \int_0^{a} x f_{X}(x) dx +\int_{a}^{+\infty} x f_{X}(x) dx \\
& &\geq   \int_{a}^{+\infty} x
f_{X}(x) dx \geq a \int_{a}^{+\infty}
f_{X}(x) dx = a \cdot  P(X\geq a)
\end{eqnarray*}.

de donde se sigue que 

$$P(X\geq a)\leq \frac{E(X)}{a}.$$

</div> 

### Desigualdad  de Markov

<l class="prop"> Corolario</l>

Sea $X$ una v.a. con $E(X)$ finita entonces  para todo $a>0$

$$P(|X|\geq a )\leq \frac{E(|X|)}{a}.$$
<div class="exercise">
**Ejercicio**

Demuestra el corolario anterior a partir de la desigualdad de Markov.
</div>

### Desigualdad de Chebychev


La desigualdad de Chebychev también se denomina  de Chebyshov y en inglés Chebyshev.

<l class="prop"> Desigualdad de Chebychev</l>

Sea  $X$ una v.a.con $E(X)=\mu$ y $Var(X)=\sigma^2$  entonces para todo $a>0$

$$P(|X-\mu|\geq a)\leq \frac{\sigma^2}{a^2}$$ 

### Demostración desigualdad de Chebychev

<div class="dem"> **Demostración**

Apliquemos la consecuencia de la desigualdad de Markov a la v.a.
no negativa 

$$Y^2=(X-\mu)^2$$

entonces

$$
P(Y^2\geq a^2) \leq 
\frac{E(Y^2)}{a^2}=\frac{E((X-\mu)^2)}{a^2}
= \frac{Var(X)}{a^2}=\frac{\sigma^2}{a^2}
.
$$




Por otra parte

$$
P(Y^2\geq a^2)=P(|Y|\geq a)= P(|X-\mu|\geq a).
$$

hecho que, junto con la desigualdad anterior,
demuestra el resultado.

</div>


### Uso de la desigualdad de Chebychev

<l class="observ"> **Utilidad básica de la desigualdad de Chebychev**</l>

Supongamos que $X$ es una v.a. con $Var(X)=0$
entonces.


Aplicando la desigualdad anterior

$$P(|X-E(X)|\geq a )=0\mbox{ para todo }a>0$$ 
lo que implica que

$$P(X=E(X))=1.$$

Por lo que  probabilidad de que $X$ sea
constantemente $E(X)$ es 1.

Lo que nos confirma la utilidad de la varianza es una
medida de la dispersión de los datos.



### Ejemplo

<div class="example">
**Ejemplo**

Se sabe que el tiempo de respuesta medio y la desviación típica de un sistema multiusuario  son 15 y 3 u.t.respectivamente. Entonces:

$$
P(|X-15|\geq 5)\leq \frac9{25}=0.36.
$$

</div>

Si substituimos $a$ por $a\cdot \sigma$ en la
desigualdad de Chebychev, nos queda:

$$
P(|X-\mu|\geq a \sigma)\leq
\frac{\sigma^2}{(a\sigma)^2}=\frac1{a^2}.
$$

Que es otra manera de expresar la desigualdad de Chebychev.


### Más formas de la desgualdad de Chebychev

La desigualdad de Chebychev también se puede escribir de al menos dos maneras más:

$$
P(\mu-a\leq X\leq \mu+a)\geq 1-\frac{\sigma^2}{a^2}
$$


y tomado como $a=k\cdot \sigma$

$$
P(\mu-k\cdot \sigma\leq X\leq \mu+ k \cdot \sigma)\geq 1-\frac1{k^2}
$$


### La varianza como medida de dispersión

Tomando la segunda expresión que hemos visto para la desigualdad de
Chebychev para distintos valores de $k>0$ tenemos la siguiente tabla.

<center>
| k | $P(|X-E(X)|\geq k  \cdot \sigma)$|
|---|---|
| 1 | $\leq 1$ |
| 2 | $\leq 0.25$ |
| 3 | $\leq 0.111$ |
| 4 | $\leq 0.0025$ |
</center>

### Interpretación de la desigualdad

* Por ejemplo para $k=2$ esta desigualdad se puede interpretar como que dada una v.a. $X$ con cualquier distribución que tenga $E(X)$ y $Var(X)$ finitos *la  probabilidad de que un valor se aleje de la media $\mu$ más de $a=2$ desviaciones típicas es menor o igual que $0.25$*.

* Es decir sólo el 25\% de los valores estarán alejados de la media
más de $2\sigma$

¡*Sea cual sea la distribución de la v.a.*!





<!--chapter:end:2.Rmd-->

# Distribuciones Notables

* En este tema estudiaremos diversos tipos de experimentos que son muy frecuentes y algunas de las variables aleatorias asociadas a ellos. 

* Estas variables reciben distintos nombres que aplicaremos sin distinción al tipo de población del experimento a la variable o a su función de probabilidad, densidad o distribución.

* Empezaremos con las variables aleatorias discretas que se presentan con frecuencia ya que están relacionadas con situaciones muy comunes como el número de caras en varios lanzamiento de una moneda, el número de veces que una maquina funciona hasta que se estropea, el numero de clientes en una cola,...


## Distribución Bernoulli 

<l class="definition"> Distribución Bernoulli </l>

* Consideremos un experimento con dos resultados posibles éxito (E) y
fracaso (F). El espacio de sucesos será $\Omega=\{E,F\}$.
* Supongamos que la probabilidad de éxito es  $P(E)=p$,  y naturalmente $P(F)=1-p=q$ con $0<p<1$.
* Consideremos la  aplicación 

$$
X:\Omega=\{E,F\}\to \mathbb{R}
$$

definida por

$$
X(E)=1\mbox{, }X(F)=0.
$$

Su  función de probabilidad es

$$
P_{X}(x)=
\left\{
\begin{array}{ll} 1-p=q & \mbox{si } x=0\\
p & \mbox{si } x=1\\
0 & \mbox{en cualquier otro caso}
\end{array}
\right..
$$

Su función de distribución es 

$$
F_{X}(x)=P(X\leq x)=
\left\{
\begin{array}{ll} 
0 & \mbox{si } x<0\\
1-p=q & \mbox{si } 0\leq x <1\\
1 & \mbox{si } 1\leq x \\
\end{array}
\right..
$$

* Bajo estas condiciones diremos que $X$  **es una v.a. Bernoulli** o que  sigue una ley de  **distribución de probabilidad  Bernoulli** de parámetro $p$.
* Lo denotaremos por
$$X\equiv Ber(p)\mbox{ o también } X\equiv B(1,p).$$
* A este tipo de  experimentos (éxito/fracaso)se les denomina experimentos Bernoulli.
* Fue su descubridor un científico suizo  [Jacob Bernoulli](https://es.wikipedia.org/wiki/Jakob_Bernoulli),  uno más de la de la conocida [familia de científicos suizos Bernoulli](https://es.wikipedia.org/wiki/Familia_Bernoulli)

### Esperanza de una v.a. $X$  $Ber(p)$

Su **valor esperado** es 

$$E(X)=\displaystyle\sum_{x=0}^1 x\cdot P(X=x)= 0\cdot(1-p)+1\cdot p=p.$$



Calculemos también $E(X^2)$

$$E(X^2)=\displaystyle\sum_{x=0}^1 x^2\cdot P(X=x)= 0^2\cdot(1-p)+1^2\cdot p=p.$$

### Varianza de una v.a. $X$  $Ber(p)$


Su  **varianza** es 

$$Var(X)=E(X^2)-\left(E(X)\right)^2=p-p^2=p\cdot (1-p)=p\cdot q.$$


Su desviación típica es 

$$
\sqrt{Var(X)}=\sqrt{p \cdot (1-p)}.
$$

### Resumen v.a con distribución Bernoulli


$X$  Bernoulli | $Ber(p)$
----------:|:--------
$D_X=$ | $\{0,1\}$
$P_X(x)=P(X=x)=$ |  $\left\{\begin{array}{ll} q & \mbox{si } x=0\\ p & \mbox{si } x=1\\0 & \mbox{en otro caso}\end{array}\right.$ 
$F_X(x)=P(X\leq X)=$ | $\left\{\begin{array}{ll} 0 & \mbox{ si } x<0\\q & \mbox{ si } 0\leq x<1\\1 & \mbox{ si } 1\leq x \end{array}\right.$
$E(X)=p$ | $Var(X)=p\cdot q$



### Distribución Bernoulli. Ejemplo

Veamos los cálculos básicos $Ber(p=0.25)$ en `R`.

```{r binomialfunciones}
dbinom(0,size=1,prob=0.25)
dbinom(1,size=1,prob=0.25)
rbinom(n=20,size = 1,prob=0.25)
```

### Distribución Bernoulli. Ejemplo


El siguiente código dibuja las función de probabilidad y la de distribución de una  $Ber(p=0.25)$

```{r eval=FALSE}
par(mfrow=c(1,2))
plot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=0.25),
     ylim=c(0,1),xlim=c(-1,2),xlab="x",
     main="Función de probabilidad\n Ber(p=0.25)")
lines(x=c(0,0,1,1),y=c(0,0.75,0,0.25), type = "h", lty = 2,col="blue")
curve(pbinom(x,size=1,prob=0.25),
      xlim=c(-1,2),col="blue",
      main="Función de distribución\n Ber(p=0.25)")
par(mfrow=c(1,1))
```


### Distribución Bernoulli. Ejemplo

```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
plot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=0.25),
     ylim=c(0,1),xlim=c(-1,2),xlab="x",
     main="Función de probabilidad\n Ber(p=0.25)")
lines(x=c(0,0,1,1),y=c(0,0.75,0,0.25), type = "h", lty = 2,col="blue")
curve(pbinom(x,size=1,prob=0.25),
      xlim=c(-1,2),col="blue",
      main="Función de distribución\n Ber(p=0.25)")
par(mfrow=c(1,1))
```

### Gráficas interactivas $Ber(p)$

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r echo = TRUE,eval=FALSE}

sliderInput("p_ber", label = "Probabilidad éxito p:",
              min = 0.01, max = 0.99, value = 0.25, step = 0.01)

renderPlot({
par(mfrow=c(1,2))
  p=input$p_ber
plot(x=c(0,1),y=dbinom(c(0,1),size=1,prob=p),
     ylim=c(0,1),xlim=c(-0.5,2),xlab="x",pch=21,
     main=paste0(c("Función de probabilidad\n
                   Ber(p=",p,")"),collapse=""),bg="black")
segments(x0=0,y0=0,x1=0,y1=1-p, col = "blue", lty =2)
segments(x0=1,y0=0,x1=1,y1=p, col = "blue", lty =2)
segments(x0=-1,y0=1-p,x1=0,y1=1-p, col = "blue", lty =2)
segments(x0=-1,y0=p,x1=1,y1=p, col = "blue", lty =2)
x=0:1
y=pbinom(x,size=1,prob=p)
curve(pbinom(x,size=1,prob=p),
      xlim=c(-1,2),col="blue",
      main=paste0(c("Función de distribución\n Ber(p=",p,")"),collapse="")
      )

par(mfrow=c(1,1))
})
```

[![](Images/noshinyImages/interactiva_ber1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)

## Distribución binomial

<l class=definition> Distribución binomial </l>

Si repetimos $n$ veces de forma independiente un experimento Bernoulli de parámetro $p$.

El espacio muestral $\Omega$ estará formado por cadenas de $E$'s y $F$'s de longitud $n$
Consideremos la v.a.

$$X(\overbrace{EFFF\ldots EEF}^{n})=\mbox{número de éxitos en la cadena}.$$

### Función de probabilidad de una  binomial

Entonces su **función de probabilidad** es 

$$
P_{X}(x)=\left\{
\begin{array}{ll}
{n\choose x}\cdot  p^x \cdot(1-p)^{n-x} &\mbox{ si } x=0,1,\ldots,n\\
0  & \mbox{ en otro caso}
\end{array}\right..
$$

### Función de distribución de binomial

Su **función de distribución** no tiene una fórmula cerrada. Hay que acumular la función de probabilidad:

$$
\begin{eqnarray*}
F_{X}(x)=P(X\leq x) & = & \sum_{i=0}^x P_X(i)\\
& = & 
\left\{
\begin{array}{ll}
0 & \mbox{ si } x\leq 0\\\displaystyle
\sum_{i=0}^k {n\choose i}\cdot  p^i \cdot (1-p)^{n-i} & \mbox{ si } 
\left\{
  \begin{array}{l} 
  k\leq x< k+1\\
  k=0,1,\ldots,n.
  \end{array}
\right.\\
1 & \mbox{ si } n\leq x
\end{array}
\right..
\end{eqnarray*}
$$


### Números binomiales con R

Los números binomiales alculan el número de equipos de baloncestodistintos que  ($k=5$ jugadores) se pueden hacer con 6 jugadores ($n=6$).

Es decir cuántas  manearas distintas hay para elegir (*choose*) 5 jugadores en un conjunto de 6 jugadores. Todo el mundo diría 
¡¡¡6!!!. Efectivamente con R es 

```{r}
choose(6,5)
```

Con 10 jugadores  el número de equipos de  5 distintos es bastante más grande

```{r}
choose(10,5)
```

Y por ejemplo con un equipo de fútbol profesional  que tiene en plantilla 22 jugadores  (quitando los guardametas) se pueden formar ¡¡nada menos que!!

```{r}
choose(22,10)
```
un bonito número capicúa que nos da el número de equipos distintos que se pueden formar.

###  Distribución Binomial

En las anteriores circunstancias diremos que la v.a. sigue una **ley de probabilidad binomial** ... con parámetros $n$ y $p$ y lo denotaremos así 
    
$$X\equiv B(n,p).$$ 
    
Obviamente se tiene que una bernoulli es una binomial con $n=1$

$$B(1,p)=Ber(p).$$

<div class="exercise"> 
**Ejercicio**

Calculad las funciones de distribución de una binomial $B(n=1,p=0.3)$ y comprobar que coinciden con  las distribuciones de una $Ber(p=0.3)$.
</div>

### Observaciones sobre la distribución binomial

* La probabilidad de fracaso se suele denotar con  $q=1-p$, **sin ningún aviso adicional**, con el fin de acortar  y agilizar la escritura de las  fórmulas.
* Su **función de distribución no tienen una formula general**, hay que calcularla con una función de R o python... En el siglo pasado se tabulaban en los libros de papel :-).
* En el material adicional os pondremos unas tablas de esta distribución
para distintos valores de $n$ y $p$ para que disfrutéis de tan ancestral método de cálculo. 
* Cualquier paquete estadístico, hoja de cálculo dispone de
funciones para el cálculo de estas probabilidades, así que el **uso de las tablas** queda **totalmente anticuado**. 

### Esperanza  de una $X$  $B(n,p)$

Su **esperanza** es 
$$E(X)=\displaystyle\sum_{k=0}^n k \cdot  {n \choose k }\cdot p^k\cdot q^{n-k} = n\cdot p.$$

La esperanza de $X^2$ es 

$$
\begin{eqnarray*}
E(X^2)&=& \displaystyle\sum_{k=0}^n k^2 \cdot  {n \choose k }\cdot p^k\cdot q^{n-k}\\
&=& n\cdot p\cdot q-(n\cdot p)^2.
\end{eqnarray*}
$$

### Varianza de una $X$  $B(n,p)$

Su **varianza** es 

 $$Var(X)=E(X^2)-\left(E(X)\right)^2=n\cdot p \cdot q=n\cdot p\cdot (1-p).$$

Su desviación  típica es
 
 $$\sqrt{n\cdot p\cdot q}=\sqrt{n\cdot p\cdot (1-p)}.$$
 
 
En otos temas veremos una forma sencilla del cálculo de la esperanza y varianza de una $B(n,p)$ como las suma de n $Ber(p)$ independientes.

<div class="exercise">
**Ejercicio**

Justificar de forma intuitiva que si $X_i$ con $i=1,2,\ldots, n$ son v.a. $Ber(p)$ independientes  entonces $X=\displaystyle\sum_{i=1}^n X_i$    sigue una distribuciń $B(n,p).$ 
</div>



### Resumen v.a con distribución binomial $B(n,p)$

$X$ binomial | $B(n,p)$ 
-------------:|:--------
$D_X=$ |  $\{0,1,\ldots n\}$ 
$P_X(x)=P(X=x)=$ |$\left\{\begin{array}{ll}{n\choose x}\cdot  p^x\cdot  (1-p)^{n-x} & \mbox{ si } x=0,1,\ldots,n\\0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ | no tiene fórmula (utilizad funciones de R o python)
$E(X)=$ |  $n\cdot p$
$Var(X)=$ | $n\cdot p \cdot (1-p)$

### Cálculos binomial con R

Veamos los cálculos básicos con funciones de R para una v.a $X$ con distribución  binomial  $B(n=10,p=0.25)$. 

Si queremos calcular con R algún valor de la función de distribución como por ejemplo $F_X(0)=P(X\leq 0)$ 

```{r binomialfuncionesA}
pbinom(0,size=10,prob=0.25)
```

y si queremos por ejemplo $F_X(4)=P(X\leq 4)$:

```{r}
pbinom(4,size=10,prob=0.25)
```

### Cálculos binomial con R

Sin embargo, si queremos calcular algún valor de la función de probabilidad como por ejemplo $P(X=0)$:

```{r binomialfunciones2A_dbinom}
dbinom(0,size=10,prob=0.25)
```

o por ejemplo para  $P(X=4)$:

```{r}
dbinom(4,size=10,prob=0.25)
```

### Generación de muestras aleatorias con R

Generaremos una muestra aleatoria  de  100 valores  de una población $B(20,0.5)$

```{r semilla_binomial}
set.seed(2019)
rbinom(100,size = 20,prob=0.5)
```

<div class="example"> 
**Ejemplo**

El ejemplo anterior correspondería a repetir 100 veces el experimento lanzar una moneda  20 veces y contar el número de caras.
</div>

###  Cálculos distribución binomial con python

Veamos los cálculos básicos con funciones de python para una v.a $X$ con distribución  binomial  $B(n=10,p=0.25)$.

Primero importamos la  función `binom` de la librería `scipy.stat`

```{python binomialfunciones2A_python}
from scipy.stats import binom
```

En general en el paquete `scipy`, la función de probabilidad se invocará con el método `pmf`, la de distribución con el método `cdf` mientras que una muestra aleatoria que siga esta distribución con el método `rvs`. En todos ellos aparecerá siempre el parámetro `loc` que se utiliza para desplazar el dominio de la variable aleatoria. Por ejemplo, en este caso 

```{python eval=F}
binom.pmf(k, n, p, loc) =  binom.pmf(k - loc, n, p)
```

###  Cálculos distribución binomial con python

Para calcular los valores de la función de distribución como por ejemplo $F_X(0)=P(X\leq 0)$ y $F_X(4)=P(X\leq 4)$ utilizamos la función `cdf`

```{python bino3_py}
binom.cdf(0,n=10,p=0.25)
binom.cdf(4,n=10,p=0.25)
```

Notemos que al no indicar el valor de `loc`, se le asume que toma el valor 0.

###  Cálculos distribución binomial con python

Para calcular los valores de la función de probabilidad $P(X=0)$ y $P(X=4)$ utilizamos la función `pmf`:

```{python bino4_py_2}
binom.pmf(0,n=10,p=0.25)
binom.pmf(4,n=10,p=0.25)
```

Notemos que al no indicar el valor de `loc`, se le asume que toma el valor 0.

###  Cálculos distribución binomial con python

Si queremos generar una muestras aleatorias que siga una distribución binomial, podemos usar la función `rvs`. En este caso, generaremos una muestra aleatoria  de  100 valores  de una población $B(20,0.5)$

```{python bino4_py_3}
binom.rvs(n=20,p=0.25,size = 100)
```

###  Cálculos distribución binomial con python

<l class="observ"> Observación</l>
Notemos que la secuencia aleatoria generada no es la misma que con R. De hecho si volvemos a ejecutar esta función obtendremos una muestra aleatoria distinta.


```{python bino4_py}
binom.rvs(n=20,p=0.25,size = 100)
```
</div>


### Cálculos binomial con python

Veamos algunos cálculos básicos con funciones de python para la binomial  $B(n=10,p=0.25)$.

```{python binomialfunciones2A_python2}
binom.cdf(5,n=10,p=0.25)
binom.pmf(1,n=10,p=0.25)
binom.rvs(n=20,p=0.25,size=10)
```

### Gráficas de la distribución binomial con R 

El siguiente código de R dibuja las función de probabilidad y la de distribución de una  $B(n=10,p=0.25)$


```{r fig.align='center',echo=TRUE,eval=FALSE}
par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dbinom(c(0:10),size=10,prob=0.25)
plot(x=c(0:10),y=dbinom(c(0:10),size=10,prob=0.25),
  ylim=c(0,1),xlim=c(-1,11),xlab="x",
  main="Función de probabilidad\n B(n=10,p=0.25)")
lines(x=rep(0:10,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(pbinom(x,size=10,prob=0.25),
  xlim=c(-1,11),col="blue",
  main="Función de distribución\n B(n=10,p=0.25)")
par(mfrow=c(1,1))
```


### Gráficas de la distribución binomial con R 

El siguiente código de R dibuja las función de probabilidad y la de distribución de una  $B(n=10,p=0.25)$


```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dbinom(c(0:10),size=10,prob=0.25)
plot(x=c(0:10),y=dbinom(c(0:10),size=10,prob=0.25),
  ylim=c(0,1),xlim=c(-1,11),xlab="x",
  main="Función de probabilidad\n B(n=10,p=0.25)")
lines(x=rep(0:10,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(pbinom(x,size=10,prob=0.25),
  xlim=c(-1,11),col="blue",
  main="Función de distribución\n B(n=10,p=0.25)")
par(mfrow=c(1,1))
```

### Gráficas interactivas binomial

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r echo = TRUE,eval=FALSE}

fluidPage(
fluidRow(
  column(6,
         sliderInput("n_binom", label = "Número de repeticiones n:",
              min = 1, max = 50, value =10 , step = 1)),
  column(6,
          sliderInput("p_binom", label = "Probabilidad éxito p:",
                     min = 0.01, max = 0.99, value = 0.25, step = 0.01)
         )
  )
)

renderPlot({
  n=input$n_binom
  pr=input$p_binom
  
  par(mfrow=c(1,2))
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dbinom(c(0:n),size=n,prob=pr)
  plot(x=c(0:n),y=dbinom(c(0:n),size=n,prob=pr),
       ylim=c(0,1),xlim=c(-1,n+1),xlab="x",
       main=paste0(c("Función de probabilidad\n B(n=",n,",p=",pr,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux, type = "h", lty = 2,col="blue")
  curve(pbinom(x,size=n,p=pr),
        xlim=c(-1,n+1),col="blue",
        main=paste0(c("Función de distribución\n B(n=",n,",p=",pr,")"),
                    collapse = ""))
        par(mfrow=c(1,1))
})

```

[![](Images/noshinyImages/interactiva_bino1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)

### Gráficos de la distribución binomial con python

<div class="exercise">
**Ejercicio**

Buscad en la documentación de python cómo se dibuja la función de probabilidad y de distribución de una binomial y recread los gráficos anteriores.
</div>

<div class="exercise-sol">
Pista: Necesitaremos investigar más librerías:

```{python}
import numpy as np
import matplotlib.pyplot as plt
```
</div>

### Gráficos de la distribución binomial con python

```{python dibu_python1,eval=FALSE}
n, p = 10, 0.25
x = np.arange(binom.ppf(0.01, n, p),binom.ppf(0.99, n, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')
ax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, binom.cdf(x, n, p), 'bo', ms=8, label='binom pmf')
ax.vlines(x, 0, binom.cdf(x, n, p), colors='b', lw=5, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle('Distribucion Binomial')
plt.show()
```




### Gráficos de la distribución binomial con python

<div class="center"> 

```{python dibu_python2,echo=FALSE}
n, p = 10, 0.25
x = np.arange(binom.ppf(0.01, n, p),binom.ppf(0.99, n, p))

fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
_=ax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')
_=ax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5) 
  
ax = fig.add_subplot(1,2,2)
_=ax.plot(x, binom.cdf(x, n, p), 'bo', ms=8, label='binom pmf')
_=ax.vlines(x, 0, binom.cdf(x, n, p), colors='b', lw=5, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
_=fig.suptitle('Distribucion Binomial')
plt.show()
```
</div>



### Ejemplo distribución binomial

<div class="example">
**Ejemplo: Número de bolas rojas extraídas  de urna con reposición.**


Tenemos una urna con $100$ bolas de las cuales 40 son rojas  y 60  blancas. Extraemos al azar una bola, anotamos su color y  la devolvemos a (reponemos en ) la urna.

Supongamos que repetimos este proceso $n=10$; reponiendo en cada ocasión la bola extraída. 

Consideremos la variable aleatoria $X=$ número de bolas rojas extraídas (con reposición)  en $n=10$ repeticiones del mismo experimento Bernoulli.


Bajo estas condiciones tenemos que  repetimos $n=10$ veces el mismo experimento Bernouilli con probabilidad de éxito (sacar bola roja) es 

$$P(Roja)=P(Éxito)=p=\frac{40}{100}=0.4.$$

Así que la variable $X=$"número de bolas rojas extraídas de la urna (con reposición) en $n=10$ ocasiones sigue una ley binomial  $B(n=10,p=0.4).$
</div>

### Ejemplo $B(n=10,p=0.4).$
<div class="example">
Nos preguntamos:

1. ¿Cuál es la probabilidad de que saquemos exactamente $4$ rojas?
2. ¿Cuál es la probabilidad de que saquemos al menos  $4$ rojas?
3. ¿Cuál es la probabilidad de que saquemos  menos de $3$ rojas?
4. ¿Cuál es el valor esperado del número de bolas rojas?
5. ¿Cuál es la desviación típica  del número de bolas rojas?

</div>

### Ejemplo $B(n=10,p=0.4).$

<div class="example-sol">
 
**Solución 1**. ¿Cuál es la probabilidad de que saquemos exactamente $4$ rojas?

Utilizando al función de probabilidad  tenemos que 

$$
\begin{eqnarray*}
P_x(X=4)&=&{10\choose 4}\cdot 0.4^4\cdot (1-0.4)^{10-4}
= \frac{10!}{(10-4)!\cdot 4!}\cdot 0.4^4\cdot 0.6^6\\
&=& \frac{7\cdot 8\cdot 9\cdot 10}{1\cdot 2\cdot 3\cdot 4}\cdot 0.4^4\cdot 0.6^6=`r round(choose(10,4)* 0.4^4*0.6^6,7)`
\end{eqnarray*}
.
$$


Con R

```{r}
dbinom(4,size=10,prob = 0.4)
```

</div>


### Ejemplo $B(n=10,p=0.4).$

<div class="example-sol">
**Solución 2**.  ¿Cuál es la probabilidad de que saquemos al menos  $4$ rojas?

Al menos 4 rojas es $P(X \geq  4)=1-P(X<4)=1-P(x\leq 3).$

Así que calculemos $P(X\leq 3)$

$$
\begin{eqnarray*}
P(x\leq 3)&=& P(X=0)+P(X=1)+P(X=2)+P(X=3)\\
&=& 
 {10\choose 0}\cdot 0.4^0\cdot (1-0.4)^{10-0}+ {10\choose 1}\cdot 0.4^1\cdot (1-0.4)^{10-1}\\
&+&{10\choose 2}\cdot 0.4^2\cdot (1-0.4)^{10-2}+ {10\choose 3}\cdot 0.4^3\cdot (1-0.4)^{10-3}\\
&=&`r round(pbinom(3,10,0.4),7)`
\end{eqnarray*}
.
$$

</div>


### Ejemplo $B(n=10,p=0.4).$
<div class="example-sol">
Con R

```{r}
pbinom(3,10,0.4)
```


Así que

$$P(X \geq 4 )=1-P(x< 4)=P(X\leq 3)=1-`r round(pbinom(3,10,0.4),7)`=`r round(1-pbinom(3,10,0.4),7)`.$$

</div>

### Ejemplo $B(n=10,p=0.4).$

<div class="example-sol">
O con R también

```{r}
1-pbinom(3,10,0.4)
```

Aunque en estos casos el parámetro `lower.tail = FALSE` es sin duda nuestra mejor opción: 

```{r}
pbinom(3,10,0.4,lower.tail = FALSE)
```

</div>

### Ejemplo $B(n=10,p=0.4).$
<div class="example-sol">

**Solución 3**.  ¿Cuál es la probabilidad de que saquemos  menos  de $3$ rojas?

$$
\begin{eqnarray*}
P(x< 3)&=& P(X\leq 2)=  P(X=0)+P(X=1)+P(X=2)\\
&=& 
{10\choose 0}\cdot 0.4^0\cdot (1-0.4)^{10-0}+ {10\choose 1}\cdot 0.4^1\cdot (1-0.4)^{10-1}\\
&+&
{10\choose 2}\cdot 0.4^2\cdot (1-0.4)^{10-2}\\
&=&`r round(pbinom(2,10,0.4),7)`
\end{eqnarray*}
.
$$


```{r}
dbinom(0,10,0.4)+dbinom(1,10,0.4)+dbinom(2,10,0.4)
pbinom(2,10,0.4)
```

</div>

### Ejemplo $B(n=10,p=0.4).$

<div class="example-sol">

**Solución 4**. ¿Cuál es el valor esperado del número de bolas rojas?

Como  $X$ es una $B(n=10,p=0.4)$ sabemos que 

$$E(X)=n\cdot p = 10\cdot 0.4=`r 10*0.4`.$$

Aunque en python tenemos la función stats que nos lo calcula directamente:

```{python}
print("E(X) = {m}".format(m=binom.stats(n = 10, p = 0.4, moments='m')))
```

</div>

### Ejemplo $B(n=10,p=0.4).$

<div class="example-sol">
**Solución 5**. ¿Cuál es la desviación típica  del número de bolas rojas?


La varianza es 

$$
Var(X)=n\cdot p \cdot(1-p)=10\cdot 0.4\cdot 0.6=`r 10*0.4*0.6`.
$$


Por lo  tanto la desviación típica es 

$$\sqrt{Var(X)}=\sqrt{`r 10*0.4*0.6`}= `r sqrt(10*0.4*0.6)`.$$

Aunque en python tenemos la función stats que nos lo calcula directamente:

```{python}
print("Var(X) = {v}".format(v=binom.stats(n = 10, p = 0.4, moments='v')))
```

</div>




## Distribución geométrica


### Distribución geométrica

* Todos hemos jugado a, por ejemplo, tirar una moneda hasta que obtengamos la primera cara.

* O también tirar una pelota a una canasta de baloncesto hasta obtener la primer la canasta.

* Desde otro punto de vista también podemos intentar modelar el número de veces que accionamos una interruptor  y la bombilla se ilumina  hasta que falla. 

* O también el número de veces que un cajero automático nos da dinero hasta que falla.

La **modelización de este tipo de problemas se consigue con la  llamada distribución geométrica**.


### Distribución geométrica


<l class="definition"> Distribución geométrica </l>

* Repitamos un experimento Bernoulli, de parámetro p, de forma independiente hasta obtener el primer éxito.
* Sea $X$ la v.a. que cuenta el número de fracasos antes del primer éxito. Por ejemplo  que  hayamos tenido  $x$ fracasos  será una cadena de $x$ fracasos culminada con un éxito. Más concretamente 

$$P(\overbrace{FFF\ldots F}^{x}E)=P(F)^{x}\cdot P(E)=(1-p)^{x}\cdot p=q^{x}\cdot p.$$


### Distribución geométrica

Su función de probabilidad es 

$$
P_X(x)=P(X=x)=\left\{\begin{array}{ll}
(1-p)^{x}\cdot p & \mbox{ si } x=0,1,2,\ldots\\
0 &\mbox{ en otro caso}
\end{array}\right..
$$




* De una v.a. como esta diremos que sigue una
distribución geométrica de parámetro $p$.
* La  denotaremos por $Ge(p)$. 
* Su dominio es  $D_X=\{0,1,2,\ldots\}$.


### Función de distribución geométrica

Calculemos P($X\leq 3$).

Por la propiedad de la probabilidad del suceso complementario tenemos que

$$
P(X\leq 3 )=1-P(X> 3)=1-P(X\geq 4)
$$

 Efectivamente, el  evento  tenemos que $X\leq 3$  es que hemos fracasado más de tres veces hasta conseguir el primer éxito; es decir **hemos fracasado 4 o más veces**, por lo tanto 


$$
\{X>3\}=\{X\geq 4\}= \{FFFF\}
$$

### Función de distribución geométrica

Ahora, al  ser los intentos sucesos independientes, tenemos que:

$$
\begin{eqnarray*}
P(X>3) & = & P(\{FFFF\})= P(F)\cdot P(F)\cdot P(F)\cdot P(F)\\
&=& (1-p)\cdot (1-p)\cdot (1-p)\cdot (1-p)= (1-p)^{3+1}\\\
&=&(1-p)^{4}.
\end{eqnarray*}
$$


Calculamos 

$$F_X(3)=P(X\leq 3)=1-P(X>3)=1-(1-p)^{3+1}.$$

Por lo que podemos generalizar a cualquier entero positivo $k=0,1,2,\ldots$  

$$F_X(k)=P(X\leq k)=1-(1-p)^{k+1}\mbox{ si } k=0,1,2,\ldots$$

### Función de distribución geométrica


En general  tendremos que 


$$
F_X(x)=P(X\leq x)=
\left\{\begin{array}{ll} 
0 & \mbox{ si } x<0\\
1- (1-p)  & \mbox{ si } k=0\leq x <1\\
1- (1-p)^2 & \mbox{ si } k=1\leq x <2\\
1- (1-p)^3 & \mbox{ si } k=2\leq x <3\\
1- (1-p)^{k+1} & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1\\\mbox{para } k=0,1,2,\ldots\end{array}
    \right.\end{array}\right.
$$



### Función de distribución geométrica

De forma más compacta tendremos que 



$$
F_X(x)=P(X\leq x)=
\left\{\begin{array}{ll} 
0 & \mbox{ si } x<0\\
1- (1-p)^{k+1} & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1\\\mbox{para } k=0,1,2,\ldots\end{array}
    \right.\end{array}
    \right.
$$

Notemos que si $k=0,1,2,\ldots$ el límite de la función de distribución es 

$$
\displaystyle\lim_{k\to +\infty } F_X(k)=\lim_{k\to +\infty } 1-(1-p)^{k+1}=
1
$$

ya que $0<1-p<1$.


### Sumas derivadas series geométricas 
Recordemos del tema de variables aleatorias que 

<l class="prop">Propiedades</l>


* Si $|r|<1$  también son convergentes las derivadas, respecto de $r$, de la serie geométrica y convergen a la derivada correspondiente. Así tenemos que
$$
\begin{eqnarray*}
\left(\sum_{k=0}^{+\infty} r^k\right)'&= & \sum_{k=1}^{+\infty}k\cdot
r^{k-1} &=& \left(\frac1{1-r}\right)'=\frac1{(1-r)^2}\\
\left(\sum_{k=0}^{+\infty} r^k\right)^{''}&=& \sum_{k=2}^{+\infty}k \cdot(k-1)\cdot
r^{k-2}&=&\left(\frac1{1-r}\right)^{''}=\frac2{(1-r)^3}
\end{eqnarray*}.
$$


### Esperanza de una v.a. $Ge(p)$

Recordemos que $P(X=x)=(1-p)^x\cdot p$ si $x=0,1,2,\ldots$ y aplicado la fórmula anterior con $r=1-p$

$$
\begin{eqnarray*}
E(X)&=&\sum_{x=0}^{+\infty} x\cdot P_x(x)=\sum_{x=0}^{+\infty} x\cdot (1-p)^x\cdot p=
p\cdot (1-p) \cdot \sum_{x=1}^{+\infty} x\cdot (1-p)^{x-1}\\
&=& p\cdot (1-p)\cdot \frac{1}{(1-(1-p))^2}=p\cdot (1-p)\cdot \frac{1}{p^2}=\frac{1-p}{p}
\end{eqnarray*}.
$$

### Valor $E(X^2)$ de una v.a. $Ge(p)$

$$
\begin{eqnarray*}
E(X^2)&=&\sum_{x=0}^{+\infty} x^2\cdot P_X(x)=\sum_{x=1}^{+\infty} x^2\cdot (1-p)^x\cdot p\\
&=& 
\sum_{x=1}^{+\infty} (x\cdot (x-1)+x)\cdot (1-p)^{x}\cdot p\\
&=&
\sum_{x=1}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x}\cdot p+\sum_{x=1}^{+\infty} x \cdot (1-p)^{x}\cdot p\\
&=&
(1-p)^{2}\cdot p\cdot \sum_{x=2}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x-2}\\ 
&  +&   (1-p)\cdot p\sum_{x=1}^{+\infty} x \cdot (1-p)^{x-1} = \ldots
\end{eqnarray*}.
$$

### Valor $E(X^2)$ de una v.a. $Ge(p)$

$$
\begin{eqnarray*}
E(X^2)&=&\ldots\\
&=&
(1-p)^{2}\cdot p\cdot \sum_{x=2}^{+\infty} x\cdot (x-1)\cdot (1-p)^{x-2}\\ 
&  +&   (1-p)\cdot p\sum_{x=1}^{+\infty} x \cdot (1-p)^{x-1}\\
&=&
p\cdot (1-p)^2 \frac{2}{(1-(1-p))^3}+  (1-p)\cdot p \frac{1}{(1-(1-p))^2}\\
&=&
p\cdot (1-p)^2 \frac{2}{p^3}+  (1-p)\cdot p \frac{1}{p^2}\\
&=&\frac{2\cdot (1-p)^2}{p^2}+\frac{1-p}{p}
\end{eqnarray*}.
$$



### Varianza de una v.a. $Ge(p)$


$$
\begin{eqnarray*}
Var(X)&=&E(X^2)-E(X)^2=\frac{2\cdot (1-p)^2}{p^2}+\frac{1-p}{p}-\left(\frac{1-p}{p}\right)^2\\
&=&
\frac{2\cdot (1-p)^2+p\cdot(1-p)-(1-p)^2}{p^2}=\frac{(1-p)^2+p\cdot(1-p)}{p^2}\\
&=&
\frac{1-2\cdot p + p^2+p-p^2}{p^2}\\
&=& \frac{1-p}{p^2}.
\end{eqnarray*}
$$
Y su desviación típica será

$$\sqrt{Var(X)}=\sqrt{\frac{1-p}{p^2}}.$$


### Resumen $Ge(p)$ empezando en 0

$X=$ Geométrica (empieza en $0$)  | número de fracasos  para conseguir el primer éxito
------:|:-----
$D_X=$ | $\{0,1,\ldots n,\ldots\}$ 
$P_X(x)=P(X=x)=$ |$\left\{\begin{array}{ll}(1-p)^{x}\cdot p & \mbox{ si } x=0,1,2,\ldots \\0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ | $\left\{\begin{array}{ll} 0 & \mbox{ si } x<0\\
  1- (1-p)^{k+1} & \mbox{ si } \left\{ \begin{array}{l}k\leq x< k+1\\\mbox{para } k=0,1,2,\ldots\end{array}
    \right.\end{array}\right.$ 
$E(X)=\frac{1-p}{p}$ | $Var(X)=\frac{1-p}{p^2}$

### La variable geométrica que cuenta los intentos para obtener el primer éxito.

* Supongamos que sólo estamos interesados en el **número de intentos** para obtener el primer éxito. 
* Si definimos $Y$= número de  intentos para obtener el  primer éxito. Entonces $Y=X+1$  donde $X\equiv Ge(p)$.
* Su dominio es valores es $D_Y=\{1,2,\ldots\}$ 
* la media se incrementa en un intento debido al  éxito  $E(Y)=E(X+1)=E(X)+1=\frac{1-p}{p}+1=\frac1{p}$.
* La varianza es la misma $Var(Y)=Var(X+1)=Var(X)=\frac{1-p}{p^2}$.


### Resumen $Ge(p)$ comenzando en $1$.

$Y$ geométrica  (que cuenta el éxito empieza en 1)| número de INTENTOS  para OBTENER el primer éxito
------:|:-----
$D_Y=$ |  $\{1,2,\ldots n,\ldots\}$ 
$P_Y(y)=P(Y=y)=$ |$\left\{\begin{array}{ll}(1-p)^{y-1}\cdot p & \mbox{ si } y=1,2,3,\ldots\\  0  & \mbox{ en otro caso.}\end{array}\right.$
$F_Y(y)=P(Y\leq y)=$ | $\left\{\begin{array}{ll} 0 & \mbox{ si } y<1\\ 1- (1-p)^{k} & \mbox{ si } \left\{ \begin{array}{l}k\leq y< k+1\\\mbox{para } k=1,2,3,\dots \end{array}    \right.\end{array}\right.$ 
$E(X)=\frac1{p}$ |$Var(X)=\frac{1-p}{p^2}$




### Propiedad de la falta de memoria

<l class="prop"> Propiedad de la falta  de memoria </l>

Sea $X$ una v.a. discreta con dominio $D_X=\{0,1,2,\ldots\}$, con $P(X=0)=p$.

Entonces $X$ sigue una ley $Ge(p)$ sí y sólo si

$$
P\left(X> k+j\big| X\geq j\right)=P(X> k)
$$
para todo $k,j=0,1,2,3\ldots$.

### Propiedad de la falta de memoria

<div class="dem">
**Demostración**

Si es geométrica entonces el lado derecho de la igualdad es 

$$
P(X>k)=1-P(X\leq k)=1-\left(1-(1-p)^{k+1}\right)=(1-p)^{k+1}
$$

El lado de izquierdo es



$$
\begin{eqnarray*} 
P\left(X> k+j\big| X\geq j\right)&=&\frac{P\left(\{X> k+j\}\cap \{X\geq j\} \right)}{P\left(X\geq j\right)}=
\frac{P\left(X>k+j \right)}{P\left(X\geq j \right)} = \frac{1-P(X\leq k+j)}{1-P(X\leq j-1)}\\
&=&  \frac{1-(1-(1-p)^{k+j+1})}{1-(1-(1-p)^{j-1+1})} =\frac{(1-p)^{k+j+1}}{(1-p)^{j}} = (1-p)^{k+1}
\end{eqnarray*}
$$


Lo que demuestra  la igualdad.


Para demostrar el recíproco tomemos $j=1$  y $k\geq 0$ entonces  por la propiedad de la pérdida de memoria

$$
P\left(X> k+1\big| X\geq 1\right)=P(X> k)
$$

Como sabemos  $P(X=0)=p$ tenemos $P(X \geq 1 )=1-P(X<1)=1-P(X=0)=1-p$

Luego  combinado las igualdades tenemos que

$$
P\left(X> k+1\big| X\geq 1\right)=\frac{P(X>k+1, X\geq 1)}{P(X\geq 1)}=\frac{P(X>k+1)}{P(X\geq 1)}=P(X>k).
$$
Así podemos poner que 

$$
\begin{eqnarray*}
P(X>k+1)&=&P(X\geq 1)\cdot P(X>k)=\left(1-P(X<1)\right)\cdot P(X>k)\\
&=&\left(1-P(X=0)\right)\cdot P(X>k)=(1-p)\cdot P(X>k).
\end{eqnarray*}
$$


Es decir  en general tenemos que 

$$
P(X>k+1)=(1-p)\cdot P(X>k)
$$
Del mismo modo para $j=2$

$$
P(X>k+2)=(1-p)\cdot P(X>k+1)
$$

Restando la primera igualdad de la última obtenemos. 

$$
P(X>k+1)-P(X>k+2)=(1-p)\cdot P(X>k)-(1-p)\cdot P(X>k+1)
$$

de donde operando en cada lado de la igualdad obtenemos la recurrencia

$$
[1-P(X\leq k+1)]-[1-P(X\leq k+2)]=(1-p)\cdot [P(X>k)-P(X>k+1)]
$$

Ahora operando 



$$
P(X\leq k+2)-P(X\leq k+1)=(1-p)\cdot[1-P(X\leq k)-\left(1-P(X\leq k+1)\right)]
$$
$$
P(X=k+2)=(1-p)\cdot[P(X\leq k+1)-P(X\leq k)]
$$
$$
P(X=k+2)=(1-p)\cdot P(X=k+1)
$$


De forma similar obtenemos 

$$
P(X=k+1)=(1-p)\cdot P(X=k)
$$
Utilicemos la recurrencia anterior  para calcular todas las probabilidades a partir de la $P(X=0)=p$; que vienen dadas por: 

$$
\begin{eqnarray*}
P(X=0)&=& p\\
P(X=1)&=&P(X=0+1)= (1-p)\cdot P(X=0) =(1-p)\cdot  p\\
P(X=2)&=&P(X=1+1)= (1-p)\cdot P(X=1)=(1-p)\cdot (1-p)\cdot p=(1-p)^2\cdot p\\
\ldots \ldots\ldots && \ldots  \ldots \ldots \ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\ldots\\
P(X=k)&=&P(X=(k-1)+1)= (1-p)\cdot P(X=k-1)=(1-p)\cdot (1-p)^{k-1}\cdot p=(1-p)^{k}\cdot p
\end{eqnarray*}.
$$
Lo que demuestra  el recíproco, es decir que $X$ es $Geom(p)$.
</div>



### Falta de memoria

<l class="observ"> Observación: Interpretación  de la propiedad</l>

La propiedad  de la falta de memoria

$$
P(X> k+j\big|X \geq j)=P(X > k)
$$   

la igualdad anterior significa  que aunque **ya llevemos al menos  $j$ fracasos** la probabilidad de **que fracasemos $k$ veces más** no disminuye; es la misma  que si empezáramos de nuevo el experimento. 

A este efecto se le suele etiquetar con la frase  **el experimento carece de memoria** o es un **experimento sin memoria** (*Memoryless Property*).

### Ejemplo falta de memoria

Un ejemplo muy sencillo nos aclarará el alcance de esta propiedad

<div class="exercise"> **Ejercicio: la llave que abre la puerta**

Tenemos un llavero con 10 llaves,  solo una de ellas abre una puerta. Cada vez que probamos una llave y falla olvidamos que llave hemos probado. ¿Cuál es la probabilidad de que  si ya lo hemos intentado  5 veces necesitemos más de 4 intentos adicionales  para abrir la puerta?
</div>

<div class="example-sol">

Tomemos $k=4,j=5$, aplicando la propiedad de la falta de memoria

$$
P(X> 4+5/X \geq 5)=P(X > 4)
$$

Después de 5 fracasos no estamos *más cerca* de abrir la puerta.
La propiedad de la  falta de  memoria  nos dice que en **después de cada intento es como si empezásemos  de nuevo a abrir la puerta**. Tras 5 fracasos la probabilidad de que fallemos más de  4 veces  más es la misma.
</div>

### Ejemplo falta de memoria 

<div class="example-sol">

¿Cuál es el número esperado de fracasos hasta abrir la puerta

$$
E(X)=\frac{1-p}{p}=\frac{1-\frac{1}{10}}{\frac{1}{10}}=\frac{\frac{9}{10}}{\frac{1}{10}}=9.
$$

La varianza es 

$$
Var(X)=\frac{1-p}{p^2}=\frac{1-\frac{1}{10}}{\left(\frac{1}{10}\right)^2}=\frac{\frac{9}{10}}{\frac{1}{100}}=
90.
$$

La desviación típica es $\sqrt{90}=`r sqrt(90)`.$
</div>

### Ejemplo: El clásico del fútbol

<div class="exercise">

**Ejemplo: partidos hasta que el Barça gana al Madrid**

Los partidos Real Madrid FC Barcelona de **la liga** española se suelen denominar  **El Clásico**, sean en el Bernabeu (estadio del Real Madrid) o en el Camp Nou (estadio del Barça)

Sea $Y$ la variable que cuenta el número de veces que  en un partido de fútbol de la liga el Real Madrid  pierde contra el Barça sea en el Camp Nou  o el Calderón.

Nuestra amiga Aina es muy culé (hincha del Barça) quiere averiguar cuántos partidos consecutivos de **El Clásico** tiene que ver hasta ver ganar al Barça por primera vez. 

Le interesa estimar cuánto le va a costar este capricho. Tendrá que comprar las entradas y pagar los viajes de Barcelona a Madrid.

Para ello  consulta [datos historicos de **El clásico**  en la wikipedia](https://es.wikipedia.org/wiki/El_Cl%C3%A1sico)  y  averigua que hasta el 3 de marzo de 2019  el Real Madrid ganó en 72 ocasiones el Barça en 72  y empataron 34 veces, en total se  han jugado 178 **Clásicos**.

La pregunta es: ¿Cuál es la probabilidad de no ver ganar al Barça en al menos tres partidos consecutivos?

</div>

### Variable geométrica: El clásico

<div class="example-sol"> 

Como nuestro aficionada tiene un tía que juega mucho al fútbol en su consola  y con los datos que le damos  estima que  la probabilidad de que el Barça gane un clásico cualquiera es

$$P(Barça)=\frac{72}{178}=`r round(72/178,4)`.$$

Supongamos  pues que nuestro  *experimento de fútbol*  sigue una ley  geométrica con probabilidad de éxito $p=P(Barça)=\frac{72}{178}.$

Entonces si $X$ es el número de partidos que pierde el Barça antes de que gane el primero  seguirá  una ley $Ge(p=\frac{72}{178})$.

Así que  lo que nos pregunta Aina es la siguiente probabilidad

$$P(X>3)=1-P(X\leq 3)=1-\left(1-\frac{72}{178}\right)^4=`r round(1-(1-72/178)^4,4)`.$$


Así que  Aina tiene una probabilidad del $87.42\%$ de que  necesite ver al menos no ganar al Barça 3 partidos antes de ver uno en el que gane.
</div>

### Variable geométrica: El clásico

<div class="exercise"> 
**Ejercicio**

Bajo las condiciones del problema Barça-Madrid de nuestra amiga Aina ¿cuál es el valor esperado de $X$? ¿y su varianza? 
 
</div>

<div class="example-sol"> 

$$X=Ge\left(p=\frac{72}{178}=`r round(72/178,4)`\right)$$

entonces 

$$E(X)=\frac{1-p}{p}=\frac{1-`r round(72/178,4)`}{`r round(72/178,4)`}=`r round((1- (72/178))/(72/178),4)`$$

y

$$Var(X)=\frac{1-p}{p^2}=\frac{1-`r round(72/178,4)`}{`r round(72/178,4)`^2}=`r round((1- (72/178))/(72/178)^2,4)`$$

La desviación típica es 
$$\sqrt{`r round((1- (72/178))/(72/178)^2,4)`}=`r round(sqrt((1- (72/178))/(72/178)^2),4)`.$$

</div>



### Cálculos con R

Veamos los cálculos básicos con  R para la distribución geométrica  $Ge(p=0.25)$. R implementa la geométrica que cuenta el número de fracasos.


$P(X=0)=(1-0.25)^0\cdot 0.25^1=0.25$

```{r binomialfunciones01}
dgeom(0,prob=0.25)
```

$P(X\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25$



```{r binomialfunciones02}
pgeom(0,prob=0.25)
```





### Cálculos con R



$P(X\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=`r 1-0.75^5`.$

```{r binomialfunciones1}
pgeom(4,prob=0.25)
```


Una muestra aleatoria de tamaño 25 de una $Ge(0.25)$

```{r}
rgeom(n=25,prob=0.25)
```

### Gráficos con R el código

```{r eval=FALSE}
par(mfrow=c(1,2))
x=c(0:10)
plot(x=x,y=dgeom(x,prob=0.25),
  ylim=c(0,1),xlim=c(-1,11),xlab="x",
  main="Función de probabilidad\n Ge(p=0.25)")
lines(x=rep(0:10,each=2),y=aux, type = "h", lty = 2,col="blue")
aux0=dgeom(c(0:10),prob=0.25)
ceros=rep(0,21)
ceros
aux=ceros
aux[2*(c(1:11))]<-aux0
curve(pgeom(x,prob=0.25),
  xlim=c(-1,10),col="blue",
  main="Función de distribución\n Ge(p=0.25)")
par(mfrow=c(1,1))
```


###  Los gráficos con R


```{r graficos22, fig.align='center',echo=FALSE}
  par(mfrow=c(1,2))
  p=0.25
  n=30
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dgeom(c(0:n),prob=p)
  plot(x=c(0:n),y=dgeom(c(0:n),prob=p),
       ylim=c(0,1),xlim=c(-1,n+1),xlab="x",
       main=paste0(c("Función de probabilidad\n Ge(p=",p,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux, type = "h", lty = 2,col="blue")
  curve(pgeom(x,prob=p),
        xlim=c(-1,n+1),col="blue",
        main=paste0(c("Función de distribución\n Ge(p=",p,")"),collapse = ""))
  par(mfrow=c(1,1))
```


### Gráficas interactivas geométrica

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r echo = TRUE,eval=FALSE}
 
sliderInput("p_geom", label = "Probabilidad de éxito:",
              min = 0.01, max = 0.99, value =0.25 , step = 0.01)
renderPlot({
  par(mfrow=c(1,2))
  p=input$p_geom
  n=30
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dgeom(c(0:n),prob=p)
  plot(x=c(0:n),y=dgeom(c(0:n),prob=p),
       ylim=c(0,1),xlim=c(-1,n+1),xlab="x",
       main=paste0(c("Función de probabilidad\n Ge(p=",p,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux, type = "h", lty = 2,col="blue")
  curve(pgeom(x,prob=p),
        xlim=c(-1,n+1),col="blue",
        main=paste0(c("Función de distribución\n Ge(p=",p,")"),collapse = ""))
  par(mfrow=c(1,1))
})
```

[![](Images/noshinyImages/interactiva_geometrica1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)

### Cálculos con python

Veamos los cálculos básicos con  python para la distribución geométrica  $Ge(p=0.25)$. scipy.stats implementa la distribución geométrica que cuenta el número  intentos así que empieza en 1.

Cargamos la  función de la librería 

```{python geom1}
from scipy.stats import geom
```


### Cálculos con python

La función de probabilidad es `geom.pmf(x,p,loc=0)=geom.pmf(x,p)` es un geométrica que cuenta el número de intentos para obtener el primer éxito el valor por defecto del último parámetro es  `loc=0`.

Si queremos la que cuenta el número de fracasos para obtener el primer éxito (la geométrica que empieza en 0) tenemos que usar `geom.pmf(x,p,loc=-1)`.

Es decir `geom.pmf(x,p,loc=-1)=geom.pmf(x-1,p,loc=0)`


### Cálculos con python

Veamos pues los cálculos para la $Ge(p)$ que empieza en $0$.

$P(X=0)=(1-0.25)^0\cdot 0.25^1=0.25$

```{python py_geom_funciones1}
geom.pmf(0,p=0.25,loc=-1)
```

$P(X\leq 0)=1- (1-0.25)^{0+1}=1-0.75=0.25$

```{python py_geom_funciones2}
geom.cdf(0,p=0.25,loc=-1)
```

### Cálculos con python

$P(X\leq 4)=1-(1-0.25)^{4+1}=1-0.75=1-0.75^5=`r 1-0.75^5`.$

```{python py_geom_funciones3}
geom.cdf(4,p=0.25,loc=-1)
```

Una muestra aleatoria de tamaño 25 de una $Ge(0.25)$

```{python py_random_binom}
geom.rvs(p=0.25, size=20, loc=-1)
```

### Cálculos con python 

<div class="exercise">
**Ejercicio**

Qué probabilidades son las que calcula el siguiente código y qué tipo de variables geométricas son?

</div>

```{python}
geom.cdf(range(5),p=0.3,loc=0)
geom.cdf(range(5),p=0.3,loc=-1)
```

### Cálculos con python  esperanza y  varianza

Con python también podemos calcular directamente algunos parámetros asociado a una función de distribución predefinida


```{python py_mean_var_stats}
geom.stats(p=0.25, loc=0, moments='mv')
geom.stats(p=0.25, loc=-1, moments='mv')
```


### Cálculos con python  esperanza y  varianza

<div class="exercise">
**Ejercicio**

Comprobad que las medias y las varianzas calculadas en el código anterior, corresponden a una $Ge(p=0.3)$ empezando en $1$ y a a un $Ge(p=0.3)$
empezando en $0$.

¿Son las varianzas siempre iguales?
</div>


### Gráficos con python

```{python geom2, eval=F}
p = 0.25
x = np.arange(geom.ppf(0.01, p),geom.ppf(0.99, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, geom.pmf(x, p), 'bo', ms=5, label='geom pmf')
ax.vlines(x, 0, geom.pmf(x, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, geom.cdf(x, p), 'bo', ms=5, label='geom pmf')
ax.vlines(x, 0, geom.cdf(x, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle('Distribucion Geometrica')
plt.show()
```


### Gráficos con python

```{python, echo=F}

p = 0.25
x = np.arange(geom.ppf(0.01, p),geom.ppf(0.99, p))

fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
_=ax.plot(x, geom.pmf(x, p), 'bo', ms=5, label='geom pmf')
_=ax.vlines(x, 0, geom.pmf(x, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5) 
  
ax = fig.add_subplot(1,2,2)
_=ax.plot(x, geom.cdf(x,p), 'bo', ms=5, label='geom cdf')
_=ax.vlines(x, 0, geom.cdf(x, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
_=fig.suptitle('Distribucion Geometrica')
_=plt.show()
```


## Distribución binomial negativa

### El problema de la puerta con dos cerraduras

Supongamos que disponemos de 10 llaves distintas y tenemos que abrir una puerta con **dos cerraduras**.

Comenzamos por la primera cerradura, de tal forma que cada vez olvidamos que llave que hemos probado.

Una vez abierta la primera cerradura probamos de igual forma con la segunda hasta que también la abrimos.

Sea $X=$ la v.a. que cuenta el número de fracasos hasta abrir la  puerta.

Acertar una llave de la puerta es un experimento Bernoulli con probabilidad de éxito $p=0.1$. Lo repetiremos hasta obtener 2 éxitos.

### Distribución binomial negativa


En general tendremos un experimento  Bernoulli con probabilidad de éxito $0<p<1$ y  tal que:

* Repetimos el experimento hasta obtener el $n$-ésimo éxito ¡¡abrir la maldita puerta!!.
* Sea $X$ la v.a que cuenta el número fallos hasta abrir la puerta, es decir, hasta  conseguir el n-ésimo éxito. Notemos que no contamos los éxitos, solo  contamos los fracasos

### Distribución binomial negativa

 Si representamos como es habitual un suceso son una cadena de F's y E's. 
 
 Si  $n=2$  estos son algunos sucesos elementales 
 $$\{EE,FEE,EFE, FFEE,FEFE,EFFE,FFFEE,FFEFE,FEFFE,EFFFE\}$$
 
 
 
$$P(X=0)=P(\{EE\})=p^2$$

$$P(X=1)=P(\{FEE,EFE\})=2\cdot (1-p)\cdot p^2$$
$$P(X=2)=P(\{FFEE,FEFE,EFFE\})=3\cdot (1-p) 2\cdot p^2$$

$$P(X=3)=P(\{FFFEE,FFEFE,FEFFE,EFFFE\})=4\cdot (1-p)^3\cdot p^2$$

### Distribución binomial negativa
 
En general su función de probabilidad es

$$
P_{X}(k)=P(X=k)=\left\{\begin{array}{ll}
     {{k+n-1}\choose{n-1}} \cdot (1-p)^{k}\cdot p^n & \mbox{si } k=0,1,\ldots\\
     0 & \mbox{en otro caso}\end{array}\right.
$$
     

### Distribución binomial negativa

Una v.a. con este tipo de distribución recibe el nombre de *binomial negativa* y la denotaremos por $BN(n,p)$. 

Notemos que $BN(1,p)=Ge(p)$.

### Distribución binomial negativa

<div class="dem">
**Demostración**

Justifiquemos el resultado. Sea $X$ una $BN(n,p)$ y sea $k=0,1,2,\ldots$.

$$P(X=k)=P(\mbox{Todas las cadenas de E's y F' con $k$ F, con $n$ E y acabadas en E})$$


$$
\overbrace{\underbrace{\overbrace{EFFF\ldots EEF}^{n-1 \quad \mbox{Éxitos}.}}}_{k \quad\mbox{Fracasos}}^{k+n-1\mbox{ posiciones}}E
$$



De estas cadenas hay  tantas como maneras de elegir de entre las $k+n-1$ primeras posiciones $n-1$ para colocar los éxitos, esta cantidad es el número binomial

$${k+n-1\choose n-1}$$

</div>


### Números binomiales negativos

<l class="definition"> Números binomiales negativos</l>

Dados dos enteros positivos $n$ y $k$ se  define en numero binomial negativo como 

$$\binom{-n}{k}=\frac{(-n)(-n-1)\cdots (-n-k+1)}{k!}.$$


Se cumple que  

$$
(t+1)^{-n}=\sum_{k=0}^{+\infty}\left(\begin{array}{c} -n
\\ k\end{array}\right) t^{k}
$$


### Números binomiales negativos

Con R es la misma función que para los números binomiales

$$
\begin{eqnarray*}
{-6\choose 4}&=&\frac{-6\cdot (-6-1)\cdot \cdot (-6-2)\cdot (-6-3) }{4!}\\
&=&  \frac{-6\cdot(-7)\cdot (-8)\cdot (-9)}{24}\\
&=& \frac{3024}{24}=126.
\end{eqnarray*}
$$


Efectivamente obtenemos el mismo resultado

```{r}
choose(-6,4)
```

### Esperanza de una $BN(n,p)$

Su **esperanza es**

$$E(X)=\displaystyle\sum_{k=0}^{+\infty} k\cdot {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n=n\cdot\frac{1-p}{p}.$$


La **esperanza del cuadrado $X^2$ es**  

$$E(X^2)=\displaystyle\sum_{k=0}^{+\infty} k^2\cdot {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n=n\cdot\frac{1-p}{p^2}+\left(n\cdot \frac{1-p}{p}\right)^2.$$

### Varianza de una $BN(n,p)$

Por último la **varianza es** 

$$
Var(X)=E(X^2)-E(X)^2=
$$

$$=n\cdot \frac{1-p}{p^2}+\left(n\cdot \frac{1-p}{p}\right)^2-\left(n\cdot \frac{1-p}{p}\right)^2=
n\cdot \frac{1-p}{p^2}.$$

y por tanto la desviación típica es

$$\sqrt{Var(X)} = \frac{\sqrt{n(1-p)}}{p}$$

### Resumen Binomial Negativa $BN(n,p)$


 $X$, $BN(n,p)$ | Número de fracasos antes de  conseguir el $n$-ésimo éxito. Probabilidad de éxito $p$
--------------:|:------------
$D_X=$ | $\{0,1,2,3\ldots\}$  
$P_X(k)=P(X=k)=$ | $\left\{\begin{array}{ll} {k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n & \mbox{si }  k=0,1,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ | $\begin{array}{l}\left\{\begin{array}{ll} 0 & \mbox{si } x<0\\\displaystyle\sum_{i=0}^{k} P(X=i) & \mbox{si  }\left\{\begin{array}{l}k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right.\end{array}\right.
\\\mbox{Calcular la suma o utilizar funciones de R o python.}
\end{array}$
$E(X)=n\cdot\frac{1-p}{p}$ | $Var(X)=n\cdot \frac{1-p}{p^2}$ 

### Ejemplo puerta dos cerraduras $BN(n=2,p=0.1)$.

<div class="exercise">
**Ejercicio: Puerta  con dos cerraduras**

Recordemos nuestra puerta con dos cerraduras que se abren secuencialmente. Tenemos un manojo de 10 llaves casi idénticas. De manera que cada vez que probamos una llave olvidamos qué llave hemos usado.


Sea $X$ la v.a que nos da el número de  intentos fallidos hasta abrir  abrir la puerta. 

</div>

### Ejemplo $BN(n,p)$ 


<div class="exercise">

Estamos interesado en modelar  este problema.  La preguntas son:

1. ¿Cuál es la distribución de probabilidad de $X$ la v.a que nos da el número fallos  hasta abrir la puerta? 
2. ¿Cuál es la función de probabilidad y de distribución del $X$?
3. ¿Cuál es la probabilidad de fallar  exactamente  5 veces antes de abrir la puerta?
4. ¿Cuál es la probabilidad de fallar más de  4?
5. ¿Cuál es  el número esperado de fallos? ¿Y su desviación típica?

</div>


### Ejemplo dos cerraduras $BN(n=2,p=0.1)$.

<div class="example-sol">

**Solución 1.**  ¿Cuál es la distribución de probabilidad de $X$ la v.a que nos da el número fallos  hasta abrir la puerta? 

Bajo estados condiciones tenemos que la probabilidad de "éxito" de cada intento es $p=\frac{1}{10}=.01$. Como cada vez *olvidamos* qué llave hemos probado  cada intento será independiente del anterior.

Así que  la variable $X$ que queremos modelar  cuenta el número  fallos  de repeticiones sucesivas e independientes de  un experimento $Ber(p=0.1)$ hasta conseguir 2 éxitos en un experimento.

Por lo tanto  podemos asegurar que $X$ sigue un distribución $BN(n=2,p=0.1).$
</div>


### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

**Solución 2.** ¿Cuál es la función de probabilidad y de distribución del $X$?

En general la función de probabilidad  de una $BN(n,p)$ es 



$$
P_X(X=k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+n-1\choose n-1} \cdot (1-p)^{k}\cdot p^n & \mbox{si }  k=0,1,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
$$
En particular la   función de probabilidad  de una $BN(n=2,p=0.1)$ es


$$
P_X(X=k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+2-1\choose 2-1} \cdot 0.9^{k}\cdot 0.1^2 & \mbox{si }  k=0,1,2,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
$$
</div>

### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

Simplificando


$$
P_X(X=k)=P(X=k)=
\left\{
\begin{array}{cc} 
{k+1\choose 1} \cdot 0.9^{k}\cdot 0.1^2 & \mbox{si }  k=0,1,2,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
$$
</div>

### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

La función de distribución  en general es 

$$
F_x(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0 & \mbox{si } x<0 \\
\displaystyle\sum_{i=0}^{k }{i+n-1\choose n-1} \cdot (1-p)^{i+n-1}\cdot p^n 
& \mbox{si }\left\{\begin{array}{l} k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right. 
\end{array}
\right.
$$

</div>


### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

Simplificando para $n=2$, $p=0.1$.

$$
F_x(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0 & \mbox{si } x<0 \\
\displaystyle\sum_{i=0}^{k }{i+1\choose 1} \cdot 0.9^{i+1}\cdot 0.1^2
& \mbox{si }\left\{\begin{array}{l} k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right. 
\end{array}
\right.
$$


</div>




### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

**Solución 3.**  ¿Cuál es la probabilidad de fallar  exactamente  5 veces antes de abrir la puerta?

$$
\begin{eqnarray*}
P(X=5)&=&{5+2-1\choose 1} \cdot 0.9^{5}\cdot 0.1^2= {6\choose 1} \cdot 0.9^{5}\cdot 0.1^2\\
&=& 6\cdot 0.9^5\cdot 0.1^2= `r 6*0.9^5*0.1^2`.
\end{eqnarray*}
$$

</div>


### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

**Solución 4.** ¿Cuál es la probabilidad de fallar más de  4



Nos piden que  
$$
P(X>4)=1-P(X\leq 4).
$$

Calculemos primero $P(X\leq 4):$

$$
\begin{eqnarray*}
P(X\leq 4) &= & \displaystyle\sum_{x=0}^{4} P(X=x)=P(X=0)+P(X=1)+P(X=2)+P(X=3)+P(X=4)\\
&=& {0+2-1\choose 1} \cdot 0.9^{0}\cdot 0.1^2+
    {1+2-1\choose 1} \cdot 0.9^{1}\cdot 0.1^2\\
  &+&
    {2+2-1\choose 1} \cdot 0.9^{2}\cdot 0.1^2+
    {3+2-1\choose 1} \cdot 0.9^{3}\cdot 0.1^2 \\ 
  &+&
    {4+2-1\choose 1} \cdot 0.9^{4}\cdot 0.1^2=\ldots
\end{eqnarray*}
$$
</div>
    
### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

$$
\begin{eqnarray*}
P(X\leq 4)=\ldots   &=& 
{1\choose 1} \cdot 0.9^{0}\cdot 0.1^2+
{2\choose 1} \cdot 0.9^{1}\cdot 0.1^2+  
{3\choose 1} \cdot 0.9^{2}\cdot 0.1^2+
{4\choose 1} \cdot 0.9^{3}\cdot 0.1^2\\ 
  &+&
{5\choose 1} \cdot 0.9^{4}\cdot 0.1^2=
0.1^2+
2\cdot 0.9 \cdot 0.1^2+
3\cdot 0.9^2\cdot 0.1^2+
4\cdot 0.9^3\cdot 0.1^2+
5\cdot 0.9^4\cdot 0.1^2\\
=
`r 0.1^2+ 2* 0.9 * 0.1^2+ 3*0.9^2* 0.1^2 +4*0.9^3* 0.1^2+5*0.9^4* 0.1^2`
\end{eqnarray*}.
$$

Por lo tanto 


$$
P(X>4)=1-P(X\leq 4)=1-`r 0.1^2+ 2* 0.9 * 0.1^2+ 3*0.9^2* 0.1^2 +4*0.9^3* 0.1^2+5*0.9^4* 0.1^2`=
`r 1- (0.1^2+ 2* 0.9 * 0.1^2+ 3*0.9^2* 0.1^2 +4*0.9^3* 0.1^2+5*0.9^4* 0.1^2)`.
$$

```{r echo=FALSE,eval=FALSE}
pnbinom(4-2,2,0.1)
0.1^2+ 2* 0.9 * 0.1^2+ 3*0.9^2* 0.1^2
dnbinom(0,2,0.1)
0.1^2
dnbinom(1,2,0.1)
2* 0.9 * 0.1^2
dnbinom(2,2,0.1)
3*0.9^2* 0.1^2
```
</div>

### Ejemplo $BN(n=2,p=0.1)$ 


<div class="example-sol">

**Solución 5.**  ¿Cuál es  el número esperado de fallos? ¿Y su desviación típica?


Como $X$ sigue una ley $BN(n=2,p=0.1)$

$$E(X)=n\cdot \frac{1-p}{p}=2\cdot \frac{1-0.1}{0.1}=18.$$

El número de fallos esperado es 18.



$$
Var(X)=n\cdot\frac{1-p}{p^2}=2 \cdot \frac{1-0.1}{0.1^2}=180.
$$

La varianza de $X$ es 180 y su desviación típica $\sqrt{180}=`r round(sqrt(180),5)`.$

</div>



### Cálculos con R

La función de  R para la función de probabilidad de   la  binomial negativa  y sus parámetros básicos son 

```
dnbinom(x, size, prob,...)`
```

Donde `size` ($n$) es el número de éxitos y  `prob` ($p$) la probabilidad de éxito.

Así en el ejemplo de la puerta $X$ es una $BN(n=size=2,p=prob=0.1)$. Por ejemplo $P(X=5)$ que hemos calculado en el ejemplo anterior es


```{r}
dnbinom(5,size=2,p=0.1)
```



### Cálculos con R

De forma similar calculamos calculamos $P(X\leq 4)$, $P(X>4)=1-P(X\leq 4)$ y $P(X>4)$.

```{r}
pnbinom(4,size=2,p=0.1)
1-pnbinom(4,size=2,p=0.1)
pnbinom(4,size=2,p=0.1,lower.tail=FALSE)
```

### Cálculos con python

La función con python es `nbinom.pmf(k, n, p, loc)`. Hay que cargarla desde `scpi.stats`

```{python}
from scipy.stats import nbinom
```

Recordemos que de nuevo se cumple que 
```{python, eval=F}
nbinom.pmf(k, n, p, loc) = nbinom.pmf(k-loc, n, p)`
```


### Cálculos $BN(n,p)$ con python

```{python}
nbinom.pmf(k=5,n=2,p=0.1)
nbinom.pmf(k=5,n=2,p=0.1,loc=0)
nbinom.cdf(k=4,n=2,p=0.1)
1-nbinom.cdf(k=4,n=2,p=0.1)
```


### Cálculos $BN(n,p)$ con python

Generemos 100 observaciones aleatorias de una $BN(n=2,0.1)$. Es decir serán las veces que hemos fallado hasta abrir la prueba 100 veces.

```{python}
nbinom.rvs(n=2, p=0.1, size=100)
```

### Cálculos $BN(n,p)$ con python

La **esperanza** y la **varianza**de una $BN(n=2,0.1)$ es 

```{python}
n, p=2,0.1
params = nbinom.stats(n,p,moments='mv')
print("E(X)={m}".format(m=params[0]))
print("Var(X)={v}".format(v=params[1]))
```

### Gráficas de la binomial negativa con R 

El siguiente código de R dibuja las función de probabilidad y la de distribución de una  $BN(n=2,p=0.1)$


```{r fig.align='center',echo=TRUE,eval=FALSE}
par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dnbinom(c(0:10),size=2,prob=0.1)
plot(x=c(0:10),y=dnbinom(c(0:10),size=2,prob=0.1),
  ylim=c(0,1),xlim=c(-1,11),xlab="x",
  main="Función de probabilidad\n BN(n=2,p=0.1)")
lines(x=rep(0:10,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(pnbinom(x,size=2,prob=0,1),
  xlim=c(-1,11),col="blue",
  main="Función de distribución\n BN(n=2,p=0.1)")
par(mfrow=c(1,1))
```


### Gráficas de la binomial negativa con R 

El siguiente código de R dibuja las función de probabilidad y la de distribución de una  $BN(n=2,p=0.1)$


```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
aux=rep(0,22)
aux[seq(2,22,2)]=dnbinom(c(0:10),size=2,prob=0.1)
plot(x=c(0:10),y=dnbinom(c(0:10),size=2,prob=0.1),
  ylim=c(0,1),xlim=c(-1,11),xlab="x",
  main="Función de probabilidad\n BN(n=2,p=0.1)")
lines(x=rep(0:10,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(pnbinom(x,size=2,prob=0.1),
  xlim=c(-1,11),col="blue",
  main="Función de distribución\n BN(n=2,p=0.1)")
par(mfrow=c(1,1))
```

### Gráficas interactivas binomial negativa

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r  GRAFICOS_binomial_negativa, echo = TRUE,eval=FALSE}

fluidPage(
fluidRow(
  column(6,
         sliderInput("n_nbinom", label = "Número de éxitos n:",
              min = 1, max = 50, value =20 , step = 1)),
  column(6,
          sliderInput("p_nbinom", label = "Probabilidad de un éxito p:",
                     min = 0.01, max = 0.99, value = 0.8, step = 0.01)
         )
  )
)

renderPlot({
  n=input$n_nbinom
  pr=input$p_nbinom
  
  par(mfrow=c(1,2))
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dnbinom(c(0:n),size=n,prob=pr)
  plot(x=c(0:n),y=dnbinom(c(0:n),size=n,prob=pr),
       ylim=c(0,1),xlim=c(-1,n+1),xlab="x",
       main=paste0(c("Función de probabilidad\n BN(n=",n,",p=",pr,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux, type = "h", lty = 2,col="blue")
  curve(pnbinom(x,size=n,p=pr),
        xlim=c(-1,n+1),col="blue",
        main=paste0(c("Función de distribución\n BN(n=",n,",p=",pr,")"),
                    collapse = ""))
  par(mfrow=c(1,1))
})

```

[![](Images/noshinyImages/interactiva_binomial_negativa1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)

### Gráficos de la binomial negativa con python

<div class="exercise">
**Ejercicio**

Buscad en los manuales de python cómo se dibuja la función de probabilidad y de distribución de una binomial.
negativa 

</div>

<div class="exercise-sol">
Necesitamos de nuevo más librerías

```{python}
import numpy as np
from scipy.stats import nbinom
import matplotlib.pyplot as plt
```
</div>

### Gráficos de la binomial negativa con python


```{python dibu_python2222,eval=FALSE}
n, p = 10, 0.25
x = np.arange(0,nbinom.ppf(0.99, n, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, nbinom.pmf(x, n, p), 'bo', ms=5, label='nbinom pmf')
ax.vlines(x, 0, nbinom.pmf(x, n, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, nbinom.cdf(x, n, p), 'bo', ms=5, label='nbinom pmf')
ax.vlines(x, 0, nbinom.cdf(x, n, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle('Distribucion Binomial Negativa')
plt.show()
```



### Gráficos de la binomial negativa con python


```{python  negativa_py_show, echo=FALSE}
n, p = 10, 0.25
x = np.arange(0,nbinom.ppf(0.99, n, p))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
_=ax.plot(x, nbinom.pmf(x, n, p), 'bo', ms=5, label='nbinom pmf')
_=ax.vlines(x, 0, nbinom.pmf(x, n, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
_=ax.plot(x, nbinom.cdf(x, n, p), 'bo', ms=5, label='nbinom pmf')
_=ax.vlines(x, 0, nbinom.cdf(x, n, p), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
_=fig.suptitle('Distribucion Binomial Negativa')
_=plt.show()
```


### Ejercicio:  Acceso aleatorio a un sistema con triple clave. 


<div class="exercise">
**Sistema con tres claves de acceso**

Supongamos que tenemos un sistema informático tiene un programa de seguridad que genera accesos con   claves  de  3 dígitos  $000,001,\ldots 999$. En total 1000 posibilidades.

Como una clave de tres dígitos es fácil de romper proponemos poner  tres claves consecutivas de acceso al sistema cada una de 3 dígitos.

Para acceder al sistema hay que dar  las tres claves de forma consecutiva y por orden.

Es decir hasta que no averiguamos la primera clave no pasamos a la segunda clave.

Supongamos que cada vez que ponemos los dos dígitos olvidamos el resultado y seguimos poniendo dígitos al azar hasta adivinar la contraseña.

Así hasta conseguir entrar en el sistema.

Sea $X$ la v.a que nos da el número de fallos antes de  entrar en el sistema.

</div>

### Ejercicio  acceso aleatorio a un sistema con triple clave. 


<div class="exercise">

Estamos interesados en modelar  este problema.  La preguntas son:

1. ¿Cuál es la distribución de probabilidad de $X$ la v.a que nos da el número de fallos antes de acceder al  sistema.
2. ¿Cuál es la función de probabilidad y de distribución del $X$
3. ¿Cuál es la probabilidad de fallar  150 veces antes de acceder en el sistema?
4. ¿Cuál es la probabilidad de fallar  más de  150  veces antes de entrar en el sistema?
5. ¿Cuál es  el número esperado de fallos antes de acceder al sistema? ¿Y su desviación típica?

</div>


### Ejemplo $BN(r,p)$ 

<div class="exercise-sol">

**Solución 1.**  ¿Cuál es la distribución de probabilidad de $X$ la v.a que nos da el número de fallos antes de acceder al  sistema.

Bajo estados condiciones tenemos que la probabilidad de "éxito" de cada intento es $p=\frac{1}{1000}=0.001$. Y como cada vez *olvidamos* en los dígitos cada intento será independiente del anterior.

Así que  la variable $X$   cuenta el número de fracasos independientes hasta conseguir 3 éxitos en un experimento $Ber(p=0.001)$ por lo tanto $X$ sigue un distribución $BN(n=3,p=0.001).$

</div>


### Ejemplo $BN(r,p)$ 


<div class="exercise-sol">

**Solución 2.** ¿Cuál es la función de probabilidad y de distribución del $X$

En general la   función de probabilidad  de una $BN(n,p)$ es 


$$
P_X(X=x)=P(X=x)=
\left\{
\begin{array}{cc} 
{x+n-1\choose n-1} \cdot (1-p)^{x}\cdot p^n & \mbox{si }  x=0,1,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
$$
En particular la   función de probabilidad  de una $BN(n=3,p=0.001)$ es


$$
P_X(X=x)=P(X=x)=
\left\{
\begin{array}{cc} 
{x+2\choose 2} \cdot 0.999^{x}\cdot 0.001^3 & \mbox{si }  x=0,1,2,\ldots \\ 0 & \mbox{en otro caso.}\end{array}\right.
$$


</div>


### Solución  ejemplo  $BN(n=3,p=0.001)$ 


<div class="exercise-sol">

**Solución 3.** ¿Cuál es la probabilidad de fallar  150 veces antes de acceder en el sistema?

Nos piden

$$
P(X=150)= {152\choose 2} \cdot 0.999^{150}\cdot 0.001^3
$$

Lo calcularemos operando  con R

```{r}
choose(152,2)*0.999^150*0.001^3
```

con la función de R

```{r}
dnbinom(150,size=3,p=0.001)
```

</div>

### Solución  ejemplo  $BN(n=3,p=0.001)$ 


<div class="exercise-sol">

**Solución 3.** ¿Cuál es la probabilidad de fallar  150 veces antes de acceder en el sistema?

Nos piden

$$
P(X=150)= {152\choose 2} \cdot 0.999^{150}\cdot 0.001^3
$$

Pero también lo podemos hacer con python 

```{python}
from  scipy.special import binom
binom(152,2)*0.999**150*0.001**3
nbinom.pmf(150,n=3,p=0.001)
```

</div>


### Solución  ejemplo  $BN(n,p)$ 


<div class="example-sol">

**Solución 4.** ¿Cuál es la probabilidad de fallar  más de  150  veces antes de entrar en el sistema?


$$P(X>150)=1-P(X\leq 150)$$

Calculemos $P(X\leq 150)$

$$
\begin{eqnarray*}
P(X\leq 150) &=& P(X=0)+P(X=1)+P(X=2)+\ldots+P(X=150)= \sum_{k=0}^{150} {k+3-1\choose 3-1} \cdot (0.999)^{k}\cdot 0.001^3\\
&=& \ldots = `r pnbinom(150,3,0.001)`
\end{eqnarray*}
$$

```{r}
pnbinom(150,3,0.001)
```

```{python}
nbinom.cdf(150,n=3,p=0.001)
```
</div>


### Solución  ejemplo  $BN(n,p)$ 


<div class="example-sol">

**Solución 5.**  ¿Cuál es  el número esperado de fallos antes de acceder al sistema? ¿Y su desviación típica?

$$E(X)=n\cdot \frac{1-p}{p}=3\cdot \frac{1- 0.001}{0.001}=`r 3*(1- 0.001)/0.001`.$$
$$Var(X)=n\cdot \frac{1-p}{p^2}=3\cdot \frac{1- 0.001^2}{0.001^2}=`r 3*(1- 0.001)/0.001^2`.$$

Con python

```{python}
params = nbinom.stats(n=3,p=0.001,moments='mv')
print("E(X) = {m}".format(m=params[0]))
print("Var(X) = {v}".format(v=params[1]))
```

</div>


###  ¿Tres claves de tres dígitos o una de 9 dígitos?

<div class="exercise">

**Ejercicio**

Supongamos que ponemos una sola clave de 9 dígitos. Estudiemos en este caso la variable aleatoria que da el número de fallos antes de entrar en el sistema y comparemos los resultados.

</div>

<div class="exercice-sol">
Si seguimos suponiendo que cada vez ponemos la contraseña al azar pero esta vez con una  clave de  9 dígitos. La probabilidad de éxito será ahora $p=\frac{1}{10^{9}}$.

Si llamamos $X_9$  a la variable aleatoria que nos da el número de fallos antes de entra en el sistema seguirá una distribución $Ge(p=\frac{1}{10^9}=0.000000001)$.
</div>
###  Qué da más seguridad  ¿tres claves de tres dígitos o una de 9 dígitos?

<div class="exercice">

Su valor esperado es

$$
E(X_9)=\frac{1-p}{p}=\frac{1-0.000000001}{0.000000001}=`r (1-0.000000001)/0.000000001`.
$$

 $1000 000 000$  son  1000 millones de fallos esperados hasta abrir la puerta.
 
 Recordemos que con tres contraseñas de 3 dígitos  el valor esperado de fallos es 
 
 $$3\cdot \frac{1-0.001}{0.001}=`r 3*(1-0.001)/0.001`.$$
 
Por lo tanto es mejor una clave larga de 9 dígitos  que tres cortas si  escribimos las contraseñas al azar.
</div>

## Distribución Poisson

Diremos que una v.a. discreta $X$ con $X(\Omega)=\mathbf{N}$ tiene distribución de Poisson con parámetro $\lambda>0$, y lo denotaremos por $Po(\lambda)$ si su función de probabilidad es:

$$
P_{X}(x)=P(X=x)=
\left\{\begin{array}{ll}
\frac{\lambda^x}{x!} e^{-\lambda}& \mbox{ si } x=0,1,\ldots\\
0 & \mbox{en otro caso}\end{array}\right..
$$

Recordemos que el desarrollo en serie  de Taylor de la exponencial es 

$$
e^{\lambda}=\sum_{x=0}^{+\infty} \frac{\lambda^x}{x!}.
$$

Teniendo en cuenta esto es  fácil comprobar que  todos los valores de la función de probabilidad suman 1.


Además recordemos que   dado $x\in\mathbb{R}-\{0\}$   se tiene que  

$$
\lim_{n\to\infty} \left(1+\frac{x}{n}\right)^n=e^x.
$$

### Distribución Poisson

Así, por ejemplo, se tiene que 


$$
\lim_{n\to\infty} \left(1-\frac{\lambda}{n}\right)^n=\lim_{n\to\infty} \left(1+\frac{-\lambda}{n}\right)^n=e^{-\lambda}.
$$

### La distribución Poisson como "límite" de una binomial.

La distribución Poisson ([Siméon Denis Poisson](https://es.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson)) aparece en el conteo de determinados  eventos que se producen en un intervalo de tiempo o en el espacio.

Supongamos que nuestra variable de interés es  $X$= número de eventos en el intervalo de tiempo $(0,t]$.

Como por ejemplo el número de llamadas a un *call center* en una hora  y que sabemos que se cumplen las siguientes condiciones:

### La distribución Poisson como "límite" de una binomial.

1. El número promedio de eventos en el intervalo $(0,t]$ es
$\lambda>0$.
2. Es posible dividir el intervalo de tiempo en un
gran número de subintervalos (denotemos por $n$ al número de intervalos) de forma que:
    + La probabilidad de que se produzcan dos o más eventos en un subintervalo es despreciable.
    + El número de ocurrencias de eventos en un intervalo  es independiente del número de ocurrencias en otro intervalo.
    + La probabilidad de que un evento ocurra en un subintervalo es $p_n\cdot n=\lambda$ o lo que es lo mismo $p_n=\frac{\lambda}{n}$·

### La distribución Poisson como "límite" de una binomial.

Bajo estas condiciones podemos considerar que el número de eventos en el intervalo $(0,t]$ será el número de "éxitos" en $n$ repeticiones independientes de un proceso Bernoulli de parámetro $p_n$

Entonces si $n\to\infty$ y $p_n\cdot n$ se mantiene igual a $\lambda$ resulta que la función de probabilidad de $X$ se puede poner como

### La distribución Poisson como "límite" de una binomial.

$$
\begin{eqnarray*}
P(X_n=k)&=&\left(\begin{array}{c} n\\ k\end{array}\right) \cdot p_n^k\cdot  (1-p_n)^{n-k}
\\
&=& {n\choose k}\cdot \left(\frac{\lambda}{n}\right)^{k}\cdot \left(1-\frac{\lambda}{n}\right)^{n-k}\\
&=&
\frac{\lambda^k}{k!}\cdot\frac{n!}{(n-k)!\cdot n^k}\cdot
\left(1-\frac{\lambda}{n}\right)^{n}\cdot \left(1-\frac{\lambda}{n}\right)^{-k}=\ldots
\end{eqnarray*}
$$

### La distribución Poisson como "límite" de una binomial.


Estamos interesados en calcular 

$$
\displaystyle\lim_{n\to \infty} P(X_n=k) = \lim_{n\to \infty} \frac{\lambda^k}{k!}\cdot\frac{n!}{(n-k)!\cdot n^k} \cdot
\left(1-\frac{\lambda}{n}\right)^{n}\cdot \left(1-\frac{\lambda}{n}\right)^{-k}.
$$

Calculemos el límite de algunos de los factores de la expresión 

$$
\displaystyle\lim_{n\to \infty}\frac{n!}{(n-k)!\cdot n^k}= \lim_{n\to \infty}\frac{n\cdot (n-1)\cdots (n-k-1)}{n^k}
=\lim_{n\to \infty}\frac{n^{k}+\cdots}{n^k}=1.
$$


### La distribución Poisson como "límite" de una binomial.

$$
\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^{n}=e^{-\lambda}
$$


Y  también teniendo en cuanta que $k$ es constante.

$$
\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^{-k}=\lim_{n\to \infty} 1^{-k}=\lim_{n\to \infty}  1=1.
$$

### La distribución Poisson como "límite" de una binomial.

Para acabar

$$
\displaystyle\lim_{n\to\infty} P(X_n=k)=
\lim_{n\to\infty} \left(\begin{array}{c} n\\ k\end{array}\right)
\cdot p_n^k \cdot (1-p_n)^{n-k}= \frac{\lambda^k}{k!}\cdot 1 \cdot e^{-\lambda}\cdot 1=\frac{\lambda^k}{k!}\cdot e^{-\lambda}.
$$

Lo que confirma que  límite de una serie de variables 
$B(n,p_n=\frac{\lambda}{n})$ sigue una ley $Po(\lambda)$.

### Procesos de Poisson

Lo interesante de las variables Poisson es que podemos modificar (si el modelo lo permite)  el intervalo de tiempo $(0,t]$ en el que contamos los eventos.

Claro que esto no tiene que poder ser así. 

Pero en general si la variable es poisson en  $(0,t]$  también lo será en cualquier subintervalo $(0,t']$ para todo $t'$ tal que  $0<t'<t$. 

Así que podremos definir una serie de variables $X_t$ de distribución $Po(\lambda\cdot t)$.


### Procesos de Poisson

<l class="prop"> Definición procesos de Poisson </l>

Consideremos  un experimento *Poisson*  con $\lambda$ igual
al promedio de eventos en una unidad de tiempo (u.t.).

Si $t$ es una cantidad de tiempo en u.t., la v.a. $X_{t}$=numero de eventos en el intervalo $(0,t]$ es una $Po(\lambda\cdot t)$.

El conjunto de variables $\{X_t\}_{t>0}$ recibe el nombre de **proceso de Poisson**.


### Resumen distribución  Poisson  $X\equiv Po(\lambda)$

$X$ Poisson |  $\lambda$
-------:|:-------
$D_X=$|  $\{0,1,\ldots \}$ 
$P_X(x)=P(X=x)=$ | $\left\{\begin{array}{ll}  \frac{\lambda^x}{x!}e^{-\lambda} & \mbox{ si } x=0,1,\ldots\\ 0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ |  $\begin{array}{l}\left\{\begin{array}{ll} 0 & \mbox{si } x<0\\\displaystyle\sum_{i=0}^{k} P(X=i)= \displaystyle\sum_{i=0}^{k} \frac{\lambda^i}{i!}\cdot e^{-\lambda} & \mbox{si  }\left\{\begin{array}{l}k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right.\end{array}\right.
\\\mbox{Calcular la suma o utilizar funciones de R o python.}
\end{array}$     
$E(X)=\lambda$ | $Var(X)=\lambda$


### Resumen proceso   Poisson  $X_t\equiv Po(\lambda\cdot t)$

$X_t$  $Po(\lambda\cdot t)$ |  $\lambda$ promedio por u.t. 
-------:|:-------
$D_X=$|  $\{0,1,\ldots \}$ 
$P_X(x)=P(X=x)=$ | $\left\{\begin{array}{ll}  \frac{(\lambda\cdot t)^x}{x!}e^{-\lambda\cdot t} & \mbox{ si } x=0,1,\ldots\\ 0  & \mbox{ en otro caso.}\end{array}\right.$
$F_X(x)=P(X\leq X)=$ |  $\begin{array}{l}\left\{\begin{array}{ll} 0 & \mbox{si } x<0\\\displaystyle\sum_{i=0}^{k} P(X=i)= \displaystyle\sum_{i=0}^{k} \frac{(\lambda\cdot t)^i}{i!}\cdot e^{-\lambda\cdot t} & \mbox{si  }\left\{\begin{array}{l}k\leq x< k+1\\k=0,1,2,\ldots\end{array}\right.\end{array}\right.
\\\mbox{Calcular la suma o utilizar funciones de R o python.}
\end{array}$     
$E(X)=\lambda\cdot t$ | $Var(X)=\lambda\cdot t$

### Aproximación de la distribución binomial por la Poisson

Bajo el punto de vista anterior y si $p$ es pequeño y $n$ suficientemente grande  la distribución  $B(n,p)$ se aproxima a una $Po(\lambda=n\cdot p)$.

Existen distintos criterios (ninguno perfecto) de cuando la aproximación es buena.

Por ejemplo  si 

$$n\geq 20\mbox{ o mejor }n\geq 30, n\cdot p < 10 \mbox{ y } p\leq 0.05,$$


la aproximación  de una $B(n,p)$ por una $Po(n\cdot p)$ es buena. Sobre todo para los valores cercanos a $E(X)=\lambda$.


    

### Gráficos aproximación binomial Poisson

Condición deseable $n\geq 20$,  $n\cdot p < 10$, $p\leq 0.05$

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r echo = TRUE,eval=FALSE}
fluidPage(
fluidRow(
  column(6,
         sliderInput("n_binomP", label = "Número de repeticiones n:",
              min = 1, max = 100, value =20 , step = 1)),
  column(6,
          sliderInput("p_binomP", label = "Probabilidad éxito p:",
                     min = 0.001, max = 0.9, value = 0.05, step = 0.001)
         )
  )
)

renderPlot({
  n=input$n_binomP
  pr=input$p_binomP
  par(mfrow=c(1,2))
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dbinom(c(0:n),size=n,prob=pr)
  plot(x=c(0:n),y=dbinom(c(0:n),size=n,prob=pr),
       ylim=c(0,0.6),xlim=c(-1,n+1),xlab="x",ylab="Función de probabilidad",
       main=paste0(c("Funciones de probabilidad\n B(n=",n,",p=",pr,"), Po(lambda=",n*pr,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),n*pr)
  points(x=c(0:n),y=dpois(c(0:n),n*pr),
       ylim=c(0,0.6),xlim=c(-1,n+1),xlab="x",pch=25,col="red")
  lines(x=rep(0:n,each=2),y=aux, type = "h", lty = 3,col="red")
  legend("topleft",legend=c("Binomial","Poisson"),col=c("blue","red"),pch=c(21,25),lty=c(2,3),bty = "n")
  curve(pbinom(x,size=n,p=pr),
        xlim=c(-1,n+1),col="blue",ylab="Función de Distribución",
         main=paste0(c("Funciones de distribución \n B(n=",n,",p=",pr,"), Po(lambda=",n*pr,")"),collapse = ""))
  curve(ppois(x,n*pr),
        xlim=c(-1,n+1),col="red",add=TRUE)
  if(all(c(n>=20,n*pr<10,pr<= 0.05))){aux_l="Condición\n TRUE"} else {aux_l="Condición\n FALSE"}
  legend("topleft",legend=c(aux_l,paste0("n=",n),paste0("n*p=",n*pr),paste0("p=",pr)),bg="transparent",cex=0.8,bty = "n")
  par(mfrow=c(1,1))
})

```

[![](Images/noshinyImages/interactiva_poisson1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Ejemplo $Po(\lambda)$ 

<div class="example">
**Ejemplo**: Trampa insectos.

La conocida [lámpara antiinsectos o insecticida eléctrico](https://es.wikipedia.org/wiki/Insecticida_el%C3%A9ctrico) atrae a  los insectos voladores con una luz ultravioleta  y los mata por electrocución. 

Consideremos la v.a. $X$ que cuenta  número de insectos caídos en la trampa en una hora. Supongamos que el número promedio de insectos que captura la trampa en una hora es $E(X)=20$ y que podemos admitir que $X$ sigue una ley de probabilidad $Po(\lambda=20)$.


Nos piden 

1.  Comentar de forma breve si se cumplen intuitivamente las condiciones para tener una distribución Poisson. 
2.  Escribir de forma explicita la función de probabilidad  y de distribución de $X$.
3.  Calculad la probabilidad de  que en una hora caigan en la trampa  exactamente 21 insectos.
4.  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.
5.  ¿Cuál es el valor esperando, la varianza y la desviación típica de $X$?

</div>


### Ejemplo $Po(\lambda)$ 



<div class="example-sol">

**Solución 1.**  Comentar de forma breve si se cumplen intuitivamente las condiciones para tener una distribución Poisson. 


1. El número promedio de eventos en el intervalo $(0,1]$, una hora  es
$\lambda=20>0$.
2. Es posible dividir el intervalo de tiempo  de una hora en un
gran número de subintervalos (denotemos por $n$ al número de intervalos) de forma que:
    + La probabilidad de que se produzcan dos o más  electrocuciones un subintervalo es despreciable. No es posible que dos mosquitos se electrocuten al mismo tiempo.
    + El número de ocurrencias, electrocuciones de insectos, en un intervalo  es independiente del número de electrocuciones en otro intervalo.
    + La probabilidad de que un evento ocurra en un subintervalo es $p_n\cdot n=\lambda$ o lo que es lo mismo $p_n=\frac{\lambda}{n}$· Podemos dividir los 20  insectos promedio entre los $n$ intervalos (trozo de hora) de forma que $p_n=\frac{\lambda}{n}$. 
    + Por ejemplo si $n=60$ tenemos que $p_n=\frac{20}{60}=\frac{1}{3}$. La probabilidad de que en un minuto la trampa chisporrotee es  $\frac{1}{3}$.
    
</div>

### Ejemplo $Po(\lambda)$ 

<div class="example-sol">
**Solución 2.** Escribid de forma explicita la función de probabilidad  y de distribución de $X$.


La distribución de probabilidad de un $Po(\lambda)$ es

$$
P_X(x)=P(X=x)=\left\{\begin{array}{ll}  \frac{\lambda^x}{x!}e^{-\lambda} & \mbox{ si } x=0,1,\ldots\\ 0  & \mbox{ en otro caso.}\end{array}\right.
$$

Para un a $Po(\lambda=20)$

$$
P_X(x)=P(X=x)=\left\{\begin{array}{ll}\frac{20^x}{x!}e^{-20} & \mbox{ si } x=0,1,\ldots\\ 0  & \mbox{ en otro caso.}\end{array}\right.
$$

</div>

### Ejemplo $Po(\lambda)$ 

<div class="example-sol">
La función de distribución es 

$$
F_X(x)=P(X\leq X)=
\left\{\begin{array}{ll} 
0 & \mbox{si } x<0\\
\displaystyle\sum_{i=0}^{k} P(X=i)=\sum_{i=0}^{k}\frac{\lambda^i}{i!}\cdot e^{-\lambda} & \mbox{si  }
\left\{\begin{array}{l}
k\leq x< k+1\\k=0,1,2,\ldots
\end{array}
\right.
\end{array}
\right.
$$     


En nuestro caso 
$$
F_X(x)=P(X\leq X)=
\left\{\begin{array}{ll} 
0 & \mbox{si } x<0\\
\displaystyle\sum_{i=0}^{k} P(X=i)=\sum_{i=0}^{k}\frac{20^i}{i!}\cdot e^{-20} & \mbox{si  }
\left\{\begin{array}{l}
k\leq x< k+1\\k=0,1,2,\ldots
\end{array}
\right.
\end{array}
\right.
$$ 
 
 
</div>

### Ejemplo $Po(\lambda)$ 



<div class="example-sol">

**Solución 3.** Calculad la probabilidad de  que en una hora caigan en la trampa  exactamente 21 insectos.

Nos piden 


$$
P(X=21)=\frac{20^{21}}{21!}=`r 20^21/factorial(21)*exp(-20)`.
$$


Con R como calculadora y con la función de la distribución de  R

```{r}
20^21/factorial(21)*exp(-20)
dpois(21,lambda = 20)
```

</div>

### Ejemplo $Po(\lambda)$ 

<div class="example-sol">

**Solución 4.**  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.


Nos piden
$$
\begin{eqnarray*}
 P(X\geq 6)&=&1- P(X<6)=1-P(X\leq 5)=1-F_X(5)=1-\displaystyle\sum_{x=0}^{5} \frac{20^{x}}{x!}\cdot e^{-20}\\
 &=&
 1-\left(\frac{20^{0}}{0!}\cdot e^{-20}+\frac{20^{1}}{1!}\cdot e^{-20}+\frac{20^{2}}{2!}\cdot e^{-20}+\frac{20^{3}}{3!}\cdot e^{-20}+\frac{20^{4}}{4!}\cdot e^{-20}+\frac{20^{5}}{5!}\cdot e^{-20}\right)\\
 &=&
 1-e^{-20}\cdot \left(1+20+\frac{400}{4}+\frac{8000}{6}+\frac{160000}{24}+\frac{3200000}{120}\right)\\
 &=&
 1-e^{-20} \cdot \left(\frac{1 \cdot 120+20\cdot 120+400\cdot 30+8000\cdot 20+160000\cdot 24+3200000\cdot 1}{120}\right)\\
 &=& 1-e^{-20}\cdot\left(\frac{4186520}{120}\right)=1-`r exp(-20)+20*exp(-20)+200*exp(-20)+8000/6*exp(-20)+160000/24*exp(-20)+3200000*exp(-20)`.
\end{eqnarray*}
$$

</div>



### Ejemplo $Po(\lambda)$ 



<div class="example-sol">
**Solución 5.**  ¿Cuál es el valor esperado, la varianza y la desviación típica de $X$?

 
 El valor esperado del número de insectos caídos  en la trampa en una hora es 

$$E(X)=\lambda=20$$

Su varianza es 
$$Var(X)=\lambda=20$$

y  su desviación típica vale
$$\sqrt{Var(X)}=+\sqrt{\lambda}=+\sqrt{20}.$$
</div>

### Cálculos con R

Sea $X$ un una v.a. $Po(\lambda=3)$. Entonces $P_X(0)=P(X=0), P_X(1)=P(X=1)$: 


```{r}
dpois(0,lambda = 3)
dpois(1,lambda = 3)
```

### Cálculos con R

$F_X(0)=P(X\leq 0), F_X(1)=P(X\leq 1)$:

```{r}
ppois(0,lambda = 3)
ppois(1,lambda = 3)
dpois(0,lambda = 3)+dpois(1,lambda = 3) ### es igual a ppois(1,lambda=3)
```

### Cálculos con R

Por ejemplo podemos comprobar que $F_X(10)=\sum_{x=0}^{10} P_X(x)$

```{r}
dpois(0:10,3)
sum(dpois(0:10,3))
ppois(10,3)
```

### Cálculos distribución Poisson con R

Y también generar secuencias de observaciones aleatorias de una población $Po(3)$

```{r random_pois}
rpois(n=100,lambda = 3)
```
### Cálculos con R

<div class="exercise">
En   el ejercicio de la trampa para insectos  teníamos que $X$ es una $Po(20)$. Responded con R  a la preguntas 3 y 4 de este ejercicio

</div>

<div class="example-sol">
**Pregunta 3.**  Calculad la probabilidad de  que en una hora caigan en la trampa  exactamente 21 insectos.

 La  respuesta a la pregunta 3 es calcular  $P(X=21)$ 

```{r}
dpois(21,lambda=20)## P(X=21)
```
</div>

### Cálculos con R

<div class="example-sol">
**Pregunta 4.**  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.

La pregunta  4 nos pide calcular $P(X\geq 6)=1-P(X<6)=1-P(X\leq 5)$

```{r}
ppois(5,lambda=20)
1-ppois(5,lambda=20) ## es 1-P(X<=5)=P(X>=6)
ppois(5,lambda=20,lower.tail =FALSE ) ## acumula hacia arriba P(X>5)=P(X>=6)=P(X=6)+P(X=7)+...
```
</div>

### Gráficos  de la distribución Poisson con R

```{r  echo = TRUE,eval=FALSE}
lambda=20
par(mfrow=c(1,2))
n=qpois(0.99,lambda=lambda)
aux=rep(0,(n+1)*2)
aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)
ymax=max(ppois(0:n,lambda=lambda))
plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),
     ylim=c(0,ymax),xlim=c(-1,n+1),xlab="x",ylab="Función de probabilidad",
     main=paste0(c("Función de probabilidad\n  Po(lambda=",lambda,")"),collapse = ""))
lines(x=rep(0:n,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
curve(ppois(x,lambda=lambda),
      xlim=c(-1,n+1),col="blue",ylab="Función de Distribución",
      main=paste0(c("Función de distribución \n Po(lambda=",lambda,")"),collapse = ""))
par(mfrow=c(1,1))
```


### Gráficos  de la distribución Poisson con R

```{r graficosPOISON, fig.align='center',echo=FALSE}
lambda=20
par(mfrow=c(1,2))
n=qpois(0.99,lambda=lambda)
aux=rep(0,(n+1)*2)
aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)
ymax=max(ppois(0:n,lambda=lambda))
plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),
     ylim=c(0,ymax),xlim=c(-1,n+1),xlab="x",ylab="Función de probabilidad",
     main=paste0(c("Función de probabilidad\n  Po(lambda=",lambda,")"),collapse = ""))
lines(x=rep(0:n,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
curve(ppois(x,lambda=lambda),
      xlim=c(-1,n+1),col="blue",ylab="Función de Distribución",
      main=paste0(c("Función de distribución \n Po(lambda=",lambda,")"),collapse = ""))
par(mfrow=c(1,1))
```


### Gráficos  interactivos con R

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r pofrafico11, echo = TRUE,eval=FALSE}

sliderInput("lambda", label = "Promedio de eventos lambda",
              min = 1, max = 100, value =20 , step = 1)
renderPlot({
  lambda=input$lambda
  par(mfrow=c(1,2))
  n=qpois(0.99,lambda=lambda)
  #n
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)
  ymax=0.45
  plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),
       ylim=c(0,ymax),xlim=c(-1,n+1),xlab="x",ylab="Función de probabilidad",
       main=paste0(c("Función de probabilidad\n  Po(lambda=",lambda,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
  curve(ppois(x,lambda=lambda),
        xlim=c(-1,n+1),col="blue",ylab="Función de Distribución",
         main=paste0(c("Función de distribución \n Po(lambda=",lambda,")"),collapse = ""))
  par(mfrow=c(1,1))
})
```


[![](Images/noshinyImages/interactiva_poisson2.png)](https://joanby.shinyapps.io/DistribucionesNotables/)

### Cálculos con python

Sea $X$ un una v.a. $Po(\lambda=3)$. Entonces

$P_X(0)=P(X=0), P_X(1)=P(X=1)$   en este orden son 


```{python poisson_python}
from scipy.stats import poisson
poisson.pmf(0,mu = 3)
poisson.pmf(1,mu = 3)

```


### Cálculos con python

Sea $X$ un una v.a. $Po(\lambda=3)$. Entonces

$F_X(0)=P(X\leq 0), F_X(1)=P(X\leq 1)$   en este orden son 


```{python poisson_python_bis}
poisson.cdf(0,mu = 3)
poisson.cdf(1,mu = 3)
poisson.pmf(0,mu = 3)+poisson.pmf(1,mu= 3) ### es igual a poisson.cdf(1,lambda=3)
```



### Cálculos con python
Por ejemplo  podemos comprobar que $F_X(10)=\displaystyle\sum_{0}^{10} P_X(x)$
```{python poisson_python2}
range(0,10)
poisson.pmf(range(0,10),mu=3)
sum(poisson.pmf(range(0,10),mu=3))
poisson.cdf(10,mu=3)
```
### Cálculos con python

<div class="exercise">
En   el ejercicio de la trampa para insectos  teníamos que $X$ es una $Po(20)$. Responded con python a la preguntas 3 y 4 de este ejercicio

</div>

<div class="example-sol">
**Pregunta 3.**  Calculad la probabilidad de  que en una hora caigan en la trampa  exactamente 21 insectos.

 La  respuesta a la pregunta 3 es calcular  $P(X=21)$ 

```{python poisson_py3}
poisson.pmf(21,mu=20)
## P(X=21)
```
</div>

### Cálculos con R

<div class="example-sol">
**Pregunta 4.**  Calculad la probabilidad de  que en una hora caigan en la trampa  al menos 6 insectos.

La pregunta  4 nos pide calcular $P(X\geq 6)=1-P(X\leq 5)$

```{python poisson_py4}
1-poisson.cdf(5,mu=20) 
## es 1-P(X<=5)=P(X>=6)
```
</div>

### Cálculos con  python

Como ya hemos visto con `scipy.stats` podemos pedir los momentos de una variable aleatoria
$Po(3)$


```{python momentosPOISOON}
poisson.stats(mu=3, moments='mv')
```

Y también generar secuencias de observaciones aleatorias de una población $Po(3)$

```{python}
poisson.rvs(mu=3,size=40)
```





### Gráficos con python

```{python py_poiss1,eval=FALSE,echo=TRUE,size="scriptsize"}
from scipy.stats import poisson
mu = 10 ## mu = lambda
x = np.arange(poisson.ppf(0.01, mu),poisson.ppf(0.99, mu))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
ax.plot(x, poisson.pmf(x, mu), 'bo', ms=5, label='poisson pmf')
ax.vlines(x, 0, poisson.pmf(x, mu), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
ax.plot(x, poisson.cdf(x, mu), 'bo', ms=5, label='poisson cdf')
ax.vlines(x, 0, poisson.cdf(x, mu), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  tick.label.set_fontsize(5)
fig.suptitle('Distribucion de Poisson')
plt.show()
```


### Gráficos con python

```{python py_poiss2,eval=TRUE,echo=FALSE}
from scipy.stats import poisson
mu = 10 ## mu = lambda
x = np.arange(poisson.ppf(0.01, mu),poisson.ppf(0.99, mu))
fig =plt.figure(figsize=(5, 2.7))
ax = fig.add_subplot(1,2,1)
_=ax.plot(x, poisson.pmf(x, mu), 'bo', ms=5, label='poisson pmf')
_=ax.vlines(x, 0, poisson.pmf(x, mu), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
_=ax.plot(x, poisson.cdf(x, mu), 'bo', ms=5, label='poisson cdf')
_=ax.vlines(x, 0, poisson.cdf(x, mu), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
_=fig.suptitle('Distribucion de Poisson')
_=plt.show()
```



### Gráficos interactivos  proceso $Po(\lambda\cdot t$)

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.


```{r echo = TRUE,eval=FALSE,message=FALSE,warning=FALSE}

fluidPage(
  fluidRow(
      column(6,
           sliderInput("lambdapp", label="Promedio eventos por unidad de tiempo", min = 0.1, max = 50, value =10 , step = 0.01)),
    column(6,sliderInput("t", label = "Intervalo de tiempo (0,t]", min = 1, max = 120, value =1 , step = 0.5))
   )
)


renderPlot({
  lambda1=input$lambdapp
  t=input$t
  lambda=lambda1*t ## es lambda* t
  par(mfrow=c(1,2))
  n=qpois(0.99,lambda=lambda)
  #n
  aux=rep(0,(n+1)*2)
  aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),lambda=lambda)
  ymax=ppois(which.max(ppois(0:n,lambda))-1,lambda)*0.7
  plot(x=c(0:n),y=dpois(c(0:n),lambda=lambda),
       ylim=c(0,ymax),xlim=c(-1,n+1),xlab="x",ylab="Función de probabilidad",
       main=paste0(c("Función de probabilidad\n  Po(lambda=",lambda,")"),collapse = ""))
  lines(x=rep(0:n,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
  curve(ppois(x,lambda=lambda),
        xlim=c(-1,n+1),col="blue",ylab="Función de Distribución",
         main=paste0(c("Función de distribución \n Po(lambda=",lambda,")"),collapse = ""))
  par(mfrow=c(1,1))
  })
```

![[](Images/noshinyImages/interactivos_proceso_poisson1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Ejemplo proceso Poisson

<div class="example">

**Número de impactos de insectos en la visera de un casco**

Un colega de trabajo, al que llamaremos  JG, es muy aficionado a los grandes premios de velocidad tanto en coches como en motos.

Como es tan aficionado está obsesionado con  muchas de las más extravagantes estadísticas de estos deportes.
En particular le propusimos que estudiara el número de insectos que chocan contra la visera de un casco de un  motorista GP  o de un  conductor o de fórmula 1 .

La idea es que el número de insectos  está igualmente repartido por todo el circuito y de de promedio impactan    $\lambda>0$ insectos por minuto. También es razonable suponer  que:

* podemos dividir la superficie de la visera en cuadrados suficiente mente pequeños de forma que la probabilidad de que caigan dos insectos en la misma zona es prácticamente 0. 
* un insecto impacte en  un cuadrado cualquier  de la visera es independiente de cualquier otro cuadrado.
* si hemos dividido la visera en $n$ cuadrados la probabilidad $p_n$ de  impacto de un cuadrado  $p_n=\frac{\lambda}{n}$

Así que bajo estas condiciones  si denotamos por $X_t=$ el número de insectos que ha impactado en la visera en  el intervalo $(0,t]$ (en $t$ minutos) podemos afirmar que $X_t$  es un proceso poisson $Po(\lambda\cdot t)$.

</div>


### Ejemplo proceso Poisson

<div class="exercise-sol">

Supongamos que nos dicen que  $\lambda=3$ insectos por minuto. Entonces el proceso de poisson $X_t$ seguirá un ley $Po(3\cdot t).$ 

Ahora estamos en condiciones de  preguntar  al  proceso de Poisson. 

¿Cuál es la probabilidad de que en 10 minutos impacten más de 25 insectos?

En este caso $t=10$ $X_{10}$= número de insectos que impactan en 10 minutos, el intervalo $[0,10)$ que sigue  una $P(3\cdot 10=30)$. Por lo tanto 

$$P(X>25)=1-P(X\leq 25)$$

lo resolvemos con R

```{r}
1-dpois(25,lambda=3)
```

</div>

### Ejemplo proceso Poisson

<div class="exercise-sol">

Otra pregunta interesante es  que tengamos que esperar más de 2 minutos para observar el primer impacto 

$$P(X_2=0)=\frac{(3\cdot 2)^0}{0!}\cdot e^{-3\cdot 2}= e^{-6}=`r round(exp(-6),6)`.$$

Con R

```{r}
6^0/factorial(0)*exp(-6)
ppois(0,lambda=3*2)
```


</div>


## Distribución hipergeométrica

Supongamos que disponemos de una  urna de de sorteos que contiene $m$ bolas blancas y $n$ bolas de otro color, digamos que rojas.

En total en esta urna  hay $m+n$ bolas $m$ blancas y $n$ rojas. Si extraemos dos bolas de la urna lo podemos hacer de dos formas:

* Extraer una anotar su color y reponerla. Sacar otra y anotar su color. Hemos extraído  la bola con reposición.
* Extraer simultáneamente dos bolas (sin reposición) y contar el número de bolas blancas.

Si $X$ es la v.a. que cuenta el número de bolas blancas extraídas

* en el primer caso $X$ es una $B(n=2,p=\frac{m}{m+n})$  ya que consiste en  repetir dos veces el mismo experimento bernoulli.
* en el segundo caso $X$ sigue una distribución hipergeométrica que estudiaremos en esta sección.


<l class="definition"> Distribución hipergeométrica </l>

Sean $n$, $m$ y $k$ tres número enteros positivos y tales  que $k<m+n$.

Consideremos una urna que contiene $m+n$ bolas de las que $m$ son blancas y las restantes $n$ no (son no blancas).

El número total de bolas es $m+n$. Extraemos  de forma aleatoria $k$ bolas de la urna sin reemplazarlas.

Si  $X$ la v.a. que cuenta el número de bolas blancas extraídas.

Su dominio es 

$$D_X=\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq  x \leq \min\{m,k\}\right\}$$


Para explicarlo  veamos varios supuestos 

* $H(m=5,n=2,k=3)$. Tenemos  $m=5$ bolas blancas $n=2$ no blancas y saco $k=3$ bolas sin reposición.
  + En este caso el mínimo de bolas blancas es $1=k-n=3-2$; ya que solo hay dos no blancas.
  + Mientras que el máximo si es $k=3$; ya que tenemos más que suficientes bolas blancas. 

$$D_X=\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq  x \leq \min\{m,k\}\right\}$$

* $H(m=2,n=5,k=3)$. Tenemos $m=2$ bolas blancas, $n=5$ no blancas y saco $k=3$ bolas sin reposición. 
  + En este caso el mínimo de bolas blancas es $0$; puedo sacar 3 no blancas 
  + Mientras que el máximo si es $m=2$; ya que aunque saquemos $k=3$ al llegar a 2 ya hemos  extraído todas las bolas blancas de la urna. 

* $H(m=10,n=10,k=3)$. Tenemos $m=10$ bolas blancas, $n=10$ no blancas y saco $k=3$ bolas sin reposición. 
  + En este caso podemos obtener desde $0$ blancas hasta $k=3$ blancas.

Su función de probabilidad es:

$$
P_{X}(x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}} & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\} \mbox { para  } x\in \mathbf{N}\\
0  & \mbox{en otro caso}\end{array}\right.
$$


### Distribución hipergeométrica

Una v.a. **hipergeométrica con los  parámetros anteriores** la
denotaremos por 
$$H(m,n,k).$$

<l class="observ"> **Observación: otras parametrizaciones** </l>


En ocasiones se parametriza una v.a. hipergeométrica mediante $N=m+n$ número total de bolas, 
$k$=número de extracciones y $p=$ probabilidad de una bola blanca. 


Así podemos **parametrizar alternativamente** la distribución hipergeométrica así 

$$H(N,k,p)\mbox{ donde } p=\frac{m}{N}.$$

### Resumen  hipergeométrica  $H(m,n,k)$.

$X=$número de bolas blancas  en $k$ extracciones  sin reposición de una urna con $m$ bolas blancas y $n$ negras.| $H(m,n,k)$
------:|:------
$D_X$= | $\left\{x\in\mathbf{N}\mid \max\{0,k-n\}\leq  x \leq \min\{m,k\}\right\}$
$P_X(x)=P(X=x)=$ | $\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}} & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\} \mbox { para  } x\in \mathbf{N}\\
0  & \mbox{en otro caso}\end{array}\right.$
$F_X(x)=P(X\leq x)$ | Hay que sumarla. Utilizad funciones de R o de python.
$E(X)=\frac{k\cdot m}{m+n}$   | $Var(X)=k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}$


### Ejemplo clásico urna $m=15$ blancas, $n=10$ rojas y $k=3$ extracciones sin reposición.

<div class="example">
**Urna con bolas blancas y rojas**

Tenemos una urna con 10 bolas rojas, 15 bolas blancas. Extraemos al azar tres bolas de la urna sin reposición. Sea  $X$=número de bolas **blancas** extraídas. Bajo esta condiciones la v.a. $X$ sigue una ley de distribución $H(m=15,n=10,k=3)$.

</div>


<div class="example-sol">


La función de probabilidad es 


$$
P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{m}{x}\cdot \binom{n}{k-x}}{\binom{m+n}{k}} & \mbox{ si }
\max\{0,k-n\}\leq x \leq \min\{m,k\} \mbox { para  } x\in \mathbf{N}\\
0  & \mbox{en otro caso}\end{array}\right.
$$

Sustituyendo los parámetros obtenemos 

$$
P_X(x)=P(X=x)=\left\{
\begin{array}{ll}
\frac{\binom{15}{x}\cdot \binom{10}{3-x}}{\binom{25}{3}} & \mbox{ si }
0\leq x \leq 3 \mbox { para  } x\in \mathbf{N}\\
0  & \mbox{en otro caso}\end{array}\right.
$$


</div>


### Ejemplo clásico urna $m=15$ blancas, $n=10$ rojas y $k=3$ extracciones sin reposición.

<div class="example-sol">

La probabilidad de sacar 2 blancas será

$$
P(X=2)=\frac{\binom{15}{2}\cdot \binom{10}{3-2}}{\binom{25}{3}}
$$ 

```{r}
c(choose(15,2), choose(10,1), choose(25,3))
```


$P(X=2)=\frac{`r choose(15,2)`\cdot`r choose(10,1)` }{`r choose(25,3)`}=`r choose(15,2)*choose(10,1)/choose(25,3)`.$

```{r eval=FALSE,echo=FALSE}
phyper(2,15,10,3)
```

</div>

### Ejemplo clásico urna $m=15$ blancas, $n=10$ rojas y $k=3$ extracciones sin reposición.

<div class="example-sol">

La probabilidad de que saquemos más de   1 bola blanca es

$$
\begin{eqnarray*}
P(X> 1)&=& 1-P(X\leq 1)=1-(P(X=0)+P(X=1))\\
&=&
1-\left(\frac{\binom{15}{0}\cdot \binom{10}{3}}{\binom{25}{3}}+
\frac{\binom{15}{1}\cdot \binom{10}{2}}{\binom{25}{3}}\right)\\
&=&
1-\left(
\frac{`r choose(15,0)`\cdot`r choose(10,3)` }{`r choose(25,3)`}+\frac{`r choose(15,1)`\cdot`r choose(10,2)` }{`r choose(25,3)`}
\right)=1-\frac{120+15\cdot 45}{2300}=`r 1-(120+15*45)/2300`
\end{eqnarray*}
$$

</div>


### Ejemplo clásico urna $m=15$ blancas, $n=10$ rojas y $k=3$ extracciones sin reposición.


<div class="example-sol">

El número esperado de  bolas blancas extraídas para una v.a. $X$ $H(m=15,n=10,k=3)$ es 

$$E(X)=\frac{k\cdot m}{m+n}=\frac{3\cdot 15}{15+10}=\frac{45}{35}=`r round(45/35,6)`.$$



$$
\begin{eqnarray*}
Var(X)&=&k\cdot\frac{m}{m+n}\cdot\left(1-\frac{m}{m+n}\right) \cdot\frac{m+n-k}{m+n-1}\\
&=&3\cdot\frac{15}{15+10}\cdot\left(1-\frac{15}{15+10}\right) \cdot\frac{15+10-3}{15+10-1}\\
&=&
3\cdot\frac{15}{25}\cdot\left(1-\frac{15}{25}\right) \cdot\frac{22}{24}= 
3\cdot\frac{15}{25}\cdot\frac{25-15}{25} \cdot\frac{22}{24}\\
&=&
3\cdot\frac{15}{25}\cdot\frac{10}{25}\cdot\frac{22}{24}=`r 3*15/25*10/25*22/24`.
\end{eqnarray*}
$$

Y por lo tanto su desviación típica es 

$$
+\sqrt{Var(X)}=+\sqrt{0.66}=`r round(sqrt(0.66),6)`.
$$

</div> 
### Cálculos con R

Sea $X$ una va.a $H(m,n,k)$ Las funciones de R son $P(X=x)=$`dhyper(x,m,n,k)` y $P(X\leq q)=$`phyper(q,m,n,k)`, la generación de aleatorios de una hipergeométrica es `rhyper(nn,m,n,k)` donde `nn` es el número de observaciones aleatorias deseado.

Si $X$ es una $H(m=15,n=10,k=3)$, $P(X=2)$ y que $P(X>1)=1-P(X\leq 1)$ son... 

### Cálculos con R



```{r}
dhyper(x=2,m=15,10,k=3)
phyper(q=1,m=15,n=10,k=3)## sí, le han puesto q ya veremos el porqué
1-phyper(q=1,m=15,n=10,k=3)
```

### Cálculos con R

Una muestra aleatoria de este experimento de tamaño 200 sería...

```{r}
rhyper(nn=200,m=15,n=10,k=3)
```


### Gráficas  con R

```{r fig.align='center',echo=FALSE}
par(mfrow=c(1,2))
m=15
n=10
k=3
a=max(c(0,k-n))
b=min(c(m,k))
l=b-a+1
aux=rep(0,2*l)
aux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)
x=a:b
plot(x,y=dhyper(x,m=m,n=n,k=k),
  ylim=c(0,0.6),xlim=c(a-1,b+1),xlab="x",
  main=paste0("Función de probabilidad\n H(m=",m,", n=",n,", k=",k,")"))
lines(x=rep(a:b,each=2),y=aux, type = "h", lty = 2,col="blue")
curve(phyper(x,m=m,n=n,k=k),
  xlim=c(a-1,b+1),col="blue",
  main=paste0("Función de distribución\n H(m=",m,", n=",n,", k=",k,")"))
par(mfrow=c(1,1))
```

### Gráficos interactivos $H(m,n,k)$

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r GRAFICOS_Hiper_interac_aprox,echo = TRUE,eval=FALSE}
fluidPage(
fluidRow(
  column(4,
         sliderInput("mh", label = "Número de bolas blancas m",
              min = 1, max = 50, value =15, step = 1)),
  column(4,
         sliderInput("nh", label = "Número de bolas rojas n",
              min = 1, max = 50, value =10 , step = 1)),
  column(4,
          sliderInput("kh", label = "Número bolas extraídas k",
                     min = 1, max=25, value = 3, step = 1)
         )
  )
)

renderPlot({
  m=input$mh
  n=input$nh
  k=input$kh
  #n=10
  #k=3
  #m=15
  par(mfrow=c(1,2))
  a=max(c(0,k-n))
  b=min(c(m,k))
  l=b-a+1
  aux=rep(0,times=2*l)
  aux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)
  x=a:b
  plot(x,y=dhyper(x,m=m,n=n,k=k),
       ylim=c(0,0.6),xlim=c(a-1,b+1),xlab="x",
       main=paste0("Función de probabilidad\n H(m=",m,", n=",n,", k=",k,")"))
  lines(x=rep(a:b,each=2),y=aux, type = "h", lty = 2,col="blue")
  curve(phyper(x,m=m,n=n,k=k),
        xlim=c(a-1,b+1),col="blue",
        main=paste0("Función de distribución\n H(m=",m,", n=",n,", k=",k,")"))
  par(mfrow=c(1,1))
})
```

[![](Images/noshinyImages/interactivos_hiper_geom1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Comparación $H(m,n,k)$ y $B\left(k,\frac{m}{n+m}\right)$.

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r GRAFICOS_Hiper_interac_compara,echo = TRUE,eval=FALSE}
fluidPage(
fluidRow(
  column(4,
         sliderInput("mh2", label = "Número de bolas blancas m",
              min = 1, max = 50, value =15, step = 1)),
  column(4,
         sliderInput("nh2", label = "Número de bolas rojas n",
              min = 1, max = 50, value =10 , step = 1)),
  column(4,
          sliderInput("kh2", label = "Número bolas extraídas k",
                     min = 1, max=25, value = 3, step = 1)
         )
  )
)

renderPlot({
  m=input$mh2
  n=input$nh2
  k=input$kh2
  #n=10
  #k=3
  #m=15
  pr=round(m/(n+m),4)
  a=max(c(0,k-n))
  b=min(c(m,k))
  l=b-a+1
  aux=rep(0,times=2*l)
  auxB=rep(0,times=2*(k+1))
  aux[seq(2,2*l,2)]=dhyper(c(a:b),m=m,n=n,k=k)
  x=a:b
  auxB[seq(2,2*(k+1),2)]=dbinom(0:k,k,pr)
  par(mfrow=c(1,2))
  plot(x=c(0:k),y=dbinom(c(0:k),size=k,prob=pr),
       ylim=c(0,0.6),xlim=c(-1,k+1),xlab="x",ylab="Función de probabilidad",
       main=paste0("Funciones de probabilidad\n B(n=",n,"p=",pr,")  H(m=",m,"n=", n,"k=",k,")"))
  lines(x=rep(0:k,each=2),y=aux,pch=21, type = "h", lty = 2,col="blue")
  #aux=rep(0,(n+1)*2)
  #aux[seq(2,(n+1)*2,2)]=dpois(c(0:n),n*pr)
  points(x=c(a:b),y=dhyper(c(a:b),m=m,n=n,k=k),
         ylim=c(0,0.6),xlim=c(-1,k+1),xlab="x",pch=25,col="red")
  lines(x=rep(0:(l-1),each=2),y=aux, type = "h", lty = 3,col="red")
  legend("topleft",legend=c("Binomial","Hipergeométrica"),col=c("blue","red"),pch=c(21,25),lty=c(2,3))
  curve(pbinom(x,size=k,p=pr),
        xlim=c(-1,k+1), col="blue", ylab="Función de Distribución",
         main=paste0("Funciones de distribución\n B(",k,",",pr,") H(m=",m,"n=", n,"k=",k,")"))
  curve(phyper(x,m=m,n=n,k=k),
        xlim=c(-1,k+1),col="red",add=TRUE)
  #if(all(c(n>=20,n*pr<10,pr<= 0.05))){aux_l="Condición VERDADERA"} else {aux_l="Condición FALSA"}
  #legend("topleft",legend=c(aux_l,paste0("n=",n),paste0("n*p=",n*pr),paste0("p=",pr)),bg="transparent",cex=0.5)
  par(mfrow=c(1,1))
})
```

[![](Images/noshinyImages/interactivos_hipergeom_binom1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Cálculos con python 


Sea $X$ una $H(m,n,k)$, las funciones de `scipy.stats` cambian los parámetros 


* $M$ es el número total de bolas. Con nuestra parametrización $M=m+n$.
* $n$ es el número de bolas blancas. Con nuestra parametrización $n=m$.
* $N$  es el número de extracciones. Con nuestra parametrización $N=k$.

```{python}
from scipy.stats import hypergeom
```

### Cálculos con python 

```{python}
hypergeom.pmf(1,M=15+10,n=15,N=3)
hypergeom.cdf(1,M=15+10,n=15,N=3)
1-hypergeom.cdf(1,M=15+10,n=15,N=3)
```

### Cálculos con python 

Una muestra aleatoria de este experimento sería... 
```{python}
hypergeom.rvs(M=15+10,n=15,N=3,size=100)
```


### Gráficos con python


```{python py_hyper2:1,eval=FALSE,echo=TRUE}
from scipy.stats import hypergeom
[M, n, N] = [20, 7, 12] ##20 elementos, 7 del tipo, extraemos 12
x = np.arange(max(0, N-M+n),min(n, N))
fig =plt.figure(figsize=(5, 2.7))
 =ax = fig.add_subplot(1,2,1)
 =ax.plot(x, hypergeom.pmf(x, M, n, N), 'bo', ms=5, label='hypergeom pmf')
 =ax.vlines(x, 0, hypergeom.pmf(x, M, n, N), colors='b', lw=2, alpha=0.5)
 =ax.set_ylim([0, max(hypergeom.pmf(x, M, n, N))*1.1])
for tick in ax.xaxis.get_major_ticks():
   =tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  =tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
 =ax.plot(x, hypergeom.cdf(x, M, n, N), 'bo', ms=5, label='hypergeom cdf')
 =ax.vlines(x, 0, hypergeom.cdf(x, M, n, N), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
   =tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
   =tick.label.set_fontsize(5)
 =fig.suptitle('Distribucion Hipergeometrica')
 =plt.show()
```

### Gráficos con python


```{python py_hyper2,eval=TRUE,echo=FALSE}
from scipy.stats import hypergeom
[M, n, N] = [20, 7, 12] ##20 elementos, 7 del tipo, extraemos 12
x = np.arange(max(0, N-M+n),min(n, N))
fig =plt.figure(figsize=(5, 2.7))
_=ax = fig.add_subplot(1,2,1)
_=ax.plot(x, hypergeom.pmf(x, M, n, N), 'bo', ms=5, label='hypergeom pmf')
_=ax.vlines(x, 0, hypergeom.pmf(x, M, n, N), colors='b', lw=2, alpha=0.5)
_=ax.set_ylim([0, max(hypergeom.pmf(x, M, n, N))*1.1])
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5) 
ax = fig.add_subplot(1,2,2)
_=ax.plot(x, hypergeom.cdf(x, M, n, N), 'bo', ms=5, label='hypergeom cdf')
_=ax.vlines(x, 0, hypergeom.cdf(x, M, n, N), colors='b', lw=2, alpha=0.5)
for tick in ax.xaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
for tick in ax.yaxis.get_major_ticks():
  _=tick.label.set_fontsize(5)
_=fig.suptitle('Distribucion Hipergeometrica')
_=plt.show()
```




## Distribución uniforme 

### Distribución uniforme

Una v.a. continua $X$ diremos que tiene una distribución uniforme sobre el intervalo real $(a,b)$ ,con $a<b$, si su función de densidad es 

$$
f_X(x)=\left\{\begin{array}{ll}
\frac1{b-a} & \mbox{si } a<x<b\\ 0  & \mbox{en cualquier otro caso}
\end{array}
\right. 
$$ 


### Distribución uniforme

<div class="exercise">

**Ejercicio**

Comprobar que el área comprendida entre $f_X$ y la horizontal
vale 1.
</div>


<div class="exercise-sol">

$$
\begin{eqnarray*}
\displaystyle\int_{-\infty}^{+\infty} f_x(x)\cdot dx=\int_{a}^{b} \frac{1}{b-a} \cdot dx=\left.\frac{x}{b-a}\right]_{x=a}^{x=b}=\frac{b}{b-a}-\frac{a}{b-a}=
\frac{b-a}{b-a}=1.
\end{eqnarray*}
$$
</div>


### Función de distribución uniforme.

Su función de distribución es

$$
F_X(x)=\left\{\begin{array}{ll} 0  & \mbox{si } x\leq a\\
\frac{x-a}{b-a} & \mbox{si } a<x<b\\ 1  & \mbox{si } b\leq x
\end{array}
\right. 
$$




### Función de distribución uniforme:  cálculo.

Efectivamente:

* Si $x\leq a$ entonces 
$$F_X(x)=\displaystyle\int_{-\infty}^{x} f(t)\cdot dt= \displaystyle\int_{-\infty}^{x} 0\cdot dt.$$
* Si $a<x<b$ entonces 

$$
\begin{eqnarray*}
F_X(x)&=&\int_{-\infty}^{x} f(t)\cdot dt= \int_{-\infty}^{a} 0\cdot dt+\int_{-a}^{x} \frac1{b-a} \cdot dt\\
&=& 0 +\left.\frac{t}{b-a}\right]_{t=a}^{t=x}= \frac{x}{b-a}-\frac{a}{b-a}=\frac{x-a}{b-a}.
\end{eqnarray*}
$$

### Función de distribución uniforme:  cálculo.


* Por último si $x\geq b$ entonces 

$$
\begin{eqnarray*}
F_X(x)&=&\displaystyle\int_{-\infty}^{x} f(t) dt=\int_{a}^{b} \frac{1}{b-a} dt=
  \left.  \frac{t}{b-a} \right]_{t=a}^{t=b}
\\&=& \frac{b}{b-a}-\frac{a}{b-a}=\frac{b-a}{b-a}=1.
\end{eqnarray*}
$$


Si $X$ es una v.a. uniforme en el intervalo $(a,b)$  lo denotaremos por  $U(a,b)$.


### Esperanza y varianza  para una v.a. $X$ $U(a,b)$

Calculemos  la esperanza de $X$

$$
\begin{eqnarray*}
E(X)&=&\displaystyle\int_{-\infty}^{+\infty} x\cdot f_X(x) dx =\int_{a}^{b} x \cdot \frac{1}{b-a} dx =
\left.\frac{x^2}{2\cdot (b-a)}\right]_{x=a}^{x=b}\\
&=&\frac{b^2}{2\cdot (b-a)}-\frac{a^2}{2\cdot (b-a)}\\
&=&
\frac{b^2-a^2}{2\cdot (b-a)}=\frac{(b+a)\cdot (b-a)}{2\cdot (b-a)}\\
&=&
\frac{b+a}{2}.
\end{eqnarray*}
$$


### Esperanza y varianza  para una v.a. $X$ $U(a,b)$

Calculemos  la esperanza de $X^2$

$$
\begin{eqnarray*}
E(X^2)&=&\displaystyle\int_{-\infty}^{+\infty} x^2 f_X(x) dx=\int_{a}^{b} x^2 \frac1{b-a}
dx =\left.\frac{x^3}{3\cdot (b-a)}\right]_{x=a}^{x=b} \\
&=&\frac{b^3-a^3}{3\cdot (b-a)}=\frac{b^2+ab+a^2}{3}.
\end{eqnarray*}
$$

<div class="exercise">

**Ejercicio**

* Demostrad que la  igualdad  $b^3-a^3=(b-a)\cdot (b^2+ab+a^2)$ es cierta.

* Utilizadla para el cálculo final del valor de  $E(X^2)$.

</div>


### Esperanza y varianza  para una v.a. $X$ $U(a,b)$.

Calculemos $Var(X)$.

$$
\begin{eqnarray*}
Var(X)&=&\displaystyle E(X^2)-(E(X))^2=\frac{b^2+ab+a^2}3-\left(\frac{b+a}2\right)^2\\&=&
\frac{b^2+ab+a^2}{3}-\frac{b^2+2ab+a^2}{4}\\
&=&
\frac{4\cdot (b^2+ab+a^2)-3\cdot (b^2+2ab+a^2)}{4\cdot 3}
\\
&=&
\frac{b^2-2ab+a^2}{12}=
\frac{(b-a)^2}{12}.
\end{eqnarray*}
$$


### Gráficas $U(0,1)$

El código  de la gráficas  de una $U(0,1)$

```{r grafica_unif10, eval=FALSE}
par(mfrow=c(1,2))
a=0;b=1
curve(dunif(x,a,b),xlim=c(a-0.25,b+0.25),ylim=c(0,max(1/(b-a)+0.05,0.1)),
      col="blue",main=paste0("Función densidad  U(",a,",",b,")"),
      ylab=paste0("dunif(x,",a,", ",b,")")
      )
curve(punif(x,a,b),xlim=c(a-1,b+1),ylim=c(0,1.1),
      col="blue",main=paste0("Función de distribución U(",a,",",b,")"),
      ylab=paste0("punif(x,",a,", ",b,")",cex.axis=0.8)
      )
par(mfrow=c(1,1))
```
  


### Gráficas $U(0,1)$


```{r grafica_unif10_vista, echo=FALSE,fig.align='center'}
par(mfrow=c(1,2))
a=0;b=1
curve(dunif(x,a,b),xlim=c(a-0.25,b+0.25),ylim=c(0,max(1/(b-a)+0.05,0.1)),
      col="blue",main=paste0("Función densidad  U(",a,",",b,")"),
      ylab=paste0("dunif(x,",a,", ",b,")"))
curve(punif(x,a,b),xlim=c(a-1,b+1),ylim=c(0,1.1),
      col="blue",main=paste0("Función de distribución U(",a,",",b,")"),
      ylab=paste0("punif(x,",a,", ",b,")"))
```



### Gráficas interactivas  $U(a,b)$

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r uniforme_plots1_interactivo, echo = TRUE, eval=FALSE}
fluidPage(
fluidRow(
  column(4,
         sliderInput("a1", label = "Parámetro a",
              min = -5, max = 9, value =0 , step = 0.1)
         ),
  column(4,
          sliderInput("b1", label = "Parámetro b",
                     min = 10, max = 15, value = 5, step = 0.1)
         ),
  column(4,
         sliderInput("x1", label="x", value=9, min = -5, max = 15, step = 0.1)
         )
  
)
)

renderPlot({
  a=input$a1
  b=input$b1
  x=input$x1
  par(mfrow=c(1,2))
  #a=0;b=1;x=0.25
  xx=c(seq(min(a,x),min(b,x),by=0.001))
  curve(dunif(x,a,b),xlim=c(a-0.25,b+0.25),ylim=c(0,max(1/(b-a)+0.05,0.1)),col="blue",main=paste0("Función densidad U(",a,",",b,")"),
  ylab=paste0("dunif(x,",a,", ",b,")"),xaxt="n")
  axis(side=1, at=c(a,x,b), labels = TRUE)
  polygon(x=c(a,xx,min(x,b)),y=c(0,dunif(xx,a,b),0),
          density=20,col="skyblue")
  curve(punif(x,a,b),xlim=c(a-1,b+1),ylim=c(0,1.1),col="blue",main=paste0("Función de distribución U(",a,",",b,")"),
  ylab=paste0("punif(x,",a,", ",b,")"),xaxt="n",yaxt="n")
  segments(x0=x,y0=0,x1=x,y1=punif(x,a,b),col="red",lty=2)
  segments(x0=a-1.01,y0=punif(x,a,b),x1=x,y1=punif(x,a,b),col="red",lty=2)
  axis(side=2, at=c(0,round(punif(x,a,b),1),2), labels = TRUE)
  axis(side=1, at=c(a,x,b), labels = TRUE)
  par(mfrow=c(1,1))
})

```

[![](Images/noshinyImages/interactiva_uniforme1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Cambio lineal v.a. uniforme.


Si $X$ sigue una distribución $U(a,b)$ entonces  $Z=\frac{X-a}{b-a}$ sigue una distribución $U(0,1)$.


<div class="prop">

**Propiedad: Cambio lineal distribución uniforme**
</div>

Sea $X$ una v.a  $U(a,b)$

Si $scale\not=0$ y $loc$ son dos constantes reales   entonces 

* si $scale>0$ $T=scale\cdot X+loc$ sigue una ley $U(scale\cdot a +loc,scale\cdot b +loc)$  
* si $scale<0$ $T=scale\cdot X+loc$ sigue una ley $U(scale\cdot b +loc,scale\cdot a +loc)$


### Cambio lineal v.a. uniforme.

<div class="dem">

Supongamos  que $X$ sigue una ley $U(a,b)$, que $scale>0$ y que $T=\frac{X-loc}{scale}$

Así tenemos que 

$$
F_X(x)=P(X\leq x)=\left\{\begin{array}{ll} 0 & \mbox{ si } x\leq a\\\frac{x-a}{b-a} & \mbox{ si } a\leq x\leq b \\1 & \mbox{ si } b\leq x\end{array}\right.
$$
</div>




### Cambio lineal v.a. uniforme.

<div class="dem">

Si $T$ es una $U(scale\cdot a +loc,scale\cdot b +loc)$   su función de distribución será 


$$
\begin{eqnarray*}
F_T(t)&=&P(T\leq t)= P(scale\cdot X+ loc\leq t)= P\left(X\leq \frac{t-loc}{scale}\right)=F_X\left(\frac{t-loc}{scale}\right)\\
&=&
\left\{\begin{array}{ll} 0 & \mbox{ si } \frac{t-loc}{scale}\leq a\\\frac{\frac{t-loc}{scale}-a}{b-a} & \mbox{ si } a\leq \frac{t-loc}{scale}\leq b\\1 & \mbox{ si } b\leq \frac{t-loc}{scale}\end{array}\right.=
\left\{\begin{array}{ll} 0 & \mbox{ si }  t\leq scale\cdot a +loc \\
\frac{t-(scale\cdot a+loc)}{scale\cdot (b-a)} & \mbox{ si } scale\cdot a+loc \leq t\leq scale\cdot b+loc \\
1 & \mbox{ si } scale\cdot b+loc\leq t \end{array}\right.\\
& = &
\left\{\begin{array}{ll} 0 & \mbox{ si }  t\leq scale\cdot a +loc \\
\frac{t-(scale\cdot a+loc)}{scale\cdot b+loc-(scale\cdot a+loc)} & \mbox{ si } scale\cdot a+loc \leq t\leq scale\cdot b+loc \\
1 & \mbox{ si } scale\cdot b+loc\leq t\end{array}\right.
\end{eqnarray*}
$$

que es la función de distribución de una v.a. $U(scale\cdot a+loc,scale\cdot b+loc)$, como queríamos demostrar.
</div>



###  Cambio lineal v.a. uniforme.


<div class="exercise">
**Ejercicio**

Sea $X$ una variable $U(0,1)$ y sea $T=scale\cdot X+loc$:

* Si $T$ es $U(-5,5)$  ¿qué  valores toman $scale$ y $loc$?

* Si $T$  $loc=-10$ y $scale=10$ ¿qué distribución de probabilidad sigue  $T$ ?

* Si $T$  $loc=0$ y $scale=-1$ ¿qué distribución probabilidad sigue  $T$ ?

</div>

### Resumen v.a con distribución uniforme, $U(a,b)$

Distribución uniforme | $U(a,b)$
----:|:-----
Dominio | $D_X=(a,b)$
$f_{X}(x)$ |$\left\{\begin{array}{ll}\frac1{b-a} & \mbox{si } a<x<b\\ 0  & \mbox{en cualquier otro caso}\end{array} \right.$
$F_X(x)=P(X\leq X)=$ |  $\left\{\begin{array}{ll} 0 & \mbox{ si } x\leq a\\\frac{x-a}{b-a} & \mbox{ si } a\leq x\leq b\\1 & \mbox{ si } b\leq x\end{array}\right.$
$E(X)=$ |$\frac{a+b}2$
$Var(X)=$| $\frac{(b-a)^2}{12}$

### Cálculos con  R

Sea $X$ una $v.a.$ y $U(-1,1)$. Como es habitual , aunque ahora la variable es continua, las funciones de densidad  y de distribución son  

```{r}
dunif(x=0.5, min=-1,max=1)
punif(q=0.5,min=-1,max=1)
runif(n=5,min=-1,max=1)## generación de números aleatorios uniforme U(min.max)
```

### Cálculos con  R

Por defecto `dunif(x,min=0,max=1)`

```{r}
dunif(x=0.5)
punif(q=0.5)
runif(n=5)
```

### Cálculos con python

Sea $X$ una $v.a.$ $U(-1,1)$ $a=-1$ y $b=1$ así que $loc=-1$ y $scale=b-a=1-(-1)=2.$

```{python}
from scipy.stats import uniform
uniform.pdf(0.5,loc=-1,scale=2)
uniform.ppf(0.5,loc=-1,scale=2)
```

### Cálculos con python

Generación de aletorios uniforme

```{python}
uniform.rvs(size=30,loc=-1,scale=2)
```

### Cálculos con python

Los valores de los parámetros con por defecto  `loc=0, scale=1`

```{python}
uniform.pdf(0.5)
uniform.ppf(0.5)
uniform.rvs(size=5)
```



## Cuantiles de variables aleatorias


### Cuantiles

<div class="definition"> 
**Cuantiles** 
</div>

Si  $X$ es una v.a. con dominio $D_X$ y  $0<q<1$ llamaremos cuantil de orden $q$ al menor valor  perteneciente al dominio $x_q\in D_X$ tal que 

$$P(X\leq x_q)\geq q.$$

En `R`, cada distribución $X$ tiene la función `qX(p,...)` que devuelve precisamente el cuantil $x_p$ tal que $P(X\leq x_p)\geq p.$



### Cuantiles

<div class="example">

Por ejemplo si $X$ es una B(5,0.5)

```{r quantile1, sixe="small"}
pbinom(0:5,5,0.5)
qbinom(c(0.25,0.5,0.75),5,0.5)
qbinom(c(0.3,0.6,0.8),5,0.5)
```
</div>

### Cuantiles

<div class="example">
Como $X$ sigue una $B(5,0.5)$, recordemos que $D_X=\{0,1,2,\ldots,n=5\}.$ y que su función de distribución es  

$$
\small{
F_x(x)=P(X\leq x)=
\left\{
\begin{array}{ll}
0 & x< 0 \\
0.03125 & \mbox{ si } 0 \leq x< 1 \\
0.18750 & \mbox{ si } 1 \leq x< 2 \\
0.50000 & \mbox{ si } 2 \leq x< 3 \\
0.81250 & \mbox{ si } 3 \leq x< 4 \\
0.96875 & \mbox{ si } 4 \leq x< 5 \\
1.00000 & \mbox{ si }  5\leq x \\
\end{array}
\right.}
$$
</div>

### Cuantiles

<div class="example">
El cuantil $q=0.3$ es el  primer valor $x\in D_X$  tal que $F_X(x)=P(X\leq x_{0.3})\geq 0.3.$ así que el primer valor es $x_{0.3}=2$ ya que $F_X(2)=P(X\leq 2)=0.5 \geq 0.3$.
</div>


<div class="exercise">
**Ejercicio**

Calcular los cuantiles de  $0.6$ y $0.8$ de una $B(5,0.5).$
</div>


En general podemos considerar que $F^{-1}$ es la función que nos da los cuantiles (es decir si $F^{-1}(p)$ da más de una valor tomaremos como antiimagen el valor más pequeño que esté dentro del dominio $D_X$).


### Cuantiles

<div class="example">

**Dado  parchís**

$Sea$  $X$ la variable aleatoria uniforme discreta que nos da el número de puntos  obtenidos en el lanzamiento de una dado de parchís (seis caras y numeradas del 1 al 6).

Su dominio  es $D_X=\{1,2,3,4,5,6\}$ su función de probabilidad es 

$$
P_X(x)=P(X=x)=
\left\{
\begin{array}{ll}
 \frac{1}{6} & \mbox{ si } x=1,2,3,4,5,6. \\
0 & \mbox{ en otro caso }.
\end{array}
\right.
$$

Y su función de distribución

$$
F_X(x)= P(X\leq x)=
\left\{
\begin{array}{ll}
0 & \mbox{ si } x<1. \\
\frac{k}{6} & \mbox{ si } k\leq x< l+1 \mbox{ para } x= 1,2,3,4,6. \\
 1 & \mbox{si  } x \geq 6.
\end{array}
\right.
$$

</div>

### Cuantiles

<div class="example">

Si lo queremos simular en `R` tenemos la función

```{r}
ddado=function(x,n=6) {
  sapply(x,FUN=function(x) {
    if( x %in% c(1:n)){return(1/n)} else {return(0)}})
  }
ddado(1.5,n=6)
ddado(1:10,n=6)
```
</div>

### Cuantiles

<div class="example">

Ahora calculemos $F_X(X)=P(X\leq x)$ con una función de R

```{r}
pdado=function(x,n=6) 
  {
  sapply(x,FUN=function(y){ if (y<1){ return(0)}else{if(y>=n){return(1)} else
  {return(sum(ddado(c(1:(floor(y))),n=n)))}}})
  }
pdado(0:11,6)
```

</div>

### Cuantiles

<div class="example">


Construyamos la función de cuantiles para esta variable:  dado $0\leq p \leq 1$, será  el mínimo de la antiimagen de $p$ mediante la función de distribución $F_X^{-1}(p)$

```{r}
qdado=function(p,n=6){
sapply(p,FUN=function(pp=p,nn=n) 
  {
  if(pp<0 | pp>1) {return(NA)}
  else {
  aux=pp>=pdado(1:n,nn)
  aux
  ifelse(all(!aux),return(1),return(max(which(pp>=pdado(1:n,nn)))))}}
)
}

```


</div>

### Cuantiles

<div class="example">


Efectivamente los cuantiles del dado $X$ son 

```{r}
qdado(1.5)
qdado(-1)
qdado(c(0.1,0.5,0.6,1,1.01,2))
```

</div>

### Cuantiles

<div class="example">
Por ejemplo si $X$ es una $B(n=10,p=0.3)$

```{r}
set.seed(2222)
(q=runif(10,0,1))
qbinom(q,10,0.3)
set.seed(2222)
rbinom(10,10,0.3)
```
</div>

### Cuantiles

<div class="example">

Por ejemplo si $X$ es una $BN(n=3,p=0.1)$

```{r}
set.seed(2222)
(q=runif(10,0,1))
qnbinom(q,3,0.1)
set.seed(2222)
rnbinom(10,3,0.1)
```
</div>


### Un ejemplo gráficas cuantiles $B(n,p)$ y $Po(\lambda)$.

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r cuantiles_graficosPOBIN, echo = TRUE, eval = FALSE}
fluidPage(
fluidRow(
  column(3,
         sliderInput("nq", label = "Par. n B(n,p)",
              min = 1, max = 20, value =10 , step = 1)
         ),
  column(3,
          sliderInput("pq", label = "Par. p B(n,p)",
                     min = 0.01, max = 0.99, value = 0.5, step = 0.1)
         ),
  column(3,
         sliderInput("qq", label=" Cuantil q", value=0.75, min = 0.01, max = 0.99, step = 0.01)
         ),
  column(3,
         sliderInput("lq", label="Par. lambda Po(lambda)", value=5, min = 1, max = 20, step = 1)
         )
  )
)

  
renderPlot({
  n=input$nq
  p=input$pq
  q=input$qq
  lambda=input$lq
  par(mfrow=c(1,2))
  #n=10;p=0.5;q=0.75;lambda=5
  #xx=c(seq(min(a,x),min(b,x),by=0.001))
  probsB=pbinom(0:n,n,p)
  curve(pbinom(x,n,p),xlim=c(0-0.25,n+0.25),ylim=c(0,max(probsB+0.05,0.1)),
        col="blue",main=paste0("Función distribución\n B(n=",n,", p=",p,")"),
        ylab=paste0("dbinom(x,",n,", ",p,")"),yaxt="n")
  segments(x0 = qbinom(q,n,p),y0 = 0,x1 = qbinom(q,n,p),y1 = q,lty=2,col="red")
  segments(x0 = qbinom(q,n,p),y0 = q,x1 = -0.25,y1 = q,lty=2,col="red")
  ytick=c(0.0,q,1)
  axis(side=2, at=ytick, labels = TRUE)
  axis(side=1, at=qbinom(q,n,p), labels = TRUE)
  curve(ppois(x,lambda),xlim=c(0-0.25,2.5*lambda),ylim=c(0,1+0.1),
        col="blue",main=paste0("Función distribución \n Po(lambda=",lambda,")"),
        ylab=paste0("dpois(x, lambda",lambda,")"),yaxt="n")
  segments(x0 = qpois(q,lambda),y0 = 0,x1 = qpois(q,lambda),y1 = q,lty=2,col="red")
  segments(x0 = qpois(q,lambda),y0 = q,x1 = -0.25,y1 = q,lty=2,col="red")
  ytick=c(0.0,q,1)
  axis(side=2, at=ytick, labels = TRUE)
  axis(side=1, at=qpois(q,lambda), labels = TRUE)
  par(mfrow=c(1,1))
})
```

[![](Images/noshinyImages/interactiva_cuantiles1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Generador de números aleatorios método de la transformada inversa


Una de las utilidades de la distribución uniforme $U(0,1)$ es que si  sabemos generar números aletorios de una uniforme podemos generar números aleatorios de cualquier variable aleatoria

<l class="prop"> Propiedad. La transformada inversa </l>
Sea $Z$ una v.a. $U(0,1)$ y sea $X$ una v.a  con función de distribución $F_X$ y que  sea estrictamente creciente de forma que exista la función $F^{-1}$. Consideremos la v.a. $Y=F_X^{-1}(U)$ entonces $Y$ tiene la misma distribución que $X$. 

Notemos que $F^{-1}(p)$, bajo estas condiciones, es la función que nos da los cuantiles de $X$ para cada $0\leq p\leq 1$.

### Generador de números aleatorios método de la transformada inversa

<div class="dem">

**Demostración**

Bajo esta condiciones  $F^{-1}(y)$   nos da un solo valor  y como además es creciente tenemos que

$$
P(Y\leq y )=P\left(F_X^{-1}(U)\leq y\right)=P(U\leq F_X(y))=F_Z(F_X(y))=F_X(y).
$$

Luego $X$ es $Y$ tienen la misma función de distribución. 

</div>


<l class="observ"> **Observación: generación de  observaciones  de una v.a.  discreta**: </l>

Este método se pueden generar observaciones  de una v.a.  **discreta** a partir de observaciones aleatorias  de una v.a. $U(0,1)$.  El método es  similar a la propiedad anterior pero tomando como $F^{-1}$ la función que nos da los cuantiles de la v.a. discreta. 

## Distribución exponencial

###  Distribución del tiempo entre dos eventos Poisson

Supongamos que tenemos un proceso Poisson con parámetro $\lambda$ en una unidad de tiempo.

Sea $t$ una cantidad de tiempo en u.t. entonces $N_{t}=$ número de eventos en el intervalo de tiempo $(0,t]$ es una $Po(\lambda\cdot t)$. Consideremos la v.a. $T=$ tiempo transcurrido entre dos eventos Poisson consecutivos.

Sea $t>0$, entonces

$$
\begin{eqnarray*}
P(T>t)&=&P(\mbox{Cero eventos en el intervalo}(0,t])\\
&=&P(N_{t}=0)=
         \frac{(\lambda t)^0}{0!} e^{-\lambda
         t}=e^{-\lambda t}.
\end{eqnarray*}
$$

###  Distribución del tiempo entre dos eventos Poisson

Tomando complementarios, la función de distribución de $T$ será

$$
F_{T}(t)= P(T\leq t)=1-P(X>t)=\left\{\begin{array}{ll} 0 &\mbox{ si } t\leq 0\\
  1-e^{-\lambda t}& \mbox{ si } t>0\end{array}\right.
$$

Entonces, derivando respecto de $t$ en la expresión anterior

$$
f_{T}(t)=\left\{\begin{array}{ll}\lambda \cdot e^{-\lambda t} & \mbox{ si }  t>0\\
0 & \mbox{ si } t\leq 0 \end{array}\right.
$$

La exponencial se denota por $Exp(\lambda)$




### Propiedad de la falta de memoria

Sea $X$  una v.a. $Exp(\lambda)$ entonces

$$P(X>s+t\big|X>s)=P(X>t)\mbox{  para todo } s,t\in \mathbb{R}$$

<div class="dem">
**Demostración**

Si $X$ es una v.a. $Exp(\lambda)$ tenemos que $P(X>x)=1-P(X\leq x)=1-(1-e^{-\lambda\cdot x})=e^{-\lambda\cdot x}$ para todo $x>0$

$P(X>s+t\big|X>s)=\frac{P(\{X>s+t\}\cap \{X>s\})}{P(X>s)}=\frac{P(X>s+t)}{P(X>s)}=\frac{e^{-\lambda\cdot (s+t)}}{e^{-\lambda\cdot s}}=
\frac{e^{-\lambda\cdot s}\cdot e^{-\lambda\cdot t} }{e^{-\lambda\cdot s}}=e^{-\lambda\cdot t}=P(X>t).$
</div>

### Ejemplo distribución exponencial

<div class="example"> 
**El clásico problema del peluquero.** 

Una pequeña peluquería es regentada por un único peluquero. El peluquero está esperando al próximo cliente mientras lee el periódico. 

Supongamos que $N_T=$ número de clientes  que llegan en el intervalo $[0,t)$ es una $Po(\lambda\cdot t)$ entonces la variable $T=$ tiempo entre dos clientes consecutivos sigue una ley $Exp(\lambda)$.

Supongamos que $t$ se mide en horas y que $\lambda=4$ es el promedio de clientes por hora.

</div>

<div class="example-sol">

En este ejemplo la propiedad de la pérdida de memoria significa que
si el peluquero lleva ya esperando más de $s>0.25$  un cuarto de hora  la probabilidad de que espere $t=1/6$ de hora más (10 minutos) no cambia sigue siendo $P(T>0.25+1/6|T>0.25)=P(T>1/6).$
</div>


### Ejemplo distribución exponencial

<div class="example-sol">

El tiempo esperado (en horas) hasta el siguiente cliente es

$$
E(X)=\frac{1}{\lambda}=\frac{1}{4}=0.25.
$$

y la varianza es 

$$
Var(X)=\frac{1}{\lambda^2}=\frac{1}{4^2}=`r 1/16`.
$$

Por último ¿Cuál es la probabilidad de que nuestro peluquero esté sin  clientes (leyendo el periódico) más de 30 minutos (0.5 horas)?


$$
P(X>0.5)=1-P(X\leq 0.5)=1-(1-e^{-4\cdot 0.5 })=e^{-2})=`r exp(-2)`.
$$
</div>

### Ejemplo distribución exponencial

<div class="example-sol">

Si queremos hacer los cálculos con R, 

```{r}
pexp(0.5,rate=3)
1-pexp(0.5,rate=3)
pexp(0.5,rate=3,lower.tail = FALSE)
```

</div>

### Cálculos  con R

La función de densidad, de distribución y la generación aleatoria de valores de una exponencial, se pueden obtener en R con:

```{r}
dexp(0.001,rate=3)### alerta no es una probailidad es una densidad y puede ser >1
pexp(0.5,rate=3) ##P(X<0.5)
rexp(10,3)### diez tiempos de una exponencial
```


### Cálculos  con python

Y en  python con:


```{python}
from scipy.stats import expon
expon.pdf(0.0001,scale= 1./3)
expon.cdf(0.5,scale= 1./3) 
expon.rvs(scale=1./3,size=10)
```


### Resumen v.a con distribución exponencial, $Exp(\lambda)$

$X$ | $Exp(\lambda)$
------:|:------
$D_X=$  | $(0,+\infty)$ 
$f_{X}(x)=$ | $\left\{\begin{array}{ll}
\lambda e^{-\lambda x} & \mbox{ si }  x>0\\
0 & \mbox{ si } x\leq 0
\end{array}\right.$
$F_X(x)=P(X\leq X)=$ | $\left\{\begin{array}{ll} 0 &\mbox{si } x\leq 0\\
1-e^{-\lambda x}& \mbox{si } x>0\end{array}\right.$
$E(X)=\frac{1}{\lambda}$ | $Var(X)=\frac{1}{\lambda^2}$

### Gráficas densidad y distribución $Exp(\lambda=10)$

```{r eval=FALSE,fig.align="center"}
lambda=10
par(mfrow=c(1,2))
curve(dexp(x,rate=lambda),xlim=c(-0.05,round(qexp(0.99,rate=lambda,2),2)+0.25),
      ylim=c(0,dexp(0,lambda)+0.1),col="blue",
      main=paste0("Función densidad Exp(",lambda,")"),
      ylab=paste0("dexp(x,rate=",lambda,")"))
curve(pexp(x,rate=lambda),xlim=c(-0.05,qexp(0.999,10)),ylim=c(0,1.1),col="blue",
      main=paste0("Función de distribución Exp(",lambda,")"),
      ylab=paste0("pexp(x,rate=",lambda,")"))
par(mfrow=c(1,1))
```

### Gráficas densidad y distribución $Exp(\lambda=10)$

```{r echo=FALSE,fig.align="center"}
lambda=10
par(mfrow=c(1,2))
curve(dexp(x,rate=lambda),xlim=c(-0.05,round(qexp(0.99,rate=lambda,2),2)+0.25),
      ylim=c(0,dexp(0,lambda)+0.1),col="blue",
      main=paste0("Función densidad Exp(",lambda,")"),
      ylab=paste0("dexp(x,rate=",lambda,")"))
curve(pexp(x,rate=lambda),xlim=c(-0.05,qexp(0.999,10)),ylim=c(0,1.1),col="blue",
      main=paste0("Función de distribución Exp(",lambda,")"),
      ylab=paste0("pexp(x,rate=",lambda,")"))
par(mfrow=c(1,1))
```

### Gráficas densidad y distribución $Exp(\lambda=10)$

<div class="exercise">
**Ejercicio**

Consultad  en el manual de python [scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html). 


Dibujad la función de densidad y de distribución de una $Exp(10).$

</div>


### Gráficas interactivas de una $X$ $Exp(\lambda)$.

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r uniforme_plots1_interactivo_exponencial, echo = TRUE, eval = FALSE}
fluidPage(
fluidRow(
  column(4,
         sliderInput("le", label = "lambda",
              min = 0.1, max = 3, value =1 , step = 0.1)
         ),
  column(4,
          sliderInput("xe", label = "X=x",
                     min = 0, max = 5, value = 5, step = 0.1)
         ),
  column(4,
          sliderInput("pe", label = "Cuantil p",
                     min = 0.01, max = 1, value = 0.75, step = 0.01)
         )
)
)

renderPlot({
  lambda=input$le
  p=input$pe
  x=input$xe
  #lambda=10;p=0.75;x=0.4
  xx=seq(0,x,by=0.001)
  par(mfrow=c(1,2))
  curve(dexp(x,rate=lambda),xlim=c(-0.05,round(qexp(0.999,rate=lambda),2)),
        ylim=c(0,dexp(0,lambda)+0.1),col="blue",main=paste0("Función densidad Exp(",lambda,")"),
  ylab=paste0("dexp(x,",lambda,")"),xaxt="n")
  axis(side=1, at=c(0,x,round(qexp(0.999,rate=lambda),2)),cex.axis=0.8)
  polygon(x=c(0,xx,max(x,xx)),y=c(0,dexp(xx, rate=lambda),0),
          density=20,col="skyblue")
  curve(pexp(x,rate=lambda),xlim=c(0.01,qexp(0.999,rate=lambda)+0.1),ylim=c(0,1.1),col="blue",
        main=paste0("Función de distribución Exp(",lambda,")"),
        ylab=paste0("pexp(x,",lambda,")"),xaxt="n",yaxt="n")
  segments(x0=qexp(p,lambda),x1=qexp(p,lambda),y0=0,y1=p,col="red",lty=2)
  segments(x0=0-0.05,y0=p,x1=qexp(p,lambda),y1=p,col="red",lty=2)
  axis(side=2, at=seq(0,1,0.1), labels = TRUE)
  axis(side=1, at=seq(0,round(qexp(0.999,rate=lambda),2),by=0.1), labels = TRUE)
  par(mfrow=c(1,1))
})

```

[![](Images/noshinyImages/interactiva_exponencial1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)



### Ejercicio: las bombillas que no envejecen.

<div class="exercise">
**Ejercicio**

Supongamos que compramos una bombilla led que promete un **valor esperado** de duración de 10000 (1.14 años) horas de funcionamiento continuo. Además nos aseguran que  si $X$ es el número de horas de funcionamiento continuo de una bombilla led sigue una ley  exponencial 

* Si $X$ es $Exp(\lambda)$ ¿cuál es el valor del parámetro  $\lambda$?.
* ¿Cuál es la probabilidad de que una bombilla led ilumine más de 2 años?
* Supongamos que ya tengo una bombilla led funcionando 1 año ¿Cuál es la probabilidad de que dure dos años más?
* ¿Cuál es la varianza de la duración  en horas de este tipo de bombillas?

</div>



## Distribución normal o Gaussiana


### Distribución normal o Gaussiana

Una de las más variables  aleatorias  continua más populares  son las  llamadas    distribuciones normales o de [Gaussiana](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal) .

<l class="def"> Distribución normal o de Gauss</l>
Diremos que una v.a. $X$ sigue una ley normal de parámetros
$\mu$ y $\sigma^2$ y lo denotaremos por $N(\mu,\sigma)$
si tiene por función de densidad

$$
f_{X}(x)=\frac1{\sqrt{2\cdot\pi\cdot\sigma^2}}
e^{-\frac{1}{2}\cdot\left(\frac{x-\mu}{\sigma}\right)^2}
$$


para todo $x\in \mathbb{R}.$

### Distribución normal o Gaussiana

La gráfica de esta función es la conocida campana de Gauss.

La v.a. normal con $\mu=0$ y $\sigma=1$ recibe el nombre de
normal estándar y se suele denotar por la letra $Z$ normal $N(0,1)$.

### Distribución normal o Gaussiana


```{r normaldensidad1,fig.align="center"}
curve(dnorm(x),main="Función de densidad de una normal estándar",xlim=c(-3.9,3.9))
```


### Propiedades de la densidad normal

<l class="prop"> Propiedades de la densidad normal</l>

Sea $X$ una v.a. $N(\mu,\sigma)$ y sea $f_{X}$ su función de densidad. Entonces:

1. Evidentemente $f_{X}$ verifica todas las propiedades de las funciones de densidad.
2. $f_{X}(\mu-x)=f_{X}(\mu+x)$ es simétrica respecto de la recta $x=\mu$
3. $f_{X}$ alcanza el máximo en $x=\mu$
4. Si $F_{X}$ la función de distribución de $X$ entonces $F_{X}(\mu+x)=1-F_{X}(\mu-x)$.
5. En particular si $Z$ es una $N(0,1)$ entonces $F_{Z}(-x)=1-F_{Z}(x)$
6. $Z=\frac{X-\mu}{\sigma}$ es una v.a. $N(0,1)$ y $X=\sigma\cdot Z+\mu$ es una $N(\mu,\sigma)$ donde $Z$ es la normal estándar.

### Función de distribución  N(0,1)

Su función de distribución es, como sabemos :

$$
F(x)=\displaystyle\int_{-\infty}^{x} {1\over{\sqrt{2\cdot \pi\cdot\sigma^2}}}
e^{-{1\over 2}{\left({t-\mu}\over{\sigma}\right)}^2} dt.
$$

Que no tiene ninguna expresión algebraica "decente". Es por esta razón, y  por comodidad, que esta función está tabulada o hay que calcular con un programa.



Cuando una variable tiene distribución normal con parámetros $\mu$ y $\sigma$ la denotamos con $X$ sigue un ley de distribución $N(\mu,\sigma).$




### Resumen v.a con distribución normal, $N(\mu,\sigma)$

$X$  | $N(\mu,\sigma)$ 
-----:|:--------
$D_X=$ | $\mathbb{R}=(-\infty,+\infty)$
$f_{X}(x)$ |$=\frac{1}{\sqrt{2\pi\cdot\sigma^2}}\cdot e^{\frac{-(x-\mu)^2}{2\cdot \sigma^2}}\mbox{ para todo }x\in \mathbb{R}.$
$F_X(x)=P(X\leq X)=$ | `pnorm(x,mean=mu,sd=sigma)`. Utilizad funciones de R o python 
$E(X)=\mu.$ | $Var(X)=\sigma^2.$


###  Cálculos con R
 
 De forma la forma habitual los parámetros son `mean` y `sd` la media $\mu$ y la desviación estándar $\sigma$. Por ejemplo para una $X\sim N(\mu=1,\sigma=2)$ la función de densidad $f_X(2)$ se puede calcular como
 
```{r codigoNormalR1}
dnorm(2,mean=1,sd=2)
```

y la función de distribución $F_X(2) = P(X\leq 2)$ como

```{r codigoNormalR1_1}
pnorm(2,mean=1,sd=2) 
```

###  Cálculos con R
 
El cuantil $x_{0.95}$ es el valor que cumple  $P(X\leq x_{0.95})=0.95$ como

```{r codigoNormalR2}
qnorm(0.95,mean=1,sd=2)
```

Y la generación aleatoria de valores según $X$ como

```{r codigoNormalR3}
rnorm(n=5,mean=1,sd=2)
```


###  Cálculos con python
 
De forma la forma habitual importaremos `norm` de `scipy.stas` los parámetros son `loc` y `scale` la media $\mu$ y la desviación estándar $\sigma$. 
 
```{python}
from scipy.stats import norm
```

Por ejemplo para una $X\sim N(\mu=1,\sigma=2)$, la función de densidad $f_X(2)$:

```{python}
norm.pdf(2,loc=1,scale=2)
```

y la función de distribución $F_X(2) = P(X\leq 2)$:

```{python}
norm.cdf(2,loc=1,scale=2)
```




###  Cálculos con python

 
El cuantil $x_{0.95}$ es el valor que cumple  $P(X\leq x_{0.95})=0.95$ como

```{python}
norm.ppf(0.95,loc=1,scale=2)
```

Y la generación aleatoria de valores según $X$ como


```{python}
norm.rvs(loc=1,scale=2,size=5)
```

### Cálculos python

<div class="exercise">
**Ejercicio**

Consultad [SciPy.org](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) para dibujar las funciones de densidad y de distribución con python.
</div>

### Propiedades de la distribución normal.

La función de densidad de la
distribución normal tiene las siguientes propiedades:

* La función $f_X$ es continua.
* $\int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\cdot\pi\cdot \sigma^2}}\cdot 
e^{-\frac{1}{2}\cdot \left(\frac{x-\mu}{\sigma}\right)^2} dx =1.$ (propiedad de todas las densidades).
* $f(\mu+x)=f(\mu-x)$.
* $F(\mu-x)=1-F(\mu+x)$.



### Propiedades de la distribución normal.

```{r echo=FALSE,fig.align='center'}
curve(dnorm(x,0,1),xlim=c(-4,4),ylim=c(0,1/sqrt(2*pi)),col="blue",xaxt="n",yaxt="n",
      ylab=expression(f(x)),cex=0.5)
axis(1,at=c(-1,0,1),labels =c(expression(mu-x),expression(mu),expression(mu-x)))
axis(2,at=c(0,1/sqrt(2*pi)),labels =c(0,expression( paste(frac(1, sqrt(2 * pi))))))
segments(x0=-1,y0=0,x1=-1,y1=dnorm(-1,0,1),col="red",lty=2)
segments(x0=-1,y0=dnorm(-1,0,1),x1=-4.4,y1=dnorm(-1,0,1), col="red",lty=2)
segments(x0=1,y0=0,x1=1,y1=dnorm(1,0,1),col="red",lty=2)
segments(x0=1,y0=dnorm(1,0,1),x1=-4.4,y1=dnorm(1,0,1), col="red",lty=2)
text(x = -3,y=dnorm(-0.9),expression(f(mu-x)==f(mu+x)))
```


### Propiedades de la distribución normal

*  $\lim\limits_{x\to+\infty}f(x)=\lim\limits_{x\to-\infty}f(x)=0$ es decir tiene asíntota horizontal a derecha e izquierda.
* $f$ es estrictamente creciente si $x<\mu$ y decreciente si $x>\mu$.
* Alcanza el máximo en $x=\mu$ y en este punto vale $f(\mu)=\frac1{\sqrt{2\pi}\sigma}$
* Tiene dos puntos de inflexión en $x=\mu+\sigma$ y en $x=\mu-\sigma$.


### Propiedades de la distribución normal.

```{r echo=FALSE,fig.align='center'}
par(mfrow=c(1,2))
x=-2
xx=seq(-4,x,by=0.01)
curve(dnorm(x,0,1),xlim=c(-4,4),ylim=c(0,1/sqrt(2*pi)),col="blue",xaxt="n",yaxt="n",
      ylab=expression(f(x)),cex=0.5)
text(-3,dnorm(-2),expression(F(mu-x)))
polygon(x=c(-4,xx,x),y=c(0,dnorm(xx, 0,1),0), density=20,col="skyblue")
axis(1,at=c(-2,0),labels =c(expression(mu-x),expression(mu)))

x=2
xx=seq(-4,x,by=0.01)
curve(dnorm(x,0,1),xlim=c(-4,4),ylim=c(0,1/sqrt(2*pi)),col="blue",xaxt="n",yaxt="n",
      ylab=expression(f(x)),cex=0.5)
polygon(x=c(-4,xx,x),y=c(0,dnorm(xx, 0,1),0), density=20,col="skyblue")
axis(1,at=c(0,2),labels =c(expression(mu),expression(mu+x)))
xx2=seq(x+0.01,4,by=0.01)
polygon(x=c(x,xx2,4),y=c(0,dnorm(xx2, 0,1),0), density=20,col="red")
text(-3,dnorm(-2),expression(F(mu+x)))
text(3,dnorm(-2),expression(1-F(mu+x)))
par(mfrow=c(1,1))
```


### Gráficas interactivas parámetros normal

Para ejecutar el siguiente gráfico interactivo, solamente tienes que cargar el paquete `shiny` en tu ordenador y luego copiar/pegar las siguientes instrucciones. De este modo podrás observar los cambios en las distribuciones variando los parámetros.

```{r NORMAL_plots1_interactivo, echo = TRUE, eval = FALSE}
fluidPage(
fluidRow(
  column(3,
         sliderInput("m1", label = "mu1",
              min = -10, max = 10, value =0 , step = 0.05)
         ),
  column(3,
          sliderInput("s1", label = "sigma1",
                     min =0.1, max = 5, value = 1, step = 0.1)
         ),
  column(3,
         sliderInput("m2", label="mu2", value=4, min = -10, max = 10, step = 0.05)
         ),
  column(3,
          sliderInput("s2", label = "sigma2",
                     min =0.1, max = 5, value = 1, step = 0.1)
         )
  
)
)

renderPlot({
  m1=input$m1
  m2=input$m2
  s1=input$s1
  s2=input$s2
  mins2=min(c(s1^2,s2^2))
m=min(c(qnorm(0.01,m1,s1),qnorm(0.01,m2,s2)))
M=max(c(qnorm(0.99,m1,s1),qnorm(0.99,m2,s2)))

curve(dnorm(x,m1,s1),xlim=c(m,M),ylim=c(0,1/sqrt(2*pi*mins2)),col="red",lty=1)
legend("toplef",legend=c(expression(N(mu[1],sigma[1])),expression(N(mu[2],sigma[2]))),col=c("red","blue"),lty=c(1,2))
curve(dnorm(x,m2,s2),add=TRUE,col="blue",lty=2)
})

```

[![](Images/noshinyImages/interactiva_normal1.png)](https://joanby.shinyapps.io/DistribucionesNotables/)


### Transformaciones lineales de variables aleatorias normales

<l class="prop"> Propiedad: transformación lineal la distribución  normal </l>

Sea $X$ una variable  $N(\mu,\sigma)$  entonces la variable $Y=a X+b$ con
$a\not=0,b\in\cal{R}$ tiene distribución $N(a\mu+b, |a| \sigma)$



En particular si  $X$ sigue una $N(\mu,\sigma)$, tomando $a=\frac1{\sigma}$ y $b=
\frac{-\mu}{\sigma}$  obtenemos la tipificación  o estandarización  de la v.a. 

$$Z={{X-\mu}\over {\sigma}}$$
se distribuye $N(0,1)$, es decir $E(X)=0$ y $Var(X)=1$.

### Transformaciones lineales de variables aleatorias normales

Esta propiedad es muy útil, ya que utilizándola sólo necesitaremos tabular la
$N(0,1)$. 


Si $Z$ sigue una   distribución $N(0,1)$  diremos que $Z$ sigue una distribución normal estándar. 

Por lo tanto  podemos calcular cualquier distribución  normal  desde la distribución normal estándar:

$$
F_X(x)=F_Z \left(\frac{x-\mu}{\sigma}\right).
$$


### Propiedades de la distribución normal estándar
Sea $Z$ una $N(0,1)$.

Como en este caso $\mu=0$ y $\sigma=1$ tenemos que algunas de las propiedades anteriores se simplifican incluso más:


* De $f_X(\mu-x)=f_X(\mu+x)$ obtenemos $f_Z(-x)=f_Z(x)$
* De $F_X(\mu-x)=1-F_X(\mu+x)$ obtenemos $F_Z(-x)=1-F(x).$
* Dado $\delta>0$, 
$$
P(-\delta\leq Z \leq \delta)=F_{Z}(\delta)-F_{Z}(-\delta)=F_Z(\delta)-(1-F_Z(\delta))=
2\cdot F_Z(\delta)-1.
$$

### Cálculos con la distribución normal

<div class="exercise"> 

**Ejercicio Cálculos con la distribución  normal estándar** 

Sea  $Z$  una distribución $N(0,1)$, calcular las siguientes probabilidades en función de $F_Z$.

* $P(-4\leq Z \leq 4).$
* $P(-2\leq Z \leq 2).$
* $P(Z\leq -2).$
* $P( Z \leq 2).$
* $P( Z \geq 2).$
* $P( Z > 2).$
* $P( Z = 2).$
* $P( Z \geq -2).$
</div>


### Cálculos con la distribución normal

<div class="example-sol">

Resolvamos el ejercicio

* $P(-4\leq Z \leq 4)=F_{Z}(4)-F_{Z}(-4)=2\cdot F_Z(4)-1$
* $P(-2\leq Z \leq 2)=F_{Z}(2)-F_{Z}(-2)=2\cdot F_Z(2)-1$
* $P(Z\leq -2)=F_Z(-2)=1-F_Z(2)$
* $P( Z \leq 2)=F_{Z}(2)$
* $P( Z \geq 2)=1-P(Z<2)=1-F_{Z}(2)$
* $P( Z > 2)=1-P(Z\leq 2)=1-F_{Z}(2)$
* $P( Z = 2)=0$ ya que es una distribución continua.
* $P( Z \geq -2)=1-P(Z< -2)=1-F_{Z}(-2)=1-(1-F_Z(2))=F_Z(2).$
</div>


### Relación entre una normal y la normal estándar.

<l class="prop">**Propiedad**</l>

Si $X$ es una normal $N(\mu,\sigma)$ y $Z$ es su variable tipificada, es decir, $Z=\frac{X-\mu}{\sigma}$ es una $N(0,1)$ entonces:

$$
P(X\leq x)=P\left(\frac{X-\mu}{\sigma}\leq \frac{x-\mu}{\sigma}\right)=F_{Z}\left(\frac{x-\mu}{\sigma}\right).
$$


### Relación entre una  distribución normal y la normal estándar.

<l class="prop">**Propiedad**</l>

* Cuando tengamos un intervalo

$$
\begin{eqnarray*}
P(a<X<b)&=&P\left(\frac{a-\mu}{\sigma}<\frac{X-\mu}{\sigma}<\frac{b-\mu}{\sigma}\right)= \\
&=& P\left(\frac{a-\mu}{\sigma}<Z<\frac{b-\mu}{\sigma}\right)\\
&=&F_{Z}\left(\frac{b-\mu}{\sigma}\right)-
F_{Z}\left(\frac{a-\mu}{\sigma}\right)
\end{eqnarray*}
$$

* Si $\delta>0$ $P\left(\mu-\delta\leq X \leq\mu+\delta\right)=2\cdot  F_Z\left(\frac{\delta}{\sigma}\right)-1$


### Ejemplo cálculo probabilidades normal


<div class="exercise">
**Ejercicio**

Sea $X$ una normal com media $2$ y varianza $4$. Calcular 

* $P(1< X< 2).$
* $P(X>3).$

</div>

### Ejemplo cálculo probabilidades normal

<div class="example-sol">
**Solución**

El cálculo de la primera pregunta es
 
$$
\begin{eqnarray*}
P(1< X< 2)&=& P\left(\frac{1-2}{2}<\frac{X-2}{2}<\frac{2-2}{2}\right)= P\left(\frac{-1}{2}<Z<0\right)\\
&=& F_{Z}(0)-F_{Z}(-0.5)=\frac12-1+F_{Z}(0.5)=-\frac12+F_Z(0.5).
\end{eqnarray*}
$$

La segunda cuestión se resuelve así

$$
P(X>3)=P\left(\frac{X-2}2>\frac{3-2}{2}\right)=P(Z>0.5)=1-F_{Z}(0.5).
$$

</div>

### Ejemplo normal con R y python

<div class="exercise">
**Ejercicio**

Sea $X$ una normal com media $2$ y varianza $4$. Calcular  con R y con python las probabilidades

* $P(1< X< 2).$
* $P(X>3).$

</div>

### Ejemplo normal con R y python


<div class="example-sol">
**Solución con R**

```{r}
pnorm(2,mean=2,sd=4)-pnorm(1,mean=2,sd=4)#P(1< X< 2)
pnorm(3,mean=2,sd=4,lower.tail =FALSE)#P(X>3)
1-pnorm(3,mean=2,sd=4,lower.tail=TRUE)#P(X>3) = 1-P(X<=3)
```

**Solución con Python**


```{python}
norm.cdf(2,loc=2,scale=4)-norm.cdf(1,loc=2,scale=4)#P(1< X< 2)
1-norm.cdf(3,loc=2,scale=4)#P(X>3) = 1-P(X<=3)
norm.stats(loc=2,scale=4,moments="mv")#E(X), Var(X)
```
</div>

### La distribución normal aproxima otras distribuciones
En los temas que siguen veremos como, bajo determinadas condiciones:

* La distribución normal puede aproximar la distribución binomial
* La distribución normal puede aproximar la distribución Poisson
* La distribución normal  es la distribución límite de la media aritmética.

<!--chapter:end:3.Rmd-->

# Variables Aleatorias. Complementos

## Momentos de variables aleatorias

<l class="definition"> Definición. </l> 
Sea $X$ una variable aleatoria. Definimos el **momento de orden $n$** como 
$\momento_n = E\left(X^n\right)$.

<l class="observ"> Observación.</l>
El momento de orden $1$ de una variable aleatoria es su valor medio o $E(X)$.

Los momentos de orden $n$ caracterizan una variable $X$. O sea, que si conocemos todos los momentos de orden $n$, podemos deducir cuál es la distribución de $X$.

En general, el cálculo de los momentos de orden $n$ para una variable $X$ es bastante tedioso. 


### Ejemplo momento de orden $n$
<div class="example">
**Ejemplo: momento de orden $n$ de una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable de Bernoulli de parámetro $p$. Recordemos que su función de probabilidad es:
$$
P_X(0)=q=1-p,\ p_X(1)=p.
$$
Su momento de orden $n$ será:
$$
\momento_n = E\left(X^n\right)=p\cdot 1^n+(1-p)\cdot 0^n = p.
$$
En este caso, todos los momentos de orden $n$ valen $p$.

</div>


### Ejemplo momento de orden $n$
<div class="example">
**Ejemplo: momento de orden $n$ de una variable exponencial de parámetro $\lambda$**

Consideremos ahora una variable $X$ exponencial de parámetro $\lambda$.

Recordemos que su función de densidad es: $f_X(x)=\lambda \mathrm{e}^{-\lambda x},$ para $x\geq 0$ y $0$, en caso contrario.

Su momento de orden $n$ será:
$$
\momento_n = E\left(X^n\right)=\int_0^\infty \lambda \mathrm{e}^{-\lambda x} x^n\, dx =\frac{n!}{\lambda^n}.
$$

La expresión anterior se puede obtener integrando por partes $n$ veces y resolviendo los límites correspondientes. Dejámos al lector los cálculos correspondientes.

Fijémonos que los momentos de orden $n$ tienden a infinito a medida que $n$ crece: $\lim\limits_{n\to\infty}\momento_n = \lim\limits_{n\to\infty}\frac{n!}{\lambda^n}=\infty$.
</div>

### Ejemplo momento de orden $n$
<div class="example">
**Ejemplo: momento de orden $n$ de una variable normal de parámetros $\momento=0$ y $\sigma =1$**

Recordemos que su función de densidad es: $f_X(x)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}},$ para $x\in \mathbb{R}$.

Su momento de orden 1 será la esperanza de $X$: $\momento_1 = 0$ i su momento de orden 2 será: 
$\momento_2 = E\left(X^2\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^2\, dx = 1.$
La integral anterior se resuelve usando técnicas de integrales de dos variables. 
Dicho valor también se puede obtener usando que su varianza vale 1:
$\momento_2 = \mathrm{Var}(X)+E(X)^2 = \sigma^2 +0^2 = 1.$

Los momentos de orden impar $n$ serán cero ya que integramos una función impar:
$\momento_n = E\left(X^n\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^n\, dx = 0.$
O sea, si consideramos $g(x)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^n$, se verifica $g(-x)=-g(x)$, para todo $x\in\mathbb{R}$.

Si intentamos calcular el momento de orden 4, obtenemos:
$\momento_4 = E\left(X^4\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^4\, dx = 3,$ usando técnicas de integración de dos variables otra vez.

</div>


### Momento central de orden $n$ de una variable aleatoria
<l class="definition"> Definición. </l> 
Sea $X$ una variable aleatoria. Definimos el **momento central de orden $n$** como 
$\momentocentral_n = E\left((X-\mu)^n\right)$, donde $\mu =E(X)$ es la media o la esperanza de la variable aleatoria $X$.

<l class="observ"> Observación.</l>
El momento central de orden $1$ de una variable aleatoria es siempre 0:
$$
\momentocentral_1 = E\left((X-\mu)\right)=E(X)-E(\mu)=E(X)-E(X)=0.
$$

### Momento central de orden $n$ de una variable aleatoria

<l class="observ"> Observación.</l>
El momento central de orden $2$ de una variable aleatoria es la varianza:
$$
\momentocentral_2 = E\left((X-\mu)^2\right):= \mathrm{Var}(X).
$$

Los momentos centrales de orden $n$ caracterizan también una variable $X$. O sea, que si conocemos todos los momentos centrales de orden $n$, podemos deducir cuál es la distribución de $X$. 

### Momento central de orden $n$ de una variable aleatoria

<l class="prop"> Proposición.</l>
La relación que hay entre los momentos centrales y los momentos de una variable aleatoria es la siguiente:
$$
\momentocentral_n = \sum_{k=0}^n (-1)^{n-k} \binom{n}{k} \mu^{n-k} \momento_k = \sum_{k=0}^n (-1)^{k} \binom{n}{k} \mu^{k} \momento_{n-k},
$$
donde $\mu =E(X)$ recordemos que es la esperanza de la variable aleatoria $X$.

### Momento central de orden $n$ de una variable aleatoria


<div class="dem">
**Demostración**

Recordemos la definición de momento central de orden $n$ y desarrollemos su expresión aplicando el **binomio de Newton**:
$$
\momentocentral_n = E\left((X-\mu)^n\right) =E\left(\sum_{k=0}^n (-1)^{n-k} \binom{n}{k} X^k\mu^{n-k}\right).
$$
Aplicando la propiedad de la esperanza que la esperanza de la suma es la suma de esperanzas, obtenemos la expresión dada por la proposición:
$$
\momentocentral_n =\sum_{k=0}^n (-1)^{n-k} \binom{n}{k} \mu^{n-k} E\left(X^k\right) = \sum_{k=0}^n (-1)^{n-k} \binom{n}{k} \mu^{n-k} \momento_k.
$$
</div>


### Ejemplo momento central de orden $n$
<div class="example">
**Ejemplo: momento central de orden $n$ de una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable de Bernoulli de parámetro $p$. Recordemos que su función de probabilidad es:
$$
P_X(0)=q=1-p,\ P_X(1)=p.
$$
Usando que $E(X)=p$, su momento central de orden $n$ será:
$$
\momentocentral_n = E\left((X-p)^n\right)=p\cdot (1-p)^n+(1-p)\cdot (0-p)^n = p(1-p)^n + (-1)^n (1-p) p^n.
$$
</div> 

<div class="exercise">
**Ejercicio**

Demostrar que la expresión anterior corresponde a un polinomio de grado $n$.
</div>


### Ejemplo momento central de orden $n$
<div class="example">
**Ejemplo: momento central de orden $n$ de una variable exponencial de parámetro $\lambda$**

Consideremos ahora una variable $X$ exponencial de parámetro $\lambda$.

Recordemos que su función de densidad es: $f_X(x)=\lambda \mathrm{e}^{-\lambda x},$ para $x\geq 0$.

Usando que $E(X)=\frac{1}{\lambda}$, su momento central de orden $n$ será:
$$
\momentocentral_n = E\left(\left(X-\frac{1}{\lambda}\right)^n\right)=\int_0^\infty \lambda \mathrm{e}^{-\lambda x} \left(x-\frac{1}{\lambda}\right)^n\, dx =\frac{a_n}{\lambda^n},
$$
donde $a_n = n!\sum\limits_{k=0}^n \frac{(-1)^k}{k!}.$
</div>

### Ejemplo momento central de orden $n$
<div class="example">
**Ejemplo: momento central de orden $n$ de una variable exponencial de parámetro $\lambda$**

La expresión anterior fijado $n$ se puede obtener integrando por partes $n$ veces y resolviendo los límites correspondientes. Dejámos al lector los cálculos correspondientes. Sin embargo, la obtención de la fórmula general para $n$ se sale del nivel del curso.

Fijémonos que los momentos centrales de orden $n$ también tienden a infinito a medida que $n$ crece: $\lim\limits_{n\to\infty}\momentocentral_n = \lim\limits_{n\to\infty}\frac{a_n}{\lambda^n}=\infty$: 
$$
\lim_{n\to\infty}\momentocentral_n =\lim_{n\to\infty} \frac{n!\sum\limits_{k=0}^n \frac{(-1)^k}{k!}}{\lambda^n}= 
\lim_{n\to\infty}\sum\limits_{k=0}^n \frac{(-1)^k}{k!}\cdot \lim_{n\to\infty} \frac{n!}{\lambda^n}= \mathrm{e}^{-1}\cdot \infty = \infty.
$$
</div>

### Ejemplo momento central de orden $n$
<div class="example">
**Ejemplo: momento central de orden $n$ de una variable normal de parámetros $\mu$ y $\sigma$**

Recordemos que su función de densidad es: $f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},$ para $x\in \mathbb{R}$.

Su momento central de orden 2 será la varianza $\sigma^2$: $\momentocentral_2 =\sigma^2.$

Los momentos centrales de orden impar $n$ serán cero ya que integramos una función impar respecto $x=\mu$:
$\momentocentral_n = E\left((X-\mu)^n\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\cdot (x-\mu)^n\, dx = 0.$
O sea, si consideramos $g(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\cdot (x-\mu)^n$, se verifica $g(\mu-x)=-g(\mu +x)$, para todo $x\in\mathbb{R}$.

Si intentamos calcular el momento central de orden 4, obtenemos:
$\momentocentral_4 = E\left((X-\mu)^4\right)=\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\cdot (x-\mu)^4\, dx = 3\sigma^4.$ La integral anterior puede resolverse con el cambio de variable $t=\frac{x-\mu}{\sigma}$ y usando que:  $\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}\cdot x^4\, dx = 3.$
</div>

## Asimetría de una variable aleatoria

### Definición

Una variable aleatoria tiene **asimetría positiva** si su función de densidad o de probabilidad presenta una cola a la 
**derecha** y **asimetría negativa**, si su función de densidad o de probabilidad presenta cola a la **izquierda**.

Por ejemplo, en la figura siguiente, vemos la gráfica de la función de probabilidad de una variable aleatoria que presenta **asimetría negativa** a la izquierda y una función de densidad de una variable aleatoria que presenta **asimetría positiva** a la derecha:

### Definición

<div class="center">
```{r,echo=FALSE,fig=TRUE,warning=FALSE}
par(mfrow=c(1,2))
x=seq(from=0,to=21, by=1)
plot(x,dbinom(x,20,0.9),type="l",ylab="función de probabilidad")
x=seq(from=0,to=100, by=0.1)
plot(x,dchisq(x,10),type="l",ylab="función de densidad")
```
</div>

### ¿Cómo calcular la asimetría de una variable aleatoria?
La asimetría de una variable aleatoria $X$ se calcula a partir de sus momentos centrales de segundo y tercer orden:
$$
\gamma_1 = E\left({\left(\frac{X-\mu}{\sigma}\right)}^3\right)=\frac{\momentocentral_3}{\sigma^3},
$$
donde $\mu = E(X)$ y $\sigma^2 =\mathrm{Var}(X)$.

Dicho valor se denomina **coeficiente de asimetría de Pearson**.


### ¿Cómo calcular la asimetría de una variable aleatoria?

Usando la relación ya vista entre los momentos centrales y los momentos, podemos expresar el **coeficiente de asimetría** en función de los momentos:
$$
\gamma_1 = \frac{\momento_3 -3\mu\sigma^2-\mu^3}{\sigma^3}.
$$
Dejamos al lector la comprobación de la expresión anterior.

Por tanto, una variable aleatoria $X$ tendrá simetría positiva o a la derecha si $\gamma_1 >0$ y tendrá asimetría negativa o a la izquierda, si $\gamma_1 <0$.

### Ejemplo de cálculo de asimetría
<div class="example">
**Ejemplo: cálculo del coeficiente de asimetría para una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable de Bernoulli de parámetro $p$. Usando que $\momento_n =p$, para todo $n$ y que $\momentocentral_2 = \sigma^2 = p-p^2$, el coeficiente de asimetría $\gamma_1$ será:
$$
\gamma_1 = \frac{p-3p(p-p^2)-p^3}{\sqrt{(p-p^2)^3}} = \frac{p (1-p) (1-2p)}{{\sqrt{(p-p^2)^3}}}.
$$
Por tanto, la variable de Bernoulli de parámetro $p$ tendrá simetria negativa si $p>\frac{1}{2}$ y positiva, si $p<\frac{1}{2}$:
</div> 

<div class="center">
```{r,echo=FALSE,warning=FALSE,fig=TRUE,fig.height=4}
par(mfrow=c(1,2))
plot(c(-0.1,1.1,-0,1.1),c(-0.1,-0.1,1,1),type="n",xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE)
lines(c(0,1),c(0,0))
text(0,-0.05,0)
p=0.75
lines(c(0,0),c(0,1-p))
text(1,-0.05,1)
lines(c(1,1),c(0,p))
text(0.5,0.75,expression(p>frac(1,2)))
plot(c(-0.1,1.1,-0,1.1),c(-0.1,-0.1,1,1),type="n",xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE)
lines(c(0,1),c(0,0))
text(0,-0.05,0)
p=0.25
lines(c(0,0),c(0,1-p))
text(1,-0.05,1)
lines(c(1,1),c(0,p))
text(0.5,0.75,expression(p<frac(1,2)))
```

</div>

### Ejemplo de cálculo de asimetría
<div class="example">
**Ejemplo: cálculo del coeficiente de asimetría para una variable exponencial de parámetro $\lambda$**

Sea $X$ una variable exponencial de parámetro $\lambda$. 
Usando que $\sigma^2=\frac{1}{\lambda^2}$ y $\momentocentral_3 =\frac{a_3}{\lambda^3}=\frac{2}{\lambda^3}$, su coeficiente de asimetría de Pearson será:
$\gamma_1 = \frac{\frac{2}{\lambda^3}}{\frac{1}{\lambda^3}}=2.$

Entonces presenta asimetría positiva o a la derecha tal como se observa en su función de densidad:
</div> 

<div class="center">
```{r,echo=FALSE,warning=FALSE,fig=TRUE,fig.height=4}
par(mfrow=c(1,1))
x=seq(from=0,to=4,by=0.01)
plot(x,dexp(x,rate=2),type="l",ylab="función de densidad")
```
</div>

### Ejemplo de cálculo de asimetría
<div class="example">
**Ejemplo: cálculo del coeficiente de asimetría para una variable normal de parámetros $\mu$ y $\sigma$**

Sea $X$ una variable aleatoria normal de parámetros $\mu$ y $\sigma$. 

Tal como se ha indicado anteriormente, los momentos centrales de orden impar son nulos. 

Por tanto, en este caso $\momentocentral_3=0$ y, por tanto, $\gamma_1=0$. 

Deducimos que la distribución normal es totalmente simétrica.

De hecho, usando que su función de densidad es $f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},$ para $x\in \mathbb{R}$, se puede comprobar que $f_X(\mu-x)=f_X(\mu +x)$, o sea, tiene el eje de simetría $x=\mu$:
</div>

### Ejemplo de cálculo de asimetría
<div class="example">
**Ejemplo: cálculo del coeficiente de asimetría para una variable normal de parámetros $\mu$ y $\sigma$**
<div class="center">
```{r,echo=FALSE,warning=FALSE,fig=TRUE}
mu=1.5
sigma=2
x=seq(from=mu-5,to=mu+5,by=0.01)
plot(x,dnorm(x,mu,sigma),type="l",ylab="función de densidad")
text(mu+0.35,0.14,expression(paste("x=",mu)))
abline(v=mu,col="red")
```
</div>

</div>

## Curtosis o apuntamiento de una variable aleatoria

### Definición

La curtosis de una variable aleatoria $X$ es una medida de cómo son las colas de su función de densidad. 

Dicho en otras palabras, queremos medir de alguna manera la *tendencia* que tiene la variable aleatoria a tener valores atípicos o *outliers*.

La manera estándard de medir la curtosis de una variable aleatoria $X$ es a partir de su **momento central de cuarto orden**:
$$
\gamma_2 = E\left(\left(\frac{X-\mu}{\sigma}\right)^4\right) = \frac{\momentocentral_4}{\sigma^4},
$$
donde recordemos que $\mu=E(X)$ y $\sigma^2 =\mathrm{Var}(X)$.

A la expresión anterior se le denomina **medida de curtosis de Pearson**.

### Definición

* Diremos que una variable aleatoria no tiene exceso de curtosis o **mesocúrtica** si $\gamma_2 \approx 3$.

* Diremos que una variable aleatoria tiene exceso positivo de curtosis o **leptocúrtica** si $\gamma_2 >3$.

* Diremos que una variable aleatoria tiene exceso negativo de curtosis o **platicúrtica** si $\gamma_2 <3$.


### Ejemplo de cálculo de curtosis

<div class="example">
**Ejemplo: cálculo del coeficiente de curtosis para una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable aleatoria de parámetro $p$.

El momento central de cuarto orden de $X$ será:
$$
\momentocentral_4 = p (1-p)^4 +(1-p)p^4 = p (1-p) (3 p^2-3p+1).
$$
La medida de curtosis de Pearson será:
$$
\gamma_2 = \frac{p (1-p) (3 p^2-3p+1)}{p^2 (1-p)^2} = \frac{3 p^2-3p+1}{p(1-p)}.
$$
Se puede comprobar (ejercicio para el lector) que si $p\in \left(\frac{3-\sqrt{3}}{6},\frac{3+\sqrt{3}}{6}\right)\approx (`r round((3-sqrt(3))/6,3)`,`r round((3+sqrt(3))/6,3)`)$, $\gamma_2 <3$ y, por tanto $X$ será platicúrtica y en caso contrario, si $p\in \left(0,\frac{3-\sqrt{3}}{6}\right)\cup \left(\frac{3+\sqrt{3}}{6},1\right)$, $\gamma_2 >3$ y, por tanto, $X$ será leptocúrtica.


</div>


### Ejemplo de cálculo de curtosis
<div class="example">
**Ejemplo: cálculo del coeficiente de curtosis para una variable exponencial de parámetro $\lambda$**

Sea $X$ una variable exponencial de parámetro $\lambda$. 
Usando que $\sigma^2=\frac{1}{\lambda^2}$ y $\momentocentral_4 =\frac{a_4}{\lambda^3}=\frac{9}{\lambda^4}$, su coeficiente de asimetría de Pearson será:
$\gamma_2 = \frac{\frac{9}{\lambda^4}}{\frac{1}{\lambda^4}}=9.$

Como $\gamma_2 >3$, se trataría de una distribución leptocúrtica.
</div>

### Ejemplo de cálculo de curtosis
<div class="example">
**Ejemplo: cálculo del coeficiente de curtosis para una variable normal de parámetros $\mu$ y $\sigma$**

Sea $X$ una variable aleatoria normal de parámetros $\mu$ y $\sigma$. 

Tal como se ha indicado anteriormente, el momento central de orden 4 vale: $\momentocentral_4 = 3\sigma^4$.

Su coeficiente de curtosis será:
$$
\gamma_2 =\frac{\momentocentral_4}{\sigma^4}=\frac{3\sigma^4}{\sigma^4}=3.
$$
Deducimos, por tanto, que toda distribución normal es mesocúrtica o no tiene exceso (ni positivo ni negativo) de curtosis.


</div>

## Métodos de transformación

### Introducción

Hemos visto anteriormente que el cálculo de los **momentos** o los **momentos centrados** de una variable aleatoria $X$ puede ser muy complicado y muy tedioso.

Por dicho motivo, vamos a introducir un conjunto de funciones que nos permitirán calcular los **momentos** de la variable $X$ de forma relativamente sencilla.

### Función generatriz de momentos
<l class="definition">Definición de función generatriz de momentos: </l>
Sea $X$ una variable aleatoria $X$ con función de probabilidad $P_X$ en el caso discreto o función
de densidad $f_X$ en el caso continuo. 

Sea $t\in\mathbb{R}$ un valor real cualquiera. 

Definimos la función generatriz de momentos $\FunGenMom_X(t)$ en el valor $t$ como: $\FunGenMom_X(t)=E\left(\mathrm{e}^{tX}\right).$

### Ejemplo de cálculo de función generatriz de momentos
<div class="example">
**Ejemplo: cálculo de la función generatriz de momentos para una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable aleatoria de Bernoulli de parámetro $p$. Recordemos que su función de probabilidad es:
$$
P_X(0)=q=1-p,\ p_X(1)=p.
$$
Su función generatriz de momentos será:
$$
\FunGenMom_X (t)=E\left(\mathrm{e}^{tX}\right) =p\mathrm{e}^{t\cdot 1}+(1-p)\mathrm{e}^{t\cdot 0}=p\mathrm{e}^t+(1-p)=1+p\left(\mathrm{e}^t -1 \right).
$$
</div>

### Ejemplo de cálculo de función generatriz de momentos
<div class="example">
**Ejemplo: cálculo de la función generatriz de momentos para una variable exponencial de parámetro $\lambda$**

Sea $X$ una variable aleatoria exponencial de parámetro $\lambda$. Recordemos que su función de densidad es: $f_X(x)=\lambda \mathrm{e}^{-\lambda x},$ para $x\geq 0$ y $0$, en caso contrario.

Su función generatriz de momentos será:
$$
\FunGenMom_X (t)=E\left(\mathrm{e}^{tX}\right)=\int_0^\infty \mathrm{e}^{t x}\lambda \mathrm{e}^{-\lambda x}\, dx = \lambda \int_0^\infty\mathrm{e}^{(t-\lambda)x}\, dx = \lambda\left[\frac{\mathrm{e}^{(t-\lambda)x}}{t-\lambda}\right]_{x=0}^{x=\infty} = \frac{\lambda}{\lambda -t},\ \mbox{si } t<\lambda. 
$$
En este caso vemos que el dominio de la función generatriz de momentos $\FunGenMom_X$ es $(-\infty,\lambda)$, ya que si $t\geq \lambda$, la integral anterior no es convergente.

Fijémonos por lo que vendrá más adelante que, como $\lambda >0$, el valor $0$ pertenece al dominio de $\FunGenMom_X$.
</div>

### Ejemplo de cálculo de función generatriz de momentos
<div class="example">
**Ejemplo: cálculo de la función generatriz de momentos para una variable normal de parámetros $\mu$ y $\sigma$**

Sea $X$ una variable normal de parámetros $\mu$ y $\sigma$. 

Recordemos que su función de densidad es: $f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},$ para $x\in \mathbb{R}$.

Su función generatriz de momentos será:

$$
\begin{array}{rl}
\FunGenMom_X (t) & =E\left(\mathrm{e}^{tX}\right)=\int_{-\infty}^\infty \mathrm{e}^{tx}\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{tx-\frac{(x-\mu)^2}{2\sigma^2}}\, dx \\  & =  \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}\left((x-(\sigma^2 t+\mu))^2-2\sigma^2 t \mu-\sigma^4t^2\right)}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \mathrm{e}^{\frac{1}{2}(2 t \mu +\sigma^2 t^2)}\int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 t+\mu))^2}\, dx\\ &  = \mathrm{e}^{\frac{1}{2}(2 t \mu +\sigma^2 t^2)} \left( \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 t+\mu))^2}\, dx\right) =  \mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}}.
\end{array}
$$
La integral del último paréntesis se resuelve haciento el cambio de variable $u=x-\sigma^2 t$ y usando que la integral de la función de densidad de $X$ sobre todo $\mathbb{R}$ vale 1.
</div>

### Relación entre la función generatriz de momentos y los momentos
La razón del nombre que lleva la **función generatriz de momentos** es que podemos obtener todos los momentos de la variable a partir de ella:

<l class="prop"> Proposición </l>
Sean $X$ una variable aleatoria con **función generatriz de momentos** $\FunGenMom_X(t)$. Entonces, el momento de orden $n$ de $X$ se puede obtener de la forma siguiente:
$$
\momento_n =E\left(X^n\right)=\frac{d}{d t^n}\FunGenMom_X(t)|_{t=0} =\FunGenMom_X^{(n)}(0).
$$
O sea, el momento de orden $n$ de $X$ es la derivada $n$-ésima de la función generatriz de momentos evaluada en $t=0$.


### Relación entre la función generatriz de momentos y los momentos
<div class="dem">
**Demostración**

Recordemos la definición de la función generatriz de momentos: $\FunGenMom_X(t)=E\left(\mathrm{e}^{tX}\right).$

La idea de la demostración es probar por inducción que $\FunGenMom_X^{(n)}(t) =E\left(\mathrm{e}^{tX}\cdot X^n\right)$.

Veámoslo para $n=1$: $\FunGenMom_X'(t)=E\left(\mathrm{e}^{tX}\cdot X\right)$. 

Seguidamente, apliquemos inducción sobre $n$. Supongamos que $\FunGenMom_X^{(n)}(t) =E\left(\mathrm{e}^{tX}\cdot X^n\right)$ y veamos que $\FunGenMom_X^{(n+1)}(t) =E\left(\mathrm{e}^{tX}\cdot X^{n+1}\right)$:
$\FunGenMom_X^{(n+1)}(t) =\frac{d}{dt}(\FunGenMom_X^{(n)}(t)) =\frac{d}{dt}E\left(\mathrm{e}^{tX}\cdot X^n\right) = E\left(\mathrm{e}^{tX}\cdot X^{n+1}\right),$
tal como queríamos demostrar.

Ahora si aplicamos la expresión demostrada $\FunGenMom_X^{(n)}(t) =E\left(\mathrm{e}^{tX}\cdot X^n\right)$ a $t=0$, obtenemos:
$\FunGenMom_X^{(n)}(0) =E\left(X^n\right)=\momento_n,$
tal como dice la proposición.
</div>


### Ejemplo
<div class="example">
**Ejemplo: aplicación de la proposición en el caso en que $X$ es una variable de Bernoulli de parámetro $p$**

En este caso, recordemos que: $\FunGenMom_X (t)=1+p\left(\mathrm{e}^t -1 \right).$

Se puede comprobar que $\FunGenMom_X^{(n)}(t)=p\mathrm{e}^t$. Por tanto:
$$
\momento_n = \FunGenMom_X^{(n)}(0)=p,
$$
tal como habíamos calculado anteriormente.
</div>

### Ejemplo
<div class="example">
**Ejemplo: aplicación de la proposición en el caso en que $X$ es una variable exponencial de parámetro $\lambda$**

En este caso, recordemos que: $\FunGenMom_X (t)=\frac{\lambda}{\lambda -t},$ para $t<\lambda$ pero como $\lambda >0$, $t=0$ cumple la expresión anterior.

Dejamos como ejercicio para el lector comprobar que: $\FunGenMom_X^{(n)}(t)=\frac{\lambda n!}{(\lambda-t)^{n+1}}$.

Por tanto: 
$$
\momento_n = \FunGenMom_X^{(n)}(0) = \frac{\lambda n!}{\lambda^{n+1}}=\frac{n!}{\lambda^n},
$$
expresión que ya habíamos obtenido anteriormente.

</div>

### Ejemplo
<div class="example">
**Ejemplo: aplicación de la proposición en el caso en que $X$ es una variable normal de parámetros $\mu$ y $\sigma$**

En este caso, recordemos que: $\FunGenMom_X (t)=\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}}.$

Aplicando la fórmula de los momentos para $n=1$ obtenemos:
$\FunGenMom'(t)=\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}} \left(\mu+t\sigma^2\right)$, que en $t=0$ vale:
$\FunGenMom'(0)=\mu=E(X)$, tal como ya sabemos.

Si la aplicamos para $n=2$, obtenemos:
$\FunGenMom''(t)=\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}} \left((\mu+t\sigma^2)^2+ \sigma^2 \right) =\mathrm{e}^{ t \mu +\frac{\sigma^2 t^2}{2}} \left(t^2\sigma^4+\mu^2+\sigma^2+ 2t\mu\sigma^2 \right)$, que en $t=0$ vale:
$\FunGenMom''(0)=\mu^2+\sigma^2=E\left(X^2\right)$, tal como ya sabemos.

Para $n=3$m obtenemos:
$\FunGenMom'''(t)=e^{\mu  t+\frac{\sigma ^2 t^2}{2}}\left(\mu +\sigma ^2 t\right)
\left(\left(\mu +\sigma ^2 t\right)^2+3 \sigma ^2\right)$, que en $t=0$ vale: $\FunGenMom'''(0)=3\sigma^2\mu = E\left(X^3\right)$, valor que correspondería al momento de tercer orden de $X$.

Por último, para $n=4$, obtenemos:
$\FunGenMom^{(iv)}(t)=e^{\mu  t+\frac{\sigma ^2 t^2}{2}}
   \left(6 \sigma ^2 \left(\mu
   +\sigma ^2 t\right)^2+\left(\mu
   +\sigma ^2 t\right)^4+3 \sigma
   ^4\right)$, que en $t=0$ vale: $\FunGenMom^{(iv)}(0)=6\sigma^2\mu^2+\mu^4+3\sigma^4=E\left(X^4\right)$, valor que correspondería al momento de cuarto orden de $X$.


</div>

### Función característica
<l class="definition">Definición de función característica: </l>
Sea $X$ una variable aleatoria $X$ con función de probabilidad $P_X$ en el caso discreto o función
de densidad $f_X$ en el caso continuo. 

Sea $w\in\mathbb{R}$ un valor real cualquiera. 

Definimos la función característica $\FunCar_X(w)$ en el valor $w$ como: $\FunCar_X(w)=E\left(\mathrm{e}^{\mathrm{i} w X}\right),$  donde $\mathrm{i}$ es el número complejo $\mathrm{i}=\sqrt{-1}$.

### Función característica

<l class="observ">Observación: </l>
Si $X$ es una variable continua, la **función característica** $\FunCar_X(w)$ puede interpretarse como la **transformada de Fourier** de la **función de densidad** de $X$:
$\FunCar(w)=\int_{-\infty}^\infty f_X(x)\mathrm{e}^{\mathrm{i}w x}\, dx.$

Por tanto, usando la fórmula de la **antitransformada de Fourier**, podemos escribir la **función de densidad** $f_X(x)$ como función de la **función característica** de $X$, $\FunCar(w)$:
$f_X(x)=\frac{1}{2\pi}\int_{-\infty}^\infty \FunCar_X(w)\mathrm{e}^{-\mathrm{i}w x}\, dw.$

### Función característica

<l class="observ">Observación: </l>
En el caso discreto, o sea, Si $X$ es una variable discreta, la **función característica** $\FunCar_X(w)$ se escribe como función de la **función de probabilidad** $P_X(x_k)$ con **Dominio** $D_X=\{x_k,\ k\}$ como:
$\FunCar(w)=\sum_{k} P_X(x_k)\mathrm{e}^{\mathrm{i}w x_k}.$

En los casos en que los $x_k$ sean enteros, $x_k=k$, que son la mayoría, la ecuación anterior es la **tranformada de Fourier de la secuencia** $P_X(k)$. Dicha función es una *función periódica* en $w$ de periodo $2\pi$ ya que $\mathrm{e}^{\mathrm{i}(w+2\pi)k}=\mathrm{e}^{\mathrm{i}wk}.$

Por tanto, usando la fórmula de **inversión**,  podemos escribir la **función de probabilidad** $P_X(k)$ como función de la función característica de $X$, $\FunCar(w)$:
$P_X(k)=\frac{1}{2\pi}\int_{0}^{2\pi} \FunCar_X(w)\mathrm{e}^{-\mathrm{i}w k}\, dw.$

### Ejemplo de cálculo de función característica
<div class="example">
**Ejemplo: cálculo de la función característica para una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable aleatoria de Bernoulli de parámetro $p$. Recordemos que su función de probabilidad es:
$$
P_X(0)=q=1-p,\ p_X(1)=p.
$$
Su función característica será:
$$
\FunCar_X (w)=E\left(\mathrm{e}^{\mathrm{i}wX}\right) =p\mathrm{e}^{\mathrm{i}w\cdot 1}+(1-p)\mathrm{e}^{\mathrm{i}w\cdot 0}=p\mathrm{e}^{\mathrm{i}w}+(1-p)=1+p\left(\mathrm{e}^{\mathrm{i}w} -1 \right).
$$
Comprobemos la fórmula de la inversión:
$$
\begin{array}{rl}
P_X(1) & = \frac{1}{2\pi}\int_0^{2\pi} \left(1+p\left(\mathrm{e}^{\mathrm{i}w} -1 \right)\right) e^{-\mathrm{i}w\cdot 1}\, dw =\frac{1}{2\pi}\left(\int_0^{2\pi} (1-p)e^{-\mathrm{i}w}\, dw + \int_0^{2\pi} p\, dw\right) \\ & = \frac{1}{2\pi}\left( (1-p) \left[\frac{\mathrm{e}^{-\mathrm{i}w}}{-\mathrm{i}}\right]_0^{2\pi} +2\pi p\right)=\frac{1}{2\pi}\left((1-p)\cdot 0 +2\pi p\right)=p, \\
P_X(0) & = \frac{1}{2\pi}\int_0^{2\pi} \left(1+p\left(\mathrm{e}^{\mathrm{i}w} -1 \right)\right) e^{-\mathrm{i}w\cdot 0}\, dw =\frac{1}{2\pi}\left(\int_0^{2\pi} (1-p) \, dw + \int_0^{2\pi} p \mathrm{e}^{\mathrm{i}w}\, dw\right) \\ & = \frac{1}{2\pi}\left( (1-p) \cdot 2\pi  +p \left[\frac{\mathrm{e}^{\mathrm{i}w}}{\mathrm{i}}\right]_0^{2\pi}\right)=\frac{1}{2\pi}\left((1-p)\cdot 2\pi + p\cdot 0\right)=1-p.
\end{array}
$$
</div>

### Ejemplo de cálculo de función característica
<div class="example">
**Ejemplo: cálculo de la función característica para una variable exponencial de parámetro $\lambda$**

Sea $X$ una variable aleatoria exponencial de parámetro $\lambda$. Recordemos que su función de densidad es: $f_X(x)=\lambda \mathrm{e}^{-\lambda x},$ para $x\geq 0$ y $0$, en caso contrario.

Su función característica será:
$$
\FunCar_X (w)=E\left(\mathrm{e}^{\mathrm{i}wX}\right)=\int_0^\infty \mathrm{e}^{\mathrm{i}w x}\lambda \mathrm{e}^{-\lambda x}\, dx = \lambda \int_0^\infty\mathrm{e}^{(\mathrm{i}w-\lambda)x}\, dx = \lambda\left[\frac{\mathrm{e}^{(\mathrm{i}w-\lambda)x}}{\mathrm{i}w-\lambda}\right]_{x=0}^{x=\infty} = \frac{\lambda}{\lambda -\mathrm{i} w}. 
$$
La expresión anterior es válida para todo $w\in\mathbb{R}$ ya que su valor sería:
$\FunCar_X (w)=\frac{\lambda}{\lambda -\mathrm{i} w}\cdot \frac{\lambda +\mathrm{i} w}{\lambda +\mathrm{i} w}=\frac{\lambda^2+\mathrm{i}\lambda w}{\lambda^2+w^2}=\frac{\lambda^2}{\lambda^2+w^2}+\mathrm{i}\frac{\lambda w}{\lambda^2+w^2}.$
En la última expresión hemos separado la parte real de la imaginaria.

Calculemos la función de densidad a partir de la función característica:
$$
f_X(x)=\frac{1}{2\pi}\int_{-\infty}^\infty \frac{\lambda}{\lambda -\mathrm{i} w}\mathrm{e}^{-\mathrm{i}wx}\, dw = a\mathrm{e}^{-a x},
$$
si $x>0$ y $0$ en caso contrario. El cálculo de la integral anterior debe realizarse usando el *Teorema de los Residuos*,  [Residue theorem](https://en.wikipedia.org/wiki/Residue_theorem) y se sale de los objetivos de este curso.
</div>

### Ejemplo de cálculo de función característica
<div class="example">
**Ejemplo: cálculo de la función característica para una variable normal de parámetros $\mu$ y $\sigma$**

Sea $X$ una variable normal de parámetros $\mu$ y $\sigma$. 

Recordemos que su función de densidad es: $f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},$ para $x\in \mathbb{R}$.

Su función característica será:

$$
\begin{array}{rl}
\FunCar_X (w) & =E\left(\mathrm{e}^{\mathrm{i}w X}\right)=\int_{-\infty}^\infty \mathrm{e}^{\mathrm{i}w x}\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{\mathrm{i}wx-\frac{(x-\mu)^2}{2\sigma^2}}\, dx \\  & =  \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}\left((x-(\sigma^2 \mathrm{i}w+\mu))^2-2\sigma^2 \mathrm{i}w \mu+\sigma^4 w^2\right)}\, dx = \frac{1}{\sqrt{2\pi}\sigma} \mathrm{e}^{\frac{1}{2}(2 \mathrm{i}w \mu -\sigma^2 w^2)}\int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 \mathrm{i}w+\mu))^2}\, dx\\ &  = \mathrm{e}^{\frac{1}{2}(2 \mathrm{i}w \mu -\sigma^2 w^2)} \left( \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty \mathrm{e}^{-\frac{1}{2\sigma^2}(x-(\sigma^2 \mathrm{i}w+\mu))^2}\, dx\right) =  \mathrm{e}^{ \mathrm{i}w \mu -\frac{\sigma^2 w^2}{2}}.
\end{array}
$$
La integral del último paréntesis se resuelve haciento el cambio de variable $u=x-\sigma^2 \mathrm{i}w$ y usando que la integral de la función de densidad de $X$ sobre todo $\mathbb{R}$ vale 1.
</div>


### Ejemplo de cálculo de función característica
<div class="example">
**Ejemplo: cálculo de la función característica para una variable normal de parámetros $\mu$ y $\sigma$**

Calculemos la función de densidad a partir de la función característica:
$$
\begin{array}{rl}
f_X(x) & =\frac{1}{2\pi}\int_{-\infty}^\infty \mathrm{e}^{ \mathrm{i}w \mu -\frac{\sigma^2 w^2}{2}}\mathrm{e}^{-\mathrm{i} w x}\, dw = \frac{1}{2\pi}\int_{-\infty}^\infty \mathrm{e}^{\left(\frac{\mathrm{i}w\sigma}{\sqrt{2}}+\frac{\mu-x}{\sigma\sqrt{2}}\right)^2-\frac{(\mu-x)^2}{2\sigma^2}}\, dw =\frac{1}{2\pi}\mathrm{e}^{-\frac{(\mu-x)^2}{2\sigma^2}}\int_{-\infty}^\infty \mathrm{e}^{\left(\frac{\mathrm{i}w\sigma}{\sqrt{2}}+\frac{\mu-x}{\sigma\sqrt{2}}\right)^2}\, dw \\ & = \frac{1}{2\pi}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\int_{-\infty}^\infty \mathrm{e}^{-\left(\frac{w\sigma}{\sqrt{2}}+\frac{\mu-x}{\mathrm{i}\sigma\sqrt{2}}\right)^2}\, dw \stackrel{\mbox{cambio de variable } u=\frac{w\sigma}{\sqrt{2}}+\frac{\mu-x}{\mathrm{i}\sigma\sqrt{2}}}{=} \frac{1}{2\pi}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}}\int_{-\infty}^\infty \frac{\sqrt{2}}{\sigma}\mathrm{e}^{-u^2}\, du \\ & \stackrel{\int_{-\infty}^\infty \mathrm{e}^{-u^2}\, du =\sqrt{\pi}}{=} \frac{1}{\sqrt{2}\pi\sigma} \mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}} \sqrt{\pi} = \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x-\mu)^2}{2\sigma^2}},
\end{array}
$$
función que coincide con la densidad de la distribución $N(\mu,\sigma)$.

</div>

### Relación entre la función característica y los momentos
La relación entre la **función característica** y los **momentos** es la siguiente:

<l class="prop"> Proposición </l>
Sean $X$ una variable aleatoria con **función característica** $\FunCar_X(w)$. Entonces, el momento de orden $n$ de $X$ se puede obtener de la forma siguiente:
$$
\momento_n =E\left(X^n\right)=\frac{1}{\mathrm{i}^n}\frac{d}{d w^n}\FunCar_X(w)|_{w=0} =\frac{1}{\mathrm{i}^n}\FunCar_X^{(n)}(0).
$$
O sea, el momento de orden $n$ de $X$ es la derivada $n$-ésima de la función característica evaluada en $w=0$ dividido por $\mathrm{i}^n$.


### Relación entre la función característica y los momentos
<div class="exercise">
**Ejercicio**

La demostración se realiza de forma similar a la demostración de la proposición que relaciona la función generatriz de momentos y los momentos. 

Se deja como ejercicio al lector.
</div>


<div class="exercise">
**Ejercicio**

Realizar los mismos ejemplos que los realizados para la función generatriz de momentos. O sea:

* Si $X$ es una variable de Bernoulli de parámetro $p$, demostrar usando la función característica que para todo $n$, $\momento_n = E\left(X^n\right)=p$.

* Si $X$ es una variable exponencial de parámetro $\lambda$, demostrar usando la función característica que para todo $n$, $\momento_n =  E\left(X^n\right)=\frac{n!}{\lambda^n}$.

* Si $X$ es una variable normal de parámetros $\mu$ y $\sigma$, demostrar usando la función característica que $E(X)=\mu$, $E\left(X^2\right)=\mu^2+\sigma^2$, $E\left(X^3\right)=3\sigma^2\mu$ y $E\left(X^4\right)=6\sigma^2\mu^2+\mu^4+3\sigma^4$.


</div>


## Fiabilidad

### Introducción

Sea $T\geq 0$ una variable aleatoria que nos da, por ejemplo, el tiempo de vida de cierto componente o dispositivo.

Vamos a definir medidas para estudiar la fiabilidad de este tipo de variables aleatorias.



<l class="definition">Definición:</l>
Sea $T\geq 0$ una variable aleatoria. La **fiabilidad** de $T$ en el tiempo $t$ se define como la probabilidad que el sistema, componente o dispositivo funcione en el tiempo $t$: $R(t)=P(T>t)$.

<l class="observ">Observación:</l>
Dada una variable $T\geq 0$, la relación existente entre la **fiabilidad** $R$ y la **función de distribución** $F_T$ es la siguiente:
$$
R(t)=P(T>t)=1-P(T\leq t)=1-F_T (t)
$$

### Tiempo medio de vida

<l class="observ">Observación:</l>
Dada una variable $T\geq 0$ continua, el **tiempo medio de vida** de la variable $T$ sería $E(T)$. Entonces, este **tiempo medio de vida** se puede calcular como: 
$E(T)=\int_0^\infty R(t)\, dt.$

Veámoslo. Para ello basta ver que $E(T)=\int_0^\infty (1-F_T(t))\, dt$, donde $F_T(t)$ es la función de distribución de la variable $T$:
$$
\begin{array}{rl}
E(T) & =\int_{t=0}^{t=\infty} 1-F_T(t)\, dt=\int_{t=0}^{t=\infty}\int_{u=t}^{u=\infty} f_T(u)\,du\,dt \\ & =\int_{u=0}^{u=\infty} f_T(u)\int_{t=0}^{t=u} \, dt\, du =\int_{u=0}^{u=\infty} f_T(u)\cdot u\, du = E(T),
\end{array}
$$
donde $f_T(u)$ seria la función de densidad de la variable $T$ en el valor $u$.


### Ejemplo
<div class="example">
**Ejemplo**

Sea $T$ una variable aleatoria exponencial de parámetro $\lambda$.

La fiabilidad de $T$ sería: $R(t)=P(T>t)=1-F_T(t)=\mathrm{e}^{-\lambda t}$:
<div class="center">
```{r,echo=FALSE,fig=TRUE,warning=FALSE}
x=seq(from=0,to=4, by=0.01)
lambda=2
plot(x,1-pexp(x,lambda),type="l",ylab="función de fiabilidad")
```
</div>

</div>

## Generación de muestras de variables aleatorias por ordenador

### Introducción 

La simulación por **computadora** de cualquier fenómeno aleatorio implica la **generación de variables aleatorias** con distribuciones prefijadas de antemano. 

Por ejemplo, la simulación de un sistema de colas implica generar el tiempo entre las llegadas de los clientes, así como los tiempos de servicio de cada cliente.

Fijémonos que fijar la variable aleatoria $X$ es equivalente a fijar la **función de distribución $F_X(x)$** o la **función de densidad $f_X(x)$** en el caso continuo o la **función de probabilidad $P_X(x)$** en el caso discreto.

Todos los métodos que vamos a describir presuponen que podemos generar **números aleatorios** que se distribuyen **uniformemente** entre 0 y 1. En `R` se puede hacer usando la función `runif(n)`, donde `n` es la cantidad de números aleatorios entre 0 y 1 a generar.


### Método de transformación

El **método de transformación** se basa en el resultado siguiente:

<l class="prop">Proposición: </l>
Sea $X$ una variable aleatoria con función de distribución $F_X(x)$. Supongamos que $F_X(x)$ es estrictamente creciente o que existe $F_X^{-1}(y)$, para todo $y\in [0,1]$. Sea $Y$ la variable aleatoria definida como: $Y=F_X(X)$. Entonces la distribución de $Y$ es uniforme en el intervalo $[0,1]$.

<div class="dem">
**Demostración:**

Claramente, por propia definición de $Y$, tenemos que el dominio de $Y$ es $[0,1]$ ya que el conjunto recorrido de la función de distribución de cualquier variable es el intervalo $[0,1]$. 

Para ver que la distribución de $Y$ es $U[0,1]$ basta comprobar que $F_Y(y)=y$, para todo $y\in [0,1]$:
$$
\begin{array}{rl}
F_Y(y) & =P(Y\leq y)=P(F_X(X)\leq y)\stackrel{\mbox{usando que $F_X$ es estrictamente creciente}}{=} P(X\leq F_X^{-1}(y)) \\ & =F_X(F_X^{-1}(y))=y.
\end{array}
$$
</div>

### Método de transformación

Usando la proposición anterior, dada una variable $X$, como la distribución de la variable aleatoria $Y=F_X(X)$ es $U[0,1]$, si hacemos $X=F_X^{-1}(Y)$, tendremos que si sabemos generar una muestra de $Y$, aplicándole a la muestra la función $F_X^{-1}$ tendremos generada una muestra de $X$.


### Ejemplo
<div class="example">
**Ejemplo: generar una muestra de una variable exponencial de parámetro $\lambda$**

Recordemos que si $X$ es exponencial de parámetro $\lambda$, su función de distribución es: $F_X(x)=1-\mathrm{e}^{-\lambda x}$.

Hallemos a continuación $F_X^{-1}$:
$$
y=1-\mathrm{e}^{-\lambda x},\ \Leftrightarrow 1-y=\mathrm{e}^{-\lambda x},\ \Leftrightarrow \ln(1-y)=-\lambda x,\ \Leftrightarrow x=-\frac{1}{\lambda}\ln(1-y).
$$
Por tanto, $F_X^{-1}(y)=-\frac{1}{\lambda}\ln(1-y)$.
</div>

### Ejemplo
<div class="example">
**Ejemplo: generar una muestra de una variable exponencial de parámetro $\lambda$**

Generemos una muestra con `R` de 25 valores de una variable exponencial de parámetro $\lambda=2$ usando el método anterior:
```{r}
n=25
lambda=2
muestra.y = runif(n)
muestra.x = -(1/lambda)*log(1-muestra.y)
muestra.x
```



</div>


### Ejemplo
<div class="example">
**Ejemplo: generar una muestra de una variable exponencial de parámetro $\lambda$**

Vamos a testear si nuestro método funciona. 

Para ello generaremos una muestra de 500 valores usando el método de transformación y dibujaremos su **histograma de frecuencias relativas**.

Seguidamente dibujaremos la **función de densidad de la variable exponencial de parámetro $\lambda$** y compararemos los resultados:

```{r,eval=FALSE}
n=500
lambda=2
muestra.y = runif(n)
muestra.x = -(1/lambda)*log(1-muestra.y)
hist(muestra.x,freq=FALSE,main="Histograma de la muestra")
x2=seq(from=0,to=2.5,by=0.01)
lines(x2,dexp(x2,lambda),col="red")
```


</div>

### Ejemplo
<div class="example">
**Ejemplo: generar una muestra de una variable exponencial de parámetro $\lambda$**
<div class="center">

```{r,echo=FALSE}
n=500
lambda=2
set.seed(2019)
muestra.y = runif(n)
muestra.x = -(1/lambda)*log(1-muestra.y)
hist(muestra.x,freq=FALSE,main="Histograma de la muestra")
x2=seq(from=0,to=2.5,by=0.01)
lines(x2,dexp(x2,lambda),col="red")
```

</div>

</div>

### Método de rechazo

Sea $X$ una variable aleatoria continua tal que su función de densidad verifica:

* Existen valores $a$ y $b$ tal que $f_X(x)= 0$ si $x\not\in [a,b]$.
* Existen valores $c$ y $d$ tal que $f_X(x)\in [c,d]$, si $x\in [a,b]$.

En resumen, los puntos $(x,f(x))$ pertenecen al rectángulo $[a,b]\times [c,d]$ y en caso contrario $f_X(x)=0$.

En el gráfico siguiente, $a=0$, $b=2$, $c=0$ y $d=1$.


### Método de rechazo

<div class="center">


```{r,echo=FALSE}
xmin=0
xmax=2
ymin=0
ymax=2
tolx=0.01*(xmax-xmin)
toly=0.05*(ymax-ymin)
quantsx=2
quantsy=2
f = function(x){ifelse(x>=0 & x<=1,x,ifelse(x>=1&x<=2,2-x,0))}
plot(c(xmin-tolx,xmax+tolx,xmin-tolx,xmax+tolx),c(ymin-toly,ymin-toly,ymax+toly,ymax+toly),type="n",xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE)
x=seq(from=xmin,to=xmax,by=0.01)
#points(x,f(x),type="l")
lines(c(xmin,xmin),c(ymin,ymax))
lines(c(xmin,xmax),c(ymin,ymin))
text(xmax-3*tolx,-4*tolx,"x")
text(toly,ymax+toly/2,"y")
for (i in 0:(quantsx)){
  lines(rep(xmin+((xmax-xmin)/quantsx)*i,2),c(ymin-0.5*toly,ymin+0.5*toly))
  text(xmin+((xmax-xmin)/quantsx)*i,ymin-1*toly,xmin+((xmax-xmin)/quantsx)*i,cex=0.75)}
for (i in 0:(quantsy)){
  lines(c(xmin-tolx,xmin+tolx),rep(ymin+((ymax-ymin)/quantsy)*i,2))
  text(xmin-3*tolx,ymin+((ymax-ymin)/quantsy)*i,ymin+((ymax-ymin)/quantsy)*i,cex=0.75)}
x2=seq(from=xmin,to=xmax,by=0.01)
lines(x2,f(x2),col="red")
lines(c(0,2),c(1,1),col="blue")
lines(c(2,2),c(0,1),col="blue")
text(0.35,0.5,expression(f[X](x)))
```
</div>


### Método de rechazo

Para generar una **muestra aleatoria** de la variable $X$, hacemos lo siguiente:

1) generamos un valor aleatorio $x$ entre $a$ y $b$.

2) generamos un valor aleatorio $y$ entre $c$ y $d$.

3) si $y\leq f_X(x)$, aceptamos $x$ como valor de la muestra. En caso contrario, volvemos a empezar en 1.


### Ejemplo
<div class="example">
**Ejemplo**

El gráfico de la figura anterior corresponde a la función de densidad siguiente:
$$
f_X(x)=\begin{cases}
x, & \mbox{ si }0\leq x\leq 1,\\
2-x, & \mbox{ si }1\leq x\leq 2,\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
</div>

### Ejemplo
<div class="example">

Vamos a generar una muestra de $25$ valores usando el **método del rechazo**:
```{r}
a=0; b=2; c=0; d=1; n=25; i=1;
f = function(x){ifelse(x>=0 & x<=1,x,ifelse(x>=1&x<=2,2-x,0))}
muestra=c()
while(i <=n){
  x=runif(1,a,b)
  y=runif(1,c,d)
  if(y <= f(x)){muestra=c(muestra,x); i=i+1}
}
muestra
```
</div>

### Ejemplo
<div class="example">
Como hicimos con el ejemplo del **método de transformación**, vamos a generar una muestra de 500 valores de la variable $X$, vamos a dibujar el **histograma de frecuencias relativas** junto con la función de densidad para ver si ésta se aproxima a dicho histograma:
```{r,eval=FALSE}
a=0; b=2; c=0; d=1; n=500; i=1;
f = function(x){ifelse(x>=0 & x<=1,x,ifelse(x>=1&x<=2,2-x,0))}
muestra=c()
while(i <=n){
  x=runif(1,a,b)
  y=runif(1,c,d)
  if(y <= f(x)){muestra=c(muestra,x); i=i+1}
}
hist(muestra,freq=FALSE,main="Histograma de la muestra")
x2=seq(from=0,to=2,by=0.01)
lines(x2,f(x2),col="red")
```

</div>


### Ejemplo
<div class="center">

```{r,echo=FALSE}
a=0; b=2; c=0; d=1; n=500; i=1;
f = function(x){ifelse(x>=0 & x<=1,x,ifelse(x>=1&x<=2,2-x,0))}
muestra=c()
while(i <=n){
  x=runif(1,a,b)
  y=runif(1,c,d)
  if(y <= f(x)){muestra=c(muestra,x); i=i+1}
}
hist(muestra,freq=FALSE,ylab="frecuencias relativas",main="Histograma de la muestra", ylim = c(0,1))
x2=seq(from=0,to=2,by=0.01)
lines(x2,f(x2),col="red")
```
</div>

## Entropía

### Introducción

La **entropía** es una medida de la **incertidumbre** en un experimento aleatorio. 

Veremos cómo la **entropía** cuantifica la **incertidumbre** por la cantidad de **información** requerida para especificar el resultado de un experimento aleatorio. 


### Entropía de una variable aleatoria
Supongamos que tenemos una variable aleatoria $X$ discreta con valores enteros: $D_X=\{1,2,\ldots,N\}$.

Sea $k\in D_X$ un valor de la variable. Estamos interesados en cuantificar la **incertidumbre** del suceso $A_k =\{X=k\}$. 

O sea, cuánta **menos incertidumbre** tenga $A_k$, más **alta será su probabilidad**, y cuánta **más incertidumbre**, **menos probabilidad** de aparecer $A_k$.

### Entropía de una variable aleatoria

Una medida que cumple las condiciones anteriores es la siguiente: $I(A_k)=I(\{X=k\})=\ln\left(\frac{1}{P(X=k)}\right)=-\ln\left(P(X=k)\right).$

Por ejemplo, si $P(A_k)=1$, o sea, $A_k$ aparece "**seguro**", entonces tiene incertidumbre **nula**, $I(A_k)=0$, y si $P(A_k)=0$, o sea, $A_k$ no aparece "**nunca**", tiene incertidumbre **máxima**, $I(A_k)=\infty$.


### Entropía de una variable aleatoria
La motivación anterior hace que definamos la **entropía** de una variable aleatoria de la forma siguiente:

<l class="definition">Definición:</l>
Sea $X$ una variable aleatoria con función de densidad $f_X(x)$ en el caso continuo o función de probabilidad $P_X(x)$ en el caso discreto. Definimos **entropía de X** como: 
$\Entropia_X = E\left(-\ln(f_X)\right)=\int_{-\infty}^\infty -\ln(f_X(x)) f_X(x)\, dx,$ en el caso continuo y,
$\Entropia_X = E\left(-\ln(P_X)\right)=\sum_{x_k\in D_X} -\ln(P_X(x_k)) P_X(x_k),$ en el caso discreto.

### Ejemplo
<div class="example">
**Ejemplo: entropía de una variable de Bernoulli de parámetro $p$**

Sea $X$ una variable de Bernoulli de parámetro $p$.

Recordemos que su función de probabilidad $P_X$ es: $P_X(0)=1-p=q,$ $P_X(1)=p$.

La entropía de $X$ será:
$$
\Entropia_X = E\left(-\ln(P_X)\right) = -(1-p)\cdot \ln(1-p)-p\cdot \ln p.
$$
El gráfico de la entropía se puede observar en el gráfico siguiente donde $X$ tiene entropía máxima cuando $p=\frac{1}{2}$ que sería cuando $X$ tiene incertidumbre máxima al tratar de adivinar el resultado de $X$ y $X$ tiene entropía mínima cuando $p=0$ o $p=1$ ya que en estos casos el resultado de $X$ sería siempre $0$ o $1$, respectivamente.

</div>

### Ejemplo
<div class="example">
**Ejemplo: entropía de una variable de Bernoulli de parámetro $p$**
<div class="center">
```{r,echo=FALSE,fig=TRUE}
x=seq(from=0,to=1,by=0.01)
f=function(x){-((1-x)*log(1-x)+x*log(x))}
plot(x,f(x),type="l",ylab="Entropía")
```
</div>
</div>

### Ejemplo

<div class="example">
**Entropía de una variable aleatoria exponencial de parámetro $\lambda$**

Sea $X$ una variable aleatoria exponencial de parámetro $\lambda$. 

Recordemos que su función de densidad es: $f_X(x)=\lambda \mathrm{e}^{-\lambda x}$, si $x\geq 0$ y $f_X(x)=0$, en caso contrario.

Su entropía será:
$$
\begin{array}{rl}
\Entropia_X & = E\left(-\ln(f_X)\right)=-\int_0^\infty \ln\left(\lambda\mathrm{e}^{-\lambda x}\right)\lambda\mathrm{e}^{-\lambda x}\, dx = -\lambda \int_0^\infty (\ln(\lambda) -\lambda x)\mathrm{e}^{-\lambda x}\, dx \\ & = -\ln (\lambda)\int_0^\infty \lambda\mathrm{e}^{-\lambda x}\, dx+\lambda \int_0^\infty \lambda x \mathrm{e}^{-\lambda x}\, dx =-\ln(\lambda)\int_0^\infty f_X(x)\, dx +\lambda E(X)\\ & =-\ln(\lambda)+\lambda \frac{1}{\lambda} =1-\ln(\lambda).
\end{array}
$$
El gráfico de la entropía se puede observar en el gráfico siguiente donde $X$ tiene entropía máxima cuando $\lambda=0$ que sería cuando $X$ tiene incertidumbre máxima al tratar de adivinar el resultado de $X$ al tener media $E(X)=\frac{1}{\lambda}=\infty$ y $X$ tiene entropía mínima cuando $\lambda$ tiende a $\infty$ ya que su media $E(X)=\frac{1}{\lambda}$ tendería a 0.

</div>


### Ejemplo
<div class="example">
**Ejemplo: entropía de una variable exponencial de parámetro $\lambda$**
<div class="center">
```{r,echo=FALSE,fig=TRUE}
x=seq(from=0,to=5,by=0.01)
f=function(x){1-log(x)}
plot(x,f(x),type="l",ylab="Entropía")
```
</div>

</div>

<!--chapter:end:4.Rmd-->

# Vectores aleatorios bidimensionales

## Dos variables aleatorias

### Introducción
Muchos experimentos aleatorios involucran varias variables aleatorias. 

Por ejemplo, dado un individuo de 30 años escogido al azar de una cierta población, medir su altura y su peso conjuntamente.

Otro ejemplo más complejo sería la medición continuada de un *fenómeno aleatorio* que se repite en el tiempo, como sería medir la temperatura media un día determinado del año, por ejemplo el día 1 de enero en un cierto lugar. 

La variable aleatoria que nos da la medición en 10 años sería una variable aleatoria de varias variables que involucra 10 variables aleatorias supuestas independientes e idénticamente distribuidas, lo que en **estadística inferencial** se le llama una **muestra aleatoria simple**.

### Dos variables aleatorias. Definición

Recordemos que una **variable aleatoria** $X$ es una aplicación que toma valores numéricos para cada resultado de un experimento aleatorio:
$$
\begin{array}{rl}
(X,Y): \Omega & \longrightarrow \mathbb{R}\\
w & \longrightarrow X(w).
\end{array}
$$
A partir de la definición anterior, generalizamos la noción de **variable aleatoria unidimensional** a **variable aleatoria bidimensional**:

<l class="definition">Definición de variable aleatoria bidimensional:</l>
Dado un experimento aleatorio con **espacio muestral** $\Omega$, definimos **variable aleatoria bidimensional** $(X,Y)$ a toda aplicación 
$$
\begin{array}{rl}
X: \Omega & \longrightarrow \mathbb{R}^2\\
w & \longrightarrow (X(w),Y(w)).
\end{array}
$$

### Dos variables aleatorias. Ejemplos
<div class="example">
**Ejemplo**

Consideremos el experimento aleatorio de lanzar un dado no trucado dos veces.

Sea $S$ la suma de los resultados obtenidos y $P$ el producto de los mismos. 

La variable aleatoria $(S,P)$ que asigna a cada resultado $w=(x_1,x_2)$ donde $x_1$ es el resultado obtenido en el primer lanzamiento y $x_2$, el resultado obtenido en el segundo, los valores: $S(w)=x_1+x_2$ y $P(w)=x_1\cdot x_2$ sería una variable aleatoria bidimensional.

El suceso $\{2\leq S\leq 4,\ 3\leq P\leq 6\}$ seria:
$$
\{2\leq S\leq 4,\ 3\leq P\leq 6\} = \{(1,3),(3,1),(2,2)\}.
$$

</div>
<div class="example">
**Ejemplo**

Consideremos el experimento aleatorio de elegir al azar un estudiante de primer curso de grado. Sea $w$ el estudiante elegido. Consideremos la variable aleatoria $(H,W)$ que asigna a dicho estudiante $w$, $H(w):$ la altura de dicho estudiante en cm. y $W(w):$ el peso de dicho estudiante en kg.

Estamos interesado en sucesos del tipo $A=\{H\leq 176,\ W\leq 85\}$, o sea, el conjunto de estudiantes que miden menos de 1.76 m. y que pesan menos de 85 kg.
</div>

<!-- ### Dos variables aleatorias. Introducción  -->
<!-- Los sucesos que se derivan de una **variable aleatoria bidimensional** estan especificados por regiones del plano. -->
<!-- Veamos algunos ejemplos: -->

<!-- * Suceso: $\{X+Y\leq 1\}$. Sería la zona sombreada del gráfico siguiente: -->

<!-- ```{r,echo=FALSE} -->
<!-- xmin=-2 -->
<!-- xmax=3 -->
<!-- ymin=-2 -->
<!-- ymax=3 -->
<!-- tolx=0.0075*(xmax-xmin) -->
<!-- toly=0.0075*(ymax-ymin) -->
<!-- quantsx=5 -->
<!-- quantsy=5 -->
<!-- f = function(x){1-x} -->
<!-- plot(c(xmin-tolx,xmax+tolx,xmin-tolx,xmax+tolx),c(ymin-toly,ymin-toly,ymax+toly,ymax+toly),type="n",xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE) -->
<!-- x=seq(from=xmin,to=xmax,by=0.01) -->
<!-- #points(x,f(x),type="l") -->
<!-- lines(c(0,0),c(ymin,ymax)) -->
<!-- lines(c(xmin,xmax),c(0,0)) -->
<!-- text(xmax-tolx,2*tolx,"x") -->
<!-- text(toly,ymax+toly/2,"y") -->
<!-- for (i in 0:(quantsx)){ -->
<!--   lines(rep(xmin+((xmax-xmin)/quantsx)*i,2),c(-0.5*toly,0.5*toly)) -->
<!--   text(xmin+((xmax-xmin)/quantsx)*i,-3*toly,xmin+((xmax-xmin)/quantsx)*i,cex=0.75)} -->
<!-- for (i in 0:(quantsy)){ -->
<!--   lines(c(-tolx,tolx),rep(ymin+((ymax-ymin)/quantsy)*i,2)) -->
<!--   text(-3*tolx,ymin+((ymax-ymin)/quantsy)*i,ymin+((ymax-ymin)/quantsy)*i,cex=0.75)} -->
<!-- x2=seq(from=xmin,to=xmax,by=0.01) -->
<!-- lines(x2,f(x2),col="red") -->
<!-- #for (i in 1:length(x2)){ -->
<!-- ##  lines(c(x2[i],x2[i]),c(-2,f(x2[i])),lty=1) -->
<!-- #} -->
<!-- polygon(c(xmax,xmin,x2),c(ymin,ymin,f(x2)),col="red") -->
<!-- #for (i in 1:(length(x2)-1)){ -->
<!-- ##  polygon(c(x2[i],x2[i+1],x2[i+1],x2[i]),c(-2,-2,f(x2[i+1]),f(x2[i])),col="blue") -->
<!-- #} -->
<!-- ``` -->


### Dos variables aleatorias. Introducción 
Los sucesos que se derivan de una **variable aleatoria bidimensional** estan especificados por regiones del plano.
Veamos algunos ejemplos:

Suceso: $\{X+Y\leq 1\}$. Sería la zona sombreada del gráfico siguiente:

<div class="center">

```{r, echo=FALSE, label=bid1_1,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/Bidim1.png",dpi=1200)
```
</div>

### Dos variables aleatorias. Introducción 
Suceso: $\{X^2+Y^2\leq 4\}$. Sería la zona sombreada del gráfico siguiente:

<div class="center">

```{r, echo=FALSE, label=bid2,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/Bidim2.png",dpi=1200)
```
</div>

### Dos variables aleatorias. Introducción 
Suceso: $\{\max\{X,Y\}\geq 1\}$. Sería la zona sombreada del gráfico siguiente:

<div class="center">

```{r, echo=FALSE, label=bid3,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/Bidim3.png",dpi=1200)
```
</div>

### Dos variables aleatorias. Introducción 

La probabilidad de que la **variable bidimensional** pertenezca a una cierta **región del plano $B$** se define de la forma siguiente:
$$
P((X,Y)\in B)=P\{w\in \Omega,\ |\ (X(w),Y(w))\in B\},
$$
o sea, la probabilidad anterior es la probabilidad del suceso formado por los elementos de $w\in\Omega$ que cumplen que su **imagen** por la **variable aleatoria bidimensional $(X,Y)$** esté en $B$.


Por ejemplo, si consideramos $B=\{X+Y\leq 1\}$, $P((X,Y)\in B)$ sería la probabilidad del suceso formado por los elementos $w$ de $\Omega$ tal que la suma de las imágenes por $X$ e $Y$ sea menor o igual que 1: $X(w)+Y(w)\leq 1$.

## Función de distribución conjunta

### Función de distribución conjunta. Introducción
Dada una **variable aleatoria bidimensional** $(X,Y)$, queremos estudiar cómo se distribuye la probabilidad de sucesos cualesquiera de la forma $\{(X,Y)\in B\}$, donde $B$ es una región del plano.

Para ello, definimos la **función de distribución conjunta**:

<l class="definition">Definición de función de distribución conjunta:</l>
Dada una variable bidimensional $(X,Y)$, definimos su **función de distribución conjunta** $F_{XY}$ a la función definida sobre $\mathbb{R}^2$ de la manera siguiente:
$$
\begin{array}{rl}
F_{XY}: \mathbb{R}^2 & \longrightarrow \mathbb{R}\\
(x,y) & \longrightarrow F_{XY}(x,y)=P(X\leq x,\ Y\leq y).
\end{array}
$$

### Función de distribución conjunta. Introducción

O sea, dado un valor $(x,y)\in \mathbb{R}^2$, consideramos la región del plano $(-\infty,x]\times (-\infty,y]$:
<div class="center">

```{r, echo=FALSE, label=bid4,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/Fxy.png",dpi=1200)
```
</div>

### Función de distribución conjunta. Introducción
Entonces la **función de distribución conjunta** en el valor $(x,y)$ es la probabilidad del suceso formado por aquellos elementos tal que la imagen por la **variable aleatoria bidimensional** $(X,Y)$ caen dentro de la región sombreada en el gráfico anterior:

$$
\begin{array}{rl}
F_{XY}(x,y) & =P\{w\in\Omega,\ |\ (X(w),Y(w))\in (-\infty,x]\times (-\infty,y]\} \\ & = P\{w\in\Omega,\ |\ X(w)\leq x,\ Y(w)\leq y\}.
\end{array}
$$

### Función de distribución conjunta. Propiedades
Sea $(X,Y)$ una variable bidimensional. Sean $F_{XY}$ su **función de distribución conjunta**. Dicha función satisface las propiedades siguientes:

* La función de distribución conjunta es no decreciente en cada una de las variables:
$$
\mbox{Si }x_1\leq x_2, \mbox{ y }y_1\leq y_2,\mbox{ entonces, }F_{XY}(x_1,y_1)\leq F_{XY}(x_2,y_2).
$$

* $F_{XY}(x,-\infty)=F_{XY}(-\infty,y)=0,$ $F_{XY}(\infty,\infty)=1$, para todo $x,y\in\mathbb{R}$.


### Función de distribución conjunta. Propiedades

* Las variables aleatorias $X$ e $Y$ se llaman **variables aleatorias marginales** y sus funciones de distribución $F_X$ y $F_Y$ pueden hallarse de la forma siguiente como función de la **función de distribución conjunta** $F_{XY}$:
$$
F_X(x)=F_{XY}(x,\infty),\ F_Y(y)=F_{XY}(\infty,y),
$$
para todo $x,y\in\mathbb{R}$.

* La función de distribución conjunta es continua por el "norte" y por el "este":
$$
\begin{array}{rl}
\lim_{x\to a^+}F_{XY}(x,y) & =\lim_{x\to a, x> a}F_{XY}(x,y)=F_{XY}(a,y), \\
\lim_{y\to b^+}F_{XY}(x,y) & =\lim_{y\to b, y> b}F_{XY}(x,y)=F_{XY}(x,b),
\end{array}
$$
para todo $a,b\in\mathbb{R}$. Ver figura siguiente.

### Función de distribución conjunta. Propiedades
<div class="center">

```{r, echo=FALSE, label=bid5,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/Fxy2.png",dpi=1200)
```
</div>


### Función de distribución conjunta. Propiedades

* Dados $x_1<x_2$ y $y_1<y_2$, consideramos $B$ el rectángulo de vértices $(x_1,y_1)$, $(x_1,y_2)$, $(x_2,y_1)$ y $(x_2,y_2)$: $(x_1,x_2]\times (y_1,y_2]$. Entonces,
$$
\begin{array}{rl}
P((X,Y)\in B)  = & F_{XY}(x_2,y_2)-F_{XY}(x_2,y_1)-F_{XY}(x_1,y_2)\\ & +F_{XY}(x_1,y_1).
\end{array}
$$

### Función de distribución conjunta. Propiedades

<div class="center">

```{r, echo=FALSE, label=bid6,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/Fxy3.png",dpi=1200)
```
</div>

### Función de distribución conjunta. Ejemplo
<div class="example">
**Ejemplo**

Consideremos una variable aleatoria bidimensional $(X,Y)$ con **función de distribución conjunta**:
$$
F_{XY}(x,y)=\begin{cases}
0, & \mbox{si }x<0,\mbox{ o }y<0,\\
xy, & \mbox{si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
x, & \mbox{si }0\leq x\leq 1,\ y> 1, \\
y, & \mbox{si }0\leq y\leq 1,\ x> 1, \\
1, & x\geq 1,\ y\geq 1.
\end{cases}
$$
En la figura siguiente, hemos representado por zonas cómo está definida $F_{XY}$.
</div>


### Función de distribución conjunta. Ejemplo
<div class="example">
<div class="center">

```{r, echo=FALSE, label=bid7,fig.cap="",out.width = "450px"}
knitr::include_graphics("Images/FxyEx.png",dpi=1200)
```
</div>
</div>

### Función de distribución conjunta. Ejemplo
<div class="example">
Comprobemos algunas de las propiedades que hemos enunciado anteriormente:

* Claramente $F_{XY}(x,-\infty)=F_{XY}(-\infty,y)=0$ ya que $F_{XY}(x,y)=0$ si $x<0$ o $y<0$. Por tanto, si hacemos tender $x$ o $y$ hacia $-\infty$, obtendremos que $F_{XY}(x,-\infty)=F_{XY}(-\infty,y)=0$.

* De la misma manera $F_{XY}(\infty,\infty)=1$ ya que $F_{XY}(x,y)=1$ para $x>1$ e $y>1$. Por tanto, si hacemos tender $x$ e $y$ hacia $\infty$, obtendremos $F_{XY}(\infty,\infty)=1$.

* Hallemos las marginales:
$$
F_X(x)=F_{XY}(x,\infty)=\begin{cases}
0, & \mbox{ si }x<0,\\
x, & \mbox{ si } 0\leq x\leq 1,\\
1, & \mbox{ si } x>1.
\end{cases}
$$
Para ver la expresión anterior basta trazar la recta vertical $X=x$ en el gráfico anterior y ver hacia dónde tiende a medida que la $y$ se va hacia $\infty$. 

¿Habéis averiguado cuál es la distribución de $X$?
</div>


### Función de distribución conjunta. Ejemplo
<div class="example">
¡Efectivamente!, $X$ es la uniforme en el intervalo $(0,1)$.

Dejamos como ejercicio hallar la distribución marginal para la variable $Y$.

* Comprobemos que $F_{XY}$ es continua por el "norte" y el "este" en el punto $(1,1)$ que sería un punto problemático:
$$
\lim_{x\to 1,x> 1} F_{XY}(x,1)=\lim_{x\to 1,x> 1} 1  = F_{XY}(1,1),\ \lim_{y\to 1,y> 1} F_{XY}(1,y)=\lim_{y\to 1,y> 1} 1  = F_{XY}(1,1).
$$

</div>

### Función de distribución conjunta. Ejemplo con `R`
<div class="example">
Hagamos un gráfico 3D de la **función de distribución conjunta** usando la función `persp` de `R` para $x$ e $y$ entre -2 y 2.

Primero definimos la **función** y luego la dibujamos:

```{r,eval=FALSE}
f.dist.con = function(x,y){ifelse(x<0 | y<0,0,
                           ifelse(x>=0 & x<=1 & y>=0 & y<=1,x*y,
                           ifelse(x>=0 & x<=1 & y >1,x,ifelse(y>=0 & y<=1 & x>1,y,1))))}
x=seq(from=-2,to=2,by=0.1)
y=seq(from=-2,to=2,by=0.1)
z=outer(x,y,f.dist.con)
persp(x,y,z,theta=50,phi=40,col="blue",shade=0.25,ticktype="detailed")
```

</div>

### Función de distribución conjunta. Ejemplo con `R`

```{r,echo=FALSE,fig.align='center',fig.height=6.5}
f.dist.con = function(x,y){ifelse(x<0 | y<0,0,ifelse(x>=0 & x<=1 & y>=0 & y<=1,x*y,
                           ifelse(x>=0 & x<=1 & y >1,x,ifelse(y>=0 & y<=1 & x>1,y,1))))}
x=seq(from=-2,to=2,by=0.1)
y=seq(from=-2,to=2,by=0.1)
z=outer(x,y,f.dist.con)
persp(x,y,z,theta=50,phi=40,col="green",shade=0.25,ticktype="detailed")
```

### Función de distribución conjunta. Ejemplo

<div class="example">
**Ejemplo: dos lanzamientos de un dado no trucado**

Consideremos el experimento aleatorio de lanzar dos veces un dado no trucado. 

Sea $(S,P)$ la **variable aleatoria bidimensional** que nos da la suma y el producto de los resultados obtenidos, respectivamente.

La **función de distribución conjunta** en el valor $(3,4)$ será:
$$
F_{XY}(3,4) = P(S\leq 3,\ P\leq 4)=P\{(1,1), (1,2), (2,1) \}=\frac{3}{36}=\frac{1}{12}\approx `r round(1/12,3)`, 
$$
ya que $\Omega$ tiene en total $36$ resultados:
$$
\Omega =\{(1,1),(1,2).\ldots, (6,6)\}.
$$
y los únicos resultados en los que la suma es menor o igual que 3 y el producto menor o igual que 4 son $(1,1)$ (suma 2 producto 1), $(1,2)$ (suma 3 y producto 2) y $(2,1)$ (suma 3 y producto 2).
</div>

### Función de distribución conjunta. Ejemplo

<div class="exercise">
**Ejercicio**

Hallar el valor de la **función de distribución conjunta** para la **variable aleatoria bidimensional** anterior $(S,P)$ en los valores $(i,j)$ siguientes: $(4,5),\ (4,9),\ (5,9),\ (6,10)$.
</div>

## Variables aleatorias bidimensionales discretas

### Variables aleatorias bidimensionales discretas. Introducción

<l class="definition">Definición de variable aleatoria bidimensional discreta:</l>
Sea $(X,Y)$ una **variable aleatoria bidimensional**. Diremos que es discreta cuando su conjunto de valores en $\mathbb{R}^2$, $(X,Y)(\Omega)$ es un conjunto finito o numerable. 

En la mayoría de los casos, dicho conjunto será un subconjunto de los enteros naturales.

### Variables aleatorias bidimensionales discretas. Ejemplo

<div class="example">
**Ejemplo**

La variable aleatoria bidimensional anterior que nos daba la suma y el producto de los resultados obtenidos por los dos lanzamientos, respectivamente es discreta ya que: 
$$
\begin{array}{rl}
(S,P)(\Omega) & =\{(2,1),(3,2),(4,3),(4,4),(5,4),(5,6),(6,5),(6,8),(6,9),(7,6),(7,10),(7,12),(8,12),\\ & (8,15),(8,16),(9,18),(9,20),(10,24),(10,25),(11,30),(12,36)\}.
\end{array}
$$

</div>

### Variables aleatorias bidimensionales discretas. Ejemplo

<div class="exercise">
**Ejercicio**

Comprobar que el conjunto $(S,P)(\Omega)$ dado por el ejemplo coincide con la expresión dada. 
O sea, hallar el conjunto $(S,P)(\Omega)$:
$$
\begin{array}{rl}
(S,P): \Omega & \longrightarrow \mathbb{R}^2\\
(1,1) & \longrightarrow (S(1,1),P(1,1))=(2,1),\\
(1,2) & \longrightarrow (S(1,2),P(1,2))=(3,2),\\
\vdots & \vdots \\
(6,6) & \longrightarrow (S(6,6),P(6,6))=(12,36).
\end{array}
$$

</div>

### Función de probabilidad conjunta
<l class="definition">Definición de función de probabilidad conjunta:</l>
Dada una **variable aleatoria bidimensional discreta** $(X,Y)$ con $(X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,\ j=1,2,\ldots,\}$, definimos la función de probabilidad discreta $P_{XY}$ para un valor $(x,y)\in\mathbb{R}^2$ de la siguiente forma:
$$
\begin{array}{rl}
P_{XY}: \mathbb{R}^2 & \longrightarrow \mathbb{R}\\
(x,y) & \longrightarrow P_{XY}(x,y)=P(X= x,\ Y= y).
\end{array}
$$

<l class="observ">Observación:</l>
Si $(x,y)\not\in (X,Y)(\Omega)$, el valor de la **función de probabilidad conjunta** en $(x,y)$ en nulo: $P_{XY}(x,y)=0$, ya que, en este caso, el conjunto $\{w\in\Omega,\ | (X(w),Y(w))=(x,y)\}=\emptyset$ ya que recordemos $(x,y)\not\in (X,Y)(\Omega)$.

### Función de probabilidad conjunta

Por tanto, de cara a calcular $P_{XY}$ basta calcular $P_{XY}(x_i,y_j)$ para $(x_i,y_j)\in (X,Y)(\Omega)$:

<div class="center">
| $X/Y$| $y_1$    | $y_2$  | $\ldots$ | $y_N$ |
|----|----|----|----|----|
| $x_1$| $P_{XY}(x_1,y_1)$ | $P_{XY}(x_1,y_2)$ | $\ldots$ | $P_{XY}(x_1,y_N)$|
| $x_2$| $P_{XY}(x_2,y_1)$ | $P_{XY}(x_2,y_2)$ | $\ldots$ | $P_{XY}(x_2,y_N)$|
| $\vdots$ |$\vdots$ |$\vdots$ |$\vdots$ |$\vdots$ |
| $x_M$| $P_{XY}(x_M,y_1)$ | $P_{XY}(x_M,y_2)$ | $\ldots$ | $P_{XY}(x_M,y_N)$|
</div>


### Función de probabilidad conjunta. Ejemplo
<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

La **función de probabilidad conjunta** será:
<div class="center">
| $S/P$| 1 | 2| 3 | 4 | 5| 6 | 8| 9| 10 | 12 | 15 | 16 | 18 | 20 | 24 | 25 | 30 | 36 
|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--
| 2    |$\frac{1}{36}$|0 |0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0
| 3    | 0 | $\frac{2}{36}$ |0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0
| 4   | 0 | 0 | $\frac{2}{36}$ | $\frac{1}{36}$ | 0|0|0|0|0|0|0|0|0|0|0|0|0|0
| 5   | 0 | 0 | 0 | $\frac{2}{36}$ | 0 | $\frac{2}{36}$ | 0|0|0|0|0|0|0|0|0|0|0|0
| 6 | 0 | 0 | 0 | 0 | $\frac{2}{36}$ | 0 | $\frac{2}{36}$ |$\frac{1}{36}$|0|0|0|0|0|0|0|0|0|0
</div>

</div>


### Función de probabilidad conjunta. Ejemplo
<div class="example">
<div class="center">
| $S/P$| 1 | 2| 3 | 4 | 5| 6 | 8| 9| 10 | 12 | 15 | 16 | 18 | 20 | 24 | 25 | 30 | 36 
|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--
| 7 | 0 |0|0|0|0|$\frac{2}{36}$|0|0|$\frac{2}{36}$|$\frac{2}{36}$|0|0|0|0|0|0|0|0
|8  |0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|$\frac{2}{36}$|$\frac{1}{36}$|0|0|0|0|0|0
|9 |0|0|0|0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|$\frac{2}{36}$|0|0|0|0
| 10 | 0|0|0|0|0|0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|$\frac{1}{36}$|0|0
| 11 | 0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|$\frac{2}{36}$|0
| 12 |  0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|$\frac{1}{36}$
</div>

</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">

Vamos a definir unas funciones en `R` para calcular la **función de probabilidad conjunta**.

La función `pdado` devuelve la probabilidad de que salga la cara `x` en un dado de `n` caras donde por defecto $n=6$:
```{r}
pdado =function(x,n=6)  sapply(x,FUN=function(x) 
  if( x %in% c(1:n))  {return(1/n)} else {return(0)})
```
Vamos a probarla. La probabilidad de que salga la cara 4 en un dado de 6 caras vale:
```{r}
pdado(4,6)
```
</div>


### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
La función `pdado2` devuelve la probabilidad de que salgan las caras `x` e  `y` cuando lanzamos un dado de `n` caras dos veces:
```{r}
pdado2 =function(x,y,n=6) {pdado(x,n)*pdado(y,n)}
```
Por ejemplo la probabilidad de que salgan las caras 3 y 4 en un dado de 6 caras será:
```{r}
pdado2(3,4,6)
```

</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
La función `psum_prod` nos da la **función de probabilidad conjunta** de la suma y el producto cuando lanzamos dos dados de `n` caras:
```{r}
psum_prod=function(x,y,n=6){
  Dxy=data.frame(d1=rep(1:n,each=n),d2=rep(1:n,times=n))
  Dxy$suma=Dxy$d1+Dxy$d2
  Dxy$producto=Dxy$d1*Dxy$d2
  aux=Dxy[Dxy$suma==x& Dxy$producto==y,]
  sum(apply(aux[,1:2],FUN=function(x) {pdado2(x[1],x[2],n=n)},1 ))
}
```

Por ejemplo, sabemos que $P_{SP}(6,8)=\frac{2}{36}=`r round(2/36,4)`$:


```{r}
psum_prod(6,8)
```


</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
Para construir la tabla de la **función de probabilidad conjunta** para la variable $(S,P)$ hacemos lo siguiente:
```{r,eval=FALSE}
n=6
Dxy=data.frame(d1=rep(1:n,each=n),d2=rep(1:n,times=n))
Dxy$suma=Dxy$d1+Dxy$d2
Dxy$producto=Dxy$d1*Dxy$d2
tabla.func.prob.conjunta=prop.table(table(Dxy$suma,Dxy$producto))
knitr::kable(round(tabla.func.prob.conjunta[1:6,1:9],4))
knitr::kable(round(tabla.func.prob.conjunta[1:6,10:18],4))
knitr::kable(round(tabla.func.prob.conjunta[7:11,1:9],4))
knitr::kable(round(tabla.func.prob.conjunta[7:11,10:18],4))
```

</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
n=6
Dxy=data.frame(d1=rep(1:n,each=n),d2=rep(1:n,times=n))
Dxy$suma=Dxy$d1+Dxy$d2
Dxy$producto=Dxy$d1*Dxy$d2
tabla.func.prob.conjunta=prop.table(table(Dxy$suma,Dxy$producto))
knitr::kable(round(tabla.func.prob.conjunta[1:6,1:9],4))

```

</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.func.prob.conjunta[1:6,10:18],4))
```


</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.func.prob.conjunta[7:11,1:9],4))
```


</div>

### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.func.prob.conjunta[7:11,10:18],4))

```


</div>

### Propiedades de la función de probabilidad conjunta

Sea $(X,Y)$ una **variable aleatoria bidimensional discreta** con conjunto de valores $(X,Y)(\Omega)=\{(x_i,y_j)\, i=1,2,\ldots,\ j=1,2,\ldots\}$. Entonces su **función de probabilidad conjunta** verifica las propiedades siguientes:

La suma de todos los valores de la **función de probabilidad conjunta** sobre el conjunto de valores siempre vale 1: $$\sum_{i}\sum_j P_{XY}(x_i,y_j)=1.$$


### Propiedades de la función de probabilidad conjunta

Sea $B$ una región del plano. El valor de la probabilidad $P((X,Y)\in B)$ se puede calcular de la forma siguiente:
$$
P((X,Y)\in B) =\sum_{(x_i,y_j)\in B} P_{XY}(x_i,y_j).
$$
O sea, la probabilidad de que la variable bidimensional coja valores en $B$ es igual a la suma de todos aquellos valores de la función de probabilidad conjunta que están en $B$.

### Propiedades de la función de probabilidad conjunta

En particular, tenemos la relación siguiente que relaciona la **función de distribución conjunta** con la **función de probabilidad conjunta**:
$$
F_{XY}(x,y)=\sum_{x_i\leq x, y_j\leq y} P_{XY}(x_i,y_j).
$$
Dicha expresión se deduce de la expresión anterior considerando $B=(-\infty,x]\times (-\infty,y]$.


### Propiedades de la función de probabilidad conjunta. Ejemplo

<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

<div class="exercise">
**Ejercicio**

Comprobad usando la tabla de la función de probabilidad conjunta que la suma de todos sus valores suma 1.
</div>

Apliquemos la fórmula que relaciona la función de distribución conjunta con la función de probabilidad conjunta para $(x,y)=(5,4)$.

Recordemos la tabla de la función de probabilidad conjunta hasta $S=5$ y $P=4$:




</div>


### Propiedades de la función de probabilidad conjunta. Ejemplo

<div class="example">

<div class="center">
| $S/P$| 1 | 2| 3 | 4 | 
|--|--|--|---|---|--
| 2    |$\frac{1}{36}$|0 |0|0|$\ldots$
| 3    | 0 | $\frac{2}{36}$ |0|0|$\ldots$
| 4   | 0 | 0 | $\frac{2}{36}$ | $\frac{1}{36}$ | $\ldots$
| 5   | 0 | 0 | 0 | $\frac{2}{36}$ | $\ldots$
| $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$
</div>


</div>

### Propiedades de la función de probabilidad conjunta. Ejemplo

<div class="example">
Observamos que los únicos valores $(x_i,y_j)\in (X,Y)(\Omega)$ que verifican $x_i\leq 5$ y $y_j\leq 4$ son $(2,1)$, $(3,2)$, $(4,3)$, $(4,4)$ y $(5,4)$. Por tanto,
$$
\begin{array}{rl}
F_{SP}(5,4) & = P_{SP}(2,1)+P_{SP}(3,2)+P_{SP}(4,3)+P_{SP}(4,4)+P_{SP}(5,4) \\ & = \frac{1}{36}+\frac{2}{36}+\frac{2}{36}+\frac{1}{36}+\frac{2}{36} = \frac{8}{36}=\frac{2}{9}.
\end{array}
$$
O sea, "a la larga", de cada 9 ocasiones que lanzamos un dado dos veces, en 2 ocasiones obtenemos un resultado cuya suma es menor o igual que 5 y cuyo producto es menor o igual que 4.
</div>

### Propiedades de la función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
Para definir la **función de distribución conjunta** definimos la función siguiente en `R`:
```{r}
func.dist.conj = function(x,y,n=6){
  sum(tabla.func.prob.conjunta[as.integer(rownames(tabla.func.prob.conjunta))<=x,
                            as.integer(colnames(tabla.func.prob.conjunta)) <=y])
}
```
Comprobemos que $F_{SP}(5,4)=\frac{2}{9}=`r round(2/9,4)`$:
```{r}
func.dist.conj(5,4)
```


</div>


### Variables aleatorias marginales
Consideremos una variable aleatoria **bidimensional discreta $(X,Y)$** con **función de probabilidad conjunta** $P_{XY}(x_i,y_j)$, con $(x_i,y_j)\in (X,Y)(\Omega)$, $i=1,2,\ldots$, $j=1,2,\ldots$.

La tabla de la **función de probabilidad conjunta** contiene suficiente información para obtener las **funciones de probabilidad** de las variables $X$ e $Y$. 

Dichas variables $X$ e $Y$ se denominan **distribuciones marginales** y sus correspondientes **funciones de probabilidad**, **funciones de probabilidad marginales** $P_X$ de la variable $X$ y $P_Y$ de la variable $Y$.

Veamos cómo obtener $P_X$ y $P_Y$ a partir de la tabla $P_{XY}$.

### Variables aleatorias marginales
<l class="prop">Proposición. Expresión de las funciones de probabilidad marginales. </l>
Sea $(X,Y)$ una variable aleatoria **bidimensional discreta** con **función de probabilidad conjunta** $P_{XY}(x_i,y_j)$, con $(x_i,y_j)\in (X,Y)(\Omega)$, $i=1,2,\ldots$, $j=1,2,\ldots$.

Las **funciones de probabilidad marginales** $P_X(x_i)$ y $P_Y(y_j)$ se calculan usando las expresiones siguientes:
$$
\begin{array}{rl}
P_X(x_i)  & = \sum_{j=1} P_{XY}(x_i,y_j),\  i=1,2,\ldots,\\ P_Y(y_j) &  = \sum_{i=1} P_{XY}(x_i,y_j),\ \ j=1,2,\ldots
\end{array}
$$

### Variables aleatorias marginales


O sea, si pensamos $P_{XY}$ como una tabla bidimensional donde en la primera fila están los valores de la variable $Y$ ($y_1,y_2,\ldots$) y en la primera columna están los valores de la variable $X$ ($x_1,x_2,\ldots$), para obtener la **función de probabilidad marginal** de la variable $X$ en el valor $x_i$, $P_X(x_i)$, hay que sumar todos los valores de $P_{XY}(x_i,y_j)$ correspondientes a la fila $i$-ésima y para obtener la **función de probabilidad marginal** de la variable $Y$ en el valor $y_j$, $P_Y(y_j)$, hay que sumar todos los valores de $P_{XY}(x_i,y_j)$ correspondientes a la columna $j$-ésima.

### Variables aleatorias marginales. Ejemplo

<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

Hallemos la función de probabilidad marginal para la suma de los resultados $S$ usando la expresión vista:
$$
\begin{array}{rl}
P_S(2) & = P_{SP}(2,1)=\frac{1}{36},\\
P_S(3) & = P_{SP}(3,2)=\frac{2}{36},\\
P_S(4) & = P_{SP}(4,3)+P_{SP}(4,4)=\frac{2}{36}+\frac{1}{36}=\frac{3}{36}=\frac{1}{12},\\
P_S(5) & = P_{SP}(5,4)+P_{SP}(5,6)=\frac{2}{36}+\frac{2}{36}=\frac{4}{36}=\frac{1}{9},\\
P_S(6) & = P_{SP}(6,5)+P_{SP}(6,8)+P_{SP}(6,9)=\frac{2}{36}+\frac{2}{36}+\frac{1}{36}=\frac{5}{36},\\
P_S(7) & = P_{SP}(7,6)+P_{SP}(7,10)+P_{SP}(7,12)=\frac{2}{36}+\frac{2}{36}+\frac{2}{36}=\frac{6}{36}=\frac{1}{6},\\
P_S(8) & = P_{SP}(8,12)+P_{SP}(8,15)+P_{SP}(8,16)=\frac{2}{36}+\frac{2}{36}+\frac{1}{36}=\frac{5}{36},\\
P_S(9) & = P_{SP}(9,18)+P_{SP}(9,20)=\frac{2}{36}+\frac{2}{36}=\frac{4}{36}=\frac{1}{9},\\
P_S(10) & = P_{SP}(10,24)+P_{SP}(10,25)=\frac{2}{36}+\frac{1}{36}=\frac{3}{36}=\frac{1}{12},\\
P_S(11) & = P_{SP}(11,30)=\frac{2}{36},\\
P_S(12) & = P_{SP}(12,36)=\frac{1}{36}.
\end{array}
$$

</div>

### Variables aleatorias marginales. Ejemplo
<div class="example">
La **función de probabilidad marginal** de la suma $S$ queda resumida en la tabla siguiente:

<div class="center">
| $S$| 2 | 3| 4 | 5 | 6| 7| 8 | 9 | 10 | 11 | 12 
|--|--|--|--|--|--|--|--|--|--|--|--
| $P_S$|$\frac{1}{36}$|$\frac{2}{36}$|$\frac{3}{36}$|$\frac{4}{36}$|$\frac{5}{36}$|$\frac{6}{36}$|$\frac{5}{36}$|$\frac{4}{36}$|$\frac{3}{36}$|$\frac{2}{36}$|$\frac{1}{36}$
</div>

</div>



### Variables aleatorias marginales. Ejemplo con `R`
<div class="example">
Para hallar la **función de probabilidad marginal** de la suma basta sumar las filas de la tabla que nos daba la **función de probabilidad conjunta**:
```{r}
marginal.suma = apply(tabla.func.prob.conjunta,1,sum)
marginal.suma
```
</div>

### Variables aleatorias marginales. Ejemplo con `R`
<div class="example">
De la misma manera, para hallar la **función de probabilidad marginal** del producto basta sumar las columnas de la tabla anterior:
```{r}
marginal.producto = apply(tabla.func.prob.conjunta,2,sum)
marginal.producto
```
</div>

## Variables aleatorias bidimensionales continuas

### Introducción
Recordemos la definición de **variable continua unidimensional**: $X$ es continua si existe una función $f_X:\mathbb{R}\longrightarrow \mathbb{R}$, llamada **función de densidad** no negativa $f_X(x)\geq 0$, para todo $x\in\mathbb{R}$ tal que para cualquier intervalo $(a,b)$, la probabilidad de que $X$ esté en $(a,b)$ se calcula de la forma siguiente:
$$
P(X\in B)=P(a< X < b)=\int_B f_{X}(x)\,du=\int_a^b f_{X}(x)\,dx.
$$

### Introducción
La generalización natural será, entonces:

<l class="definition">Definición de variable aleatoria bidimensional continua. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional. Diremos que $(X,Y)$ es continua si existe una función 
$f_{XY}:\mathbb{R}^2\longrightarrow \mathbb{R}$ llamada **función de densidad** no negativa $f_{XY}(x,y)\geq 0$ para todo $(x,y)\in\mathbb{R}^2$ tal que dado cualquier región $B$ del plano, la probabilidad de que $(X,Y)$ esté en $B$ se calcula de la forma siguiente:
$$
P((X,Y)\in B)=\int\int_B f_{XY}(x,y)\,dx\,dy.
$$

### Ejemplo
<div class="example">
**Ejemplo**

Consideremos la **función de densidad siguiente**:
$$
f_{XY}(x,y)=\begin{cases}
1, & \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$
En este caso, si consideramos $B=\left[-1,\frac{1}{2}\right]\times \left[-1,\frac{1}{2}\right]$, la probabilidad de que $(X,Y)$ esté en $B$ se calcularía de la forma siguiente:
$$
P((X,Y)\in B)=\int_{-1}^{\frac{1}{2}}\int_{-1}^{\frac{1}{2}} f_{XY}(x,y)\, dx\, dy =\int_0^{\frac{1}{2}}\int_0^{\frac{1}{2}} 1\, dx\,dy=\int_0^{\frac{1}{2}} 1\, dx\int_0^{\frac{1}{2}} 1\, dy=\frac{1}{2}\cdot\frac{1}{2}=\frac{1}{4}.
$$
En la figura siguiente hemos dibujado en morado la región donde $f_{XY}$ no es cero, o sea $[0,1]\times [0,1]$, la región $B$ en verde y la región intersección de las dos anteriores que es donde tenemos que integrar la **función de densidad** dada.
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid8,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/VaUniformeBidi.png",dpi=1200)
```
</div>

### Propiedades de la función de densidad
Sea $(X,Y)$ una **variable aleatoria bidimensional continua** con **función de densidad** $f_{XY}$. Entonces dicha función verifica las propiedades siguientes:

* La integral de dicha función sobre todo el plano vale 1: 
$$
\int\int_{\mathbb{R}^2} f_{XY}(x,y)\,dx\,dy =1.
$$
Para ver dicha propiedad, basta considerar $B=\mathbb{R}^2$, tener en cuenta que el suceso $(X,Y)\in \mathbb{R}^2$ es el total $\Omega$ y aplicar la definición de $f_{XY}$:
$$
P((X,Y)\in \mathbb{R}^2)=1= \int\int_{\mathbb{R}^2} f_{XY}(x,y)\,dx\,dy.
$$

### Propiedades de la función de densidad
* La relación que hay entre la **función de distribución** $F_{XY}$ y la **función de densidad** $f_{XY}$ es la siguiente:
$$
F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^y f_{XY}(u,v)\,du\,dv.
$$
Para ver dicha propiedad, basta considerar $B=(-\infty,x]\times (-\infty,y]$ y aplicar la definición de **función de distribución**:
$$
F_{XY}(x,y)=P((X,Y)\in (-\infty,x]\times (-\infty,y])=\int_{-\infty}^x\int_{-\infty}^y f_{XY}(u,v)\,du\,dv.
$$

### Propiedades de la función de densidad
* La relación que hay entre la **función de densidad** $f_{XY}$ y la **función de distribución** $F_{XY}$ es la siguiente:
$$
f_{XY}(x,y)=\frac{\partial^2 F_{XY}(x,y)}{\partial x\partial y}.
$$
Dicha propiedad se deduce de la anterior, derivando primero respecto a $x$ y después respecto a $y$ para eliminar las dos integrales.

* Las **funciones de densidad marginales** de las variables $X$ e $Y$, $f_X(x)$ y $f_Y(y)$ respectivamente, se calculan de la forma siguiente:
$$
f_X(x)=\int_{-\infty}^\infty f_{XY}(x,y)\, dy,\ f_Y(y)=\int_{-\infty}^\infty f_{XY}(x,y)\, dx
$$

### Ejemplo
<div class="example">
**Ejemplo anterior**

Comprobemos las propiedades usando la **función de densidad** del ejemplo anterior: 
$f_{XY}(x,y)=\begin{cases}
1, & \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, & \mbox{en caso contrario.}
\end{cases}$

* La integral de $f_{XY}$ sobre todo el plano vale 1:
$$
\int\int_{\mathbb{R}^2} f_{XY}(x,y)\,dx\, dy=\int_0^1\int_0^1 1\, dx\, dv=\int_0^1 1\, dx\int_0^1 1\, dy=1\cdot 1=1.
$$

* Vamos a calcular la función de distribución $F_{XY}$. Para ello dividimos el plano en 5 zonas tal como muestra la figura siguiente:
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid9,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/VaUniformeBidi2.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">
Sea $(x,y)$ un punto cualquiera de $\mathbb{R}^2$. De cara a calcular $F_{XY}(x,y)$ tenemos que averiguar el conjunto intersección siguiente: $([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])$ ya que el dominio donde $f_{XY}$ es no nula es $[0,1]\times [0,1]$ y la función de distribución $F_{XY}(x,y)$ valdrá:
$$
F_{XY}(x,y)=\int_{-\infty}^x\int_{-\infty}^y f_{XY}(u,v)\,du\,dv =\int\int_{([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])} f_{XY}(u,v)\,du\,dv.
$$

* Caso $(x,y)\in \mbox{Zona A}$ o $x<0$ o $y<0$ En este caso: $([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])=\emptyset.$ Ver figura siguiente donde la zona morada $([0,1]\times [0,1]$) no se interseca con la zona verde ($(-\infty,x]\times (-\infty,y]$).

Por tanto en este caso, $F_{XY}(x,y)=0$.
</div>


### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid10,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/VaUniformeBidi3.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">
* Caso $(x,y)\in \mbox{Zona B}$, o $(x,y)\in [0,1]\times [0,1]$. En este caso: $([0,1]\times [0,1])\cap ((-\infty,x]\times (-\infty,y])=[0,x]\times [0,y].$ Ver figura siguiente. 

Por tanto en este caso, 
$$
F_{XY}(x,y)=\int_0^x \int_0^y 1\,du\,dv =\int_0^x 1\, du\int_0^y 1\, dy =x\cdot y.
$$

</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid11,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/VaUniformeBidi4.png",dpi=1200)
```
</div>

### Ejemplo
<div class="example">
Dejamos como ejercicio los otros casos. En resumen:
$$
F_{XY}(x,y)=\begin{cases}
0, & \mbox{ si }x<0, \mbox{ o }y<0,\\
x y, & \mbox{ si }(x,y)\in [0,1]\times [0,1],\\
x, & \mbox{ si }0\leq x\leq 1,\ y>1,\\
y, & \mbox{ si }x>1,\ 0\leq y\leq 1,\\
1, & \mbox{ si } x>1,\ y>1.
\end{cases}
$$
¿Os suena? 

Ver el primer ejemplo que pusimos del tema. Es la misma variable aleatoria bidimensional. 
Ahora sabemos que se trata de una **variable aleatoria bidimensional continua**.
</div>

### Ejemplo
<div class="example">
Comprobemos seguidamente que si derivamos dos veces la expresión de $F_{XY}$, primero respecto $x$ y después respecto $y$, obtendremos la **función de densidad** $f_{XY}$.

Si derivamos respecto $x$ obtenemos:
$$
\frac{\partial F_{XY}(x,y)}{\partial x}=\begin{cases}
0, & \mbox{ si }x<0, \mbox{ o }y<0,\\
y, & \mbox{ si }(x,y)\in [0,1]\times [0,1],\\
1, & \mbox{ si }0\leq x\leq 1,\ y>1,\\
0, & \mbox{ si }x>1,\ 0\leq y\leq 1,\\
0, & \mbox{ si } x>1,\ y>1.
\end{cases}
$$
Si ahora derivamos respecto $y$ obtenemos:
$$
\frac{\partial^2 F_{XY}(x,y)}{\partial y\partial x}=\begin{cases}
0, & \mbox{ si }x<0, \mbox{ o }y<0,\\
1, & \mbox{ si }(x,y)\in [0,1]\times [0,1],\\
0, & \mbox{ si }0\leq x\leq 1,\ y>1,\\
0, & \mbox{ si }x>1,\ 0\leq y\leq 1,\\
0, & \mbox{ si } x>1,\ y>1,
\end{cases}
$$
expresión que coincide con la **función de densidad** $f_{XY}(x,y)$.
</div>


### Ejemplo
<div class="example">
Hallemos para finalizar las **funciones de densidad marginales**. Empecemos con $f_X(x)$:
$$
f_X(x)=\int_{-\infty}^\infty  f_{XY}(x,y)\, dy.
$$
Recordemos que la región donde no se anulaba la **función de densidad conjunta** $f_{XY}$ era el cuadrado $[0,1]\times [0,1]$. Por tanto, fijado $x$, el valor de $f_X(x)$ será no nulo si la recta vertical $X=x$ interseca dicho cuadrado. Y esto ocurre siempre que $x\in (0,1)$. Por tanto,
$$
f_X(x)=\begin{cases}
\int_{0}^1  f_{XY}(x,y)\, dy=\int_{0}^1  1\, dy=1, & \mbox{ si }x\in (0,1),\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
Por tanto la variable $X$ sigue la distribución uniforme en el intervalo $[0,1]$.

Dejamos como ejercicio comprobar que la variable $Y$ también sigue la distribución uniforme en el mismo intervalo.
</div>


### Ejemplo 2
<div class="example">
**Ejemplo**

Consideremos la variable aleatoria bidimensional $(X,Y)$ con **función de densidad**:
$$
f_{XY}(x,y)=\begin{cases}
c \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario,}
\end{cases}
$$
donde $c$ es un valor que se tiene que hallar para que $f_{XY}$ sea función de densidad.

Para hallar $c$, hemos de imponer que la integral de la función anterior debe ser 1 sobre todo el plano $\mathbb{R}^2$.

Primero fijémonos en como es la región de integración (zona morada de la figura). Fijado un valor $x\geq 0$, el valor $y$ va desde $y=0$ hasta $y=x$. Por tanto, para calcular el valor de $c$, hay que hacer lo siguiente:


</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid12,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/Ejemplo2Bidi.png",dpi=1200)
```
</div>

### Ejemplo 2
<div class="example">

$$
\begin{array}{rl}
1 & =\int\int_{\mathbb{R}^2}f_{XY}(x,y)\, dx\, dy=\int_{x=0}^{x=\infty}\int_{y=0}^{y=x} c \mathrm{e}^{-x}\mathrm{e}^{-y} \, dy\, dx =c \int_{x=0}^{x=\infty}\mathrm{e}^{-x}\int_{y=0}^{y=x}\mathrm{e}^{-y}\, dy\, dx \\ & =
c \int_{x=0}^{x=\infty}\mathrm{e}^{-x}\left[-\mathrm{e}^{-y}\right]_{y=0}^{y=x}\, dx = c \int_{x=0}^{x=\infty}\mathrm{e}^{-x}\left(1-\mathrm{e}^{-x}\right)\, dx =c \int_{x=0}^{x=\infty}\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx \\ & = c \left[-\mathrm{e}^{-x}+\frac{1}{2}\mathrm{e}^{-2x}\right]_{x=0}^{x=\infty} = c\left(1-\frac{1}{2}\right)=\frac{c}{2}.
\end{array}
$$
El valor de $c$ será $c=2$.

Vamos a calcular seguidamente su función de distribución.

Fijémonos que, en este caso, si $x<0$ o $y<0$, $F_{XY}(x,y)=0$, ya que el dominio $B=(-\infty,x]\times (-\infty,y]$ no interseca la zona morada del gráfico anterior.

Suponemos entonces que $x\geq 0$ e $y\geq 0$. 

Vamos a considerar dos casos:

* $x\leq y$. Ver zona verde del gráfico siguiente.

* $x\geq y$. Ver zona morada del gráfico siguiente.
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid13,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/Ejemplo2Bidi2.png",dpi=1200)
```
</div>

### Ejemplo 2
<div class="example">
* Caso $x\leq y$ (zona verde de la figura adjunta). En este caso, si hacemos la intersección de la región $B=(-\infty,x]\times (-\infty,y]$ (zona azul) con la zona morada o región donde $f_{XY}(x,y)\neq 0$ obtenemos el triángulo $T_{x,y}=\{(u,v)\in\mathbb{R}^2,\ 0\leq u\leq x,\ 0\leq v\leq u\}.$ Ver figura adjunta.

Por tanto,
$$
\begin{array}{rl}
F_{XY}(x,y) & =\int_{u=0}^{u=x}\int_{v=0}^{v=u} f_{XY}(u,v)\,dv\,du= 2 \int_{u=0}^{u=x} \mathrm{e}^{-u}\int_{v=0}^{v=u}  \mathrm{e}^{-v}\,dv\,du  =
2 \int_{u=0}^{u=x} \mathrm{e}^{-u}\left[-\mathrm{e}^{-v}\right]_{v=0}^{v=u}\, du \\ & = 2 \int_{u=0}^{u=x} \mathrm{e}^{-u} (1-\mathrm{e}^{-u})\, du =2 \int_{u=0}^{u=x} \left(\mathrm{e}^{-u}-\mathrm{e}^{-2u}\right)\, du=2 \left[-\mathrm{e}^{-u}+\frac{1}{2}\mathrm{e}^{-2u}\right]_{u=0}^{u=x}  \\ & =
2\left(-\mathrm{e}^{-x}+\frac{1}{2}\mathrm{e}^{-2x}+1-\frac{1}{2}\right) =1-2\mathrm{e}^{-x}+\mathrm{e}^{-2x}.
\end{array}
$$

</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid14,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/Ejemplo2Bidi3.png",dpi=1200)
```
</div>


### Ejemplo 2
<div class="example">
* Caso $x\geq y$ (zona morada de la figura adjunta). En este caso, si hacemos la intersección de la región $B=(-\infty,x]\times (-\infty,y]$ (zona azul) con la zona morada o región donde $f_{XY}(x,y)\neq 0$ obtenemos el trapecio $T_{x,y}=\{(u,v)\in\mathbb{R}^2,\ 0\leq v\leq y,\ v\leq u\leq x\}.$ Ver figura adjunta.

Por tanto,
$$
\begin{array}{rl}
F_{XY}(x,y) & =\int_{v=0}^{v=y}\int_{u=v}^{u=x} f_{XY}(u,v)\,dv\,du= 2 \int_{v=0}^{v=y} \mathrm{e}^{-v}\int_{u=v}^{u=x} \mathrm{e}^{-u}\,du\,dv  =
2 \int_{v=0}^{v=y} \mathrm{e}^{-v}\left[-\mathrm{e}^{-u}\right]_{u=v}^{u=x}\, dv \\ & = 2 \int_{v=0}^{v=y} \mathrm{e}^{-v} (\mathrm{e}^{-v}-\mathrm{e}^{-x})\, du =2 \int_{v=0}^{v=y} \left(\mathrm{e}^{-2v}-\mathrm{e}^{-v-x}\right)\, du=2 \left[-\frac{1}{2}\mathrm{e}^{-2v}+\mathrm{e}^{-v-x}\right]_{v=0}^{v=y}  \\ & =
2\left(-\frac{1}{2}\mathrm{e}^{-2y}+\mathrm{e}^{-x-y}+\frac{1}{2}-\mathrm{e}^{-x}\right) =1-2\mathrm{e}^{-x}-\mathrm{e}^{-2y}+2\mathrm{e}^{-x-y}.
\end{array}
$$
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid15,fig.cap="",out.width = "700px"}
knitr::include_graphics("Images/Ejemplo2Bidi4.png",dpi=1200)
```
</div>

### Ejemplo 2
<div class="example">
En resumen:
$$
F_{XY}(x,y)=\begin{cases}
1-2\mathrm{e}^{-x}+\mathrm{e}^{-2x}, & \mbox{si }x\geq 0,\ y\geq 0,\ x\leq y,\\
1-2\mathrm{e}^{-x}-\mathrm{e}^{-2y}+2\mathrm{e}^{-x-y}, & \mbox{si }x\geq 0,\ y\geq 0,\ x\geq y,\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
</div>

### Ejemplo 2
<div class="example">
Comprobemos a continuación que si derivamos dos veces la expresión de $F_{XY}$, primero respecto $x$ y después respecto $y$, obtendremos la **función de densidad** $f_{XY}$.

Si derivamos respecto $x$ obtenemos:
$$
\frac{\partial F_{XY}(x,y)}{\partial x}=\begin{cases}
2\mathrm{e}^{-x}-2\mathrm{e}^{-2x}, & \mbox{si }x\geq 0,\ y\geq 0,\ x\leq y,\\
2\mathrm{e}^{-x}-2\mathrm{e}^{-x-y}, & \mbox{si }x\geq 0,\ y\geq 0,\ x\geq y,\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
Si ahora derivamos respecto $y$ obtenemos:
$$
\frac{\partial^2 F_{XY}(x,y)}{\partial y\partial x}=\begin{cases}
0, & \mbox{si }x\geq 0,\ y\geq 0,\ x\leq y,\\
2\mathrm{e}^{-x-y}, & \mbox{si }x\geq 0,\ y\geq 0,\ x\geq y,\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
expresión que coincide con la **función de densidad** $f_{XY}(x,y)$.
</div>


### Ejemplo 2
<div class="example">
Hallemos las **funciones de densidad marginales**. Fijémonos que basta tener en cuenta los casos en que $x\geq 0$ e $y\geq 0$ ya que en caso contrario tanto $f_X(x)$ como $f_Y(y)$ serán nulas.

$$
\begin{array}{rl}
f_X(x) & = \int_{-\infty}^{\infty} f_{XY}(x,y)\, dy =\int_{y=0}^{y=x}2\mathrm{e}^{-x-y}\, dy = 2\left[-\mathrm{e}^{-x-y}\right]_{y=0}^{y=x} = 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right),\mbox{ si }x\geq 0, \\
f_Y(y) & = \int_{-\infty}^{\infty} f_{XY}(x,y)\, dx =\int_{x=y}^{x=\infty}2\mathrm{e}^{-x-y}\, dx = 2\left[-\mathrm{e}^{-x-y}\right]_{x=y}^{x=\infty} = 2\mathrm{e}^{-2y}, \mbox{ si }y\geq 0.
\end{array}
$$
Vemos que la variable $Y$ corresponde a una distribución exponencial de parámetro $\lambda =2$.

</div>

### Ejemplo 2 con `R`
<div class="example">
Dibujemos la **función de densidad conjunta** y la **función de distribución conjunta** con `R`. Primero las definimos:

```{r}
fun.den.con = function(x,y){ifelse(x>=0 & y>=0 & x>=y,
                                   2*exp(-x-y),0)}
fun.dist.con = function(x,y){ifelse(x>=0 & y>=0 & x<=y,
                    1-2*exp(-x)+exp(-2*x),ifelse(x>=0 & y>=0 & x>=y,
                    1-2*exp(-x)-exp(-2*y)+2*exp(-x-y),0))}
```
A continuación las dibujamos para $x$ e $y$ entre $-1$ y $4$:
```{r,eval=FALSE}
x=seq(from=-1,to=4,by=0.1)
y=seq(from=-1,to=4,by=0.1)
z.fun.den.con=outer(x,y,fun.den.con)
z.fun.dist.con = outer(x,y,fun.dist.con)
persp(x,y,z.fun.den.con,theta=50,phi=40,col="blue",shade=0.25,ticktype="detailed")
persp(x,y,z.fun.dist.con,theta=50,phi=40,col="blue",shade=0.25,ticktype="detailed")
```
</div>

### Ejemplo 2 con `R`
```{r,echo=FALSE,fig.align='center',fig.height=6.5}
x=seq(from=-1,to=4,by=0.1)
y=seq(from=-1,to=4,by=0.1)
z.fun.den.con=outer(x,y,fun.den.con)
z.fun.dist.con = outer(x,y,fun.dist.con)
persp(x,y,z.fun.den.con,theta=50,phi=40,col="green",shade=0.25,ticktype="detailed")
```

### Ejemplo 2 con `R`
```{r,echo=FALSE,fig.align='center',fig.height=6.5}
persp(x,y,z.fun.dist.con,theta=50,phi=40,col="green",shade=0.25,ticktype="detailed")
```

### La distribución gaussiana bidimensional
Vamos a generalizar la distribución normal a dos dimensiones.

<l class="definition">Definición de distribución gaussiana bidimensional. </l>
Diremos que la distribución de la variable aleatoria bidimensional $(X,Y)$ es **gaussiana bidimensional** dependiendo del parámetro $\rho$ si su **función de densidad conjunta** es:
$$
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty <x,y<\infty.
$$


### La distribución gaussiana bidimensional
Propiedades de la **función de densidad de la variable gaussiana bidimensional**:

* Para cualquier punto $(x,y)\in\mathbb{R}^2$, la **función de densidad** es no nula: $f_{XY}(x,y)>0$.

* La **función de densidad** tiene un único máximo absoluto en el punto $(0,0)$ que vale $f_{XY}(0,0)=\frac{1}{2\pi\sqrt{1-\rho^2}}.$ Por tanto, para $\rho=0$, dicho máximo alcanza el mínimo valor posible y si $\rho\to \pm 1$, dicho máximo tiende a $\infty$.

### La distribución gaussiana bidimensional
* Las densidades marginales $f_X(x)$ y $f_Y(y)$ son normales $N(0,1)$. 

<div class="dem">
Veámoslo con $f_X(x)$. Por simetría, quedaría deducido para $f_Y(y)$:
$$
\begin{array}{rl}
f_X(x) & =\frac{1}{2\pi\sqrt{1-\rho^2}}\int_{-\infty}^\infty \mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy =
\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}}\int_{-\infty}^\infty \mathrm{e}^{-\frac{(-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy \\ & = \frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}} \int_{-\infty}^\infty \mathrm{e}^{-\frac{(y-\rho x)^2}{2(1-\rho^2)}} \mathrm{e}^{\frac{\rho^2 x^2}{2(1-\rho^2)}}\, dy \\ & =\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2}} \int_{-\infty}^\infty \mathrm{e}^{-\frac{(y-\rho x)^2}{2(1-\rho^2)}}\, dy,  \mbox{ hacemos cambio $z=\frac{y-\rho x}{\sqrt{1-\rho^2}}$}\\ & = \frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{x^2}{2}} \int_{-\infty}^\infty \mathrm{e}^{-\frac{z^2}{2}}\sqrt{1-\rho^2}\, dy =\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}},
\end{array}
$$
función que coincide con la **función de densidad** de la variable $N(0,1)$. 
</div>

### La distribución gaussiana bidimensional

<div class="dem">
En el último paso hemos usado que 
$$
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty \mathrm{e}^{-\frac{z^2}{2}}\, dz=1,
$$
ya que correspondería al área de una **función de densidad** de una distribución $N(0,1)$.
</div>


### La distribución gaussiana bidimensional en `R`
<div class="example">
En `R` existe el paquete `bivariate` para trabajar con algunas distribuciones conjuntas; en particular, con la **distribución normal bidimensional**.

La función que nos la densidad de la **distribución normal bidimensional** es `nbvpdf` y tiene 5 parámetros: la **media** de $X$ ($\mu_X$), la **media** de $Y$ ($\mu_Y$), la **desviación típica** de $X$ ($\sigma_X$), la **desviación típica** de $Y$ ($\sigma_Y$) y un concepto que veremos más adelante, la **correlación** entre $X$ e $Y$ ($\rho_{XY}$).

En el ejemplo que estamos tratando, los valores de los parámetros anteriores son: $\mu_X=\mu_Y=0$, $\sigma_X=\sigma_Y=1$ y $\rho_{XY}=\rho.$

Vamos a hacer un gráfico de la **distribución normal bidimensional** para $\rho=\frac{1}{2}.$

```{r,eval=FALSE}
library(bivariate)
f = nbvpdf (0, 0, 1, 1, 0.5)
plot(f,TRUE)
```


</div>

### La distribución gaussiana bidimensional en `R`

```{r,echo=FALSE,fig.align='center',fig.height=6}
library(bivariate)
f = nbvpdf (0, 0, 1, 1, 0.5)
plot(f,TRUE)
```


## Independencia de variables aleatorias

### Independencia de variables aleatorias discretas
Recordemos que dos sucesos $A$ y $B$ son independientes si $P(A\cap B)=P(A)\cdot P(B)$.

¿Cómo trasladar dicho concepto al caso de variables aleatorias?

En el caso de **variables aleatorias discretas bidimensionales** vimos que, dada una variable aleatoria bidimensional discreta $(X,Y)$ con $(X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,j=1,2,\ldots\}$, los sucesos de la forma $\{X=x_i,\  Y=y_j\}$ determinaban cómo se distribuían los valores de la variable $(X,Y)$. De ahí la definición siguiente:

### Independencia de variables aleatorias discretas
<l class="definition">Definición de independencia para variables aleatorias bidimensionales discretas. </l>
Sean $(X,Y)$ una **variable aleatoria bidimensional discreta** con $(X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots,j=1,2,\ldots\}$ y **función de probabilidad** $P_{XY}$ y **funciones de probabilidad marginales** $P_X$ y $P_Y$. Entonces $X$ e $Y$ son independientes si:
$$
P_{XY}(x_i,y_j)=P_X(x_i)\cdot P_Y(y_k),\ i=1,2,\ldots,j=1,2,\ldots
$$
o dicho de otra forma:
$$
P(X=x_i,\ Y=y_k)=P(X=x_i)\cdot P(Y=y_k),\ i=1,2,\ldots,j=1,2,\ldots
$$


### Ejemplo
<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

Consideramos la variable aleatoria $(S,P)$ donde $S$ representa la suma de los valores obtenidos al lanzar dos veces un dado y $P$, su producto. 

En este caso $S$ y $P$ no son independientes ya que recordemos que por ejemplo $P_{SP}(3,2)=\frac{2}{36}$, $P_S(3)=\frac{2}{36}$ y $P_P(2)=\frac{2}{36}$, ya que en este último caso, sólo hay dos posibles resultados en los que el producto dé 2: el $(1,2)$ y el $(2,1)$.

Entonces no se cumple que $P_{SP}(3,2)=P_S(3)\cdot P_P(2)$, ya que $\frac{2}{36}\neq \frac{2}{36}\cdot \frac{2}{36}$.

De ahí que no sean independientes ya que la condición anterior se debería cumplir para todos los valores $x_i$ e $y_k$ y hemos encontrado un contraejemplo en donde no se cumple.

</div>

<l class="observ">Observación. </l>
Si la tabla de la **función de probabilidad conjunta** de $(X,Y)$ contiene algún $0$, $X$ e $Y$ no pueden ser independientes. ¿Podéis decir por qué?

### Ejemplo
<div class="example">
**Ejemplo**

Veamos un caso de independencia.

Consideramos el experimento aleatorio de lanzar un dado dos veces. Sea $X$ el resultado del primer lanzamiento e $Y$, el resultado del segundo lanzamiento.

Veamos que, en este caso, $X$ e $Y$ son independientes.

El valor de $(X,Y)(\Omega)=\{(1,1),(1,2),\ldots,(6,6)\}$, en total 36 resultados.

La **función de probabilidad conjunta** en un valor cualquiera $(i,j)$ con $i,j\in\{1,2,3,4,5,6\}$ será:
$P_{XY}(i,j)=\frac{1}{36}$ ya que la probabilidad que salga $i$ en el primer lanzamiento es $\frac{1}{6}$ y la probabilidad de que salga $j$ en el segundo lanzamiento, también. Por tanto, la probabilidad de que salga $i$ en el primer lanzamiento y $j$ en el segundo será: $\frac{1}{6}\cdot \frac{1}{6}=\frac{1}{36}.$
</div>


### Ejemplo
<div class="example">
**Ejemplo**

Las **funciones de densidad marginales** de $X$ e $Y$ serán:
<div class="center">
| $X$ o $Y$| 1 | 2| 3 | 4 | 5| 6 
|--|--|--|--|--|--|--
| $P_X$ o $P_Y$|$\frac{1}{6}$|$\frac{1}{6}$|$\frac{1}{6}$|$\frac{1}{6}$|$\frac{1}{6}$|$\frac{1}{6}$
</div>

Por tanto, para todo $(i,j)$ con $i,j\in\{1,2,3,4,5,6\}$ se cumplirá:
$$
P_{XY}(i,j)=\frac{1}{36}=\frac{1}{6}\cdot \frac{1}{6}=P_X(i)\cdot P_Y(j).
$$
Deducimos que son independientes.
</div>

### Ejemplo con `R`
<div class="example">
Para comprobar si dos variables aleatorias $X$ e $Y$ son independientes o no en `R` en general, una vez calculada la tabla de la **función de probabilidad**, podemos calcular la tabla de **independencia teórica** $P_T(x_i,y_j)$ y compararlas. Ésta segunda tabla se define de la forma siguiente: 
$$
P_T(x_i,y_j)=P_X(x_i)\cdot P_Y(y_j),
$$
donde $P_X$ y $P_Y$ son las distribuciones marginales.

La tabla de **independencia teórica ** en el caso de la suma y el producto se calcularían de la forma siguiente:
```{r}
tabla.ind.teor =  marginal.suma%*%t(marginal.producto)
tabla.ind.teor = as.data.frame(tabla.ind.teor)
rownames(tabla.ind.teor)=rownames(tabla.func.prob.conjunta)
colnames(tabla.ind.teor)=colnames(tabla.func.prob.conjunta)
```
Si comparáis los resultados de la tabla de **independencia teórica** mostrada en las transparencias siguientes con los resultados de la tabla de la **función de probabilidad conjunta**, veréis que no son iguales. Por tanto, $S$ y $P$ no son **independientes**.

</div>

### Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.ind.teor[1:6,1:9],4))
```


</div>

### Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.ind.teor[1:6,10:18],4))
```


</div>

### Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.ind.teor[7:11,1:9],4))
```


</div>

### Ejemplo con `R`
<div class="example">
```{r,echo=FALSE}
knitr::kable(round(tabla.ind.teor[7:11,10:18],4))
```


</div>

### Independencia de variables aleatorias continuas
La definición dada para **variables aleatorias discretas** se traslada de forma natural a las **variables aleatorias continuas**:

<l class="definition">Definición de independencia para variables aleatorias bidimensionales continuas. </l>
Sean $(X,Y)$ una **variable aleatoria bidimensional continua** con **función de densidad conjunta** $f_{XY}$ y **funciones de densidad marginales** $f_X$ y $f_Y$. Entonces $X$ e $Y$ son independientes si:
$$
f_{XY}(x,y)=f_X(x)\cdot f_Y(y),\ \mbox{para todo $x,y\in\mathbb{R}$.}
$$

### Independencia de variables aleatorias continuas. Ejemplo
<div class="example">
**Ejemplo**

Recordemos el ejemplo siguiente visto donde teníamos una **variable aleatoria bidimensional continua** $(X,Y)$ con **función de densidad conjunta**:
$$
f_{XY}(x,y)=\begin{cases}
1, & \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$
y con densidad marginales:
$$
f_{X}(x)=\begin{cases}
1, & \mbox{ si }0\leq x\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\quad f_{Y}(y)=\begin{cases}
1, & \mbox{ si }0\leq y\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
</div>

### Independencia de variables aleatorias continuas. Ejemplo
<div class="example">
**Ejemplo**

Veamos que son independientes.

Consideremos dos casos:

* $(x,y)\in [0,1]\times [0,1]$. En este caso:
$$
f_{XY}(x,y) =1 =1\cdot 1=f_X(x)\cdot f_Y(y).
$$

* $(x,y)\not\in [0,1]\times [0,1]$. En este caso:
$$
f_{XY}(x,y) =0 = f_X(x)\cdot f_Y(y),
$$
ya que si $(x,y)\not\in [0,1]\times [0,1]$, o $x\not\in [0,1]$ o $y\not\in [0,1]$. Por tanto $f_X(x)=0$ o $f_Y(y)=0$. En cualquier caso, $f_X(x)\cdot f_Y(y)=0$.
</div>

### Independencia de variables aleatorias continuas. Ejemplo
<div class="example">
**Ejemplo**

Recordemos el ejemplo siguiente visto donde teníamos una **variable aleatoria bidimensional continua** $(X,Y)$ con **función de densidad conjunta**:
$$
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario,}
\end{cases}
$$
y con densidad marginales:
$$
f_X(x)  = 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right),\mbox{ si }x\geq 0, \quad
f_Y(y)  =  2\mathrm{e}^{-2y}, \mbox{ si }y\geq 0.
$$
En este caso no son independientes ya que claramente $f_{XY}(x,y)\neq f_X(x)\cdot f_Y(y)$.
</div>


### Ejemplo de la variable gaussiana bidimensional
En este caso, recordemos que la **función de densidad conjunta** de $(X,Y)$ es:
$$
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty <x,y<\infty.
$$
Las **funciones de densidad marginales** de $X$ e $Y$ correspondían a $N(0,1)$:
$$
\begin{array}{rl}
f_X(x) & =\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}},\ -\infty <x<\infty,\\ f_Y(y) & =\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{y^2}{2}},\ -\infty <y<\infty.
\end{array}
$$

### Ejemplo de la variable gaussiana bidimensional

¿Para qué valor(es) de $\rho$ las variables normales estándar $X$ e $Y$ serían independientes?

o, ¿para qué valor(es) de $\rho$ se cumple?
$$
f_X(x)\cdot f_Y(y)=\frac{1}{2\pi}\mathrm{e}^{-\frac{x^2+y^2}{2}} = \frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}.
$$
La respuesta es claramente para $\rho=0$.

Por tanto, $\rho$ se puede interpretar como un parámetro de independencia, cuánto más cercano a cero esté, más cerca de la independencia estarán las variables $X$ e $Y$.

### Relación de la independencia y la función de distribución
El siguiente resultado nos da la relación entre la **independencia de variables aleatorias** y su **función de distribución conjunta**:

<l class="prop">Teorema. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional. Entonces 
$X$ e $Y$ son independientes si, y sólo si, la **función de distribución conjunta** es el producto de las **funciones de distribución marginales** en todo valor $(x,y)\in\mathbb{R}^2$:
$$
F_{XY}(x,y)=F_X(x)\cdot F_Y(y),\ (x,y)\in\mathbb{R}^2.
$$

### Ejemplo de variables aleatorias discretas independientes
<div class="example">
**Ejemplo**


Consideramos el experimento aleatorio de lanzar un dado dos veces. Sea $X$ el resultado del primer lanzamiento e $Y$, el resultado del segundo lanzamiento.

Recordemos que, en este caso, $X$ e $Y$ son independientes.

En primer lugar notemos que si $x<1$ o $y<1$, $F_{XY}(x,y)=0$ ya que el suceso $\{X\leq x,\ Y\leq y\}$ es vacío.

De la misma forma como $x<1$ o $y<1$, o el suceso $\{X\leq x\}$ o el suceso $\{Y\leq y\}$ son vacíos. Por tanto, o $F_X(x)=0$ o $F_Y(y)=0$.

En cualquier caso, se cumple $F_{XY}(x,y)=0=F_X(x)\cdot F_Y(y)$.

Podemos suponer, por tanto, que $x\geq 1$ e $y\geq 1$.

</div>

### Ejemplo de variables aleatorias discretas independientes
<div class="example">

Sea $(x,y)\in \mathbb{R}^2$ con $x\geq 1$ e $y\geq 1$. Podemos suponer tal que existen dos valores $i$ y $j$ en $\{1,2,\ldots\}$ con $i\leq x < i+1$ y $j\leq y <j+1$.


El valor de la **función de distribución conjunta** en $(x,y)$ será: 
$$
F_{XY}(x,y)=\begin{cases}
\frac{i\cdot j}{36}, & \mbox{si }i\leq 6, \ j\leq 6, \\
\frac{6 i}{36}, & \mbox{si }i\leq 6,\ j\geq 6,\\
\frac{6 j}{36}, & \mbox{si }i\geq 6,\ j\leq 6,\\
1, & \mbox{ si }i\geq 6,\ j\geq 6,
\end{cases}
$$
</div>
### Ejemplo de variables aleatorias discretas independientes
<div class="example">
ya que:
$$
\begin{array}{rl}
F_{XY}(x,y) & =P(X\leq i,\ Y\leq j)=P(\{(k,l)\in \{1,2,3,4,5,6\}^2,\ |\ k\leq i,\ l\leq j\})\\ & =P(\{(1,1),\ldots,(1,j),\ldots,(i,1),\ldots,(i,j)\})=\begin{cases}
\frac{i\cdot j}{36}, & \mbox{si }i\leq 6, \ j\leq 6, \\
\frac{6 i}{36}, & \mbox{si }i\leq 6,\ j\geq 6,\\
\frac{6 j}{36}, & \mbox{si }i\geq 6,\ j\leq 6,\\
1, & \mbox{ si }i\geq 6,\ j\geq 6,
\end{cases},
\end{array}
$$
ya que claramente el cardinal del conjunto $\{(1,1),\ldots,(1,j),\ldots,(i,1),\ldots,(i,j)\}$ es $\begin{cases}
i\cdot j, & \mbox{si }i\leq 6, \ j\leq 6, \\
6 i, & \mbox{si }i\leq 6,\ j\geq 6,\\
6 j, & \mbox{si }i\geq 6,\ j\leq 6,\\
36, & \mbox{ si }i\geq 6,\ j\geq 6.
\end{cases}$.
</div>

### Ejemplo de variables aleatorias discretas independientes
<div class="example">

Hallemos ahora la función de distribución de $X$ e $Y$ que consiste en el resultado del lanzamiento de un dado.

Dado $x\in\mathbb{R}$ con $x\geq 1$, existe un $i$ con $i\in\{1,2,\ldots,\}$ con $i\leq x <i+1$. En este caso, el valor de $F_X(x)$ es:
$$
F_X(x)=\begin{cases}
\frac{i}{6}, &\mbox{si }i\leq 6,\\
1, & \mbox{si }i\geq 6,
\end{cases}
$$
ya que:
$$
F_X(x)=F_X(i)=P(X\leq i)=P(\{k\in\{1,2,3,4,5,6\},\ |\ k\leq i\})=\begin{cases}
\frac{i}{6}, &\mbox{si }i\leq 6,\\
1, & \mbox{si }i\geq 6,
\end{cases},
$$
ya que el cardinal del conjunto $\{k\in\{1,2,3,4,5,6\},\ |\ k\leq i\}$ es $\begin{cases}
i, &\mbox{si }i\leq 6,\\
6, & \mbox{si }i\geq 6.
\end{cases}$
</div>

### Ejemplo de variables aleatorias discretas independientes
<div class="example">
La función de distribución de $Y$ es de la misma forma.

Por último, comprobemos que se verifica que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$, si $x\geq 1$ e $y\geq 1$.

Sea $(x,y)\in\mathbb{R}^2$ y sean los enteros $i$ y $j$ tales que $i\leq x<i+1$ y $j\leq y<j+1$. Consideremos 4 casos:

* $i\leq 6, \ j\leq 6$. En este caso:
$$
F_{XY}(x,y)=\frac{i\cdot j}{36}=\frac{i}{6}\cdot \frac{j}{6}=F_X(x)\cdot F_Y(y).
$$

* $i\leq 6,\ j\geq 6$. En este caso:
$$
F_{XY}(x,y)=\frac{6i}{36}=\frac{i}{6}\cdot 1=F_X(x)\cdot F_Y(y).
$$


</div>
### Ejemplo de variables aleatorias discretas independientes
<div class="example">
* $i\geq 6,\ j\leq 6$. En este caso:
$$
F_{XY}(x,y)=\frac{6j}{36}=1\cdot \frac{j}{6}=F_X(x)\cdot F_Y(y).
$$

* $i\geq 6,\ j\geq 6$. En este caso:
$$
F_{XY}(x,y)=1=1\cdot 1=F_X(x)\cdot F_Y(y).
$$

En resumen, para todo $(x,y)\in \mathbb{R}^2$ se verifica que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$, tal como queríamos ver.
</div>


### Ejemplo de variables aleatorias continuas independientes
<div class="example">
**Ejemplo**

Recordemos la variable aleatoria bidimensional continua con **función de densidad conjunta**:
$$
f_{XY}(x,y)=\begin{cases}
1, & \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$
Su **función de distribución conjunta** es: 
$$
F_{XY}(x,y)=\begin{cases}
0, & \mbox{si }x<0,\mbox{ o }y<0,\\
xy, & \mbox{si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
x, & \mbox{si }0\leq x\leq 1,\ y> 1, \\
y, & \mbox{si }0\leq y\leq 1,\ x> 1, \\
1, & x\geq 1,\ y\geq 1.
\end{cases}
$$
</div>

### Ejemplo de variables aleatorias continuas independientes
<div class="example">
Recordemos también que las **distribuciones marginales** de $X$ e $Y$ eran uniformes en el intervalo $[0,1]$. Por tanto, las **funciones de distribución marginales** serán:
$$
F_X(x)=\begin{cases}
0, & \mbox{si }x\leq 0, \\
x, & \mbox{si }0\leq x\leq 1, \\
1, & \mbox{si }x\geq 1. \\
\end{cases},\quad 
F_Y(y)=\begin{cases}
0, & \mbox{si }y\leq 0, \\
y, & \mbox{si }0\leq y\leq 1, \\
1, & \mbox{si }y\geq 1. \\
\end{cases}
$$
Recordemos que $X$ e $Y$ son independientes. Verifiquemos que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$. 

Distinguiremos cinco casos:

* $x<0$ o $y<0$. En este caso, $F_{XY}(x,y)=0$ y, o $F_X(x)=0$, si $x<0$, o $F_Y(y)=0$, si $y<0$. En cualquier caso, se cumple que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$.

* $0\leq x\leq 1,\ 0\leq y\leq 1$. En este caso, $F_{XY}(x,y)=xy$, $F_X(x)=x$ y $F_Y(y)=y$. Claramente, se cumple que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$.

</div>

### Ejemplo de variables aleatorias continuas independientes
<div class="example">

* $0\leq x\leq 1,\ y> 1$. En este caso, $F_{XY}(x,y)=x$, $F_X(x)=x$ y $F_Y(y)=1$. Claramente, se cumple que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$.

* $x >1,\ 0\leq y\leq  1$. En este caso, $F_{XY}(x,y)=y$, $F_X(x)=1$ y $F_Y(y)=y$. Claramente, se cumple que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$.

* $x\geq 1,\ y\geq 1$. En este caso, $F_{XY}(x,y)=1$, $F_X(x)=1$ y $F_Y(y)=1$. Claramente, se cumple que $F_{XY}(x,y)=F_X(x)\cdot F_Y(y)$.


</div>

## Momentos conjuntos y valores esperados conjuntos

### Introducción

El **valor esperado** de una variable aleatoria $X$ se identifica con el *centro de masa de la distribución de $X$*. 

La **varianza** proporciona una medida de la *extensión de la distribución*. 
   
En el caso de dos variables aleatorias, estamos interesados en cómo $X$ e $Y$ varían juntas. 

En particular, nos interesa saber si la variación de $X$ e $Y$ está correlacionada. Por ejemplo, si $X$ aumenta, ¿Y tiende a aumentar o disminuir? 

Los momentos conjuntos de $X$ e $Y$, que se definen como valores esperados de las funciones de $X$ e $Y$, proporcionan esta información.

### Valor esperado de una función de dos variables aleatorias
Sea $(X,Y)$ una variable aleatoria bidimensional. 

Sea $P_{XY}$ su **función de probabilidad conjunta** en el caso en que $(X,Y)$ sea **discreta** y $f_{XY}$ su **función de densidad conjunta** en el caso en que $(X,Y)$ sea **continua**.

Sea $Z=g(X,Y)$ una **variable aleatoria unidimensional** función de las variables $X$ e $Y$. Por ejemplo: 

* Suma de las dos variables $g(x,y)=x+y$: $Z=X+Y$.
* Producto de las dos variables $g(x,y)=x\cdot y$: $Z=X\cdot Y$.
* Suma de los cuadrados de las variables $g(x,y)=x^2+y^2$: $Z=X^2+Y^2$.

### Valor esperado de una función de dos variables aleatorias
Hay que tener en cuenta que $Z$, como **variable aleatoria unidimensional** tiene una **función de probabilidad** $P_Z$ en el caso en que $(X,Y)$ sea discreta y una **función de densidad** $f_Z$ en el caso en que $(X,Y)$ sea continua.

El siguiente resultado nos dice cómo calcular el **valor esperado** de $Z$ sin tener que calcular $P_Z$ o $f_Z$, sólo usando la información de la **variable aleatoria conjunta** $(X,Y)$:

### Valor esperado de una función de dos variables aleatorias

<l class="prop">Proposición. </l>
El valor esperado de $Z$ se puede hallar usando la expresión siguiente:

* en el caso en que $(X,Y)$ sea discreta con $(X,Y)(\Omega)=\{(x_i,y_j),\ i=1,2,\ldots, j=1,2,\ldots\}$,
$$
E(Z)  = E(g(X,Y))  =\sum_{x_i}\sum_{y_j}g(x_i,y_j)P(x_i,y_j),
$$

* en el caso en que $(X,Y)$ sea continua:
$$
E(Z)=E(g(X,Y))=\int_{-\infty}^\infty \int_{-\infty}^\infty g(x,y)f_{XY}(x,y)\, dx\, dy.
$$

### Ejemplo
<div class="example">
**Ejemplo**

Consideremos el ejemplo de la variable $(S,P)$ que nos daba la suma y el producto de los resultados cuando lanzábamos dos veces un dado. 

Vamos a calcular $E(S+P)$.

Recordemos que ya hemos calculado $P_{SP}$. La expresión de $E(S+P)$ será:
$$
\begin{array}{rll}
E(S+P) & = &(2+1)\cdot P_{SP}(2,1)+(3+2)\cdot P_{SP}(3,2)+(4+3)\cdot P_{SP}(4,3)+(4+4)\cdot P_{SP}(4,4)\\ & &
+ (5+4)\cdot P_{SP}(5,4)+(5+6)\cdot P_{SP}(5,6)+(6+5)\cdot P_{SP}(6,5)+(6+8)\cdot P_{SP}(6,8)\\ & & 
+ (6+9)\cdot P_{SP}(6,9)+(7+6)\cdot P_{SP}(7,6)+(7+10)\cdot P_{SP}(7,10)+(7+12)\cdot P_{SP}(7,12)\\ & & 
+ (8+12)\cdot P_{SP}(8,12)+(8+15)\cdot P_{SP}(8,15)+(8+16)\cdot P_{SP}(8,16)\\ & & +(9+18)\cdot P_{SP}(9,18)
+ (9+20)\cdot P_{SP}(9,20)+(10+24)\cdot P_{SP}(10,24)\\ & & +(10+25)\cdot P_{SP}(10,25)+(11+30)\cdot P_{SP}(11,30) 
+ (12+36)\cdot P_{SP}(12,36) \\ & = & 3\cdot \frac{1}{36}+5\cdot\frac{2}{36}+7\cdot \frac{2}{36}+8\cdot \frac{1}{36}+9\cdot \frac{2}{36}+11\cdot\frac{2}{36}+11\cdot \frac{2}{36}+14\cdot\frac{2}{36}+15\cdot\frac{1}{36}\\ & & 
+ 13\cdot\frac{2}{36}+17\cdot\frac{2}{36}+19\cdot\frac{2}{36}+20\cdot\frac{2}{36}+23\cdot\frac{2}{36}+24\cdot\frac{1}{36}+27\cdot\frac{2}{36}+29\cdot\frac{2}{36} \\ & & 
+ 34\cdot\frac{2}{36}+35\cdot\frac{1}{36}+41\cdot\frac{2}{36}+48\cdot\frac{1}{36}=\frac{`r 3+10+14+8+18+22+22+14*2+15+13*2+17*2+19*2+20*2+23*2+24+27*2+29*2+34*2+35+41*2+48`}{36}= `r (3+10+14+8+18+22+22+14*2+15+13*2+17*2+19*2+20*2+23*2+24+27*2+29*2+34*2+35+41*2+48)/36`.
\end{array}
$$
</div>

### Ejemplo con `R`
<div class="example">
Hallar el valor esperado de la suma $E(S+P)$ una vez hallada la tabla de la **función de probabilidad conjunta**, en `R` es bastante sencillo usando la función `outer`: 

```{r}
valores.suma = as.integer(rownames(tabla.func.prob.conjunta))
valores.producto = as.integer(colnames(tabla.func.prob.conjunta))
suma.valores = outer(valores.suma,valores.producto,"+")
(valor.esperado.suma = sum(suma.valores*tabla.func.prob.conjunta))
```
</div>

<l class="observ">Observación:</l>
En `R` para hallar el valor esperado de una función $g(X,Y)$, $E(g(X,Y))$ de las variables aleatorias $X$ e $Y$, basta sustituir el valor `+` en el script anterior por `FUN=g`, definiendo previamente la función `g`.

### Ejemplo
<div class="example">
**Ejemplo**

Recordemos el ejemplo donde $(X,Y)$ era una variable aleatoria bidimensional continua con **función de densidad conjunta**:
$$
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario.}
\end{cases}
$$
Calculemos $E(X\cdot Y)$:
$$
\begin{array}{ll}
E(X\cdot Y) & =\int_{x=0}^{x=\infty} \int_{y=0}^{y=x} 2 x y \mathrm{e}^{-x}\mathrm{e}^{-y}\, dy\, dx=2\int_{x=0}^{x=\infty} x \mathrm{e}^{-x} \int_{y=0}^{y=x}  y \mathrm{e}^{-y}\, dy\, dx \\ & = 2\int_{x=0}^{x=\infty}x \mathrm{e}^{-x} \left[-\mathrm{e}^{-y} (y+1)\right]_{y=0}^{y=x}\, dx =
2\int_{x=0}^{x=\infty}x \mathrm{e}^{-x} \left(1-\mathrm{e}^{-x}(x+1)\right)\, dx \\ &= 2\int_{x=0}^{x=\infty}x\left( \mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)-x^2\mathrm{e}^{-2x}\, dx \\ & =
2\left[-\mathrm{e}^{-x}(x+1)+\frac{1}{4}\mathrm{e}^{-2 x}(1+2x)+\frac{1}{4} \mathrm{e}^{-2 x} \left(2 x^2+2
   x+1\right)\right]_{x=0}^{x=\infty} = 2\cdot \left(1-\frac{1}{4}-\frac{1}{4}\right)=1.
\end{array}
$$
En el último cálculo hemos usado integración por partes para integrar $\int x\mathrm{e}^{-x}\,dx$, $\int x\mathrm{e}^{-2x}\,dx$ y $\int x^2\mathrm{e}^{-2x}\, dx$.
</div>

<div class="exercise">
**Ejercicio**

Hallar $E(X+Y)$ para el ejemplo anterior.

</div>

### Valor esperado de una función de dos variables aleatorias independientes

El siguiente resultado nos simplifica el cálculo del **valor esperado de una función de dos variables aleatorias** en el caso en que sean **independientes**:

<l class="prop">Proposición: cálculo del valor esperado de una función de dos variables aleatorias en el caso de independencia. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional donde suponemos que $X$ e $Y$ son independientes. 
Sea $Z=g(X,Y)$ una variable aleatoria unidimensional función de $X$ e $Y$ donde suponemos que podemos "separar" las variables $x$ e $y$ en la función $g$. O sea, existen dos funciones $g_x$ y $g_y$ tal que $g(x,y)=g_x(x)\cdot g_y(y)$ para todo valor $x,y\in\mathbb{R}$. En este caso, el valor esperado de $Z$ se puede calcular como:
$$
E(Z)=E(g(X,Y))=E_X(g_x(X))\cdot E_Y(g_y(Y)).
$$

### Valor esperado de una función de dos variables aleatorias independientes
O sea, el cálculo de $E(g(X,Y))$ que sería una suma doble en el caso de que $(X,Y)$ sea **discreta** o una integral doble en el caso en que $(X,Y)$ sea continua se transforma en el producto de dos sumas simples (caso **discreto**) o el producto de dos integrales simples (caso **continuo**):
$$
\begin{array}{rl}
E(Z) & =E(g(X,Y))=\left(\sum_{x_i} g_x(x_i)\cdot P_X(x_i)\right)\cdot \left(\sum_{y_j} g_y(y_j)\cdot P_Y(y_j)\right),\\ &\ \quad \mbox{caso discreto},\\
E(Z) & =E(g(X,Y))=\left(\int_{-\infty}^\infty g_x(x)\cdot f_X(x)\, dx\right)\cdot \left(\int_{-\infty}^\infty g_y(y)\cdot f_Y(y)\right), \\  &\ \quad \mbox{caso continuo}.
\end{array}
$$

### Valor esperado de una función de dos variables aleatorias independientes
Un caso particular de aplicación de la proposición anterior sería cuando queramos calcular $E(X\cdot Y)$. En este caso $g(x,y)=x\cdot y$, $g_x(x)=x$, y $g_y(y)=y$. 

Podemos escribir, por tanto:
$$
E(X\cdot Y)=E_X(X)\cdot E_Y(Y),
$$
si $X$ e $Y$ son independientes.

### Ejemplo
<div class="example">
**Ejemplo**


Recordemos el experimento aleatorio que consiste en lanzar un dado dos veces. Sea $X$ el resultado del primer lanzamiento e $Y$, el resultado del segundo lanzamiento.

Hemos visto que $X$ e $Y$ son independientes. 

Las marginales de $X$ e $Y$ recordemos que son las siguientes:
<div class="center">
| $X$ o $Y$| 1   |2 | 3 | 4 | 5 |  6
|----|---|---|---|---|---|---
| $P_X(i)$ o $P_Y(i)$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$
</div>
Calculemos $E(X\cdot Y)$ usando la proposición anterior:
$$
E(X\cdot Y)=E_X(X)\cdot E_Y(Y)=\left(\sum_{i=1}^6 i\cdot \frac{1}{6}\right)\cdot \left(\sum_{i=1}^6 i\cdot \frac{1}{6}\right)=\left(\frac{21}{6}\right)^2 = `r (21/6)^2`.
$$
Dejamos como ejercicio el cálculo de $E(X\cdot Y)$ usando la **función de probabilidad conjunta**  $P_{XY}$ y comprobar que da el mismo resultado.
</div>


### Ejemplo
<div class="example">
**Ejemplo**

Recordemos la variable aleatoria bidimensional continua con **función de densidad conjunta**:
$$
f_{XY}(x,y)=\begin{cases}
1, & \mbox{ si }0\leq x\leq 1,\ 0\leq y\leq 1, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$
donde vimos que $X$ e $Y$ eran independientes y de distribución uniforme en el intervalo $[0,1]$.

Calculemos $E(X\cdot Y)$ usando la proposición:
$$
E(X\cdot Y)=E_X(X)\cdot E_Y(Y)=\int_0^1 x\cdot 1\, dx\cdot \int_0^1 y\cdot 1\, dy =\left.\frac{x^2}{2}\right]_{x=0}^{x=1}\cdot \left.\frac{y^2}{2}\right]_{y=0}^{y=1}=\frac{1}{2}\cdot \frac{1}{2}=\frac{1}{4}.
$$
Dejamos como ejercicio el cálculo de $E(X\cdot Y)$ usando la **función de densidad conjunta**  $f_{XY}$ y comprobar que da el mismo resultado.
</div>

### Momentos conjuntos
A continuación vamos a definir el momento de orden $(k,l)$ para una variable aleatoria bidimensional $(X,Y)$ para intentar obtener información de su comportamiento conjunto:

<l class="definition">Definición de momento conjunto. </l>
Sean $(X,Y)$ una variable aleatoria bidimensional con **función de probabilidad conjunta** $P_{XY}$ en el caso discreto y **función de densidad conjunta** $f_{XY}$ en el caso continuo. Dados $k$ y $l$ números enteros positivos, definimos el **momento conjunto de orden $(k,l)$** para la variable $(X,Y)$ como:
$$
E\left(X^k Y^l\right)=\begin{cases}
\sum_{x_i}\sum_{y_j} x_i^k y_j^l P_{XY}(x_i,y_j), & \mbox{ caso discreto,} \\
\int_{-\infty}^\infty\int_{-\infty}^\infty x^k y^l f_{XY}(x,y)\, dx\, dy. & \mbox{ caso continuo.}
\end{cases}
$$

### Momentos conjuntos
<l class="observ">Observación.</l>
Si consideramos $l=0$, los momentos conjuntos de orden $(k,0)$ coinciden con los momentos de orden $k$ de la variable aleatoria $X$. 

De la misma forma, considerando $k=0$, los momentos conjuntos de orden $(0,l)$ coinciden con los momentos de orden $l$ de la variable aleatoria $Y$.

Para $l=1$ y $k=1$ obtenemos el momento de orden $(1,1)$ ya visto anteriormente: $E(X\cdot Y)$, denominado **correlación entre las variables $X$ e $Y$**. Si dicha correlación es nula, $E(X\cdot Y)=0$, se dice que las variables $X$ e $Y$ son **ortogonales**.

### Momentos conjuntos centrados en las medias
A continuación definamos los **momentos conjuntos centrados en las medias**:

<l class="definition">Definición de momento conjunto. </l>
Sean $(X,Y)$ una variable aleatoria bidimensional con **función de probabilidad conjunta** $P_{XY}$ en el caso discreto y **función de densidad conjunta** $f_{XY}$ en el caso continuo. Sean $\mu_X=E(X)$ y $\mu_Y=E(Y)$ los **valores esperados** de las variables $X$ e $Y$, respectivamente. Dados $k$ y $l$ números enteros positivos, definimos el **momento conjunto de orden $(k,l)$ centrado en las medias** para la variable $(X,Y)$ como:
$$
E\left((X-\mu_X)^k (Y-\mu_Y)^l\right)=\begin{cases}
\sum_{x_i}\sum_{y_j} (x_i-\mu_X)^k (y_j-\mu_Y)^l P_{XY}(x_i,y_j), & \\\ \qquad \mbox{ caso discreto,}& \\
\int_{-\infty}^\infty\int_{-\infty}^\infty (x-\mu_X)^k (y-\mu_Y)^l f_{XY}(x,y)\, dx\, dy. & \\ \ \qquad\mbox{ caso continuo.} &
\end{cases}
$$

### Covariancia entre las variables
El **momento conjunto centrado en las medias para $k=1$ y $l=1$** se denomina **covariancia** entre las variables $X$ e $Y$:
$$
\mathrm{Cov}(X,Y)=E((X-\mu_X)(Y-\mu_Y)).
$$
La covariancia puede calcularse a partir de la **correlación** entre las variables:
$$
\mathrm{Cov}(X,Y)=E((X-\mu_X)(Y-\mu_Y))=E(X\cdot Y)-\mu_X\cdot \mu_Y,
$$

### Covariancia entre las variables
ya que, usando las propiedades de la esperanza, tenemos:
$$
\begin{array}{rl}
E((X-\mu_X)(Y-\mu_Y)) & =E(X\cdot Y-\mu_Y X-\mu_X Y+\mu_X\cdot \mu_Y)\\ & =E(X\cdot Y)-\mu_YE(X)-\mu_X E(Y)+\mu_X\cdot \mu_Y \\ &  = E(X\cdot Y)-\mu_Y\cdot \mu_X-\mu_X \cdot \mu_Y+\mu_X\cdot \mu_Y \\ & = E(X\cdot Y)-\mu_X\cdot \mu_Y.
\end{array}
$$

### Covarianza entre las variables
<l class="observ">Observación. </l>
Si las variables $X$ e $Y$ son **independientes**, su **covarianza** es nula ya que vimos que $E(X\cdot Y)=\mu_X\cdot \mu_y$.

La **covarianza** es una medida de lo relacionadas están las variables $X$ e $Y$:

* Si cuando $X\geq \mu_X$, también ocurre que $Y\geq \mu_Y$ o viceversa, cuando $X\leq \mu_X$, también ocurre que $Y\leq \mu_Y$, el valor $(X-\mu_X)(Y-\mu_Y)$ será positivo y la **covarianza** será positiva.

* Si por el contrario, cuando $X\geq \mu_X$, también ocurre que $Y\leq \mu_Y$ o viceversa, cuando $X\leq \mu_X$, también ocurre que $Y\geq \mu_Y$, el valor $(X-\mu_X)(Y-\mu_Y)$ será negativo y la **covarianza** será negativa.

* En cambio, si a veces ocurre una cosa y a veces ocurre otra, la **covarianza** va cambiando de signo y puede tener un valor cercano a 0.

### Propiedades de la covarianza
* Sea $(X,Y)$ una variable aleatoria bidimensional. Entonces la **varianza de la suma/resta** se calcula usando la expresión siguiente:
$$
\mathrm{Var}(X\pm Y)=\mathrm{Var}(X)+\mathrm{Var}(Y)\pm 2 \mathrm{Cov}(X,Y).
$$

<div class="dem">
**Demostración**

La varianza de la suma/resta de las variables es, usando la propiedad de la **varianza**:
$$
\mathrm{Var}(X\pm Y)=E\left((X\pm Y)^2\right)-\left(E(X\pm Y)\right)^2.
$$
Desarrollando las expresiones anteriores, obtenemos:
$$
\begin{array}{rl}
\mathrm{Var}(X\pm Y) & =E\left(X^2+Y^2\pm 2XY\right)-\left(E(X)\pm E(Y)\right)^2 \\ & =E(X^2)+E(Y^2)\pm 2E(XY)-\left(E(X)^2+E(Y)^2\pm 2E(X)E(Y)\right) 
\\ & = E(X^2)-E(X)^2+E(Y^2)-E(Y)^2\pm 2(E(XY)-E(X)E(Y)) \\ & = \mathrm{Var}(X)+\mathrm{Var}(Y)\pm 2\mathrm{Cov}(X,Y),
\end{array}
$$
tal como queríamos ver.

</div>

### Propiedades de la covarianza
Una consecuencia de la propiedad anterior es el resultado siguiente:

<l class="prop">Proposición: si las variables son independientes, la varianza de la suma es la suma de varianzas. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional donde las variables $X$ e $Y$ son **independientes**. 
Entonces:
$$
\mathrm{Var}(X+Y)=\mathrm{Var}(X)+\mathrm{Var}(Y).
$$


<div class="dem">
**Demostración**

La demostración es muy sencilla: basta aplicar la fórmula vista anteriormente de la varianza y tener en cuenta que, como $X$ e $Y$ son independientes, su covarianza es cero: $\mathrm{Cov}(X,Y)=0$.
</div>
### Coeficiente de correlación entre las variables
La **covarianza** depende de las unidades en las que están las variables $X$ e $Y$ ya que si $a>0$ y $b>0$, entonces:
$$
\mathrm{Cov}(aX,bY)=a\cdot b\cdot \mathrm{Cov}(X,Y).
$$
Por tanto, si queremos "medir" la relación que existe entre las variables $X$ e $Y$ tendremos que "normalizar" la **covarianza** definiendo el **coeficiente de correlación** entre las variables $X$ e $Y$:

### Coeficiente de correlación entre las variables

<l class="definition">Definición del coeficiente de correlación. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional. Se define el **coeficiente de correlación** entre las variables $X$ e $Y$ como: 
$$
\rho_{XY}=\frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)}\cdot\sqrt{\mathrm{Var}(Y)}}=\frac{E(X\cdot Y)-\mu_X\cdot \mu_Y}{\sqrt{E\left(X^2\right)-\mu_X^2}\cdot \sqrt{E\left(Y^2\right)-\mu_Y^2}}.
$$


### Coeficiente de correlación entre las variables

<l class="observ">Observación. </l>
Si las variables $X$ e $Y$ son **independientes**, su **coeficiente de correlación** $\rho_{XY}=0$ es nulo ya que su **covarianza** lo es.

Notemos también que la **correlación** no tiene unidades y es invariante a cambios de escala.

Además, la **covarianza** de las **variables tipificadas** $\frac{X-\mu_X}{\sigma_X}$ y $\frac{Y-\mu_Y}{\sigma_Y}$ coincide con la **correlación** de $X$ e $Y$.

### Coeficiente de correlación entre las variables
El **coeficiente de correlación** es un valor normalizado ya que siempre está entre -1 y 1: $-1\leq\rho_{XY}\leq 1$.

<div class="dem">
Para ver la demostración de este hecho, sean $\mu_X=E(X)$, $\mu_Y=E(Y)$, $\sigma_X=\sqrt{\mathrm{Var}(X)}$ y $\sigma_Y=\sqrt{\mathrm{Var}(Y)}$. 

Consideremos la variable $Z=\left(\frac{X-\mu_X}{\sigma_X}\pm \frac{Y-\mu_Y}{\sigma_Y}\right)^2$. Como $Z\geq 0$, tenemos que $E(Z)\geq 0$. Desarrollemos el valor de $E(Z)$:

$$
\begin{array}{rl}
E(Z) & = E\left(\frac{X-\mu_X}{\sigma_X}\pm \frac{Y-\mu_Y}{\sigma_Y}\right)^2 = E\left(\left(\frac{X-\mu_X}{\sigma_X}\right)^2+\left(\frac{Y-\mu_Y}{\sigma_Y}\right)^2\pm 2\left(\frac{X-\mu_X}{\sigma_X}\right) \left(\frac{Y-\mu_Y}{\sigma_Y}\right)\right) \\ & =
E\left(\left(\frac{X-\mu_X}{\sigma_X}\right)^2\right)+E\left(\left(\frac{Y-\mu_Y}{\sigma_Y}\right)^2\right)\pm 2 E\left(\left(\frac{X-\mu_X}{\sigma_X}\right) \left(\frac{Y-\mu_Y}{\sigma_Y}\right)\right) \\ & =
\frac{1}{\sigma_X^2}E\left(\left(X-\mu_X\right)^2\right)+\frac{1}{\sigma_Y^2}E\left(\left(Y-\mu_Y\right)^2\right)\pm \frac{2}{\sigma_X\sigma_Y}E\left(\left(X-\mu_X\right) \left(Y-\mu_Y\right)\right) \\ & = \frac{1}{\sigma_X^2}\sigma_X^2+
\frac{1}{\sigma_Y^2}\sigma_Y^2 \pm\frac{2}{\sigma_X\sigma_Y} \mathrm{Cov}(X,Y) = 1+1\pm 2\frac{\mathrm{Cov}(X,Y)}{\sigma_X\sigma_Y}=2(1\pm\rho_{XY})
\end{array}
$$
</div>

### Coeficiente de correlación entre las variables
<div class="dem">
Ahora, como $E(Z)\geq 0$, tenemos que $1\pm \rho_{XY}\geq 0$, lo que significa que, por un lado $1+\rho_{XY}\geq 0$ y, por otro, $1-\rho_{XY}\geq 0$. De la primera inecuación, deducimos que $\rho_{XY}\geq -1$ y de la segunda, $\rho_{XY}\leq 1$. 

En resumen, $-1\leq\rho_{XY}\leq 1$, tal como queríamos ver.
</div>


### Ejemplo
<div class="example">
**Ejemplo**

Hallemos el **coeficiente de correlación** para el ejemplo de la variable aleatoria bidimensional continua con **función de densidad conjunta**:
$$
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario,}
\end{cases}
$$
Recordemos los cálculos realizados anteriormente:

* $E(X\cdot Y)=1.$

* $f_X(x)=2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)$, si $x\geq 0$. Su esperanza será:
$$
E(X)=\int_0^\infty x 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx=2 \left[\frac{1}{4} \mathrm{e}^{-2 x} (2 x+1)-\mathrm{e}^{-x}(x+1)\right]_0^\infty = 2\left(1-\frac{1}{4}\right)=\frac{3}{2}.
$$
</div>

### Ejemplo
<div class="example">

Calculemos a continuación su varianza: $\mathrm{Var}(X)=E\left(X^2\right)-\mu_X^2$. El valor de $E\left(X^2\right)$ será:
$$
\begin{array}{rl}
E\left(X^2\right) & =\int_0^\infty x^2 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx=2 \left[\frac{1}{4} \mathrm{e}^{-2 x}  (2x^2+2x+1)- \mathrm{e}^{-x} (x^2+2x+2)\right]_0^\infty \\ & = 2\left(2-\frac{1}{4}\right)=\frac{7}{2}.
\end{array}
$$
El valor de la varianza de $X$ será: $\mathrm{Var}(X)=\frac{7}{2}-\left(\frac{3}{2}\right)^2 = \frac{5}{4}.$

* La variable $Y$ era exponencial de parámetro $\lambda =2$. Por tanto, $E(Y)=\frac{1}{2}$, $\mathrm{Var}(Y)=\frac{1}{4}$.

El **coeficiente de correlación** entre las variables $X$ e $Y$ será:
$$
\rho_{XY}=\frac{E(X\cdot Y)-\mu_X\cdot \mu_Y}{\sqrt{\mathrm{Var}(X)}\cdot\sqrt{\mathrm{Var}(Y)}}=\frac{1-\frac{3}{2}\cdot \frac{1}{2}}{\sqrt{\frac{5}{4}}\cdot\sqrt{\frac{1}{4}}}=\frac{\sqrt{5}}{5}\approx `r round(sqrt(5)/5,3)`.
$$
Vemos que la **correlación** entre las variables $X$ e $Y$ es positiva pero no demasiado ya que su valor no está cercano a 1.
</div>

### Ejemplo normal bidimensional
<div class="example">
Recordemos que la **función de densidad** de la variable aleatoria **normal bidimensional** es:
$f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty <x,y<\infty.$

Las **variables aleatorias marginales** eran normales estándar o $N(0,1)$.

Hallemos el **coeficiente de correlación $\rho_{XY}$** en este caso.

Calculemos $E(X\cdot Y)$:
$$
\begin{array}{rl}
E(X\cdot Y) & = \int_{-\infty}^\infty x y \frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx = \frac{1}{2\pi\sqrt{1-\rho^2}}\int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}}\int_{y=-\infty}^{y=\infty}y \mathrm{e}^{-\frac{(-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx \\ & = \frac{1}{2\pi\sqrt{1-\rho^2}}\int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}}  \mathrm{e}^{\frac{\rho^2 x^2}{2(1-\rho^2)}} \int_{y=-\infty}^{y=\infty}y \mathrm{e}^{-\frac{(y-\rho y)^2}{2(1-\rho^2)}}\, dy\, dx,\\ &\ \qquad\mbox{ cambio de variable en la segunda integral $z=\frac{y-\rho x}{\sqrt{1-\rho^2}}$,}\\ & = \frac{1}{2\pi\sqrt{1-\rho^2}}\int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}{2}}  \int_{z=-\infty}^{z=\infty} \left(z\sqrt{1-\rho^2}+\rho x\right)\sqrt{1-\rho^2}\mathrm{e}^{-\frac{z^2}{2}}\, dz\, \\ & =
\frac{1}{2\pi} \int_{x=-\infty}^{x=\infty}x  \mathrm{e}^{-\frac{x^2}{2}} \left(\sqrt{1-\rho^2}\int_{z=-\infty}^{z=\infty} z \mathrm{e}^{-\frac{z^2}{2}}\, dz +\rho x \int_{z=-\infty}^{z=\infty}\mathrm{e}^{-\frac{z^2}{2}}\, dz \right)\, dx
\end{array}
$$
</div>


### Ejemplo normal bidimensional
<div class="example">
Ahora, usando que el valor esperado de una variable $N(0,1)$ es cero tenemos que:
$\int_{z=-\infty}^{z=\infty} z \mathrm{e}^{-\frac{z^2}{2}}\, dz =0,$ y usando que la integral de la **función de densidad** de la $N(0,1)$ ($\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{z^2}{2}}$) sobre todo $\mathbb{R}$ es 1, tenemos que:
$\int_{z=-\infty}^{z=\infty} \mathrm{e}^{-\frac{z^2}{2}}\, dz =\sqrt{2\pi}.$

Por tanto,
$$
E(X\cdot Y)=\frac{\rho}{2\pi} \int_{x=-\infty}^{x=\infty} x^2  \mathrm{e}^{-\frac{x^2}{2}}\sqrt{2\pi}\, dx=\frac{\rho}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} x^2  \mathrm{e}^{-\frac{x^2}{2}}\, dx.
$$
Por último, usando que la varianza de la distribución $Z=N(0,1)$ es 1, tenemos que $\mathrm{Var}(Z)=E\left(Z^2\right)-E(Z)^2$. Como $E(Z)=0$, deducimos que $E\left(Z^2\right)=1$:
$$
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty x^2\mathrm{e}^{-\frac{x^2}{2}}\, dx=1,\ \Rightarrow \int_{-\infty}^\infty x^2\mathrm{e}^{-\frac{x^2}{2}}\, dx=\sqrt{2\pi}.
$$
El valor de $E(X\cdot Y)$ será:
$$
E(X\cdot Y)=\frac{\rho}{\sqrt{2\pi}}\sqrt{2\pi}=\rho.
$$
</div>

### Ejemplo normal bidimensional
<div class="example">

La correlación entre las variables $X$ e $Y$ es precisamente $\rho$.

Ahora, usando que $\mu_X=\mu_Y=0$ y $\sigma_X=\sigma_Y=1$ ya que recordemos que las marginales son $N(0,1)$, el **coeficiente de correlación** entre las variables $X$ e $Y$ será:
$$
\rho_{XY}=\frac{E(X\cdot Y)-\mu_X\cdot \mu_Y}{\sqrt{\mathrm{Var}(X)}\cdot\sqrt{\mathrm{Var}(Y)}}=\frac{\rho-0\cdot 0}{1\cdot 1}=\rho.
$$
Por tanto, $\rho$ es el **coeficiente de correlación** entre las variables $X$ e $Y$ y mide lo correlacionadas que están dichas variables.


</div>

### Incorrelación e independencia
Hemos visto que si dos variables $X$ e $Y$ son **independientes**, entonces son **incorreladas**, o sea,  la **covarianza** es 0 ($E(X\cdot Y)=E(X)\cdot E(Y)$).

El recíproco, sin embargo, es falso. Veamos un ejemplo de variables **incorreladas** que no son independientes.

<div class="example">
**Ejemplo de variables aleatorias incorreladas pero no independientes**

Consideremos la variable aleatoria bidimensional continua con **función de densidad**:
$$
f_{XY}(x,y)=\begin{cases}
\frac{3}{8}(x^2+y^2), & \mbox{si }(x,y)\in [-1,1]\times [-1,1],\\
0, & \mbox{en caso contrario.}
\end{cases}
$$

Dejamos como ejercicio comprobar que es una **función de densidad**. O sea, que es positiva y que la integral sobre todo el plano vale 1.

</div>

### Ejemplo de variables aleatorias incorreladas pero no independientes
<div class="example">

Calculemos las **densidades marginales**:
$$
\begin{array}{rl}
f_X(x) & = \int_{-1}^{1} \frac{3}{8}(x^2+y^2)\, dy = \frac{3}{8}\left[x^2 y+\frac{y^3}{3}\right]_{-1}^1 =\frac{3}{8}\left(2 x^2+\frac{2}{3}\right)=\frac{3}{4} x^2+\frac{1}{4}, \\
f_Y(y) & = \int_{-1}^{1} \frac{3}{8}(x^2+y^2)\, dx = \frac{3}{8}\left[\frac{x^3}{3}+y^2 x\right]_{-1}^1 =\frac{3}{8}\left(\frac{2}{3}+2 y^2+\right)=\frac{3}{4} y^2+\frac{1}{4}.
\end{array}
$$

Los valores esperados de cada variable $X$ e $Y$ serán:
$$
\begin{array}{rl}
E(X) & =\int_{-1}^1 x \left(\frac{3}{4} x^2+\frac{1}{4}\right)\, dx =0, \mbox{al integrar una función impar,}\\
E(Y) & =\int_{-1}^1 x \left(\frac{3}{4} y^2+\frac{1}{4}\right)\, dx =0, \mbox{al integrar una función impar.}
\end{array}
$$
</div>

### Ejemplo de variables aleatorias incorreladas pero no independientes

<div class="example">
El valor de la **correlación** entre $X$ e $Y$ será:
$$
\begin{array}{rl}
E(X\cdot Y) & =\int_{-1}^1\int_{-1}^1 x y \frac{3}{8}(x^2+y^2)\, dy\, dx\\ & =\frac{3}{8}\left(\int_{-1}^1\int_{-1}^1 x^3 y\, dy \, dx+\int_{-1}^1\int_{-1}^1 x y^3\, dy \, dx\right) \\ & = \frac{3}{8} \left(\int_{x=-1}^{x=1}x^3 \left[\frac{y^2}{2}\right]_{y=-1}^{y=1}\, dx + \int_{y=-1}^{y=1}y^3 \left[\frac{x^2}{2}\right]_{x=-1}^{x=1}\right)=0.
\end{array}
$$
El **coeficiente de correlación** entre $X$ e $Y$ será: $\rho_{XY}=E(X\cdot Y)-E(X)\cdot E(Y)=0-0\cdot 0=0$. Por tanto, son **incorreladas**.

En cambio no son **independientes** ya que claramente si $(x,y)\in [-1,1]\times [-1,1]$,
$$
f_{XY}(x,y)=\frac{3}{8}(x^2+y^2) \neq f_X(x)\cdot f_Y(y)=\left(\frac{3}{4} x^2+\frac{1}{4}\right)\cdot \left(\frac{3}{4} y^2+\frac{1}{4}\right).
$$
</div>

## Variables aleatorias condicionales y valor esperado condicional

### Introducción

Muchas **variables aleatorias bidimensionales** de interés práctico no son independientes.

Por ejemplo, la salida $Y$ de un canal de comunicación debe depender de la entrada $X$ para transmitir información. 

En esta sección vamos a introducir variables aleatorias $Y$ cuya distribución depende de otras $X$. Dichas variables se denominan **variables aleatorias condicionales**.

También nos interesa el valor esperado de la **variable condicional** $Y$ suponiendo que conocemos $X=x$.

### Variables aleatorias condicionales discretas

Sea $(X,Y)$ una variable aleatoria bidimensional. Sea $B$ un subconjunto de los números reales $\mathbb{R}$. Recordemos que la **probabilidad condicional** del suceso $\{Y\in B\}$ suponiendo que $X=x$ se definía de la forma siguiente:
$$
P(Y\in B|X=x)=\frac{P(Y\in B,\ X=x)}{P(X=x)}, \mbox{ siempre que }P(X=x)>0.
$$

### Variables aleatorias condicionales discretas

La definición anterior motiva la definición siguiente de **variable aleatoria condicional discreta**:

<l class="definition">Definición de variable aleatoria condicional discreta. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional discreta con conjunto de valores $(X,Y)(\Omega)=\{(x_i,y_j)\ i=1,2,\ldots, j=1,2,\ldots\}$ y **función de probabilidad conjunta** $P_{XY}$. Sean $x_i$ un valor de $X(\Omega)$ con $P(X=x_i)>0$. Entonces definimos la **función de probabilidad** de la **variable aleatoria condicional discreta** $Y|X=x_i$ como:
$$
P_{Y|X=x_i}(y_j)=P(Y=y_j|X=x_i)=\frac{P(X=x_i,\ Y=y_j)}{P(X=x_i)}=\frac{P_{XY}(x_i,y_j)}{P_X(x_i)}.
$$


### Variables aleatorias condicionales discretas
<l class="observ">Observación. </l>
La **función de probabilidad** de la **variable aleatoria condicional $Y|X=x_i$** depende únicamente de la **función de probabilidad conjunta** de la variable aleatoria bidimensional $(X,Y)$.

<l class="observ">Observación. </l>
Al ser $Y|X=x_i$ una variable aleatoria unidimensional, su **función de probabilidad** tiene que verificar que la suma de todos sus valores tiene que dar 1. O sea:
$$
\sum_{y_j} P(Y=y_j|X=x_i)=1.
$$
Veámoslo:
<div class="dem">
$$
\sum_{y_j} P(Y=y_j|X=x_i)=\sum_{y_j} \frac{P_{XY}(x_i,y_j)}{P_X(x_i)}=\frac{1}{P_X(x_i)}\sum_{y_j} P_{XY}(x_i,y_j) =\frac{1}{P_X(x_i)}\cdot P_X(x_i)=1.
$$
</div>

### Variables aleatorias condicionales discretas
<l class="observ">Observación. </l>
Si $X$ e $Y$ son independientes, $Y|X=x_i =Y$, o sea, la **variable aleatoria condicional $Y|X=x_i$** coincide con $Y$. O sea, condicionar con $X=x_i$ no tiene ningún efecto sobre $Y$.

<div class="dem">
Efectivamente, veamos que $P_{Y|X=x_i}(y_j)=P_Y(y_j)$ para todo valor $y_j$ de $Y(\Omega)$:
$$
P_{Y|X=x_i}(y_j) =\frac{P_{XY}(x_i,y_j)}{P_X(x_i)} \stackrel{\mbox{Por ser independientes}}{=}\frac{P_Y(y_j)\cdot P_X(x_i)}{P_X(x_i)}=P_Y(y_j).
$$
</div>

<l class="observ">Observación. </l>
La definición de la **función de probabilidad** de la  **variable aleatoria condicional $X|Y=y_j$** se definiría de forma similar:
$$
P_{X|Y=y_j}(x_i)=P(X=x_i|Y=y_j)=\frac{P(X=x_i,\ Y=y_j)}{P(Y=y_j)}=\frac{P_{XY}(x_i,y_j)}{P_Y(y_j)}, 
$$
para todo $x_i\in X(\Omega)$.

### Variables aleatorias condicionales discretas
<l class="observ">Observación.</l>
Si tenemos la tabla de la **función de probabilidad conjunta** $P_{XY}$, para hallar la **función de distribución de la variable $Y|X=x_i$** es equivalente a considerar la fila del valor $x_i$ a la tabla y dividir todos los valores de la fila por la suma de los valores en dicha fila:
<div class="center">
| $Y|X=x_i$| $y_1$    | $y_2$  | $\ldots$ | $y_N$ |
|----|----|----|----|----|
| $P_{Y|X=x_i}$| $\frac{P_{XY}(x_i,y_1)}{P_X(x_i)}$ | $\frac{P_{XY}(x_i,y_2)}{P_X(x_i)}$ | $\ldots$ | $\frac{P_{XY}(x_i,y_N)}{P_X(x_i)}$|
</div>

### Variables aleatorias condicionales discretas
<l class="observ">Observación.</l>
De la misma manera, si tenemos la tabla de la **función de probabilidad conjunta** $P_{XY}$, para hallar la **función de distribución de la variable $X|Y=y_j$** es equivalente a considerar la columna del valor $y=y_j$ a la tabla y dividir todos los valores de la columna por la suma de los valores en dicha columna:
<div class="center">
| $X|Y=y_j$|  $P_{X|Y=y_j}$
|----|----|
| $x_1$| $\frac{P_{XY}(x_1,y_j)}{P_Y(y_j)}$ |
| $\vdots$| $\vdots$ |
| $x_M$| $\frac{P_{XY}(x_M,y_j)}{P_Y(y_j)}$ |
</div>

### Ejemplo
<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

Vamos a hallar la **variable aleatoria condicional $S|P=12$**.

Tenemos calculada la tabla de la **función de probabilidad conjunta $P_{SP}$**.

Si $P=12$, los únicos valores $x_i$ de $S(\Omega)$ para los que se verifica $P_{SP}(x_i,12)\neq 0$ son 7 y 8.

Además si calculamos $P_P(12)$, obtenemos $P(P=12)=\frac{4}{36}$ ya que hay 4 casos en que el producto da 12: $(3,4), (4,3), (2,6)$ y $(6,2)$.
</div>

### Ejemplo
<div class="example">

Por tanto, la tabla de la **función de probabilidad condicional** de la variable $S|P=12$ será:

<div class="center">
| $S|P=12$| $P_{S|P=12}$ 
|----|----|----|
|$7$| $\frac{\frac{2}{36}}{\frac{4}{36}}=\frac{1}{2}$ | 
|$8$| $\frac{\frac{2}{36}}{\frac{4}{36}}=\frac{1}{2}$ |
</div>
</div>


### Ejemplo
<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

Vamos a hallar la **variable aleatoria condicional $P|S=8$**.

Si $S=8$, los únicos valores $y_j$ de $P(\Omega)$ para los que se verifica $P_{SP}(8,y_j)\neq 0$ son 12 y 15 y 16.

El valor de $P_S(8)$ recordemos que valía: $P_S(8)=\frac{5}{36}$.

Por tanto, la tabla de la **función de probabilidad condicional** de la variable $P|S=8$ será:

<div class="center">
| $P|S=8$| $12$ | $15$ | $16$ 
|----|----|----|----|
|$P_{P|S=8}$| $\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}$ | $\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}$ | $\frac{\frac{1}{36}}{\frac{5}{36}}=\frac{1}{5}$
</div>
</div>

### Ejemplo con `R`
<div class="example">
Para hallar la **variable aleatoria condicional** $S|P=12$ hemos de condicionar por la columna $P=12$ en la tabla de la **función de probabilidad conjunta**:

```{r}
prob.cond.p12=tabla.func.prob.conjunta[,valores.producto==12]/
  sum(tabla.func.prob.conjunta[,valores.producto==12])
prob.cond.p12
```
</div>

### Ejemplo con `R`
<div class="example">
El problema es que aparecen valores con **función de probabilidad marginal** nulos. Para eliminarlos hacemos lo siguiente:

```{r}
prob.cond.p12.buena = prob.cond.p12[prob.cond.p12!=0]
prob.cond.p12.buena
```
Para hallar la **función de probabilidad marginal** $P|S=8$, haríamos lo siguiente:

```{r}
prob.cond.s8=tabla.func.prob.conjunta[valores.suma==8,]/
  sum(tabla.func.prob.conjunta[valores.suma==8,])
(prob.cond.s8.buena = prob.cond.s8[prob.cond.s8!=0])
```

</div>

### Variables aleatorias condicionales continuas
La definición en el caso continua se hace cambiando la **función de probabilidad** por la **función de densidad**:

<l class="definition">Definición de variable aleatoria condicional discreta. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional continua con **función de densidad conjunta** $f_{XY}$. Sean $x\in\mathbb{R}$ con $f_X(x)>0$. Entonces definimos la **función de densidad** de la **variable aleatoria condicional continua** $Y|X=x$ como:
$$
f_{Y|X=x}(y)=\frac{f_{XY}(x,y)}{f_X(x)}.
$$


### Variables aleatorias condicionales continuas
<l class="observ">Observación. </l>
La **función de densidad** de la **variable aleatoria condicional continua$Y|X$** depende únicamente de la **función de densidad conjunta** de la variable aleatoria bidimensional $(X,Y)$.

<l class="observ">Observación. </l>
Al ser $Y|X=x$ una variable aleatoria unidimensional, su **función de densidad** tiene que verificar que la integral de dicha función sobre todo $\mathbb{R}$ tiene que ser 1. O sea:
$$
\int_{-\infty}^\infty f_{Y|X=x}(y)\, dy=1.
$$
Veámoslo:
<div class="dem">
$$
\int_{-\infty}^\infty f_{Y|X=x}(y)\, dy =\int_{-\infty}^\infty \frac{f_{XY}(x,y)}{f_X(x)}\, dy=\frac{1}{f_X(x)}\int_{-\infty}^\infty f_{XY}(x,y)\, dy= \frac{1}{f_X(x)}\cdot f_X(x) =1.
$$
</div>

### Variables aleatorias condicionales continuas
<l class="observ">Observación. </l>
Si $X$ e $Y$ son independientes, $Y|X=x =Y$, o sea, la **variable aleatoria condicional $Y|X=x$** coincide con $Y$. O sea, condicionar con $X=x$ no tiene ningún efecto sobre $Y$.

<div class="dem">
Efectivamente, veamos que $f_{Y|X=x}(y)=f_Y(y)$ para todo valor $y\in\mathbb{R}.$
$$
f_{Y|X=x}(y) =\frac{f_{XY}(x,y)}{f_X(x)} \stackrel{\mbox{Por ser independientes}}{=}\frac{f_Y(y)\cdot f_X(x)}{f_X(x)}=f_Y(y).
$$
</div>

<l class="observ">Observación. </l>
La definición de la **función de densidad** de la  **variable aleatoria condicional $X|Y=y$** se definiría de forma similar:
$$
f_{X|Y=y}(x)=\frac{f_{XY}(x,y)}{f_Y(y)},
$$
para todo $x\in\mathbb{R}$.

### Ejemplo
<div class="example">
**Ejemplo**

Recordemos el ejemplo de la variable aleatoria bidimensional continua con **función de densidad**:
$$
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario,}
\end{cases}
$$
Dado un valor $x_0\geq 0$ cualquiera, vamos a hallar la **función de densidad** de la **variable aleatoria condicional** $Y|X=x_0$.

Fijémonos que, fijado un valor $x_0$, los valores $y$ para los cuales $f_{XY}(x_0,y)\neq 0$ cumplen $0\leq y\leq x_0$.
Por tanto,
$$
f_{Y|X=x_0}(y)=\frac{f_{XY}(x_0,y)}{f_X(x_0)}=\frac{2\mathrm{e}^{-x_0}\mathrm{e}^{-y}}{f_X(x_0)},
$$
si $0\leq y\leq x_0$, y $f_{Y|X=x_0}(y)=0$, en caso contrario.
</div>

### Ejemplo
<div class="example">
Recordemos que la **densidad marginal** de la variable $X$ era: $f_X(x_0)=2\left(\mathrm{e}^{-x_0}-\mathrm{e}^{-2x_0}\right)$. 

La **función de densidad marginal** de la variable $Y|X=x_0$ será:
$$
f_{Y|X=x_0}(y)=\frac{2\mathrm{e}^{-x_0}\mathrm{e}^{-y}}{2\left(\mathrm{e}^{-x_0}-\mathrm{e}^{-2x_0}\right)}=\frac{e^{-y}}{1-\mathrm{e}^{-x_0}},
$$
si $0\leq y\leq x_0$, y $f_{Y|X=x_0}(y)=0$, en caso contrario.

Sea ahora $y_0>0$. Calculemos ahora la **densidad marginal** de la variable $X|Y=y_0$.

Fijémonos que, fijado un valor $y_0$, los valores $x$ para los cuales $f_{XY}(x,y_0)\neq 0$ cumplen $y_0\leq x\leq \infty$. Por tanto,
$$
f_{X|Y=y_0}(x)=\frac{f_{XY}(x,y_0)}{f_Y(y_0)}=\frac{2\mathrm{e}^{-x}\mathrm{e}^{-y_0}}{f_Y(y_0)},
$$
si $y_0\leq x\leq \infty$, y $f_{X|Y=y_0}(x)=0$, en caso contrario.
</div>


### Ejemplo
<div class="example">
Recordemos que la variable $Y$ era exponencial de parámetro $\lambda=2$. Por tanto, $f_Y(y_0)=2\mathrm{e}^{-2y_0}$.

La **función de densidad marginal** de la variable $X|Y=y_0$ será:
$$
f_{X|Y=y_0}(x)=\frac{2\mathrm{e}^{-x}\mathrm{e}^{-y_0}}{2\mathrm{e}^{-2y_0}}=\frac{\mathrm{e}^{-x}}{\mathrm{e}^{-y_0}},
$$
si $y_0\leq x\leq \infty$, y $f_{X|Y=y_0}(x)=0$, en caso contrario.
</div>


### Ejemplo de la variable aleatoria normal bidimensional
<div class="example">
**Ejemplo de la normal bidimensional**

Sea $(X,Y)$ una variable aleatoria bidimensional normal bidimensional con **densidad conjunta**:
$$
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty <x,y<\infty.
$$
Sea $x\in\mathbb{R}$. Hallemos la **función de densidad** de la **variable aleatoria condicionada** $Y|X=x$.

Recordemos que las **marginales** eran $N(0,1)$. Por tanto, $f_X(x)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}.$
</div>

### Ejemplo de la variable aleatoria normal bidimensional
<div class="example">
La **función de densidad** de la variable condicional $Y|X=x$ será:
$$
f_{Y|X=x}(y)=\frac{f_{XY}(x,y)}{f_X(x)}=\frac{\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}}{\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}}=\frac{1}{\sqrt{2\pi (1-\rho^2)}}\mathrm{e}^{-\frac{(y-\rho x)^2}{2(1-\rho^2)}},\ y\in\mathbb{R}.
$$
Concluimos que la **variable aleatoria condicional $Y|X=x$** es una normal de parámetros $\mu_{Y|X=x}=\rho x$ y $\sigma_{Y|X=x}^2 =1-\rho^2$.

Tenemos dos observaciones con respecto al resultado obtenido:

* La varianza de la **variable aleatoria condicional** no depende de la $x$ que se ha fijado. Sólo depende del parámetro $\rho$. La $x$ sólo influye en la media de dicha variable.

* En el caso en que $\rho=0$, que significa que $X$ e $Y$ son independientes, la distribución condicional de $Y|X=x$ es una $N(0,1)$, distribución que coincide con la distribución de la **variable aleatoria marginal** $Y$.
</div>

### Valores esperados condicionales
<l class="definition">Definición de valor esperado condicional.</l>
Dada una variable aleatoria bidimensional $(X,Y)$, definimos el **valor esperado de la variable $Y$ dado que $X=x$** como $E(Y|x)$, o sea, el valor esperado de la **variable aleatoria condicional $Y|X=x$**:
$$
E(Y|x)=\begin{cases}
\sum_{y_j} y_j P_{Y|X=x}(y_j), & \mbox{ caso discreto,}\\
\int_{-\infty}^\infty y f_{Y|X=x}(y)\,dy, & \mbox{ caso continuo.}
\end{cases}
$$

### Valores esperados condicionales

Tenemos el siguiente resultado relacionado con los valores esperados: el valor esperado respecto $x$ del valor esperado de la **variable condicional $Y|X=x$** coincide con el valor esperado de la variable $Y$:

<l class="prop">Proposición. </l>
Sea $(X,Y)$ una variable aleatoria bidimensional. Sean $E(Y|x)$ el **valor esperado condicional de $Y$** respecto $x$. Entonces el valor esperado de la *variable aleatoria* $E(Y|X)$ como función de la variable $X$ es el valor esperado de la variable $Y$:
$$
E_X(E(Y|X))=E(Y).
$$

### Valores esperados condicionales

<div class="dem">
**Demostración**

Haremos la demostración en el caso continuo. Dejamos como ejercicio la demostración para el caso discreto.

Sea $f_{XY}$ la **función de densidad conjunta** y $f_X$ y $f_Y$ las **funciones de densidad marginales**.

El valor de $E_X(E(Y|X))$ será:
$$
\begin{array}{rl}
E_X(E(Y|X)) & =\int_{x=-\infty}^{x=\infty} E(Y|x)f_X(x)\, dx=\int_{x=-\infty}^{x=\infty}\int_{y=-\infty}^{y=\infty} y f_{Y|X=x}(y)\, dy f_X(x)\, dx \\ & = \int_{x=-\infty}^{x=\infty}\int_{y=-\infty}^{y=\infty} y \frac{f_{XY}(x,y)}{f_X(x)}f_X(x)\, dy\, dx = \int_{y=-\infty}^{y=\infty} y \int_{x=-\infty}^{x=\infty}f_{XY}(x,y)\, dx\, dy \\ &  = \int_{y=-\infty}^{y=\infty} y f_Y(y)\, dy = E(Y),
\end{array}
$$
tal como queríamos ver.
</div>

### Relación con el problema de la regresión general
El problema de la **regresión general** es el siguiente:

Sea $(X,Y)$ una variable aleatoria bidimensional. Queremos hallar una función $g$ tal que la variable $\hat{Y}=g(X)$ explique mejor la variable $Y$. 

Dicho de forma más explícita, queremos hallar una función $g$ tal que minimice el error cometido al aproximar $Y$ por $\hat{Y}=g(X)$. Dicho error se definede forma natural como el valor esperado de la variable $(Y-g(X))^2$:
$$
\min_g E\left((Y-g(X))^2\right).
$$

### Relación con el problema de la regresión general
El siguiente resultado nos dice cuál es la función $g$:

<l class="prop">Proposición: </l>
La función $g$ solución del problema de **regresión general** es la siguiente: $g(x)=E(Y|X=x)$. 

O sea, la función $g$ asigna a cada valor $x$ de la variable aleatoria $X$, el valor esperado de la **variable condicional** $Y|X=x$.

En resumen, la función $g(x)=E(Y|X=x)$ es la función que minimiza el error. A la curva $y=g(x)$ se la denomina **curva general de regresión de $Y$ sobre $X$**.

### Valores esperados condicionales. Caso general
Podemos generalizar los valores esperados condicionales en el sentido que en lugar de hallar $E(Y|X=x)$, hallar $E(g(Y)|X=x)$, donde $g$ es una función de la variable aleatoria $Y$:

<l class="definition">Definición de valor esperado condicional.</l>
Dada una variable aleatoria bidimensional $(X,Y)$ y una función $g$, definimos el **valor esperado de la variable $g(Y)$ dado que $X=x$** como $E(g(Y)|x)$, o sea, el valor esperado de la **variable aleatoria condicional $g(Y)|X=x$**:
$$
E(g(Y)|x)=\begin{cases}
\sum_{y_j} g(y_j) P_{Y|X=x}(y_j), & \mbox{ caso discreto,}\\
\int_{-\infty}^\infty g(y) f_{Y|X=x}(y)\,dy, & \mbox{ caso continuo.}
\end{cases}
$$

<l class="observ">Observación:</l> cuando $g(y)=y^k$, tenemos definidos los **momentos condicionados de orden $k$** de la variable $Y|X=x$.

### Ejemplo
<div class="example">
**Ejemplo de la suma y el producto de los resultados de dos lanzamientos de un dado**

Vamos a hallar el valor esperado de la **variable aleatoria condicional $P|S=8$**.

Recordemos su **función de probabilidad**:

<div class="center">
| $P|S=8$| $12$ | $15$ | $16$ 
|----|----|----|----|
|$P_{P|S=8}$| $\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}$ | $\frac{\frac{2}{36}}{\frac{5}{36}}=\frac{2}{5}$ | $\frac{\frac{1}{36}}{\frac{5}{36}}=\frac{1}{5}$
</div>


Su valor esperado será, pues:
$$
E(P|S=8)=12\cdot \frac{2}{5}+15\cdot \frac{2}{5}+16\cdot \frac{1}{5}=\frac{`r 12*2+15*2+16`}{5}=`r (12*2+15*2+16)/5`.
$$
El valor medio del producto de los resultados al lanzar un dado dos veces cuando la suma de dichos resultados es 8 vale `r (12*2+15*2+16)/5`.
</div>

### Ejemplo con `R`
<div class="example">
El valor esperado de la variable $E(P|S=8)$ será:

```{r}
valores.cond.s8=as.integer(names(prob.cond.s8.buena))
sum(valores.cond.s8*prob.cond.s8.buena)
```

</div>

### Ejemplo
<div class="example">
Recordemos el ejemplo de la variable aleatoria bidimensional continua con **función de densidad**:
$$
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario,}
\end{cases}
$$

Vimos que si fijamos $x_0>0$, la **función de densidad** de la **variable aleatoria condicionada** $Y|X=x_0$ era:
$$
f_{Y|X=x_0}(y)=\begin{cases}
\frac{e^{-y}}{1-\mathrm{e}^{-x_0}}, & \mbox{ si }0\leq y\leq x_0, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$

Hallemos su valor esperado:
$$
E(Y|X=x_0)=\int_0^{x_0} y \frac{e^{-y}}{(1-\mathrm{e}^{-x_0})}\, dy=\frac{1}{(1-\mathrm{e}^{-x_0})}\left[-\mathrm{e}^{-y} (y+1)\right]_0^{x_0} = \frac{1-\mathrm{e}^{-x_0}(1+x_0)}{1-\mathrm{e}^{-x_0}}.
$$
</div>

### Ejemplo
<div class="example">
Verifiquemos la propiedad vista anteriormente $E_X(E(Y|x))=E(Y)$. Recordemos que la **función de densidad marginal** de la variable $X$ era: $f_X(x)=2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)$, para $x>0$:
$$
\begin{array}{rl}
E_X(E(Y|x)) & =\int_0^\infty E(Y|x)\cdot f_X(x)\, dx = \int_0^\infty \frac{1-\mathrm{e}^{-x}(1+x)}{1-\mathrm{e}^{-x}}\cdot 2\left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}\right)\, dx 
\\ & =  2\int_0^\infty \frac{1-\mathrm{e}^{-x}(1+x)}{1-\mathrm{e}^{-x}} \mathrm{e}^{-x}\left(1-\mathrm{e}^{-x}\right)\, dx = 2 \int_0^\infty \left(\mathrm{e}^{-x}-\mathrm{e}^{-2x}(1+x)\right)\, dx \\ & = 2\left[-\mathrm{e}^{-x}+\mathrm{e}^{-2 x}
   \left(\frac{x}{2}+\frac{3}{4}\right)\right]_0^\infty = 2 \left(1-\frac{3}{4}\right)=\frac{1}{2}.
\end{array}
$$

Recordemos que la variable $Y$ era exponencial de parámetro $\lambda=2$. Por tanto $E(Y)=\frac{1}{\lambda}=\frac{1}{2}$, valor que coincide con el hallado, tal como queríamos ver.
</div>

## Variables aleatorias definidas como función de dos variables aleatorias conjuntas

### Introducción

Dado un experimento aleatorio, a veces estaremos interesados en una o más funciones de las variables asociadas con el experimento.

Por ejemplo, si consideramos el experimento aleatorio de lanzar un dado dos veces y definimos la **variable aleatoria bidimensional** $(X_1,X_2)$ como la variable que nos da el resultado de cada lanzamiento, podemos expresar la suma y el producto  como $S=X_1+X_2$, $P=X_1\cdot X_2$.

Otros ejemplos podrían ser considerar el experimento aleatoria de realizar mediciones repetidas de la misma cantidad aleatoria. Entonces, podríamos estar interesados en el valor máximo y mínimo en el conjunto, así como la media muestral y la varianza muestral. 

### Introducción

En esta sección presentamos métodos para determinar las probabilidades de eventos que involucran **funciones de dos variables aleatorias**.

Daremos métodos de cómo hallar la **función de distribución** y la **función de probabilidad** (caso discreto) o la **función de densidad** (caso continuo) de la variable aleatoria definida como función de la **variable aleatoria bidimensional**.



### Variable aleatoria función de la variable aleatoria bidimensional
<l class="prop">Proposición.</l>
Sea $(X,Y)$ una variable aleatoria bidimensional con **función de probabilidad** $P_{XY}$ (caso discreto) o **función de densidad** (caso continuo). Sea $g$ una función y definimos la **variable aleatoria unidimensional** $Z$ como $Z=g(X,Y)$. Entonces la función de distribución de $Z$ será:
$$
\begin{array}{rl}
F_Z(z) & = P(Z\leq z)=\sum\sum_{(x_i,y_j),\ |\ g(x_i,y_j)\leq z} P_{XY}(x_i,y_j),\ z\in\mathbb{R},\\ &\ \qquad\mbox{ (caso discreto),}\\
F_Z(z) & = P(Z\leq z)=\int\int_{(x,y)\in\mathbb{R}^2,\ |\ g(x,y)\leq z} f_{XY}(x,y)\,dy\, dx, \ z\in\mathbb{R},\\ &\ \qquad\mbox{ (caso continuo).}
\end{array}
$$

### Variable aleatoria función de la variable aleatoria bidimensional
<l class="observ">Observación.</l>
En el caso discreto, la variable aleatoria será discreta con valores $Z(\Omega)=\{z_{ij}=g(x_i,y_j),\ |\ (x_i,y_j)\in (X,Y)(\Omega)\}$. 
Hay que tener en cuenta que en dicho conjunto puede haber repeticiones, o sea, pueden existir dos parejas $(i,j)$ y $(i',j')$ tal que $z_{ij}=z_{i'j'}$.

La expresión de la **función de probabilidad** en el caso discreto se complica mucho debido a dichas repeticiones y es mejor hallarla en cada caso concreto.

La última observación se puede aplicar también en el caso continuo: la expresión de la **función de densidad** se halla en cada caso concreto.

### Ejemplo variables aleatorias discretas
<div class="example">
**Ejemplo del lanzamiento de un dado dos veces.**

Consideremos el experimento aleatorio de lanzar dos veces un dado. 

Sea $(X,Y)$ la **variable aleatoria** bidimensional discreta ya estudiada anteriormente donde $X$ nos da el resultado del primer lanzamiento e $Y$, el resultado del segundo lanzamiento.

Vimos que $(X,Y)(\Omega)=\{(i,j),\ i=1,2,3,4,5,6,\ j=1,2,3,4,5,6\}$ con **función de probabilidad conjunta** $P_{XY}(i,j)=\frac{1}{36}$, $i=1,2,3,4,5,6,\ j=1,2,3,4,5,6.$

Anteriormente hemos estudiado la suma $S$ de los resultados. En este caso podemos interpretar $S=g(X,Y)$ donde $g(x,y)=x+y$.

Como la función $S$ ya ha sido estudiada y el producto se ha dejado como ejercicio, estudiaremos la siguiente variable aleatoria función de $X$ e $Y$: $Z=X^2+Y^2$. 

Realizaremos los cálculos con ayuda de `R` ya que hacerlos a mano es bastante tedioso.

Los valores de $Z(\Omega)$ serán: $Z(\Omega)=\{z_{ij}=i^2+j^2,\ i=1,2,3,4,5,6,\ j=1,2,3,4,5,6\}$. Observad que hay parejas $(i,j)$ que dan lugar a los mismos valores, por ejemplo $1^2+2^2 = 2^2+1^2$, y, en general, si $i\neq j$, $z_{ij}=i^2+j^2=z_{ji}=j^2+i^2$.

</div>

### Ejemplo variables aleatorias discretas
<div class="example">
Para hallar el conjunto $Z(\Omega)$ usamos la función `outer` de `R`:

```{r}
g=function(x,y){x^2+y^2}  ## definimos la función g
sort(unique(as.vector(outer(1:6,1:6,g))))
```
Vemos que hay `r length(sort(unique(as.vector(outer(1:6,1:6,g)))))` valores distintos de la variable $Z$.

Para hallar la **función de probabilidad** de $Z$ hemos de calcular para cada valor $z_k$, las parejas $(i,j)$ tal que $i^2+j^2=z_k$:

</div>

### Ejemplo variables aleatorias discretas

<div class="example">
```{r}
valores.variable.Z = sort(unique(as.vector(outer(1:6,1:6,g))))  
matriz.valores = outer(1:6,1:6,g) ## aplicamos la función g a 
##  todas las parejas (i,j), i,j=1,2,3,4,5,6
frecuencias = c()  ## vector donde guardaremos las frecuencias de los valores de Z
for (i in 1:length(valores.variable.Z)){
  z=valores.variable.Z[i]
  frecuencias=c(frecuencias,length(matriz.valores[matriz.valores==z]))
}
frecuencias
```

</div>

### Ejemplo variables aleatorias discretas

<div class="example">

La **función de probabilidad** de $Z$ será:
```{r}
función.probabilidad.Z=data.frame(rbind(valores.variable.Z,round(frecuencias/36,3)))
rownames(función.probabilidad.Z)=c("Z","P_Z")
función.probabilidad.Z
```



</div>

### Ejemplo variables aleatorias continuas
<div class="example">
Recordemos la variable aleatoria bidimensional $(X,Y)$ con **función de densidad**:
$$
f_{XY}(x,y)=\begin{cases}
2 \mathrm{e}^{-x}\mathrm{e}^{-y}, & 0\leq y\leq x < \infty,\\
0, & \mbox{ en caso contrario,}
\end{cases}
$$
Consideremos la variable aleatoria $Z=X+Y$. Vamos a calcular la **función de densidad** de $Z$.

En primer lugar, los valores de $Z$ para los que $f_Z(z)\neq 0$ cumplen $z\geq 0$ ya que $X\geq 0$ e $Y\geq 0$.

Calculemos la **función de distribución** de la variable $Z$. Sean $z\in\mathbb{R}$ con $z\geq 0$:
$$
F_Z(z)=P(Z\leq z)=P(X+Y\leq z)=\int\int_{\{(x,y)\mathbb{R}^2,\ |\ x+y\leq z\}\cap \{(x,y)\in \mathbb{R}^2,\ |\ 0\leq y\leq x<\infty\}} 2 \mathrm{e}^{-x}\mathrm{e}^{-y}\, dy\, dx
$$
El gráfico siguiente muestra en color violeta la región de integración para hallar $F_Z(z)$ dado un $z\geq 0$.
</div>

### Ejemplo variables aleatorias continuas
<div class="center">

```{r, echo=FALSE, label=bid19,fig.cap="",out.width = "750px"}
knitr::include_graphics("Images/EjSumaXY.png",dpi=1200)
```
</div>


### Ejemplo variables aleatorias continuas
<div class="example">

El valor de $F_Z(z)$ será: (fijémonos que primero fijamos la $y$ y para cada $y$ la $x$ va desde la recta $x=y$ hasta la recta $x=z-y$)
$$
\begin{array}{rl}
F_Z(z) & =\int_{y=0}^{y=\frac{z}{2}}\int_{x=y}^{x=z-y}2 \mathrm{e}^{-x}\mathrm{e}^{-y}\, dx\, dy = 2 \int_{y=0}^{y=\frac{z}{2}} \mathrm{e}^{-y} \left[-\mathrm{e}^{-x}\right]_{x=y}^{x=z-y}\, dy \\ & = 2 \int_{y=0}^{y=\frac{z}{2}} \mathrm{e}^{-y} \left(\mathrm{e}^{-y}-\mathrm{e}^{y-z}\right)\, dy = 2 \int_{y=0}^{y=\frac{z}{2}} \left(\mathrm{e}^{-2y}-\mathrm{e}^{-z} \right)\, dy  = 2\left[-\frac{1}{2}\mathrm{e}^{-2y}-\mathrm{e}^{-z} y\right]_{y=0}^{y=\frac{z}{2}} \\ & = 2\left(\frac{1}{2}-\frac{1}{2}\mathrm{e}^{-z}-\frac{z}{2}\mathrm{e}^{-z}\right) = 1-\mathrm{e}^{-z}(1+z),\ z\geq 0.
\end{array}
$$
La **función de densidad** de $Z$ será:
$$
f_Z(z)=F'_Z(z)=z \mathrm{e}^{-z},\ z\geq 0,
$$
y $f_Z(z)=0$ en caso contrario.
</div>

### Ejemplo de la suma de dos normales 
<div class="example">
Consideremos el caso en que la variable aleatoria $(X,Y)$ tenga distribución **normal bidimensional**. 

Recordemos que su **función de densidad conjunta** era:
$$
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty <x,y<\infty.
$$
Consideremos $S=X+Y$. Estudiemos qué distribución tiene $S$.

Dado un valor $z\in\mathbb{R}$, la **función de distribución** de $S$ en $s$ será:
$$
\begin{array}{rl}
F_S(s) & =P(S\leq s)=\int\int_{\{(x,y)\in\mathbb{R}^2,\ |\ x+y\leq s\}}\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx \\ & =
\frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty}\int_{y=-\infty}^{y=s-x}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx = \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}} \int_{y=-\infty}^{y=s-x}\mathrm{e}^{-\frac{(-2\rho xy+y^2)}{2(1-\rho^2)}}\, dy\, dx  \\ &\ \qquad\mbox{hacemos el cambio siguiente en la segunda integral $t=y+x$}\\ & = \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2(1-\rho^2)}} \int_{t=-\infty}^{t=s}\mathrm{e}^{-\frac{(-2\rho x(t-x)+(t-x)^2)}{2(1-\rho^2)}}\, dt\, dx 
\end{array}
$$

</div>


### Ejemplo de la suma de dos normales 
<div class="example">
$$
\begin{array}{rl}
F_S(s) & =  \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{(1+\rho)x^2}{1-\rho^2}}\int_{t=-\infty}^{t=s} \mathrm{e}^{-\frac{(t^2-2(1+\rho) t x)}{2(1-\rho^2)}}\, dt\, dx \\ & = \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{(1+\rho)x^2}{1-\rho^2}}\int_{t=-\infty}^{t=s} \mathrm{e}^{-\frac{(t-(1+\rho)x)^2}{2(1-\rho^2)}} \mathrm{e}^{\frac{(\rho+1)^2 x^2}{2(1-\rho^2)}}\, dt\, dx  \\ & = \frac{1}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot \sqrt{2\pi (1-\rho^2)} F_X(s)\, dx, \\ & \mbox{ donde $F_X(s)$ es la función de distribución de una variable $X$ normal de parámetros} \\ & \mbox{ $\mu =(1+\rho)x$ y $\sigma^2=1-\rho^2$.} \\ & = \frac{1}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot F_X(s)\, dx.
\end{array}
$$ 
Para calcular la **función de densidad** $f_S(s)$ aplicamos la expresión $f_S(s)=F'_S(s)$ y la derivación bajo el signo integral:
$$
\begin{array}{rl}
f_S(s) & = \frac{1}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot f_X(s)\, dx = \frac{1}{\sqrt{2\pi}}\int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{x^2}{2}}\cdot \frac{1}{\sqrt{2\pi (1-\rho^2)}}\mathrm{e}^{-\frac{(s-(1+\rho)x)^2}{2(1-\rho^2)}}\, dx \\ & = \frac{\mathrm{e}^{-\frac{s^2}{2(1-\rho^2)}}}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{(2(1+\rho) x^2-2(1+\rho)xs)}{2(1-\rho^2)}}\, dx= \frac{\mathrm{e}^{-\frac{s^2}{2(1-\rho^2)}}}{2\pi\sqrt{1-\rho^2}} \int_{x=-\infty}^{x=\infty} \mathrm{e}^{-\frac{\left(x-\frac{s}{2}\right)^2}{1-\rho}}\mathrm{e}^{\frac{s^2}{4(1-\rho)}}\, dx
\end{array}
$$
</div>


### Ejemplo de la suma de dos normales 
<div class="example">
En la última integral hacemos el cambio $u=x-\frac{z}{2}$:
$$
f_S(s)  =\frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{1-\rho^2}} \int_{u=-\infty}^{u=\infty} \mathrm{e}^{-\frac{u^2}{1-\rho}}\, du.
$$
A continuación usando que $f_Z(z)=\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}$ es la función de densidad de la distribución $Z=N(0,1)$, podemos escribir: $\int_{-\infty}^\infty \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}=1,\ \Rightarrow \int_{-\infty}^\infty \mathrm{e}^{-\frac{x^2}{2}}=\sqrt{2\pi}.$

Si en la última integral hacemos el cambio $v=\sqrt{\frac{2}{1-\rho}}u$, obtenemos:
$$
\begin{array}{rl}
f_S(s)  & = \frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{1-\rho^2}}\int_{v=-\infty}^{v=\infty}\mathrm{e}^{-\frac{v^2}{2}} \sqrt{\frac{1-\rho}{2}}\, dv= \frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{2(1+\rho)}}\int_{v=-\infty}^{v=\infty}\mathrm{e}^{-\frac{v^2}{2}} \, dv \\ & = \frac{\mathrm{e}^{-\frac{s^2}{4(1+\rho)}}}{2\pi\sqrt{2(1+\rho)}} \sqrt{2\pi}= \frac{1}{\sqrt{2\pi 2(1+\rho)}}\mathrm{e}^{-\frac{s^2}{4(1+\rho)}},\ s\in\mathbb{R}.
\end{array}
$$
</div>

### Ejemplo de la suma de dos normales 
<div class="example">

Dicha función de densidad corresponde a una distribución normal de parámetros $\mu =0$ y $\sigma = \sqrt{2(1+\rho)}$.

En resumen, la distribución de la suma de dos normales es una normal de parámetros $S=N(\mu=0,\sigma = \sqrt{2(1+\rho)})$.
</div>

### Transformaciones lineales de variables aleatorias
Consideremos una variable aleatoria bidimensional continua $(X,Y)$ con **función de densidad conjunta** $f_{XY}$.

Definimos la variable aleatoria bidimensional continua $(U,V)$ a partir de una transformación lineal de la variable $(X,Y)$. O sea, existe una matriz $\mathbf{M}=\begin{pmatrix}a & b\\ c& d\end{pmatrix}$ y un vector $\mathbf{n}=\begin{pmatrix}\alpha\\\beta \end{pmatrix}$ tal que:
$$
\begin{array}{rl}
\begin{pmatrix}U\\ V\end{pmatrix} & =\mathbf{M}\cdot \begin{pmatrix}X\\ Y\end{pmatrix}+\mathbf{n}=\begin{pmatrix}a & b\\ c& d\end{pmatrix}\cdot\begin{pmatrix}X\\ Y\end{pmatrix}+\begin{pmatrix}\alpha\\\beta \end{pmatrix},\\  & \Rightarrow \left.\begin{array}{rl}U & = aX+bY+\alpha,\\ V & =cX+dY+\beta.\end{array}\right\}
\end{array}
$$

### Transformaciones lineales de variables aleatorias
Para que $(U,V)$ sea una variable aleatoria bidimensional, necesitamos que la matriz $\mathbf{M}$ sea no singular, o $\mathrm{det}(\mathbf{M})\neq 0$.

Nos preguntamos cuál es la relación entre la **función de densidad** de la variable $(U,V)$, $f_{UV}$ y la **función de densidad** de la variable $(X,Y)$, $f_{XY}$. La expresión siguiente nos da dicha relación:
$$
f_{UV}(u,v)=\frac{1}{|\mathrm{det}(\mathbf{M})|}f_{XY}\left(\mathbf{M}^{-1}\begin{pmatrix}u-\alpha\\ v-\beta\end{pmatrix}\right), \ (u,v)\in\mathbb{R}^2.
$$

### Transformaciones lineales de variables aleatorias

<l class="observ">Observación. </l> 
Si la variable $(X,Y)$ tiene una región $D$ donde $f_{XY}(x,y)\neq 0$, para todo $(x,y)\in D$, antes de aplicar la expresión anterior para hallar la **función de densidad** de la variable $(U,V)$ hemos de calcular cómo se transforma $D$ con la matriz $\mathbf{M}$. O sea, hay que hallar la región 
$$
D'=\mathbf{M}(D)=\{(u,v)\in\mathbb{R}^2,\ \mbox{existe $(x,y)\in D$ con } (u,v)=\mathbf{M}(x,y)+\mathbf{n}\}.
$$

### Ejemplo
<div class="example">
**Ejemplo**

Consideremos la variable $(X,Y)$ continua con función de densidad:
$$
f_{XY}(x,y)=\begin{cases}
\frac{1}{2}(1+x+y), & \mbox{ si }(x,y)\in R, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$
donde $R$ es el rombo de vértices $(1,0)$, $(0,1)$, $(-1,0)$ y $(0,-1)$, ver figura adjunta.

Otra forma de definir la función anterior sería:
$$
f_{XY}(x,y)=\begin{cases}
\frac{1}{2}(1+x+y), & -1\leq x\leq 0,\ -1-x\leq y\leq x+1, \\
\frac{1}{2}(1+x+y), & 0\leq x\leq 0,\ x-1\leq y\leq 1-x, \\
0, & \mbox{en caso contrario.}
\end{cases}
$$
Dejamos como ejercicio al lector comprobar que la función anterior es una **función de densidad**.
</div>

### Ejemplo


<div class="center">

```{r, echo=FALSE, label=Ej2.png,fig.cap="",out.width = "750px"}
knitr::include_graphics("Images/EjTranLineal.png",dpi=1200)
```
</div>

### Ejemplo
<div class="example">
Consideramos la variable aleatoria bidimensional $(U,V)$ definida a partir de la variable $(X,Y)$:
$$
\begin{pmatrix}U\\ V\end{pmatrix}=\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}\cdot\begin{pmatrix}X\\ Y\end{pmatrix},\ \Rightarrow \left.\begin{array}{rl}U & = X-Y,\\ V & =X+Y.\end{array}\right\}
$$
La región $R$ se transforma en el cuadrado $C$ de vértices $(1,1)$, $(-1,1)$, $(-1,-1)$ y $(1,-1)$ ya que si aplicamos la matriz a los vértices del rombo, obtenemos los vértices de cuadrado:
$$
\begin{array}{rl}
\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}\cdot \begin{pmatrix}1\\ 0\end{pmatrix} & =\begin{pmatrix}1\\ 1\end{pmatrix},\qquad 
\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}\cdot \begin{pmatrix}0\\ 1\end{pmatrix}=\begin{pmatrix}-1\\ 1\end{pmatrix},\\ 
\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}\cdot \begin{pmatrix}-1\\ 0\end{pmatrix} & =\begin{pmatrix}-1\\ -1\end{pmatrix},\qquad 
\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}\cdot \begin{pmatrix}0\\ -1\end{pmatrix}=\begin{pmatrix}1\\ -1\end{pmatrix}.
\end{array}
$$
Ver la figura adjunta.

Para hallar la **función de densidad** $f_{UV}$ necesitamos escribir $X$ e $Y$ en función de $U$ y $V$:
$$
\begin{pmatrix}X\\ Y\end{pmatrix}=\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}^{-1}\cdot\begin{pmatrix}U\\ V\end{pmatrix}=\begin{pmatrix}\frac{1}{2} & \frac{1}{2}\\ -\frac{1}{2}& \frac{1}{2}\end{pmatrix}\cdot\begin{pmatrix}U\\ V\end{pmatrix},\ \Rightarrow \left.\begin{array}{rl}X & = \frac{1}{2}(U+V),\\ Y & =\frac{1}{2}(-U+V).\end{array}\right\}
$$
</div>

### Ejemplo


<div class="center">

```{r, echo=FALSE, label=Ej3.png,fig.cap="",out.width = "750px"}
knitr::include_graphics("Images/EjTranLineal2.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">
La **función de densidad** $f_{UV}$ será, por tanto,
$$
\begin{array}{rl}
f_{UV}(u,v) & =\frac{1}{\left|\mathrm{det}\begin{pmatrix}1 & -1\\ 1& 1\end{pmatrix}\right|}\cdot f_{XY}\left(\frac{1}{2}(u+v),\frac{1}{2}(-u+v)\right) \\ & =\frac{1}{2}\cdot \frac{1}{2}\cdot \left(1+\frac{1}{2}(-u+v)+\frac{1}{2}(u+v)\right)=\frac{1}{4}(1+v),
\end{array}
$$
para $(u,v)$ perteneciente al cuadrado $C$ de vértices $(1,1)$, $(-1,1)$, $(-1,-1)$ y $(1,-1)$, o si se quiere para $-1\leq u\leq 1$, $-1\leq v\leq 1$, y $f_{UV}(u,v)=0$, en caso contrario.

Observamos que es más cómodo trabajar con las variables $(u,v)$ en vez de trabajar con las variables $(x,y)$ por dos razones:

- La región donde la **función de densidad** no es nula es más simple, ya que trabajar con un cuadrado simplifica mucho más los cálculos que trabajar con un rombo a la hora de hallar la **función de distribución**, **densidades marginales**, **densidades condicionadas**, **valores esperados**, etc.
- La expresión de la **función de densidad** también es más simple, ya que sólo depende de la segunda variable $v$; sin embargo, la **función de densidad** inicial $f_{XY}$ dependía de las dos variables $x$ e $y$.
</div>

### Ejemplo de la normal bidimensional
<div class="example">
Consideremos el caso en que la variable aleatoria $(X,Y)$ tenga distribución **normal bidimensional**. 

Recordemos que su **función de densidad conjunta** era:
$$
f_{XY}(x,y)=\frac{1}{2\pi\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{(x^2-2\rho xy+y^2)}{2(1-\rho^2)}},\ -\infty <x,y<\infty.
$$
Recordemos que las **distribuciones marginales** eran distribuciones $N(0,1)$.

La idea es hallar la **función de densidad conjunta** de una distribución normal bidimensional para la que sus **distribuciones marginales** sean dos normales $N(\mu_1,\sigma_1)$ y $N(\mu_2,\sigma_2)$.

Recordemos que si $Z=N(0,1)$, entonces $\sigma_1\cdot Z+\mu_1 =N(\mu_1,\sigma_1)$. Este hecho, motiva que consideremos el cambio lineal siguiente a las variables $X$ e $Y$:
$$
\begin{pmatrix}U\\ V\end{pmatrix}=\begin{pmatrix}\sigma_1 & 0\\ 0& \sigma_2\end{pmatrix}\cdot\begin{pmatrix}X\\ Y\end{pmatrix}+\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix},\ \Rightarrow \left.\begin{array}{rl}U & = \sigma_1\cdot X+\mu_1,\\ V & =\sigma_2\cdot Y+\mu_2.\end{array}\right\}
$$
</div>

### Ejemplo de la normal bidimensional
<div class="example">
La función de densidad conjunta $f_{UV}$ será:
$$
\begin{array}{rl}
f_{UV}(u,v) & = \frac{1}{\left|\begin{pmatrix}\sigma_1 & 0\\ 0& \sigma_2\end{pmatrix}\right|} f_{XY}\left(\frac{u-\mu_1}{\sigma_1},\frac{v-\mu_2}{\sigma_2}\right)
=\frac{1}{\sigma_1\cdot \sigma_2}f_{XY}\left(\frac{u-\mu_1}{\sigma_1},\frac{v-\mu_2}{\sigma_2}\right)\\ & =
\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\mathrm{e}^{-\frac{\left(\left(\frac{u-\mu_1}{\sigma_1}\right)^2-2\rho \left(\frac{u-\mu_1}{\sigma_1}\right)\left(\frac{v-\mu_2}{\sigma_2}\right)+\left(\frac{v-\mu_2}{\sigma_2}\right)^2\right)}{2(1-\rho^2)}},
\end{array}
$$
para $(u,v)\in\mathbb{R}^2$.

Si llamamos $\mathbf{\Sigma}$ a la matriz $\mathbf{\Sigma}=\begin{pmatrix}\sigma_1^2 & \rho\sigma_1\sigma_2\\ \rho\sigma_1\sigma_2 & \sigma_2^2\end{pmatrix}$, llamada **matriz de covarianzas** de la distribución normal $(U,V)$ la **función de densidad** anterior puede escribirse como:
$$
f_{UV}(u,v)=\frac{1}{2\pi \sqrt{\left|\mathrm{\Sigma}\right|}}\mathrm{e}^{-\frac{1}{2}(\mathbf{u}-\mathbf{\mu})^\top \mathbf{\Sigma}^{-1}(\mathbf{u}-\mathbf{\mu})},\ \mbox{donde $\mathbf{u}=\begin{pmatrix}u \\ v\end{pmatrix}$ y $\mathbf{\mu}=\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix}$.}
$$
La variable aleatoria bidimensional $(X,Y)$ sería la **variable aleatoria tipificada** con respecto de la variable $(U,V)$.
</div>

### Transformaciones generales de variables aleatorias
Consideremos una variable aleatoria bidimensional continua $(X,Y)$ con **función de densidad conjunta** $f_{XY}$.

Definimos la variable aleatoria bidimensional continua $(U,V)$ a partir de una transformación general de la variable $(X,Y)$. O sea, existen dos funciones de dos variables $g_1$ y $g_2$ tal que:
$$
U  = g_1 (X,Y),\quad 
V  = g_2 (X,Y).
$$
Vamos a suponer que las funciones $g_1$ y $g_2$ son invertibles, o sea, dados $(u,v)$, podemos encontrar $(x,y)$ tal que $x=h_1(u,v)$ e $y=h_2(u,v)$. Las funciones $h_1$ y $h_2$ serían las inversas de las funciones $g_1$ y $g_2$, respectivamente.


### Transformaciones generales de variables aleatorias

La **función de densidad conjunta** $f_{UV}$ se puede expresar de la forma siguiente en función de la **función de densidad conjunta** $f_{XY}$:
$$
\begin{array}{rl}
f_{UV}(u,v) & =\left|\mathrm{det}\begin{pmatrix}\frac{\partial h_1}{\partial u} & \frac{\partial h_1}{\partial v}\\ \frac{\partial h_2}{\partial u} & \frac{\partial h_2}{\partial v}\end{pmatrix}\right|f_{XY}(h_1(u,v),h_2(u,v))\\ & =\frac{1}{\left|\mathrm{det}\begin{pmatrix}\frac{\partial g_1}{\partial x} & \frac{\partial g_1}{\partial y}\\ \frac{\partial g_2}{\partial x} & \frac{\partial g_2}{\partial y}\end{pmatrix}\right|_{x=h_1(u,v),y=h_2(u,v)}}f_{XY}(h_1(u,v),h_2(u,v)).
\end{array}
$$



### Transformaciones generales de variables aleatorias

A la matriz $\begin{pmatrix}\frac{\partial g_1}{\partial x} & \frac{\partial g_1}{\partial y}\\ \frac{\partial g_2}{\partial x} & \frac{\partial g_2}{\partial y}\end{pmatrix}$ se le llama **matriz jacobiana del cambio** y a la matriz $\begin{pmatrix}\frac{\partial h_1}{\partial u} & \frac{\partial h_1}{\partial v}\\ \frac{\partial h_2}{\partial u} & \frac{\partial h_2}{\partial v}\end{pmatrix}$, **matriz jacobiana del cambio inverso**.

### Ejemplo
<div class="example">
**Ejemplo. Cambio a polares**

Sea $(X,Y)$ una variable aleatoria bidimensional cuya **función de densidad conjunta** es:
$$
f_{XY}(x,y)=
\begin{cases}
\frac{2}{\pi}\left(x^2 + y^2\right), & \mbox{si }(x,y)\in D_1, \\
0, & \mbox{en caso contrario,}
\end{cases}
$$
donde $D_1$ es el disco de radio $1$:
$$
D_1 = \{(x,y)\in\mathbb{R}^2,\ | \ x^2+y^2\leq 1\}.
$$
El cambio a polares consiste en considerar las coordenadas polares $(r,\alpha)$ de un punto cualquiera $(x,y)$ del plano, ver figura adjunta. El cambio que pasa de $(r,\alpha)$ a $(x,y)$ (fijaos que sería el cambio inverso, según nuestra notación o $h_1$y $h_2$, respectivamente) sería:
$$
x=h_1(r,\alpha)=r\cdot \cos\alpha,\quad y=h_2(r,\alpha)=r\cdot \sin\alpha.
$$

</div>

### Ejemplo


<div class="center">

```{r, echo=FALSE, label=Ej4.png,fig.cap="",out.width = "750px"}
knitr::include_graphics("Images/Polares.png",dpi=1200)
```
</div>

### Ejemplo
<div class="example">
Fijémonos que, con el cambio a polares, el disco unidad $D_1$ se transforma en el rectángulo $[0,1]\times [0,2\pi]$. 

Hallemos el **jacobiano del cambio inverso**:
$$
\mathrm{det}\begin{pmatrix}\frac{\partial h_1}{\partial u} & \frac{\partial h_1}{\partial v}\\ \frac{\partial h_2}{\partial u} & \frac{\partial h_2}{\partial v}\end{pmatrix} =\mathrm{det}\begin{pmatrix}\cos\alpha & -r\sin\alpha\\ \sin\alpha & r\cdot\cos\alpha\end{pmatrix} = r.
$$
La **función de densidad conjunta** $f_{r\alpha}$ en las nuevas variables (polares) será:
$$
f_{r\alpha}(r,\alpha)=r\cdot \frac{2}{\pi}\left((r\cos\alpha)^2+(r\sin\alpha)^2\right)=\frac{2}{\pi}\cdot r^3,
$$
 si $(r,\alpha)\in [0,1]\times [0,2\pi]$.
</div>

### Ejemplo

<div class="example">
Podemos comentar que, gracias al cambio a polares, en este caso, es mucho más sencillo y cómodo trabajar con las variables $(r,\alpha)$ en vez de trabajar con las variables $(x,y)$ por dos razones:

- La región donde la **función de densidad** no es nula es más simple, ya que trabajar con un rectángulo simplifica mucho más los cálculos que trabajar con un disco a la hora de hallar la **función de distribución**, **densidades marginales**, **densidades condicionadas**, **valores esperados**, etc.

Por ejemplo, comprobar que el área de la **función de densidad conjunta** $f_{r\alpha}$ da $1$ es trivial:
$$
\int_{r=0}^{r=1}\int_{\alpha =0}^{\alpha =2\pi}\frac{2}{\pi} r^3\, d\alpha\, dr = \frac{2}{\pi}\cdot 2\pi \left[\frac{r^4}{4}\right]_{r=0}^{r=1}=4\cdot \frac{1}{4}=1.
$$
- La expresión de la **función de densidad** también es más simple, ya que sólo depende de la primera variable $r$; sin embargo, la **función de densidad** inicial $f_{XY}$ dependía de las dos variables $x$ e $y$.

</div>

<!--chapter:end:5.Rmd-->

# Vectores aleatorios

## Varias variables aleatorias

En el capítulo anterior trabajamos con **variables aleatorias $n$-dimensionales**

En este capítulo vamos a generalizar los conceptos introducidos para **variables aleatorias bidimensionales**, con $n\geq 3$.

El ejemplo que comentamos en el capítulo de variables aleatorias de medir la temperatura media un día determinado del año durante 10 años sería un ejemplo de variable aleatoria 10-dimensional.



### Varias variables aleatorias. Definición

La generalización de la noción de **variable aleatoria $n$-dimensional** a partir de la noción de **variable aleatoria bidimensional** es bastante obvia:

<l class="definition">Definición de variable aleatoria $n$-dimensional:</l>
Dado un experimento aleatorio con **espacio muestral** $\Omega$, definimos **variable aleatoria $n$-dimensional** $\mathbf{X}=(X_1,X_2,\ldots,X_n)$ a toda aplicación 
$$
\begin{array}{rl}
\mathbf{X}=(X_1,X_2,\ldots,X_n): \Omega & \longrightarrow \mathbb{R}^n\\
w & \longrightarrow \mathbf{X}(w)=(X_1(w),X_2(w),\ldots,X_n(w)).
\end{array}
$$

### Varias variables aleatorias. Ejemplos
<div class="example">
**Ejemplo**

Tenemos tres puertos de entrada de paquetes de internet. 

Supongamos que cada milisegundo llega un paquete y el switch lo asigna a cada uno de los puertos con probabilidad $\frac{1}{3}$.

Estudiamos cómo se distribuyen los paquetes en 4 milisegundos. 

Sea $\mathbf{X}=(X_1,X_2,X_3)$ la variable aleatoria 3-dimensional, donde $X_i$ nos da el número de paquetes que ha recibido el puerto $i$-ésimo durante estos 4 milisegundos.

Por ejemplo, el suceso $\{X_1\leq 1, X_2\geq 3, X_3\leq 1\}$ sería $\{(0,3,0),(0,3,1),(0,4,0),(0,4,1),(1,3,0),(1,3,1),(1,4,0),(1,4,1)\}$.

</div>


### Varias variables aleatorias. Introducción 
Los sucesos que se derivan de una **variable aleatoria $n$-dimensional** estan especificados por regiones del espacio $n$-dimensional.

Veamos algunos ejemplos:

Suceso: $\{X_1+X_2+X_3\leq 1\}$. En el gráfico siguiente, el plano $x_1+x_2+x_3=1$ separa el espacio en dos partes. Sería la parte que corresponde al punto $(0,0,0)$.

O sea, si pensamos el plano anterior como un "espejo" sería la parte de atrás del mismo.

### Ejemplo

<div class="center">

```{r, echo=FALSE, label=bid1,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/EjPlano3D.png",dpi=1200)
```
</div>

### Varias variables aleatorias. Introducción 
Suceso: $\{X_1^2+X_2^2+X_3^2\leq 1\}$. Sería el interior de la esfera del gráfico siguiente:

### Varias variables aleatorias. Introducción 
<div class="center">
```{r, echo=FALSE, label=bid2_0,fig.cap="",out.width = "750px"}
knitr::include_graphics("Images/EjEsfera3D.png",dpi=1200)
```
</div>

### Varias variables aleatorias. Introducción 
Suceso: $\{0\leq X_1\leq 1,\ 0\leq X_2\leq 1,\ 0\leq X_3\leq 1\}$. Sería el interior del cubo del gráfico siguiente:

### Varias variables aleatorias. Introducción 
<div class="center">
```{r, echo=FALSE, label=bid3_0,fig.cap="",out.width = "950px"}
knitr::include_graphics("Images/Ej3DCubo.png",dpi=1200)
```
</div>

### Varias variables aleatorias. Introducción 

La probabilidad de que la **variable $n$-dimensional** pertenezca a una cierta **región del $n$-espacio $B\subset \mathbb{R}^n$** se define de la forma siguiente:
$$
P((X_1,X_2,\ldots,X_n)\in B)=P\{w\in \Omega,\ |\ (X_1(w),X_2(w),\ldots,X_n)\in B\},
$$
o sea, la probabilidad anterior es la probabilidad del suceso formado por los elementos de $w\in\Omega$ que cumplen que su **imagen** por la **variable aleatoria $n$-dimensional $(X_1,X_2,\ldots,X_n)$** esté en $B$.


Por ejemplo, si consideramos $B=\{X_1+X_2+\cdots +X_n\leq 1\}$, $P((X_1,X_2,\ldots,X_n)\in B)$ sería la probabilidad del suceso formado por los elementos $w$ de $\Omega$ tal que la suma de las imágenes por $X_i$ desde $i=1$ hasta $n$ sea menor o igual que 1: $X_1(w)+\cdots +X_n\leq 1$.

## Función de distribución conjunta

### Función de distribución conjunta. Introducción
Dada una **variable aleatoria $n$-dimensional** $(X_1,X_2,\ldots,X_n)$, queremos estudiar cómo se distribuye la probabilidad de sucesos cualesquiera de la forma $\{(X_1,X_2,\ldots,X_n)\in B\}$, donde $B$ es una región del espació $n$-dimensional $\mathbb{R}^n$.

Para ello, definimos la **función de distribución conjunta**:

<l class="definition">Definición de función de distribución conjunta:</l>
Dada una variable $n$-dimensional $(X_1,X_2,\ldots,X_n)$, definimos su **función de distribución conjunta** $F_{X_1\ldots X_n}$ a la función definida sobre $\mathbb{R}^n$ de la manera siguiente:
$$
\begin{array}{rl}
F_{X_1\ldots X_n}: \mathbb{R}^n & \longrightarrow \mathbb{R}\\
(x_1,\ldots,x_n) & \longrightarrow F_{X_1\ldots X_n}(x_1,\ldots,x_n)=P(X_1\leq x_1,\ldots,X_n\leq x_n).
\end{array}
$$

### Función de distribución conjunta. Introducción

O sea, dado un valor $(x_1,\ldots,x_n)\in \mathbb{R}^n$, consideramos la región del espacio $n$-dimensional $(-\infty,x_1]\times\cdots\times (-\infty,x_n]$.

Entonces la **función de distribución conjunta** en el valor $(x_1,\ldots,x_n)$ es la probabilidad del suceso formado por aquellos elementos tal que la imagen por la **variable aleatoria $n$-dimensional** $(X_1,X_2,\ldots,X_n)$ caen dentro de la región anterior:

$$
\begin{array}{rl}
F_{X_1\ldots X_n}(x_1,\ldots,x_n) & =P\{w\in\Omega,\ |\ (X_1(w),\ldots,X_n(w)) \\ & \qquad\qquad\in (-\infty,x_1]\times\cdots\times (-\infty,x_n]\} \\ & = P\{w\in\Omega,\ |\ X_1(w)\leq x_1,\ldots, X_n(w)\leq x_n\}.
\end{array}
$$


### Función de distribución conjunta. Introducción
El gráfico siguiente muestra el conjunto $(-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3]$ en $\mathbb{R}^3$ para un valor $(x,y,z)$:

<div class="center">
```{r, echo=FALSE, label=bid777,fig.cap="",out.width = "550px"}
knitr::include_graphics("Images/Fx1x2x3.png",dpi=1200)
```
</div>


### Función de distribución conjunta. Propiedades
Sea $(X_1,X_2,\ldots,X_n)$ una variable $n$-dimensional. Sean $F_{X_1\ldots X_n}$ su **función de distribución conjunta**. Dicha función satisface las propiedades siguientes:

* La función de distribución conjunta es no decreciente en cada una de las variables:
$$
\mbox{Si }x_i\leq x_i', \mbox{ para todo $i$, }\mbox{ entonces, }F_{X_1\ldots X_n}(x_1,\ldots,x_n)\leq F_{X_1\ldots X_n}(x_1',\ldots,x_n').
$$

* $F_{X_1\ldots X_n}(x_1,\ldots,x_{i-1},\stackrel{(i)}{-\infty},x_{i+1},\ldots,x_n)=0,$ para todo $i$ y  $F_{X_1\ldots X_n}(\infty,\ldots,\infty)=1$, para todo $x_1,\ldots,x_n\in\mathbb{R}$.


### Función de distribución conjunta. Propiedades

* Las variables aleatorias $X_1,\ldots, X_n$ se llaman **variables aleatorias marginales** y sus funciones de distribución $F_{X_1},\ldots, F_{X_n}$ pueden hallarse de la forma siguiente como función de la **función de distribución conjunta** $F_{X_1\ldots X_n}$:
$$
F_{X_i}(x_i)=F_{X_1\ldots X_n}(\infty,\ldots,\infty,\stackrel{(i)}{x_i},\infty,\ldots,\infty),
$$
para todo $x_1,\ldots,x_n\in\mathbb{R}$ y para todo $i=1,\ldots,n$.

### Función de distribución conjunta. Propiedades

* La función de distribución conjunta es continua por la derecha en todas las variables $x_i$:
$$
\begin{array}{rl}
 & \lim\limits_{x_i\to a^+}F_{X_1\ldots X_n}(x_1,\ldots,x_{i-1},\stackrel{(i)}{x_i},x_{i+1},\ldots,x_n) \\ &\qquad =\lim\limits_{x_i\to a, x_i> a}F_{X_1\ldots X_n}(x_1,\ldots,x_{i-1},\stackrel{(i)}{x_i},x_{i+1},\ldots,x_n)\\ &\qquad =F_{X_1\ldots X_n}(x_1,\ldots,x_{i-1},\stackrel{(i)}{a},x_{i+1},\ldots,x_n),
\end{array}
$$
para todo $a\in\mathbb{R}$ y para todo $i=1,\ldots,n$.


### Función de distribución conjunta. Ejemplo
<div class="example">
**Ejemplo**

Consideremos una variable aleatoria $3$-dimensional $(X_1,X_2,X_3)$ con **función de distribución conjunta**:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
0, & \mbox{si }x_1<0,\mbox{ o }x_2<0,\mbox{ o }x_3 <0\\
x_1^2\cdot x_2^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
 x_2^2\cdot x_3^2, & \mbox{si }x_1> 1,\ 0\leq x_2\leq  1,\ 0\leq x_3\leq  1, \\
 x_1^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq  1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 x_3^2, & \mbox{si }x_1> 1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 x_1^2\cdot x_2^2, & \mbox{si }0\leq x_1\leq  1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
 x_1^2, & \mbox{si }0\leq x_1\leq  1,\ x_2 >  1,\ x_3> 1,\\
 x_2^2, & \mbox{si }x_1>1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
1, & \mbox{si }x_1\geq 1,\ x_2\geq 1,\ x_3\geq 1.
\end{cases}
$$

</div>

### Función de distribución conjunta. Ejemplo
<div class="example">
**Ejemplo**

En las figuras siguientes, hemos representado por zonas cómo está definida $F_{X_1X_2X_3}$.

La primera figura muestra las zonas en la "planta baja" o para $0\leq x_3\leq 1$.
En color marrón, está representada la región $0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1$, en color amarillo, la región $x_1> 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1$, en color verde, la región $x_1>1,\ x_2>1,\ 0\leq x_3\leq 1$ y en color violeta, la región $0\leq x_1\leq 1,\ x_2>1,\ 0\leq x_3\leq 1$.


La segunda figura muestra las zonas del "primer piso" o para $x_3>1$. Los colores tienen un significado similar a los de la primera figura: en color marrón, está representada la región $0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\  x_3> 1$, en color amarillo u ocre, la región $x_1> 1,\ 0\leq x_2\leq 1,\ x_3> 1$, en color verde, la región $x_1>1,\ x_2>1,\ x_3> 1$ y en color violeta, la región $0\leq x_1\leq 1,\ x_2>1,\ x_3> 1$.
</div>


### Función de distribución conjunta. Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid7_0,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/Ej3DFxyz.png",dpi=1200)
```
</div>


### Función de distribución conjunta. Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid77,fig.cap="",out.width = "650px"}
knitr::include_graphics("Images/Ej3DFxy2pis.png",dpi=1200)
```
</div>

### Función de distribución conjunta. Ejemplo
<div class="example">
Comprobemos algunas de las propiedades que hemos enunciado anteriormente:

* Claramente $F_{X_1X_2X_3}(x_1,x_2,-\infty)=F_{X_1X_2X_3}(x_1,-\infty,x_3)=F_{X_1X_2X_3}(-\infty,x_2,x_3)=0$ ya que $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$ si $x_1<0$ o $x_2<0$ o $x_3<0$. Por tanto, si hacemos tender $x_1$ o $x_2$ o $x_3$ hacia $-\infty$, obtendremos que $F_{X_1X_2X_3}(x_1,x_2,-\infty)=F_{X_1X_2X_3}(x_1,-\infty,x_3)=F_{X_1X_2X_3}(-\infty,x_2,x_3)=0$.

* De la misma manera $F_{X_1X_2X_3}(\infty,\infty,\infty)=1$ ya que $F_{X_1X_2X_3}(x_1,x_2,x_3)=1$ para $x_1>1$, $x_2>1$ y $x_3>1$. Por tanto, si hacemos tender $x_1$, $x_2$ y $x_3$ hacia $\infty$, obtendremos $F_{X_1X_2X_3}(\infty,\infty,\infty)=1$.

* Hallemos las marginales:
$$
F_{X_1}(x_1)=F_{X_1X_2X_3}(x_1,\infty,\infty)=\begin{cases}
0, & \mbox{ si }x_1 < 0,\\
x_1, & \mbox{ si } 0\leq x_1\leq 1,\\
1, & \mbox{ si } x_1>1.
\end{cases}
$$
Para ver la expresión anterior basta trazar el plano $X_1=x_1$ en el gráfico anterior y ver hacia dónde tiende a medida que las variables $x_2$ y $x_3$ se van hacia $\infty$. 

¿Habéis averiguado cuál es la distribución de $X_1$?
</div>


### Función de distribución conjunta. Ejemplo
<div class="example">
¡Efectivamente!, $X_1$ es la uniforme en el intervalo $(0,1)$.

Dejamos como ejercicio hallar la distribución marginal para las variables $X_2$ e $X_3$.

* Comprobemos que $F_{X_1X_2X_3}$ es continua por la derecha para las variables $x_1$, $x_2$ y $x_3$ en el punto $(1,1,1)$ que sería un punto problemático:
$$
\begin{array}{rl}
 \lim_{x_1\to 1,x_1> 1} F_{X_1X_2X_3}(x_1,1,1) & =\lim_{x_1\to 1,x_1> 1} 1  = F_{X_1X_2X_3}(1,1,1),\\
 \lim_{x_2\to 1,x_2> 1} F_{X_1X_2X_3}(1,x_2,1) & =\lim_{x_2\to 1,x_2> 1} 1 = F_{X_1X_2X_3}(1,1,1),\\  
\lim_{x_3\to 1,x_3> 1} F_{X_1X_2X_3}(1,1,x_3) & =\lim_{x_3\to 1,x_3> 1} 1  = F_{X_1X_2X_3}(1,1,1).
\end{array}
$$

</div>

### Ejemplo con `R`
<div class="example">
Realizar un gráfico 3D de la **función de distribución conjunta** no es posible ya que deberíamos pasar a $\mathbb{R}^4$. 

Lo que sí es posible es dibujar las curvas de nivel de dicha función para un valor de $x_3$ fijado. 

El los gráficos siguientes dibujamos las curvas de nivel para $x_3=0,0.5,1$ i $x_3=1.5$.

Primero definimos la **función** y luego la dibujamos para $x_1$ y $x_2$ entre $-1$ y $3$:

</div>

### Ejemplo con `R`
<div class="example">

```{r,eval=FALSE}
f.dist.con = function(x1,x2,x3){ifelse(x1<0 | x2<0 | x3 <0,0,
          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3>=0 & x3<=1,x1^2*x2^2*x3^2,
          ifelse(x1>1 & x2>=0 & x2<=1 & x3>=0 & x3<=1,x2^2*x3^2,
          ifelse(x1>=0 & x1<=1 & x2>1 & x3>=0 & x3<=1,x1^2*x3^2,
          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3>1,x1^2*x2^2,
          ifelse(x1>=0 & x1<=1 & x2 >1 & x3 >1,x1^2,
          ifelse(x1>1 & x2 >=0 & x2<=1 & x3 >1,x2^2,
          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3 >1,x3^2,1))))))))}
x1=seq(from=-1,to=3,by=0.05)
x2=seq(from=-1,to=3,by=0.05)
curva.nivel.0=outer(x1,x2,f.dist.con,x3=0)
curva.nivel.0.5=outer(x1,x2,f.dist.con,x3=0.5)
curva.nivel.1=outer(x1,x2,f.dist.con,x3=1)
curva.nivel.1.5=outer(x1,x2,f.dist.con,x3=1.5)
image(x1,x2,curva.nivel.0)
image(x1,x2,curva.nivel.0.5)
image(x1,x2,curva.nivel.1)
image(x1,x2,curva.nivel.1.5)
```

</div>


### Ejemplo con `R`. Curva de nivel para $x_3=0$

```{r,echo=FALSE,fig.align='center',fig.height=5.5}
f.dist.con = function(x1,x2,x3){ifelse(x1<0 | x2<0 | x3 <0,0,
          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3>=0 & x3<=1,x1^2*x2^2*x3^2,
          ifelse(x1>1 & x2>=0 & x2<=1 & x3>=0 & x3<=1,x2^2*x3^2,
          ifelse(x1>=0 & x1<=1 & x2>1 & x3>=0 & x3<=1,x1^2*x3^2,
          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3>1,x1^2*x2^2,
          ifelse(x1>=0 & x1<=1 & x2 >1 & x3 >1,x1^2,
          ifelse(x1>1 & x2 >=0 & x2<=1 & x3 >1,x2^2,
          ifelse(x1>=0 & x1<=1 & x2>=0 & x2<=1 & x3 >1,x3^2,1))))))))}
x1=seq(from=-1,to=3,by=0.05)
x2=seq(from=-1,to=3,by=0.05)
curva.nivel.0=outer(x1,x2,f.dist.con,x3=0)
curva.nivel.0.5=outer(x1,x2,f.dist.con,x3=0.5)
curva.nivel.1=outer(x1,x2,f.dist.con,x3=1)
curva.nivel.1.5=outer(x1,x2,f.dist.con,x3=1.5)
image(x1,x2,curva.nivel.0)
```


### Ejemplo con `R`. Curva de nivel para $x_3=0.5$

```{r,echo=FALSE,fig.align='center',fig.height=5.5}
image(x1,x2,curva.nivel.0.5)
```

### Ejemplo con `R`. Curva de nivel para $x_3=1$

```{r,echo=FALSE,fig.align='center',fig.height=5.5}
image(x1,x2,curva.nivel.1)
```

### Ejemplo con `R`. Curva de nivel para $x_3=1.5$

```{r,echo=FALSE,fig.align='center',fig.height=5.5}
image(x1,x2,curva.nivel.1.5)
```


### Función de distribución conjunta. Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado tres veces**

Consideremos el experimento aleatorio que consiste en lanzar un dado tres veces. 

El espacio $\Omega$ de resultados será:
$$
\Omega =\{(i,j,k),\ | i,j,k=1,2,3,4,5,6\}.
$$
En total tendremos $6\cdot 6\cdot 6=6^3=`r 6^3`$ resultados posibles.

Consideremos la variable 3-dimensional $\mathbf{X}=(X_1,X_2,X_3)$, donde $X_1$ nos da el número de 1's obtenidos, $X_2$, el número de 2's y $X_3$, el número de 3's.

El conjunto $\mathbf{X}(\Omega)$ tiene en total 64 elementos ya que cada componente $X_i$ puede tener en total 4 resultados: 0, 1, 2 o 3. Por tanto el conjunto total de resultados será: $4\cdot 4\cdot 4=4^3=`r 4^3`$.
</div>


### Función de distribución conjunta. Ejemplo
<div class="example">

El valor de función de distribución conjunta en el resultado $(0,0,0)$ será:
$$
F_{X_1X_2X_3}(0,0,0)=p(X_1\leq 0,\ X_2\leq 0,\ X_3\leq 0)=\frac{3^3}{6^3}=\left(\frac{1}{2}\right)^3 =`r 1/2^3`,
$$
ya que si $X_1\leq 0$, $X_2\leq 0$ y $X_3\leq 0$, significa que no ha salido ni ningún 1, ni ningún 2 ni ningún 3. Sólo pueden salir 4's, 5's o 6's y existen $3\cdot 3\cdot 3=3^3=`r 3^3`$ posibilidades de que esto pase entre $6^3=`r 6^3`$ posibilidades posibles.
</div>

## Variables aleatorias $n$-dimensionales discretas

### Variables aleatorias $n$-dimensionales discretas. Introducción

<l class="definition">Definición de variable aleatoria $n$-dimensional discreta:</l>
Sea $(X_1,\ldots,X_n)$ una **variable aleatoria $n$-dimensional**. Diremos que es discreta cuando su conjunto de valores en $\mathbb{R}^n$, $(X_1,\ldots,X_n)(\Omega)$ es un conjunto finito o numerable. 

En la mayoría de los casos, dicho conjunto será un subconjunto de los enteros naturales.

### Ejemplo

<div class="example">
**Ejemplo**

La variable aleatoria 3-dimensional anterior que nos daba el número de 1's obtenidos, el número de 2's y el número de 3's es discreta ya que
$$
\begin{array}{rl}
\mathbf{X}(\Omega)=\{& (0,0,0),(1,0,0),(0,1,0),(0,0,1),(2,0,0),(0,2,0),(0,0,2),(3,0,0),(0,3,0),(0,0,3), \\
& (0,1,1),(1,0,1),(1,1,0),(0,1,2),(0,2,1),(1,0,2),(2,0,1),(1,2,0),(2,1,0),(0,1,3), \\ &
(0,3,1),(1,0,3),(3,0,1),(1,3,0),(3,1,0),(0,2,2),(2,0,2),(2,2,0),(0,2,3),(3,2,0),\\ &
(2,0,3),(3,0,2),(2,3,0),(3,2,0),(0,3,3),(3,0,3),(3,3,0),(1,1,1),(1,1,2),(1,2,1),\\ &
(2,1,1),(1,1,3),(1,3,1),(3,1,1),(1,2,2),(2,1,2),(2,2,1),(1,2,3),(2,1,3),(1,3,2),\\ &
(3,1,2),(2,3,1),(3,2,1),(1,3,3),(3,1,3),(3,3,1),(2,2,2),(2,2,3),(2,3,2),(3,2,2)\\ &
(2,3,3),(3,2,3),(3,3,2),(3,3,3)\}.
\end{array}
$$

</div>


### Función de probabilidad conjunta
<l class="definition">Definición de función de probabilidad conjunta:</l>
Dada una **variable aleatoria $n$-dimensional discreta** $(X_1\ldots,X_n)$ con $(X_1\ldots,X_n)(\Omega)=\{(x_{i_1},x_{i_2},\ldots,x_{i_n}),\ i_1=1,2,\ldots,\ i_n=1,2,\ldots,\}$, definimos la función de probabilidad discreta $P_{X_1\ldots X_n}$ para un valor $(x_{i_1},x_{i_2},\ldots,x_{i_n})\in\mathbb{R}^n$ de la siguiente forma:
$$
\begin{array}{rl}
P_{X_1\ldots X_n}: \mathbb{R}^n & \longrightarrow \mathbb{R}\\
(x_{i_1},x_{i_2},\ldots,x_{i_n}) & \longrightarrow P_{X_1\ldots X_n}(x_{i_1},x_{i_2},\ldots,x_{i_n})=P(X= x_{i_1},\ldots X_n= x_{i_n}).
\end{array}
$$

### Función de probabilidad conjunta
<l class="observ">Observación:</l>
Si $(x_{i_1},x_{i_2},\ldots,x_{i_n})\not\in (X_1\ldots,X_n)(\Omega)$, el valor de la **función de probabilidad conjunta** en $(x_{i_1},x_{i_2},\ldots,x_{i_n})$ en nulo: $P_{X_1\ldots X_n}(x_{i_1},x_{i_2},\ldots,x_{i_n})=0$, ya que, en este caso, el conjunto $\{w\in\Omega,\ | (X_1(w),\ldots,X_n(w))=(x_{i_1},x_{i_2},\ldots,x_{i_n})\}=\emptyset$ ya que recordemos $(x_{i_1},x_{i_2},\ldots,x_{i_n})\not\in (X_1\ldots,X_n)(\Omega)$.

### Función de probabilidad conjunta

Por tanto, de cara a calcular $P_{X_1\ldots X_n}$ basta calcular $P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n})$ para $(x_{i_1},\ldots,x_{i_n})\in (X_1\ldots,X_n)(\Omega)$.

Los valores de $P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n})$ estarían organizados en una tabla $n$-dimensional.


### Ejemplo
<div class="example">
**Ejemplo de la variable 3-dimensional que nos da el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces**

Para mostrar la **función de probabilidad conjunta** haremos una tabla bidimensional para cada valor de $X_3$. 

Como $X_3(\Omega)=\{0,1,2,3\}$, en total mostraremos 4 tablas bidimensionales.
</div>

### Ejemplo

<div class="example">
Tabla para $X_3=0$:

<div class="center">
| $X_1/X_2$| 0 | 1 | 2 | 3 
|--|--|--|--|--
| 0  | $\frac{1}{8}$ | $\frac{1}{8}$ | $\frac{1}{24}$ | $\frac{1}{`r 6^3`}$
| 1  | $\frac{1}{8}$ | $\frac{1}{12}$ | $\frac{1}{72}$ | $0$
| 2  | $\frac{1}{24}$ | $\frac{1}{72}$ | $0$ | $0$
| 3  | $\frac{1}{216}$ | $0$ | $0$ | $0$
</div>

</div>

### Ejemplo

<div class="example">
Tabla para $X_3=1$:

<div class="center">
| $X_1/X_2$| 0 | 1 | 2 | 3 
|--|--|--|--|--
| 0  | $\frac{1}{8}$ | $\frac{1}{12}$ | $\frac{1}{72}$ | $0$
| 1  | $\frac{1}{12}$ | $\frac{1}{36}$ | $0$ | $0$
| 2  | $\frac{1}{72}$ | $0$ | $0$ | $0$
| 3  | $0$ | $0$ | $0$ | $0$
</div>

</div>

### Ejemplo

<div class="example">
Tabla para $X_3=2$:

<div class="center">
| $X_1/X_2$| 0 | 1 | 2 | 3 
|--|--|--|--|--
| 0  | $\frac{1}{24}$ | $\frac{1}{72}$ | $0$ | $0$
| 1  | $\frac{1}{72}$ | $0$ | $0$ | $0$
| 2  | $0$ | $0$ | $0$ | $0$
| 3  | $0$ | $0$ | $0$ | $0$
</div>

</div>

### Ejemplo

<div class="example">
Tabla para $X_3=3$:

<div class="center">
| $X_1/X_2$| 0 | 1 | 2 | 3 
|--|--|--|--|--
| 0  | $\frac{1}{216}$ | $0$ | $0$ | $0$
| 1  | $0$ | $0$ | $0$ | $0$
| 2  | $0$ | $0$ | $0$ | $0$
| 3  | $0$ | $0$ | $0$ | $0$
</div>

</div>



### Función de probabilidad conjunta. Ejemplo con `R`
<div class="example">
La función `fun.prod.con` nos da la **función de probabilidad conjunta** de la variable aleatoria $\mathbf{X}$ cuando lanzamos un dado tres veces:
```{r}

fun.prob.con=function(x1,x2,x3){
  n=6
  cuenta.1 =function(x){length(x[x==1])}
  cuenta.2 =function(x){length(x[x==2])}
  cuenta.3 =function(x){length(x[x==3])}
  Dxyz=data.frame(d1=rep(1:n,each=n),d2=rep(1:n,times=n),d3=rep(1:n,each=n*n))
  X1=apply(Dxyz,1,cuenta.1)
  X2=apply(Dxyz,1,cuenta.2)
  X3=apply(Dxyz,1,cuenta.3)
  frecuencia = table(X1==x1 & X2==x2 & X3==x3)
  res=ifelse(length(frecuencia)==2,frecuencia[2],0)
  return(res/6^3)
}
```



</div>

### Ejemplo con `R`
<div class="example">
Para construir la tabla de la **función de probabilidad conjunta** para la variable $\mathbf{X}=(X_1,X_2,X_3)$ con $X_3=0$ hacemos lo siguiente:
```{r,eval=FALSE}
valores.variables=0:3
tabla.0 = c()
for (i in 1:length(valores.variables)){for (j in 1:length(valores.variables)){
  tabla.0=c(tabla.0,fun.prob.con(valores.variables[i],valores.variables[j],0));
}}
tabla.0 = matrix(tabla.0,length(valores.variables),length(valores.variables))
rownames(tabla.0)=valores.variables
colnames(tabla.0)=valores.variables
knitr::kable(tabla.0)
```
Con los demás valores de $X_3$, lo haríamos de forma similar.

</div>


### Ejemplo con `R`
<div class="example">

Tabla con $X_3=0$:

```{r,echo=FALSE}
valores.variables=0:3
tabla.0 = c()
for (i in 1:length(valores.variables)){for (j in 1:length(valores.variables)){
  tabla.0=c(tabla.0,fun.prob.con(valores.variables[i],valores.variables[j],0));
}}
tabla.0 = matrix(tabla.0,length(valores.variables),length(valores.variables))
rownames(tabla.0)=valores.variables
colnames(tabla.0)=valores.variables
knitr::kable(tabla.0)
```

</div>

### Ejemplo con `R`
<div class="example">

Tabla con $X_3=1$:

```{r,echo=FALSE}
valores.variables=0:3
tabla.1 = c()
for (i in 1:length(valores.variables)){for (j in 1:length(valores.variables)){
  tabla.1=c(tabla.1,fun.prob.con(valores.variables[i],valores.variables[j],1));
}}
tabla.1 = matrix(tabla.1,length(valores.variables),length(valores.variables))
rownames(tabla.1)=valores.variables
colnames(tabla.1)=valores.variables
knitr::kable(tabla.1)
```

</div>

### Ejemplo con `R`
<div class="example">

Tabla con $X_3=2$:

```{r,echo=FALSE}
valores.variables=0:3
tabla.2 = c()
for (i in 1:length(valores.variables)){for (j in 1:length(valores.variables)){
  tabla.2=c(tabla.2,fun.prob.con(valores.variables[i],valores.variables[j],2));
}}
tabla.2 = matrix(tabla.2,length(valores.variables),length(valores.variables))
rownames(tabla.2)=valores.variables
colnames(tabla.2)=valores.variables
knitr::kable(tabla.2)
```

</div>

### Ejemplo con `R`
<div class="example">

Tabla con $X_3=3$:

```{r,echo=FALSE}
valores.variables=0:3
tabla.3 = c()
for (i in 1:length(valores.variables)){for (j in 1:length(valores.variables)){
  tabla.3=c(tabla.3,fun.prob.con(valores.variables[i],valores.variables[j],3));
}}
tabla.3 = matrix(tabla.3,length(valores.variables),length(valores.variables))
rownames(tabla.3)=valores.variables
colnames(tabla.3)=valores.variables
knitr::kable(tabla.3)
```

</div>



### Propiedades de la función de probabilidad conjunta

Sea $(X_1\ldots,X_n)$ una **variable aleatoria $n$-dimensional discreta** con conjunto de valores $(X_1\ldots,X_n)(\Omega)=\{(x_{i_1},\ldots,x_{i_n})\, i_1=1,\ldots,\ i_n=1,\ldots\}$. Entonces su **función de probabilidad conjunta** verifica las propiedades siguientes:

La suma de todos los valores de la **función de probabilidad conjunta** sobre el conjunto de valores siempre vale 1: $$\sum_{i_1}\cdots\sum_{i_n} P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n})=1.$$


### Propiedades de la función de probabilidad conjunta

Sea $B$ una región del espacio $\mathbb{R}^n$. El valor de la probabilidad $P((X_1\ldots,X_n)\in B)$ se puede calcular de la forma siguiente:
$$
P((X_1\ldots,X_n)\in B) =\sum_{(x_{i_1},\ldots,x_{i_n})\in B} P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n}).
$$
O sea, la probabilidad de que la variable $n$-dimensional coja valores en $B$ es igual a la suma de todos aquellos valores de la función de probabilidad conjunta que están en $B$.

### Propiedades de la función de probabilidad conjunta

En particular, tenemos la relación siguiente que relaciona la **función de distribución conjunta** con la **función de probabilidad conjunta**:
$$
F_{X_1\ldots X_n}(x_1,\ldots,x_n)=\sum_{x_{i_1}\leq x_1,\ldots, x_{i_n}\leq x_n} P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n}).
$$
Dicha expresión se deduce de la expresión anterior considerando $B=(-\infty,x_1]\times\cdots\times (-\infty,x_n]$.


### Ejemplo

<div class="example">
**Ejemplo anterior del lanzamiento de un dado tres veces**

<div class="exercise">
**Ejercicio**

Comprobad usando la tabla de la función de probabilidad conjunta que la suma de todos sus valores suma 1.
</div>

Apliquemos la fórmula que relaciona la función de distribución conjunta con la función de probabilidad conjunta para $(x_1,x_2,x_3)=(1,2,2)$.






</div>


### Ejemplo

<div class="example">
Observamos que los únicos valores $(x_{i_1},x_{i_2},x_{i_3})\in (X_1 X_2,X_3)(\Omega)$ que verifican $x_{i_1}\leq 1$, $x_{i_2}\leq 2$ y $x_{i_3}\leq 2$ son $(0,0,0)$, $(0,0,1)$, $(0,0,2)$, $(0,1,0)$, $(0,1,1)$, $(0,1,2)$, $(0,2,0)$, $(0,2,1)$, $(0,2,2)$, $(1,0,0)$, $(1,0,1)$, $(1,0,2)$, $(1,1,0)$, $(1,1,1)$, $(1,1,2)$, $(1,2,0)$, $(1,2,1)$ y $(1,2,2)$:
$$
\begin{array}{rl}
F_{X_1X_2X_3}(1,2,2) & =P_{X_1X_2X_3}(0,0,0)+P_{X_1X_2X_3}(0,0,1)+P_{X_1X_2X_3}(0,0,2)+P_{X_1X_2X_3}(0,1,0)\\ & +P_{X_1X_2X_3}(0,1,1)+P_{X_1X_2X_3}(0,1,2)+P_{X_1X_2X_3}(0,2,0)+P_{X_1X_2X_3}(0,2,1)\\ & +P_{X_1X_2X_3}(0,2,2) +
P_{X_1X_2X_3}(1,0,0)+P_{X_1X_2X_3}(1,0,1)+P_{X_1X_2X_3}(1,0,2)\\ & +P_{X_1X_2X_3}(1,1,0)+P_{X_1X_2X_3}(1,1,1)+
P_{X_1X_2X_3}(1,1,2)+P_{X_1X_2X_3}(1,2,0)\\ & + P_{X_1X_2X_3}(1,2,1)+P_{X_1X_2X_3}(1,2,2)\\ &=
\frac{1}{8}+\frac{1}{8}+\frac{1}{24}+\frac{1}{8}+\frac{1}{12}+\frac{1}{72}+\frac{1}{24}+\frac{1}{72}+0+\frac{1}{8}+\frac{1}{12}+\frac{1}{72}+\frac{1}{12}+\frac{1}{36}\\ & +0+\frac{1}{72}+0+0=\frac{11}{12}=`r round(11/12,4)`.
\end{array}
$$


</div>


### Ejemplo con `R`
<div class="example">

La función de distribución conjunta sería en `R`:
```{r}
fun.dis.con = function(x1,x2,x3){
  suma=0
  i1=0; i2=0; i3=0;
  while(i1 <=x1 & i1<=3){
    while(i2 <= x2 & i2<=3){
      while(i3<= x3 & i3 <=3){
        suma=suma+fun.prob.con(i1,i2,i3); i3=i3+1;
      }
      i3=0; i2=i2+1;
    }
    i2=0; i3=0; i1=i1+1;
  }
  return(suma)
}
```
</div>

### Ejemplo con `R`
<div class="example">

Comprobemos que la **función de distribución conjunta** en el valor $(1,2,2)$ nos da el mismo resultado que vimos anteriormente:

```{r}
fun.dis.con(1,2,2)
```

</div>

### Variables aleatorias marginales
Consideremos una variable aleatoria **$n$-dimensional discreta $(X_1\ldots,X_n)$** con **función de probabilidad conjunta** $P_{X_1\ldots,X_n}(x_{i_1},\ldots,x_{i_n})$, con $(x_{i_1},\ldots,x_{i_n})\in (X_1\ldots,X_n)(\Omega)$, $i_1=1,2,\ldots$, $i_n=1,2,\ldots$.

La tabla de la **función de probabilidad conjunta** contiene suficiente información para obtener las **funciones de probabilidad conjunta** de cualquier **variable aleatoria $k$-dimensional** $(X_{s_1},\ldots,X_{s_k})$ donde $\{s_1,\ldots,s_k\}$ es un subconjunto de las componentes $\{1,\ldots,n\}$ de la variable aleatoria $n$-dimensional.  . 


### Variables aleatorias marginales
<l class="prop">Proposición. Expresión de las funciones de probabilidad marginales. </l>
Sea $\mathbf{X}=(X_1\ldots,X_n)$ una variable aleatoria **$n$-dimensional discreta** con **función de probabilidad conjunta** $P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n})$, con $(x_{i_1},\ldots,x_{i_n})\in (X_1\ldots,X_n)(\Omega)$, $i_1=1,2,\ldots$, $i_n=1,2,\ldots$.

Sea $\{s_1,\ldots,s_k\}$ un subconjunto del conjunto de las componentes $\{1,\ldots,n\}$ donde suponemos que $s_1 < s_2<\cdots < s_k$. Entonces la **función de probabilidad conjunta** $P_{X_{s_1}\ldots X_{s_k}}$ de la variable aleatoria $k$-dimensional $(X_{s_1},\ldots, X_{s_k})$ se calcula usando la expresión siguiente:
$$
\begin{array}{rl}
P_{X_{s_1}\ldots X_{s_k}}(x_{s_1},\ldots,x_{s_k})  & = \sum_{x_t} P_{X_1\ldots X_n}(\mathbf{x}_s,\mathbf{x}_t),
\end{array}
$$

### Variables aleatorias marginales

donde $(\mathbf{x}_s,\mathbf{x}_t)$ es un valor de $\mathbf{X}(\Omega)$ tal que tiene como componente $s_i$ el valor $x_{s_i}$ para $i=1,\ldots, k$ y con $\mathbf{x}_t$ queremos decir todas las demás componentes que no son las $s_i$. La suma tiene todos los sumandos $\mathbf{x}_t$ para los que se cumpla que $(\mathbf{x}_s,\mathbf{x}_t)\in \mathbf{X}(\Omega)$.

En el caso particular de $n=3$, podemos calcular las **funciones de probabilidad conjunta** de las variables unidimensionales $X_1$, $X_2$ y $X_3$ y de las variables bidimensionales $(X_1,X_2)$, $(X_1,X_3)$ y $(X_2,X_3)$.


### Ejemplo

<div class="example">
**Ejemplo de la variable 3-dimensional que nos da el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces**

Hallemos, en primer lugar, la **función de probabilidad marginal** de las variable $X_1$, $X_2$ y $X_3$. Empecemos con $X_1$:
$$
\begin{array}{rl}
P_{X_1}(0) & = P_{X_1X_2X_3}(0,0,0)+P_{X_1X_2X_3}(0,0,1)+P_{X_1X_2X_3}(0,0,2)+P_{X_1X_2X_3}(0,0,3)+P_{X_1X_2X_3}(0,1,0) \\ & +P_{X_1X_2X_3}(0,1,1)+P_{X_1X_2X_3}(0,1,2)+P_{X_1X_2X_3}(0,1,3)+P_{X_1X_2X_3}(0,2,0)+P_{X_1X_2X_3}(0,2,1)\\ &
+P_{X_1X_2X_3}(0,2,2)+P_{X_1X_2X_3}(0,2,3)+P_{X_1X_2X_3}(0,3,0)+P_{X_1X_2X_3}(0,3,1)+P_{X_1X_2X_3}(0,3,2)\\ &
P_{X_1X_2X_3}(0,3,3)=`r round(sum(tabla.0),4)`,\\
P_{X_1}(1) & = P_{X_1X_2X_3}(1,0,0)+P_{X_1X_2X_3}(1,0,1)+P_{X_1X_2X_3}(1,0,2)+P_{X_1X_2X_3}(1,0,3)+P_{X_1X_2X_3}(1,1,0) \\ & +P_{X_1X_2X_3}(1,1,1)+P_{X_1X_2X_3}(1,1,2)+P_{X_1X_2X_3}(1,1,3)+P_{X_1X_2X_3}(1,2,0)+P_{X_1X_2X_3}(1,2,1)\\ &
+P_{X_1X_2X_3}(1,2,2)+P_{X_1X_2X_3}(1,2,3)+P_{X_1X_2X_3}(1,3,0)+P_{X_1X_2X_3}(1,3,1)+P_{X_1X_2X_3}(1,3,2)\\ &
P_{X_1X_2X_3}(1,3,3)=`r round(sum(tabla.1),4)`,\\
\end{array}
$$
</div>

### Ejemplo

<div class="example">
$$
\begin{array}{rl}
P_{X_1}(2) & = P_{X_1X_2X_3}(2,0,0)+P_{X_1X_2X_3}(2,0,1)+P_{X_1X_2X_3}(2,0,2)+P_{X_1X_2X_3}(2,0,3)+P_{X_1X_2X_3}(2,1,0) \\ & +P_{X_1X_2X_3}(2,1,1)+P_{X_1X_2X_3}(2,1,2)+P_{X_1X_2X_3}(2,1,3)+P_{X_1X_2X_3}(2,2,0)+P_{X_1X_2X_3}(2,2,1)\\ &
+P_{X_1X_2X_3}(2,2,2)+P_{X_1X_2X_3}(2,2,3)+P_{X_1X_2X_3}(2,3,0)+P_{X_1X_2X_3}(2,3,1)+P_{X_1X_2X_3}(2,3,2)\\ &
P_{X_1X_2X_3}(2,3,3)=`r round(sum(tabla.2),4)`,\\
P_{X_1}(3) & = P_{X_1X_2X_3}(3,0,0)+P_{X_1X_2X_3}(3,0,1)+P_{X_1X_2X_3}(3,0,2)+P_{X_1X_2X_3}(3,0,3)+P_{X_1X_2X_3}(3,1,0) \\ & +P_{X_1X_2X_3}(3,1,1)+P_{X_1X_2X_3}(3,1,2)+P_{X_1X_2X_3}(3,1,3)+P_{X_1X_2X_3}(3,2,0)+P_{X_1X_2X_3}(3,2,1)\\ &
+P_{X_1X_2X_3}(3,2,2)+P_{X_1X_2X_3}(3,2,3)+P_{X_1X_2X_3}(3,3,0)+P_{X_1X_2X_3}(3,3,1)+P_{X_1X_2X_3}(3,3,2)\\ &
P_{X_1X_2X_3}(3,3,3)=`r round(sum(tabla.3),4)`
\end{array}
$$
</div>

### Ejemplo

<div class="example">

La distribución marginal de la variable $X_1$ es la siguiente:

<div class="center">
| $X_1$ | 0 | 1| 2 |3 
|--|--|--|--|--
| $P_{X_1}$|$`r round(sum(tabla.0),4)`$|$`r round(sum(tabla.1),4)`$|$`r round(sum(tabla.2),4)`$|$`r round(sum(tabla.3),4)`$
</div>

Las distribuciones marginales de las variables $X_2$ y $X_3$ coinciden con la distribución marginal de la variable $X_1$. Lo dejamos como ejercicio.
</div>

### Ejemplo
<div class="example">
A continuación, calculemos la **función de probabilidad marginal conjunta** de la variable $(X_1,X_2)$:
$$
\begin{array}{rl}
P_{X_1X_2}(0,0) & = P_{X_1X_2X_3}(0,0,0)+P_{X_1X_2X_3}(0,0,1)+P_{X_1X_2X_3}(0,0,2)+P_{X_1X_2X_3}(0,0,3)=`r round(sum(fun.prob.con(0,0,0)+fun.prob.con(0,0,1)+fun.prob.con(0,0,2)+fun.prob.con(0,0,3)),4)`, \\
P_{X_1X_2}(0,1) & = P_{X_1X_2X_3}(0,1,0)+P_{X_1X_2X_3}(0,1,1)+P_{X_1X_2X_3}(0,1,2)+P_{X_1X_2X_3}(0,1,3)=`r round(sum(fun.prob.con(0,1,0)+fun.prob.con(0,1,1)+fun.prob.con(0,1,2)+fun.prob.con(0,1,3)),4)`, \\
P_{X_1X_2}(0,2) & = P_{X_1X_2X_3}(0,2,0)+P_{X_1X_2X_3}(0,2,1)+P_{X_1X_2X_3}(0,2,2)+P_{X_1X_2X_3}(0,2,3)=`r round(sum(fun.prob.con(0,2,0)+fun.prob.con(0,2,1)+fun.prob.con(0,2,2)+fun.prob.con(0,2,3)),4)`, \\
P_{X_1X_2}(0,3) & = P_{X_1X_2X_3}(0,3,0)+P_{X_1X_2X_3}(0,3,1)+P_{X_1X_2X_3}(0,3,2)+P_{X_1X_2X_3}(0,3,3)=`r round(sum(fun.prob.con(0,3,0)+fun.prob.con(0,3,1)+fun.prob.con(0,3,2)+fun.prob.con(0,3,3)),4)`, \\
P_{X_1X_2}(1,0) & = P_{X_1X_2X_3}(1,0,0)+P_{X_1X_2X_3}(1,0,1)+P_{X_1X_2X_3}(1,0,2)+P_{X_1X_2X_3}(1,0,3)=`r round(sum(fun.prob.con(1,0,0)+fun.prob.con(1,0,1)+fun.prob.con(1,0,2)+fun.prob.con(1,0,3)),4)`, \\
P_{X_1X_2}(1,1) & = P_{X_1X_2X_3}(1,1,0)+P_{X_1X_2X_3}(1,1,1)+P_{X_1X_2X_3}(1,1,2)+P_{X_1X_2X_3}(1,1,3)=`r round(sum(fun.prob.con(1,1,0)+fun.prob.con(1,1,1)+fun.prob.con(1,1,2)+fun.prob.con(1,1,3)),4)`, \\
P_{X_1X_2}(1,2) & = P_{X_1X_2X_3}(1,2,0)+P_{X_1X_2X_3}(1,2,1)+P_{X_1X_2X_3}(1,2,2)+P_{X_1X_2X_3}(1,2,3)=`r round(sum(fun.prob.con(1,2,0)+fun.prob.con(1,2,1)+fun.prob.con(1,2,2)+fun.prob.con(1,2,3)),4)`, \\
P_{X_1X_2}(1,3) & = P_{X_1X_2X_3}(1,3,0)+P_{X_1X_2X_3}(1,3,1)+P_{X_1X_2X_3}(1,3,2)+P_{X_1X_2X_3}(1,3,3)=`r round(sum(fun.prob.con(1,3,0)+fun.prob.con(1,3,1)+fun.prob.con(1,3,2)+fun.prob.con(1,3,3)),4)`, \\
P_{X_1X_2}(2,0) & = P_{X_1X_2X_3}(2,0,0)+P_{X_1X_2X_3}(2,0,1)+P_{X_1X_2X_3}(2,0,2)+P_{X_1X_2X_3}(2,0,3)=`r round(sum(fun.prob.con(2,0,0)+fun.prob.con(2,0,1)+fun.prob.con(2,0,2)+fun.prob.con(2,0,3)),4)`, \\
P_{X_1X_2}(2,1) & = P_{X_1X_2X_3}(2,1,0)+P_{X_1X_2X_3}(2,1,1)+P_{X_1X_2X_3}(2,1,2)+P_{X_1X_2X_3}(2,1,3)=`r round(sum(fun.prob.con(2,1,0)+fun.prob.con(2,1,1)+fun.prob.con(2,1,2)+fun.prob.con(2,1,3)),4)`, \\
P_{X_1X_2}(2,2) & = P_{X_1X_2X_3}(2,2,0)+P_{X_1X_2X_3}(2,2,1)+P_{X_1X_2X_3}(2,2,2)+P_{X_1X_2X_3}(2,2,3)=`r round(sum(fun.prob.con(2,2,0)+fun.prob.con(2,2,1)+fun.prob.con(2,2,2)+fun.prob.con(2,2,3)),4)`, \\
P_{X_1X_2}(2,3) & = P_{X_1X_2X_3}(2,3,0)+P_{X_1X_2X_3}(2,3,1)+P_{X_1X_2X_3}(2,3,2)+P_{X_1X_2X_3}(2,3,3)=`r round(sum(fun.prob.con(2,3,0)+fun.prob.con(2,3,1)+fun.prob.con(2,3,2)+fun.prob.con(2,3,3)),4)`, \\
\end{array}
$$

</div>

### Ejemplo
<div class="example">
$$
\begin{array}{rl}
P_{X_1X_2}(3,0) & = P_{X_1X_2X_3}(3,0,0)+P_{X_1X_2X_3}(3,0,1)+P_{X_1X_2X_3}(3,0,2)+P_{X_1X_2X_3}(3,0,3)=`r round(sum(fun.prob.con(3,0,0)+fun.prob.con(3,0,1)+fun.prob.con(3,0,2)+fun.prob.con(3,0,3)),4)`, \\
P_{X_1X_2}(3,1) & = P_{X_1X_2X_3}(3,1,0)+P_{X_1X_2X_3}(3,1,1)+P_{X_1X_2X_3}(3,1,2)+P_{X_1X_2X_3}(3,1,3)=`r round(sum(fun.prob.con(3,1,0)+fun.prob.con(3,1,1)+fun.prob.con(3,1,2)+fun.prob.con(3,1,3)),4)`, \\
P_{X_1X_2}(3,2) & = P_{X_1X_2X_3}(3,2,0)+P_{X_1X_2X_3}(3,2,1)+P_{X_1X_2X_3}(3,2,2)+P_{X_1X_2X_3}(3,2,3)=`r round(sum(fun.prob.con(3,2,0)+fun.prob.con(3,2,1)+fun.prob.con(3,2,2)+fun.prob.con(3,2,3)),4)`, \\
P_{X_1X_2}(3,3) & = P_{X_1X_2X_3}(3,3,0)+P_{X_1X_2X_3}(3,3,1)+P_{X_1X_2X_3}(3,3,2)+P_{X_1X_2X_3}(3,3,3)=`r round(sum(fun.prob.con(3,3,0)+fun.prob.con(3,3,1)+fun.prob.con(3,3,2)+fun.prob.con(3,3,3)),4)`, \\
\end{array}
$$

</div>

### Ejemplo
<div class="example">
La **función de probabilidad marginal conjunta** de la variable $(X_1,X_2)$ queda resumida en la tabla siguiente:

<div class="center">
| $X_1/X_2$ | 0 | 1| 2 |3 
|--|--|--|--|--
|$0$|$`r round(sum(fun.prob.con(0,0,0)+fun.prob.con(0,0,1)+fun.prob.con(0,0,2)+fun.prob.con(0,0,3)),4)`$|$`r round(sum(fun.prob.con(0,1,0)+fun.prob.con(0,1,1)+fun.prob.con(0,1,2)+fun.prob.con(0,1,3)),4)`$|$`r round(sum(fun.prob.con(0,2,0)+fun.prob.con(0,2,1)+fun.prob.con(0,2,2)+fun.prob.con(0,2,3)),4)`$|$`r round(sum(fun.prob.con(0,3,0)+fun.prob.con(0,3,1)+fun.prob.con(0,3,2)+fun.prob.con(0,3,3)),4)`$
|$1$|$`r round(sum(fun.prob.con(1,0,0)+fun.prob.con(1,0,1)+fun.prob.con(1,0,2)+fun.prob.con(1,0,3)),4)`$|$`r round(sum(fun.prob.con(1,1,0)+fun.prob.con(1,1,1)+fun.prob.con(1,1,2)+fun.prob.con(1,1,3)),4)`$|$`r round(sum(fun.prob.con(1,2,0)+fun.prob.con(1,2,1)+fun.prob.con(1,2,2)+fun.prob.con(1,2,3)),4)`$|$`r round(sum(fun.prob.con(1,3,0)+fun.prob.con(1,3,1)+fun.prob.con(1,3,2)+fun.prob.con(1,3,3)),4)`$
|$2$|$`r round(sum(fun.prob.con(2,0,0)+fun.prob.con(2,0,1)+fun.prob.con(2,0,2)+fun.prob.con(2,0,3)),4)`$|$`r round(sum(fun.prob.con(2,1,0)+fun.prob.con(2,1,1)+fun.prob.con(2,1,2)+fun.prob.con(2,1,3)),4)`$|$`r round(sum(fun.prob.con(2,2,0)+fun.prob.con(2,2,1)+fun.prob.con(2,2,2)+fun.prob.con(2,2,3)),4)`$|$`r round(sum(fun.prob.con(2,3,0)+fun.prob.con(2,3,1)+fun.prob.con(2,3,2)+fun.prob.con(2,3,3)),4)`$
|$3$|$`r round(sum(fun.prob.con(3,0,0)+fun.prob.con(3,0,1)+fun.prob.con(3,0,2)+fun.prob.con(3,0,3)),4)`$|$`r round(sum(fun.prob.con(3,1,0)+fun.prob.con(3,1,1)+fun.prob.con(3,1,2)+fun.prob.con(3,1,3)),4)`$|$`r round(sum(fun.prob.con(3,2,0)+fun.prob.con(3,2,1)+fun.prob.con(3,2,2)+fun.prob.con(3,2,3)),4)`$|$`r round(sum(fun.prob.con(3,3,0)+fun.prob.con(3,3,1)+fun.prob.con(3,3,2)+fun.prob.con(3,3,3)),4)`$
</div>

Las **funciones de probabilidad marginales** de las variables $(X_1,X_3)$ y $(X_2,X_3)$ dan el mismo resultado que la tabla anterior.
</div>



### Ejemplo con `R`
<div class="example">
La **función de probabilidad marginal** de la variable $X_1$ en `R` se halla de la forma siguiente:

```{r}
fun.marginal.X1 = function(x){
  suma=0;
  for (i in 0:3){for (j in 0:3){suma=suma+fun.prob.con(x,i,j)}}
  return(suma)
}
tabla.fun.marginal.X1=data.frame(fun.marginal.X1(0),fun.marginal.X1(1),
                            fun.marginal.X1(2),fun.marginal.X1(3));
colnames(tabla.fun.marginal.X1)=0:3
knitr::kable(tabla.fun.marginal.X1)
```


</div>


### Ejemplo con `R`
<div class="example">
La **función de probabilidad marginal** de la variable $(X_1,X_2)$ en `R` se halla de la forma siguiente:

```{r,eval=FALSE}
fun.marginal.X1.X2 = function(x,y){
  suma=0;
  for (i in 0:3){suma=suma+fun.prob.con(x,y,i)}
  return(suma)
}
tabla.fun.marginal.X1.X2=c()
for (i in 0:3){
  tabla.fun.marginal.X1.X2=cbind(tabla.fun.marginal.X1.X2,c(fun.marginal.X1.X2(i,0),
                                                            fun.marginal.X1.X2(i,1),
                                                            fun.marginal.X1.X2(i,2),
                                                            fun.marginal.X1.X2(i,3)))}
tabla.fun.marginal.X1.X2=as.data.frame(tabla.fun.marginal.X1.X2)
rownames(tabla.fun.marginal.X1.X2)=0:3
colnames(tabla.fun.marginal.X1.X2)=0:3
knitr::kable(tabla.fun.marginal.X1.X2)
```


</div>


### Ejemplo con `R`
<div class="example">

```{r,echo=FALSE}
fun.marginal.X1.X2 = function(x,y){
  suma=0;
  for (i in 0:3){suma=suma+fun.prob.con(x,y,i)}
  return(suma)
}
tabla.fun.marginal.X1.X2=c()
for (i in 0:3){
  tabla.fun.marginal.X1.X2=cbind(tabla.fun.marginal.X1.X2,c(fun.marginal.X1.X2(i,0),
                                                            fun.marginal.X1.X2(i,1),
                                                            fun.marginal.X1.X2(i,2),
                                                            fun.marginal.X1.X2(i,3)))}
tabla.fun.marginal.X1.X2=as.data.frame(tabla.fun.marginal.X1.X2)
rownames(tabla.fun.marginal.X1.X2)=0:3
colnames(tabla.fun.marginal.X1.X2)=0:3
knitr::kable(tabla.fun.marginal.X1.X2)
```

</div>



## Variables aleatorias $n$-dimensionales continuas

### Introducción
Recordemos la definición de **variable continua bidimensional**: $(X,Y)$ es continua si existe una función $f_{XY}:\mathbb{R}^2\longrightarrow \mathbb{R}$, llamada **función de densidad conjunta** no negativa $f_{XY}(x,y)\geq 0$, para todo $(x,y)\in\mathbb{R}^2$ tal que para cualquier región $B$ del plano, la probabilidad de que $(X,Y)$ esté en $B$ se calcula de la forma siguiente:
$$
P((X,Y)\in B)=\int\int_B f_{XY}(x,y)\,dx\, dy.
$$

### Introducción
La generalización natural será, entonces:

<l class="definition">Definición de variable aleatoria $n$-dimensional continua. </l>
Sea $(X_1\ldots,X_n)$ una variable aleatoria $n$-dimensional. Diremos que $(X_1\ldots,X_n)$ es continua si existe una función 
$f_{X_1\ldots X_n}:\mathbb{R}^n\longrightarrow \mathbb{R}$ llamada **función de densidad conjunta** no negativa $f_{X_1\ldots X_n}(x_1,\ldots,x_n)\geq 0$ para todo $(x_1,\ldots,x_n)\in\mathbb{R}^n$ tal que dado cualquier región $B$ del espacio $n$-dimensional, la probabilidad de que $(X_1\ldots,X_n)$ esté en $B$ se calcula de la forma siguiente:
$$
P((X_1\ldots,X_n)\in B)=\int\cdots\int_B f_{X_1\ldots X_n}(x_1,\ldots,x_n)\,dx_1\cdots\,dx_n.
$$

### Ejemplo
<div class="example">
**Ejemplo**

Consideremos una variable aleatoria $3$-dimensional $(X_1,X_2,X_3)$ con **función de densidad conjunta**:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
0, & \mbox{en caso contrario.}\\
\end{cases}
$$

En la figura siguiente hemos dibujado en rosa la región donde $f_{X_1X_2X_3}$ no es cero, o sea $[0,1]\times [0,1]\times [0,1]$.
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid8_0,fig.cap="",out.width = "900px"}
knitr::include_graphics("Images/Cubo3D2.png",dpi=1200)
```
</div>

### Propiedades de la función de densidad
Sea $(X_1\ldots,X_n)$ una **variable aleatoria $n$-dimensional continua** con **función de densidad conjunta** $f_{X_1\ldots X_n}$. Entonces dicha función verifica las propiedades siguientes:

* La integral de dicha función sobre todo el espacio $n$-dimensional vale 1: 
$$
\int\int_{\mathbb{R}^n} f_{X_1\ldots X_n}(x_1,\ldots,x_n)\,dx_1\cdots dx_n =1.
$$
Para ver dicha propiedad, basta considerar $B=\mathbb{R}^n$, tener en cuenta que el suceso $(X_1\ldots,X_n)\in \mathbb{R}^n$ es el total $\Omega$ y aplicar la definición de $f_{X_1\ldots X_n}$:
$$
P((X_1\ldots,X_n)\in \mathbb{R}^n)=1= \int\cdots\int_{\mathbb{R}^n} f_{X_1\ldots X_n}(x_1,\ldots,x_n)\,dx_1\cdots dx_n.
$$

### Propiedades de la función de densidad
* La relación que hay entre la **función de distribución conjunta** $F_{X_1\ldots X_n}$ y la **función de densidad conjunta** $f_{X_1\ldots X_n}$ es la siguiente:
$$
F_{X_1\ldots X_n}(x_1,\ldots,x_n)=\int_{-\infty}^{x_1}\cdots\int_{-\infty}^{x_n} f_{X_1\ldots X_n}(u_1,\ldots,u_n)\,du_1\cdots du_n.
$$
Para ver dicha propiedad, basta considerar $B=(-\infty,x_1]\times\cdots\times (-\infty,x_n]$ y aplicar la definición de **función de distribución conjunta**:
$$
\begin{array}{rl}
& F_{X_1\ldots X_n}(x_1,\ldots,x_n)=P((X_1\ldots,X_n)\in (-\infty,x_1]\times\cdots (-\infty,x_n])\\ &\qquad =\int_{-\infty}^{x_1}\cdots\int_{-\infty}^{x_n} f_{X_1\ldots X_n}(u_1,\ldots,u_n)\,du_1\cdots du_n.
\end{array}
$$

### Propiedades de la función de densidad
* La relación que hay entre la **función de densidad** $F_{X_1\ldots X_n}$ y la **función de distribución** $f_{X_1\ldots X_n}$ es la siguiente:
$$
f_{X_1\ldots X_n}(x_1,\ldots,x_n)=\frac{\partial^n F_{X_1\ldots X_n}(x_1,\ldots,x_n)}{\partial x_1\cdots\partial x_n}.
$$
Dicha propiedad se deduce de la anterior, derivando primero respecto a $x_1$, después respecto a $x_2$ y sucesivamente hasta llegar a $x_n$ para eliminar las $n$ integrales.


### Propiedades de la función de densidad

* La **función de densidad marginal** de la variable $k$ dimensional $(X_{s_1},\ldots,X_{s_k})$ con $\{s_1,\ldots, s_k\}$ un subconjunto de $\{1,\ldots,n\}$, $f_{X_{s_1}\ldots,X_{s_k}}$ se calculan de la forma siguiente:
$$
f_{X_{s_1}\ldots,X_{s_k}}(x_{s_1},\ldots,x_{s_k})=\int_{x_{t_1}=-\infty}^{x_{t_1}=\infty}\cdots \int_{x_{t_{n-k}}=-\infty}^{x_{t_{n-k}}=\infty} f_{X_1\ldots X_n}(x_1,\ldots,x_n)\, dx_{t_1}\cdots dx_{t_{n-k}},
$$
con $\{t_1,\ldots,t_{n-k}\}=\{1,\ldots,n\}\setminus \{s_1,\ldots,s_k\}.$ O sea, las variables $t$'s son las que no aparecen en la definición de la variable aleatoria $k$ dimensional $(X_{s_1},\ldots,X_{s_k})$.



### Ejemplo
<div class="example">
**Ejemplo anterior**

Comprobemos las propiedades usando la **función de densidad** del ejemplo anterior: 
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
0, & \mbox{en caso contrario.}\\
\end{cases}
$$

La integral de $f_{X_1X_2X_3}$ sobre todo el espacio 3D vale 1:
$$
\begin{array}{rl}
& \int\int\int_{\mathbb{R}^3} f_{X_1X_2X_3}(x_1,x_2,x_3)\,dx\, dy=\int_0^1\int_0^1\int_0^1 8 x_1\cdot x_2\cdot x_3\, dx_1\,dx_2\,dx_3\\ & \qquad=8\int_0^1 x_1\, dx_1\int_0^1 x_2\, dx_2\int_0^1 x_3\,dx_3=8\left[\frac{x_1^2}{2}\right]_0^1\cdot\left[\frac{x_2^2}{2}\right]_0^1\cdot \left[\frac{x_3^2}{2}\right]_0^1=8\cdot\left(\frac{1}{2}\right)^3 =1.
\end{array}
$$

</div>

### Ejemplo
<div class="example">
Vamos a calcular la función de distribución $F_{X_1X_2X_3}$. 

Recordemos que la expresión de la función de distribución en función de la función de densidad era:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{-\infty}^{x_1}\int_{-\infty}^{x_2}\int_{-\infty}^{x_3}f_{X_1X_2X_3}(u_1,u_2,u_3)\,du_1\, du_2\, du_3.
$$
Como la región del espacio 3D donde $f_{X_1X_2X_3}(x_1,x_2,x_3)$ es no nula es el cubo unidad $[0,1]\times [0,1]\times [0,1]$, fijado un punto del espacio $(x_1,x_2,x_3)$ será fundamental calcular la intersección de dicho cubo unidad con la región $(-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3]$. 

Dicha intersección $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])$ será la región donde tendremos que integrar la función de densidad para hallar la función de distribución en el punto $(x_1,x_2,x_3)$.

Para hallar la región anterior, vamos a dividir el espacio 3D en tres "pisos": 

* "Sótano " o zona donde $x_3<0$.
* "Planta baja" o zona donde $0\leq x_3\leq 1$.
* "Primer piso" o zona donde $x_3>1$.
</div>

### Ejemplo
<div class="example">
* Si $(x_1,x_2,x_3)$ está en el "sótano" o $x_3<0$, claramente, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=\emptyset$. Por tanto, $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$.

* Si $(x_1,x_2,x_3)$ está en la planta baja o $0\leq x_3\leq 1$, vamos a distinguir cuatro casos dependiendo de los valores de $x_1$ y $x_2$:

  * $x_1 <0$ o $x_2 <0$. En este caso, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=\emptyset$. Por tanto, $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$.
  * $0\leq x_1\leq 1$ y $0\leq x_2\leq 1$. En este caso: $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=[0,x_1]\times [0,x_2]\times [0,x_3]$, ver figura adjunta.

Por tanto,
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{0}^{x_1}\int_{0}^{x_2}\int_{0}^{x_3} 8 x_1 x_2 x_3 dx_1\, dx_2\ dx_3 = 
8\left[\frac{x_1^2}{2}\right]_0^{x_1}\left[\frac{x_2^2}{2}\right]_0^{x_2}\left[\frac{x_3^2}{2}\right]_0^{x_3} = x_1^2 x_2^2 x_3^2.
$$


</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid_09,fig.cap="",out.width = "800px"}
knitr::include_graphics("Images/Fx1x2x3bajos.png",dpi=1200)
```
</div>

### Ejemplo
<div class="example">

Seguimos en la planta "baja",

* Si $x_1 >1$ y $0\leq x_2\leq 1$, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=[0,1]\times [0,x_2]\times [0,x_3]$, ver figura adjunta. Hemos dibujado sólo la parte "positiva" de la región $(-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3]$ ya que la parte "negativa" claramente no interseca con $[0,1]\times [0,1]\times [0,1]$ para no complicar demasiado la figura.

En este caso,
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{0}^{1}\int_{0}^{x_2}\int_{0}^{x_3} 8 x_1 x_2 x_3 dx_1\, dx_2\ dx_3 = 
8\left[\frac{x_1^2}{2}\right]_0^{1}\left[\frac{x_2^2}{2}\right]_0^{x_2}\left[\frac{x_3^2}{2}\right]_0^{x_3} = x_2^2 x_3^2.
$$

* Si $0\leq x_1$ y $x_2>1$, sería un caso parecido al caso anterior pero "cambiando los papeles" de $x_1$ y $x_2$. 
Por tanto, 
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2 x_3^2.
$$
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid99,fig.cap="",out.width = "800px"}
knitr::include_graphics("Images/Fx1x2x3bajosx1.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">

Seguimos en la planta "baja",

* Si $x_1>1$ y $x_2>1$, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=[0,1]\times [0,1]\times [0,x_3]$, ver figura adjunta. También hemos dibujado sólo la parte "positiva" de la región $(-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3]$ ya que la parte "negativa" claramente no interseca con $[0,1]\times [0,1]\times [0,1]$ para no complicar demasiado la figura.

En este caso,
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{0}^{1}\int_{0}^{1}\int_{0}^{x_3} 8 x_1 x_2 x_3 dx_1\, dx_2\ dx_3 = 
8\left[\frac{x_1^2}{2}\right]_0^{1}\left[\frac{x_2^2}{2}\right]_0^{1}\left[\frac{x_3^2}{2}\right]_0^{x_3} = x_3^2.
$$
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid991,fig.cap="",out.width = "800px"}
knitr::include_graphics("Images/Fx1x2x3bajosx1x2.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">

Supongamos ahora que $(x_1,x_2,x_3)$ está en el "primer piso" o $x_3>1$. Aquí también vamos a distinguir 4 casos:


*   $x_1 <0$ o $x_2 <0$. En este caso, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=\emptyset$. Por tanto, $F_{X_1X_2X_3}(x_1,x_2,x_3)=0$.

* $0\leq x_1\leq 1$ y $0\leq x_2\leq 1$. En este caso: $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=[0,x_1]\times [0,x_2]\times [0,1]$, ver figura adjunta.

En este caso,
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{0}^{x_1}\int_{0}^{x_2}\int_{0}^{1} 8 x_1 x_2 x_3 dx_1\, dx_2\ dx_3 = 
8\left[\frac{x_1^2}{2}\right]_0^{x_1}\left[\frac{x_2^2}{2}\right]_0^{x_2}\left[\frac{x_3^2}{2}\right]_0^{1} = x_1^2 x_2^2.
$$
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid992,fig.cap="",out.width = "800px"}
knitr::include_graphics("Images/Fx1x2x3piso.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">

Seguimos en el "primer piso",

* Si $x_1 >1$ y $0\leq x_2\leq 1$, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=[0,1]\times [0,x_2]\times [0,1]$, ver figura adjunta. 

En este caso,

$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{0}^{1}\int_{0}^{x_2}\int_{0}^{1} 8 x_1 x_2 x_3 dx_1\, dx_2\ dx_3 = 
8\left[\frac{x_1^2}{2}\right]_0^{1}\left[\frac{x_2^2}{2}\right]_0^{x_2}\left[\frac{x_3^2}{2}\right]_0^{1} = x_2^2.
$$

* Si $0\leq x_1 \leq 1$ y $ x_2> 1$. Este caso sería parecido al caso anterior pero "cambiando los papeles" de $x_1$ y $x_2$. 
Por tanto, 
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2.
$$

</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid993,fig.cap="",out.width = "800px"}
knitr::include_graphics("Images/Fx1x2x3pisox1.png",dpi=1200)
```
</div>


### Ejemplo
<div class="example">

Seguimos en el "primer piso",

* Si $x_1>1$ y $x_2>1$, $([0,1]\times [0,1]\times [0,1])\cap ((-\infty,x_1]\times (-\infty,x_2]\times (-\infty,x_3])=[0,1]\times [0,1]\times [0,1]$, ver figura adjunta. 

En este caso,
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\int_{0}^{1}\int_{0}^{1}\int_{0}^{1} 8 x_1 x_2 x_3 dx_1\, dx_2\ dx_3 = 
8\left[\frac{x_1^2}{2}\right]_0^{1}\left[\frac{x_2^2}{2}\right]_0^{1}\left[\frac{x_3^2}{2}\right]_0^{1} = 1.
$$
</div>

### Ejemplo
<div class="center">

```{r, echo=FALSE, label=bid994,fig.cap="",out.width = "800px"}
knitr::include_graphics("Images/Fx1x2x3pisox1x2.png",dpi=1200)
```
</div>

### Ejemplo
<div class="example">
En resumen:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
0, & \mbox{si }x_1<0,\mbox{ o }x_2<0,\mbox{ o }x_3 <0\\
x_1^2\cdot x_2^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
 x_2^2\cdot x_3^2, & \mbox{si }x_1> 1,\ 0\leq x_2\leq  1,\ 0\leq x_3\leq  1, \\
 x_1^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq  1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 x_3^2, & \mbox{si }x_1> 1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 x_1^2\cdot x_2^2, & \mbox{si }0\leq x_1\leq  1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
 x_1^2, & \mbox{si }0\leq x_1\leq  1,\ x_2 >  1,\ x_3> 1,\\
 x_2^2, & \mbox{si }x_1>1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
1, & \mbox{si }x_1\geq 1,\ x_2\geq 1,\ x_3\geq 1.
\end{cases}
$$

Dicha función era la función que nos sirvió como ejemplo a la hora de introducir la variables aleatorias $n$-dimensionales. Ahora sabemos que es continua y conocemos su función de densidad.
</div>


</div>

### Ejemplo
<div class="example">
Comprobemos seguidamente que si derivamos tres veces la expresión de $F_{X_1X_2X_3}$, primero respecto $x_1$, luego respecto $x_2$ y finalmente respecto $x_3$, obtendremos la **función de densidad** $f_{X_1X_2X_3}$.

Si derivamos respecto $x_1$ obtenemos:
$$
\frac{\partial F_{X_1X_2X_3}(x_1,x_2,x_3)}{\partial x_1}=\begin{cases}
0, & \mbox{si }x_1<0,\mbox{ o }x_2<0,\mbox{ o }x_3 <0\\
2 x_1\cdot x_2^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
 0, & \mbox{si }x_1> 1,\ 0\leq x_2\leq  1,\ 0\leq x_3\leq  1, \\
 2 x_1 \cdot x_3^2, & \mbox{si }0\leq x_1\leq  1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 0, & \mbox{si }x_1> 1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 2 x_1\cdot x_2^2, & \mbox{si }0\leq x_1\leq  1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
 2 x_1, & \mbox{si }0\leq x_1\leq  1,\ x_2 >  1,\ x_3> 1,\\
 0, & \mbox{si }x_1>1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
0, & \mbox{si }x_1\geq 1,\ x_2\geq 1,\ x_3\geq 1.
\end{cases}
$$
</div>

### Ejemplo
<div class="example">
Si ahora derivamos respecto $x_2$ obtenemos:
$$
\frac{\partial^2 F_{X_1X_2X_3}(x_1,x_2,x_3)}{\partial x_2\partial x_1}=\begin{cases}
0, & \mbox{si }x_1<0,\mbox{ o }x_2<0,\mbox{ o }x_3 <0\\
4 x_1\cdot x_2\cdot x_3^2, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
 0, & \mbox{si }x_1> 1,\ 0\leq x_2\leq  1,\ 0\leq x_3\leq  1, \\
 0, & \mbox{si }0\leq x_1\leq  1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 0, & \mbox{si }x_1> 1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 4 x_1\cdot x_2, & \mbox{si }0\leq x_1\leq  1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
 0, & \mbox{si }0\leq x_1\leq  1,\ x_2 >  1,\ x_3> 1,\\
 0, & \mbox{si }x_1>1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
0, & \mbox{si }x_1\geq 1,\ x_2\geq 1,\ x_3\geq 1.
\end{cases}
$$

</div>

### Ejemplo
<div class="example">
Por último, si derivamos respecto $x_3$, obtenemos:
$$
\frac{\partial^3 F_{X_1X_2X_3}(x_1,x_2,x_3)}{\partial x_3\partial x_2\partial x_1}=\begin{cases}
0, & \mbox{si }x_1<0,\mbox{ o }x_2<0,\mbox{ o }x_3 <0\\
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
 0, & \mbox{si }x_1> 1,\ 0\leq x_2\leq  1,\ 0\leq x_3\leq  1, \\
 0, & \mbox{si }0\leq x_1\leq  1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 0, & \mbox{si }x_1> 1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 0, & \mbox{si }0\leq x_1\leq  1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
 0, & \mbox{si }0\leq x_1\leq  1,\ x_2 >  1,\ x_3> 1,\\
 0, & \mbox{si }x_1>1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
0, & \mbox{si }x_1\geq 1,\ x_2\geq 1,\ x_3\geq 1,
\end{cases}
$$
expresión que coincide con la función de densidad $f_{X_1X_2X_3}(x_1,x_2,x_3)$.
</div>

### Ejemplo
<div class="example">
Acabemos el ejemplo calculando las **funciones de densidad marginales** de las variables $X_1$, $X_2$, $X_3$, $(X_1,X_2)$, $(X_1,X_3)$, $(X_2,X_3)$.

Debido a la simetría de la región donde $f_{X_1X_2X_3}(x_1,x_2,x_3)$ no se anula, es suficiente calcular la función de densidad marginal para las variables $X_1$ y $(X_1,X_2)$. Para ver las demás, basta cambiar los "papeles" de las variables correspondientes. Por ejemplo, la función de densidad de la variable $X_2$ será la misma que la de la variable $X_1$ cambiando $x_1$ por $x_2$.
</div>

### Ejemplo
<div class="example">
Para hallar la función de densidad de la variable $X_1$, aplicamos la fórmula vista anteriormente:
$$
f_{X_1}(x_1)=\int_{-\infty}^\infty\int_{-\infty}^\infty  f_{X_1X_2X_3}(x_1,x_2,x_3)\, dx_2\, dx_3.
$$
Recordemos que la región donde no se anulaba la **función de densidad conjunta** $f_{X_1X_2X_3}$ era el cubo $[0,1]\times [0,1]\times [0,1]$. Por tanto, fijado $x_1$, el valor de $f_{X_1}(x_1)$ será no nulo si el plano "vertical" $X_1=x_1$ interseca dicho cubo. Y esto ocurre siempre que $x_1\in (0,1)$. Por tanto,
$$
f_{X_1}(x_1)=\begin{cases}
\int_{0}^1\int_0^1 8 x_1x_2 x_3  \, dx_2\, dx_3=8x_1\left[\frac{x_2^2}{2}\right]_0^1 \left[\frac{x_3^2}{2}\right]_0^1 =2 x_1, & \mbox{ si }x_1\in (0,1),\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
</div>

### Ejemplo
<div class="example">
Para hallar la función de densidad conjunta de la variable $(X_1,X_2)$, aplicamos la expresión siguiente:
$$
f_{X_1X_2}(x_1,x_2)=\int_{-\infty}^\infty  f_{X_1X_2X_3}(x_1,x_2,x_3)\, dx_3.
$$
En este caso, fijado $x_1$ y $x_2$, tenemos que ver cuando la recta "vertical" $X_1=x_1$, $X_2=x_2$ intersecta el cubo $[0,1]\times [0,1]\times [0,1]$ y esto ocurre siempre que $(x_1,x_2)\in [0,1]\times [0,1]$.
Por tanto,

$$
f_{X_1X_2}(x_1,x_2)=\begin{cases}
\int_{0}^1 8 x_1x_2 x_3  \, dx_3=8x_1x_2 \left[\frac{x_3^2}{2}\right]_0^1 =4 x_1 x_2, & \mbox{ si }(x_1,x_2)\in [0,1]\times [0,1],\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
</div>

### La distribución gaussiana $n$-dimensional
Vamos a generalizar la distribución normal a $n$ dimensiones.

<l class="definition">Definición de distribución gaussiana $n$-dimensional. </l>
Diremos que la distribución de la variable aleatoria $n$-dimensional $(X_1\ldots,X_n)$ es **gaussiana $n$-dimensional** dependiendo del **vector de medias** $\mathbf{\mu}$ y de la **matriz de covarianzas** $\Sigma$ si su **función de densidad conjunta** es:
$$
\begin{array}{rl}
& f_{X_1\ldots X_n}(x_1,\ldots,x_n)=\frac{1}{(2\pi)^{\frac{n}{2}}\sqrt{\mathbf{|\Sigma|}}}\mathrm{e}^{-\frac{1}{2}(\mathbf{x-\mu})^\top\mathbf{\Sigma}^{-1}(\mathbf{x-\mu})},\\ & \qquad  -\infty <x_1,\ldots,x_n<\infty,
\end{array}
$$
Se denota $\mathbf{X}=(X_1,\ldots,X_n)$ con $\mathbf{X}={\cal N}(\mathbf{\mu},\mathbf{\Sigma})$.



### La distribución gaussiana $n$-dimensional
donde $\mathbf{x}=\begin{pmatrix}x_1\\\vdots\\ x_n\end{pmatrix}$, $\mathbf{\mu}=\begin{pmatrix}\mu_1\\\vdots\\ \mu_n\end{pmatrix}$ es el **vector de medias** de cada variable aleatoria $X_1,\ldots, X_n$ y $\mathbf{\Sigma}$ es la denominada **matriz de covarianzas** que nos sirve para estudiar la relación lineal entre las variables $X_i$, $i=1,\ldots, n$.

De hecho la componente $(i,j)$ de la **matriz de covarianzas** $\mathbf{\Sigma}$, $\sigma_{ij}$ es la **covarianza** entre las variables $X_i$ y $X_j$. 

Por tanto, los elementos de la diagonal de la **matriz de covarianzas** $\mathbf{\Sigma}$, $\sigma_{ii}$, serán las varianzas de las variables $X_i$, $i=1,\ldots,n$.


### La distribución gaussiana $n$-dimensional
Propiedades de la **función de densidad de la variable gaussiana $n$-dimensional**:

* Para cualquier punto $(x_1,\ldots,x_n)\in\mathbb{R}^n$, la **función de densidad** es no nula: $f_{X_1\ldots X_n}(x_1,\ldots,x_n)>0$.

* La **función de densidad** tiene un único máximo absoluto en el punto $\mathbf{\mu}$ que vale $f_{X_1\ldots X_n}(\mathbf{\mu})=\frac{1}{(2\pi)^{\frac{n}{2}}\sqrt{\mathbf{|\Sigma|}}}$. 


### La distribución gaussiana $n$-dimensional
Antes de estudiar cómo son las distribuciones de las **marginales** de una distribución **normal $n$-dimensional**, enunciemos el resultado siguiente:

<l class="prop">Proposición (transformación afín de una **normal $n$-dimensional**)</l>
Sea $\mathbf{X}={\cal N}(\mathbf{\mu},\mathbf{\Sigma})$ una distribución **normal $n$-dimensional**. Sea la variable $k$-dimensional $\mathbf{Y}$ construida como $\mathbf{Y}=\mathbf{c}+\mathbf{C}\mathbf{X}$, con $\mathbf{C}$ una matriz $k\times n$ y $\mathbf{c}$ un vector $k$-dimensional. Entonces la variable $Y$ se distribuye como una variable **normal $k$-dimensional** de media $\mathbf{\mu}_{\mathbf{Y}}=\mathbf{c}+\mathbf{C}\mathbf{\mu}$ y matriz de covarianzas $\mathbf{\Sigma}_{\mathbf{Y}}=\mathbf{C}\mathbf{\Sigma}\mathbf{C}^\top$: $\mathbf{Y}={\cal N}(\mathbf{c}+\mathbf{C}\mathbf{\mu},\mathbf{C}\mathbf{\Sigma}\mathbf{C}^\top)$.

### La distribución gaussiana $n$-dimensional
Usando la proposición anterior, podemos afirmar:

<l class="prop">Proposición (distribución marginal de una **variable normal $n$-dimensional**)</l>
Sea $\mathbf{X}={\cal N}(\mathbf{\mu},\mathbf{\Sigma})$ una distribución **normal $n$-dimensional**. Sea $(X_{s_1},\ldots,X_{s_k})$ la variable $k$ dimensional con las componentes $s_1,\ldots,s_k$, con $s_i\in\{1,\ldots,n\}$, entonces la variable $(X_{s_1},\ldots,X_{s_k})$ se distribuye según una **normal $k$-dimensional** de media $(\mu_{s_1},\ldots,\mu_{s_k})$ y matriz de covarianzas $\mathbf{\Sigma'}$ formada por las $s_1,\ldots,s_k$ filas y columnas de la matriz de covarianzas de la variable $\mathbf{X}$, $\mathbf{\Sigma}$.

### La distribución gaussiana $n$-dimensional
Para ver la proposición anterior a partir de la proposición de la transformación afín, hagamos un ejemplo concreto:

<div class="example">
Consideremos una variable normal $5$-dimensional de **vector de medias** general $\mathbf{\mu}=(\mu_1,\mu_2,\mu_3,\mu_4,\mu_5)$ y **matriz de covarianzas**
$$
\mathbf{\Sigma}=\begin{pmatrix}
\sigma_{11} & \sigma_{12} & \sigma_{13} & \sigma_{14} & \sigma_{15} \\
\sigma_{21} & \sigma_{22} & \sigma_{23} & \sigma_{24} & \sigma_{25} \\
\sigma_{31} & \sigma_{32} & \sigma_{33} & \sigma_{34} & \sigma_{35} \\
\sigma_{41} & \sigma_{42} & \sigma_{43} & \sigma_{44} & \sigma_{45} \\
\sigma_{51} & \sigma_{52} & \sigma_{53} & \sigma_{54} & \sigma_{55} 
\end{pmatrix}
$$

</div>

### La distribución gaussiana $n$-dimensional
<div class="example">
Queremos estudiar cuál es la distribución de la variable $3$-dimensional $(X_2,X_4,X_5)$. Para ello consideramos el vector $\mathbf{c}=0$ y la matriz $\mathbf{C}$ siguiente:
$$
\mathbf{C}=\begin{pmatrix}
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1 \\
\end{pmatrix}
$$
O sea, $\mathbf{C}$ es una matriz $3\times 5$ que vale 1 en los lugares $(1,2)$, $(2,4)$ y $(3,5)$. Fijémonos que las segundas componentes de los lugares anteriores son precisamente las componentes elegidas de la variable $\mathbf{X}$.

La matriz $\mathbf{Y}=\mathbf{C}\mathbf{X}=\begin{pmatrix}X_2\\X_4\\X_5\end{pmatrix}$ vale precisamente la variable marginal que queremos estudiar.
</div>


### La distribución gaussiana $n$-dimensional
<div class="example">
Aplicando la proposición de la transformación afín, podemos afirmar que la distribución de la variable $\mathbf{Y}=\begin{pmatrix}X_2\\X_4\\X_5\end{pmatrix}$ es una normal $3$ dimensional de **vector de medias** $\mu_{\mathbf{Y}}=\mathbf{C}\mathbf{\mu}=\begin{pmatrix}\mu_2\\\mu_4\\\mu_5\end{pmatrix}$ y vector de covarianzas
$$
\mathbf{\Sigma'}=\mathbf{C}\mathbf{\Sigma}\mathbf{C}^\top = \begin{pmatrix}\sigma_{22} & \sigma_{24} & \sigma_{25}\\ \sigma_{42} & \sigma_{44} & \sigma_{45} \\  \sigma_{52} & \sigma_{54} & \sigma_{55}\end{pmatrix}, 
$$
tal como indica la última proposición sobre distribuciones marginales.
</div>

## Independencia de variables aleatorias


### Independencia de variables aleatorias discretas
La generalización de **independencia** a variables aleatorias $n$-dimensionales es clara:

<l class="definition">Definición de independencia para variables aleatorias $n$-dimensionales discretas. </l>
Sean $(X_1\ldots,X_n)$ una **variable aleatoria $n$-dimensional discreta** con $(X_1\ldots,X_n)(\Omega)=\{(x_{i_1},\ldots,x_{i_n}),\ i_1=1,2,\ldots,i_n=1,2,\ldots\}$ y **función de probabilidad conjunta** $P_{X_1\ldots X_n}$ y **funciones de probabilidad marginales** $P_{X_1},\ldots P_{X_n}$. Entonces $X_1,\ldots X_n$ son independientes si:
$$
P_{X_1\ldots X_n}(x_{i_1},\ldots,x_{i_n})=P_{X_1}(x_{i_1})\cdots P_{X_n}(x_{i_n}),\ i_1=1,2,\ldots,i_n=1,2,\ldots
$$

o dicho de otra forma:

$$
P(X_1=x_{i_1},\ X_n=x_{i_n})=P(X_1=x_{i_1})\cdots P(X_n=x_{i_n}),\ i_1=1,2,\ldots,i_n=1,2,\ldots
$$


### Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado tres veces**

Consideremos el experimento aleatorio que consiste en lanzar un dado tres veces. 

Recordemos que hemos estudiado la variable aleatoria $(X_1,X_2,X_3)$ donde $X_1$ nos daba el número de 1's que han salido, $X_2$, el número de 2's y $X_3$, el número de 3's.

Las variables aleatorias anteriores no son independientes ya que, por ejemplo:
$$
P_{X_1,X_2,X_3}(1,1,3)=`r tabla.3[2,2]`\neq P_{X_1}(1)\cdot P_{X_2}(1)\cdot P_{X_3}(3)=`r fun.marginal.X1(1)`\cdot `r fun.marginal.X1(1)`\cdot `r fun.marginal.X1(3)`=`r round(fun.marginal.X1(1)^2*fun.marginal.X1(3),4)`.
$$

</div>

<l class="observ">Observación. </l>
Al igual que pasaba con las variables bidimensionales, si la tabla de la **función de probabilidad conjunta** de $(X_1,\ldots,X_n)$ contiene algún $0$, las variables $X_1,\ldots, X_n$ no pueden ser independientes. ¿Podéis decir por qué?

<l class="observ"> Observación. </l>
Si $X_1,\ldots, X_n$ son variables aleatorias independientes, y consideramos una distribución marginal, por ejemplo $(X_{s_1},\ldots,X_{s_k})$, entonces las variables $X_{s_1},\ldots,X_{s_k}$ también son independientes.

### Independencia de variables aleatorias continuas
La definición dada para **variables aleatorias discretas** se traslada de forma natural a las **variables aleatorias continuas**:

<l class="definition">Definición de independencia para variables aleatorias $n$-dimensionales continuas. </l>
Sean $(X_1\ldots,X_n)$ una **variable aleatoria $n$-dimensional continua** con **función de densidad conjunta** $f_{X_1\ldots X_n}$ y **funciones de densidad marginales** $f_{X_1},\ldots,f_{X_n}$. Entonces $X_1,\ldots, X_n$ son independientes si:
$$
f_{X_1\ldots X_n}(x_1,\ldots,x_n)=f_{X_1}(x_1)\cdots f_{X_n}(x_n),\ \mbox{para todo $x_1,\ldots,x_n\in\mathbb{R}$.}
$$

### Ejemplo
<div class="example">
**Ejemplo**

Recordemos el ejemplo siguiente visto donde teníamos una **variable aleatoria $3$-dimensional continua** $(X_1,X_2,X_3)$ con **función de densidad conjunta**:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
0, & \mbox{en caso contrario.}\\
\end{cases}
$$
y con densidad marginales:
$$
\begin{array}{rl}
f_{X_1}(x_1) & =\begin{cases}
2x_1, & \mbox{ si }0\leq x\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\quad f_{X_2}(x_2)=\begin{cases}
2x_2, & \mbox{ si }0\leq x_2\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\\ f_{X_3}(x_3) & =\begin{cases}
2x_3, & \mbox{ si }0\leq x_3\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}
\end{array}
$$
</div>

### Ejemplo
<div class="example">
**Ejemplo**

Veamos que son independientes.

Consideremos dos casos:

* $(x_1,x_2,x_3)\in [0,1]\times [0,1]\times [0,1]$. En este caso:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3) =8 x_1 x_2 x_3 =2 x_1 2 x_2 2 x_3=f_{X_1}(x_1)\cdot f_{X_2}(x_2)\cdot f_{X_3}(x_3).
$$

* $(x_1,x_2,x_3)\not\in [0,1]\times [0,1]\times [0,1]$. En este caso:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)  =0 = f_{X_1}(x_1)\cdot f_{X_2}(x_2)\cdot f_{X_3}(x_3),
$$
ya que si $(x_1,x_2,x_3)\not\in  [0,1]\times [0,1]\times [0,1]$, o $x_1\not\in [0,1]$ o $x_2\not\in [0,1]$, o $x_3\not\in [0,1]$. Por tanto $f_{X_1}(x_1)=0$ o $f_{X_2}(x_2)=0$ o $f_{X_3}(x_3)=0$. En cualquier caso, $f_{X_1}(x_1)\cdot f_{X_2}(x_2)\cdot f_{X_3}(x_3)=0$.
</div>


### Ejemplo de la variable gaussiana $n$-dimensional
En este caso, recordemos que la **función de densidad conjunta** de $(X_1,\ldots,X_n)$ es:
$$
\begin{array}{rl}
& f_{X_1\ldots X_n}(x_1,\ldots,x_n)=\frac{1}{(2\pi)^{\frac{n}{2}}\sqrt{\mathbf{|\Sigma|}}}\mathrm{e}^{-\frac{1}{2}(\mathbf{x-\mu})^\top\mathbf{\Sigma}^{-1}(\mathbf{x-\mu})},\\ & \qquad  -\infty <x_1,\ldots,x_n<\infty,
\end{array}
$$
donde $\mathbf{\mu}$ es el vector de medias y $\mathbf{\Sigma}$, la matriz de covarianzas.

Recordemos también que las **funciones de densidad marginales** de $X_1,\ldots, X_n$ correspondían a $N(\mu_i,\sigma_{ii})$, con $i=1,\ldots, n$:
$$
f_{X_i}(x_i)  =\frac{1}{\sqrt{2\pi\sigma_{ii}^2}}\mathrm{e}^{-\frac{(x_i-\mu_i)^2}{2\sigma_{ii}^2}},\ -\infty <x_i<\infty,\ i=1,\ldots,n.
$$

### Ejemplo de la variable gaussiana $n$-dimensional

¿Cómo tiene que ser la matriz de covarianzas $\mathbf{\Sigma}$ para que las variables $X_1,\ldots,X_n$ sean independientes?

O, expresado matemáticamente,
$$
\begin{array}{rl}
f_{X_1}(x_1)\cdots f_{X_n}(x_n) & =\frac{1}{\left(2\pi\right)^{\frac{n}{2}}\sigma_{11}\cdots \sigma_{nn}}\mathrm{e}^{-\sum\limits_{i=1}^n\frac{(x_i-\mu_i)^2}{2\sigma_{ii}^2}}=f_{X_1\ldots X_n}(x_1,\ldots,x_n) \\ & =\frac{1}{(2\pi)^{\frac{n}{2}}\sqrt{\mathbf{|\Sigma|}}}\mathrm{e}^{-\frac{1}{2}(\mathbf{x-\mu})^\top\mathbf{\Sigma}^{-1}(\mathbf{x-\mu})}.
\end{array}
$$

### Ejemplo de la variable gaussiana $n$-dimensional

La respuesta es claramente cuando la matriz de covarianzas $\mathbf{\Sigma}$ es diagonal, o sea, si $\sigma_{ij}=0,$ para $i\neq j$, para todo $i,j=1,\ldots,n$.

En resumen, cuando la covarianza entre dos variables cualesquiera $X_i$ y $X_j$ distintas es cero, las variables normales $X_1,\ldots,X_n$ son independientes.


### Relación de la independencia y la función de distribución
El siguiente resultado nos da la relación entre la **independencia de variables aleatorias** y su **función de distribución conjunta**:

<l class="prop">Teorema. </l>
Sea $(X_1\ldots,X_n)$ una variable aleatoria $n$-dimensional. Entonces 
$X_1,\ldots,X_n$ son independientes si, y sólo si, la **función de distribución conjunta** es el producto de las **funciones de distribución marginales** en todo valor $(x_1,\ldots,x_n)\in\mathbb{R}^n$:
$$
F_{X_1\ldots X_n}(x_1,\ldots,x_n)=F_{X_1}(x_1)\cdots F_{X_n}(x_n),\ (x_1,\ldots,x_n)\in\mathbb{R}^n.
$$


### Ejemplo 
<div class="example">
**Ejemplo**

Recordemos la variable aleatoria $3$-dimensional continua con **función de densidad conjunta**:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
0, & \mbox{en caso contrario.}\\
\end{cases}
$$
Recordemos también **función de distribución conjunta** es: 
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
0, & \mbox{si }x_1<0,\mbox{ o }x_2<0,\mbox{ o }x_3 <0\\
x_1^2\cdot x_2^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
 x_2^2\cdot x_3^2, & \mbox{si }x_1> 1,\ 0\leq x_2\leq  1,\ 0\leq x_3\leq  1, \\
 x_1^2\cdot x_3^2, & \mbox{si }0\leq x_1\leq  1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 x_3^2, & \mbox{si }x_1> 1,\ x_2> 1,\ \ 0\leq x_3\leq  1, \\
 x_1^2\cdot x_2^2, & \mbox{si }0\leq x_1\leq  1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
 x_1^2, & \mbox{si }0\leq x_1\leq  1,\ x_2 >  1,\ x_3> 1,\\
 x_2^2, & \mbox{si }x_1>1,\ 0\leq x_2\leq  1,\ x_3> 1,\\
1, & \mbox{si }x_1\geq 1,\ x_2\geq 1,\ x_3\geq 1.
\end{cases}
$$
</div>

### Ejemplo 
<div class="example">
Recordemos las **funciones de densidad** de las **distribuciones marginales**:
$$
\begin{array}{rl}
f_{X_1}(x_1) & =\begin{cases}
2x_1, & \mbox{ si }0\leq x\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\quad f_{X_2}(x_2)=\begin{cases}
2x_2, & \mbox{ si }0\leq x_2\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\\ f_{X_3}(x_3) & =\begin{cases}
2x_3, & \mbox{ si }0\leq x_3\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}
\end{array}
$$
Dejamos como ejercicio verificar que las expresiones siguientes correspondes a las **funciones de distribución marginales**: 

$$
\begin{array}{rl}
F_{X_1}(x_1) & =\begin{cases}
0, & \mbox{ si }x_1<0, \\
x_1^2, & \mbox{ si }0\leq x_1\leq 1,\\
1, & \mbox{ si }x_1 > 1.
\end{cases}\quad F_{X_2}(x_2) & =\begin{cases}
0, & \mbox{ si }x_2<0, \\
x_2^2, & \mbox{ si }0\leq x_2\leq 1,\\
1, & \mbox{ si }x_2 > 1.
\end{cases}\\ F_{X_3}(x_3) & =\begin{cases}
0, & \mbox{ si }x_3<0, \\
x_3^2, & \mbox{ si }0\leq x_3\leq 1,\\
1, & \mbox{ si }x_3 > 1.
\end{cases}
\end{array}
$$

</div>

### Ejemplo 
<div class="example">
Recordemos que $X_1$, $X_2$ y $X_3$ son independientes. Por tanto verifiquemos que $F_{X_1X_2X_3}(x_1,x_2,x_3)=F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3)$ para todos los valores $x_1,x_2,x_3\in\mathbb{R}$.

Distingamos los mismos casos que en la **función de distribución conjunta**:

* $x_1<0$, o $x_2<0$, o $x_3 <0$. En este caso, o $F_{X_1}(x_1)=0$, o $F_{X_2}(x_2)=0$ o $F_{X_3}(x_3)=0$. En cualquier caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=0= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $0\leq x_1\leq 1$, y $0\leq x_2\leq 1$, y $0\leq x_3\leq 1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2\cdot x_2^2\cdot x_3^2= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $x_1> 1$, y $0\leq x_2\leq  1$, y $0\leq x_3\leq  1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_2^2\cdot x_3^2=1\cdot x_2^2\cdot x_3^2= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $0\leq x_1\leq  1,$ y $x_2> 1$, y $0\leq x_3\leq  1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2\cdot x_3^2=x_1^2\cdot 1\cdot x_3^2= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

</div>
### Ejemplo 
<div class="example">
* $x_1> 1$, y $x_2> 1$, y $0\leq x_3\leq  1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_3^2=1\cdot 1\cdot x_3^2= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $0\leq x_1\leq  1$, y $0\leq x_2\leq  1$, y $x_3> 1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2\cdot x_2^2=x_1^2\cdot x_2^2\cdot 1= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $0\leq x_1\leq  1$, y $x_2 >  1$, y $x_3> 1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_1^2=x_1^2\cdot 1\cdot 1= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $x_1>  1$, y $0\leq x_2 \leq   1$, y $x_3> 1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=x_2^2=1\cdot x_2^2\cdot 1= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$

* $x_1>  1$, y $x_2>1$, y $x_3> 1$. En este caso:
$$
F_{X_1X_2X_3}(x_1,x_2,x_3)=1=1\cdot 1\cdot 1= F_{X_1}(x_1)\cdot F_{X_2}(x_2)\cdot F_{X_3}(x_3).
$$
</div>

## Momentos conjuntos y valores esperados conjuntos

### Valor esperado de una función de $n$ variables aleatorias
Sea $(X_1,\ldots,X_n)$ una variable aleatoria $n$-dimensional. 

Sea $P_{X_1\ldots X_n}$ su **función de probabilidad conjunta** en el caso en que $(X_1,\ldots,X_n)$ sea **discreta** y $f_{X_1\ldots X_n}$ su **función de densidad conjunta** en el caso en que $(X_1,\ldots,X_n)$ sea **continua**.

### Valor esperado de una función de $n$ variables aleatorias 

Sea $Z=g(X_1,\ldots,X_n)$ una **variable aleatoria unidimensional** función de las variables $X_1,\ldots,X_n$. Por ejemplo: 

* Media aritmética de las $n$ variables $g(x_1,\ldots,x_n)=\frac{x_1+\cdots + x_n}{n}$: $Z=\frac{X_1+\cdots +X_n}{n}$.
* Media geométrica de las $n$ variables $g(x_1,\ldots,x_n)=\sqrt[n]{x_1\cdots x_n}$: $Z=\sqrt[n]{X_1\cdots X_n}$.
* Suma de los cuadrados de las variables $g(x_1,\ldots,x_n)=x_1^2+\cdots +x_n^2$: $Z=X_1^2+\cdots +X_n^2$.

### Valor esperado de una función de dos variables aleatorias
Hay que tener en cuenta que $Z$, como **variable aleatoria unidimensional** tiene una **función de probabilidad** $P_Z$ en el caso en que $(X_1,\ldots,X_n)$ sea discreta y una **función de densidad** $f_Z$ en el caso en que $(X_1,\ldots,X_n)$ sea continua.

El siguiente resultado nos dice cómo calcular el **valor esperado** de $Z$ sin tener que calcular $P_Z$ o $f_Z$, sólo usando la información de la **variable aleatoria conjunta** $(X_1,\ldots,X_n)$:

### Valor esperado de una función de dos variables aleatorias

<l class="prop">Proposición. </l>
El valor esperado de $Z$ se puede hallar usando la expresión siguiente:

* en el caso en que $(X_1,\ldots,X_n)$ sea discreta con $(X_1,\ldots,X_n)(\Omega)=\{(x_{i_1},\ldots,x_{i_n}),\ i_1=1,2,\ldots, i_n=1,2,\ldots\}$,
$$
E(Z)  = E(g(X_1\ldots,X_n))  =\sum_{x_{i_1}}\cdots\sum_{x_{i_n}}g(x_{i_1},\ldots,x_{i_n})P(x_{i_1},\ldots,x_{i_n}),
$$

### Valor esperado de una función de dos variables aleatorias
* en el caso en que $(X_1,\ldots,X_n)$ sea continua:
$$
\begin{array}{rl}
& E(Z)=E(g(X_1\ldots,X_n)) \\ & \quad =\int_{-\infty}^\infty\cdots\int_{-\infty}^\infty g(x_1,\ldots,x_n)f_{X_1\ldots X_n}(x_1,\ldots,x_n)\, dx_1\ldots dx_n.
\end{array}
$$

### Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado tres veces**

Consideremos el ejemplo de la variable $(X_1,X_2,X_3)$ que nos daba el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces.

Vamos a calcular $E\left(X_1\cdot X_2\cdot X_3\right)$. 
El valor esperado anterior se calcularía de la forma siguiente:
$$
E\left(X_1\cdot X_2\cdot X_3\right)=\sum_{i_1=0}^3\sum_{i_2=0}^3
\sum_{i_3=0}^3 i_1\cdot i_2\cdot i_3\cdot P_{X_1X_2X_3}(i_1,i_2,i_3),
$$
en total $4^3=`r 4^3`$ términos. Como el cálculo es tedioso, lo vamos a realizar con ayuda de `R`. 

</div>

### Ejemplo con `R`
<div class="example">
```{r}
valor.esperado=0;
for (i1 in 0:3){
  for (i2 in 0:3){
    for (i3 in 0:3){
      valor.esperado=valor.esperado+i1*i2*i3*fun.prob.con(i1,i2,i3)
    }
  }
}
valor.esperado
```



</div>

### Ejemplo
<div class="example">
**Ejemplo**

Recordemos la variable aleatoria $3$-dimensional $(X_1,X_2,X_3)$ con **función de densidad conjunta**:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
0, & \mbox{en caso contrario.}\\
\end{cases}
$$
Calculemos $E(X_1^2+X_2^2+X_3^2)$:
$$
\begin{array}{rl}
E(X_1^2+X_2^2+X_3^2) & =\int_{x_1=0}^{x_1=1} \int_{x_2=0}^{x_2=1}\int_{x_3=0}^{x_3=1} (x_1^2+x_2^2+x_3^2) 8 x_1 x_2 x_3 \,dx_1\, dx_2\, dx_3\\ & =8\left(\int_{x_1=0}^{x_1=1} \int_{x_2=0}^{x_2=1}\int_{x_3=0}^{x_3=1}   x_1^3 x_2 x_3 \,dx_1\, dx_2\, dx_3 + \int_{x_1=0}^{x_1=1} \int_{x_2=0}^{x_2=1}\int_{x_3=0}^{x_3=1}   x_1 x_2^3 x_3 \,dx_1\, dx_2\, dx_3 \right.\\ & \left. + \int_{x_1=0}^{x_1=1} \int_{x_2=0}^{x_2=1}\int_{x_3=0}^{x_3=1}   x_1 x_2 x_3^3 \,dx_1\, dx_2\, dx_3\right) \\ & =
8\left(\left[\frac{x_1^4}{4}\right]_0^1 \left[\frac{x_2^2}{2}\right]_0^1 \left[\frac{x_3^2}{2}\right]_0^1 + \left[\frac{x_1^2}{2}\right]_0^1 \left[\frac{x_2^4}{4}\right]_0^1 \left[\frac{x_3^2}{2}\right]_0^1 + \left[\frac{x_1^2}{2}\right]_0^1 \left[\frac{x_2^2}{2}\right]_0^1 \left[\frac{x_3^4}{4}\right]_0^1\right) \\ & =8\cdot 3\cdot \frac{1}{16}=\frac{3}{2}=`r 3/2`.
\end{array}
$$
</div>

### Propiedad del valor esperado de la suma de variables
En estos momentos estamos en condiciones de demostrar el resultado siguiente:

<l class="prop">Proposición. Valor esperado de la suma de variables aleatorias.</l>
Sea $(X_1,\ldots,X_n)$ una variable aleatoria $n$-dimensional. Entonces el valor esperado de la variable aleatoria suma de las variables es igual a la suma de los valores esperados de cada variable:
$$
E(X_1+\cdots + X_n)=E(X_1)+\cdots + E(X_n).
$$

### Propiedad del valor esperado de la suma de variables
<div class="dem">
**Demostración**

Haremos la demostración para el caso continuo. Dejamos como ejercicio la demostración en el caso discreto.

El valor esperado de la suma de variables será en función de la **función de densidad conjunta** $f_{X_1\ldots X_n}$:
$$
\begin{array}{rl}
E(X_1+\cdots + X_n) & = \int_{-\infty}^\infty\cdots\int_{-\infty}^\infty (x_1+\cdots + x_n)f_{X_1\ldots X_n}(x_1,\ldots,x_n)\,dx_1\ldots dx_n \\ & = \int_{-\infty}^\infty\cdots\int_{-\infty}^\infty x_1f_{X_1\ldots X_n}(x_1,\ldots,x_n)\,dx_1\ldots dx_n+ \cdots \\ & + \int_{-\infty}^\infty\cdots\int_{-\infty}^\infty x_n f_{X_1\ldots X_n}(x_1,\ldots,x_n)\,dx_1\ldots dx_n \\ & = E(X_1)+\cdots + E(X_n).
\end{array}
$$

</div>

### Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado tres veces**

Consideremos el ejemplo de la variable $(X_1,X_2,X_3)$ que nos daba el número de 1's, 2's y 3's en el lanzamiento de un dado tres veces.

Comprobemos en este caso que $E(X_1+X_2+X_3)=E(X_1)+E(X_2)+E(X_3)$.
</div>

### Ejemplo
<div class="example">
Calculemos $E(X_1+X_2+X_3)$ con `R` usando la misma técnica que en el ejemplo donde calculábamos $E(X_1\cdot X_2\cdot X_3)$:
```{r}
valor.esperado=0;
for (i1 in 0:3){
  for (i2 in 0:3){
    for (i3 in 0:3){
      valor.esperado=valor.esperado+(i1+i2+i3)*fun.prob.con(i1,i2,i3)
    }
  }
}
valor.esperado
```

</div>

### Ejemplo
<div class="example">

La distribución marginal de cada una de las variables $X_1$, $X_2$ y $X_3$ recordemos que es la siguiente:

<div class="center">
| $X_1$ | 0 | 1| 2 |3 
|--|--|--|--|--
| $P_{X_1}$|$`r round(sum(tabla.0),4)`$|$`r round(sum(tabla.1),4)`$|$`r round(sum(tabla.2),4)`$|$`r round(sum(tabla.3),4)`$
</div>

</div>

### Ejemplo
<div class="example">


El valor de $E(X_1)=E(X_2)=E(X_3)$ será:
```{r}
esperanza.X1=0
for (i in 0:3){
  esperanza.X1=esperanza.X1+i*fun.marginal.X1(i)
}
esperanza.X1
```
Claramente:
$$
E(X_1+X_2+X_3)=`r valor.esperado`=E(X_1)+E(X_2)+E(X_3)=`r esperanza.X1`+`r esperanza.X1`+`r esperanza.X1`.
$$

</div>


### Valor esperado de una función de $n$ variables aleatorias independientes

El siguiente resultado nos simplifica el cálculo del **valor esperado de una función de $n$ variables aleatorias** en el caso en que sean **independientes**:

<l class="prop">Proposición: cálculo del valor esperado de una función de $n$ variables aleatorias en el caso de independencia. </l>
Sea $(X_1,\ldots,X_n)$ una variable aleatoria $n$-dimensional donde suponemos que $X_1,\ldots,X_n$ son independientes. 
Sea $Z=g(X_1,\ldots,X_n)$ una variable aleatoria unidimensional función de $X_1,\ldots,X_n$ donde suponemos que podemos "separar" las variables $x_1,\ldots, x_n$ en la función $g$. O sea, existen $n$ funciones $g_1,\ldots, g_n$  tal que $g(x_1,\ldots,x_n)=g_1(x_1)\cdots g_n(x_n)$ para todo valor $x_1,\ldots,x_n\in\mathbb{R}$. En este caso, el valor esperado de $Z$ se puede calcular como:
$$
E(Z)=E(g(X_1\ldots,X_n))=E_{X_1}(g_1(X_1))\cdots E_{X_n}(g_n(X_n)).
$$

### Valor esperado de una función de dos variables aleatorias independientes
O sea, el cálculo de $E(g(X_1\ldots,X_n))$ que sería una suma múltiple en el caso de que $(X_1,\ldots,X_n)$ sea **discreta** o una integral múltiple en el caso en que $(X_1,\ldots,X_n)$ sea continua se transforma en el producto de $n$ sumas simples (caso **discreto**) o el producto de $n$ integrales simples (caso **continuo**):
$$
\begin{array}{rl}
E(Z) & =E(g(X_1\ldots,X_n))\\ & =\left(\sum_{x_{i_1}} g_1(x_{i_1})\cdot P_{X_1}(x_{i_1})\right)\cdots \left(\sum_{x_{i_n}} g_n(x_{i_n})\cdot P_{X_n}(x_{i_n})\right), \ \mbox{caso discreto},\\
E(Z) & =E(g(X_1\ldots,X_n)) \\ & =\left(\int_{-\infty}^\infty g_1(x_1)\cdot f_{X_1}(x_1)\, dx_1\right)\cdots \left(\int_{-\infty}^\infty g_n(x_n)\cdot f_{X_n}(x_n)\right), \ \mbox{caso continuo}.
\end{array}
$$

### Valor esperado de una función de dos variables aleatorias independientes
Un caso particular de aplicación de la proposición anterior sería cuando queramos calcular $E(X_1\cdots X_n)$. En este caso $g(x_1,\ldots,x_n)=x_1\cdots x_n$, $g_1(x_1)=x_1$, y $g_n(x_n)=x_n$. 

Podemos escribir, por tanto:
$$
E(X_1\cdots X_n)=E_{X_1}(X_1)\cdots E_{X_n}(X_n),
$$
si $X_1,\ldots,X_n$ son independientes.


### Ejemplo
<div class="example">
Recordemos el ejemplo con función de densidad conjunta:
$$
f_{X_1X_2X_3}(x_1,x_2,x_3)=\begin{cases}
8 x_1\cdot x_2\cdot x_3, & \mbox{si }0\leq x_1\leq 1,\ 0\leq x_2\leq 1,\ 0\leq x_3\leq 1, \\
0, & \mbox{en caso contrario.}\\
\end{cases}
$$
Recordemos que son independientes. Comprobemos que $E(X_1\cdot X_2\cdot X_3)=E(X_1)\cdot E(X_2)\cdot E(X_3)$.

Calculemos $E(X_1\cdot X_2\cdot X_3)$:
$$
\begin{array}{rl}
E(X_1\cdot X_2\cdot X_3)  & = \int_0^1\int_0^1\int_0^1 x_1\cdot x_2\cdot x_3\cdot 8 x_1\cdot x_2\cdot x_3\,dx_1\, dx_2\, dx_3 \\ & = 8\int_0^1\int_0^1\int_0^1 x_1^2\cdot x_2^2\cdot x_3^2\,dx_1\, dx_2\, dx_3 =8\left[\frac{x_1^3}{3}\right]_0^1\left[\frac{x_2^3}{3}\right]_0^1
\left[\frac{x_3^3}{3}\right]_0^1 = 8\cdot \frac{1}{3^3}=\frac{8}{27}=`r round(8/27,4)`.
\end{array}
$$

Recordemos que las **densidades marginales** eran:
$$
\begin{array}{rl}
f_{X_1}(x_1) & =\begin{cases}
2x_1, & \mbox{ si }0\leq x\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\quad f_{X_2}(x_2)=\begin{cases}
2x_2, & \mbox{ si }0\leq x_2\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}\\ f_{X_3}(x_3) & =\begin{cases}
2x_3, & \mbox{ si }0\leq x_3\leq 1,\\
0, & \mbox{en caso contrario.}
\end{cases}
\end{array}
$$
</div>

### Ejemplo
<div class="example">

Por tanto:
$$
E(X_1)=E(X_2)=E(X_3)=\int_0^1 x\cdot 2 x\, dx =2 \int_0^1 x^2\, dx=2\left[\frac{x^3}{3}\right]_0^1=\frac{2}{3}.
$$
Claramente, se verifica:
$$
E(X_1\cdot X_2\cdot X_3)=\frac{8}{27}=E(X_1)\cdot E(X_2)\cdot E(X_3)=\left(\frac{2}{3}\right)^3.
$$
</div>

### Propiedades de la covarianza
Veamos cómo se calcula la **covarianza** de dos combinaciones lineales de variables aleatorias:

<l class="prop">Proposición (covarianza de dos combinaciones lineales de variables aleatorias). </l>
Sean $(X_1,\ldots,X_n)$ e $(Y_1,\ldots, Y_n)$ dos variables aleatorias $n$-dimensionales. Sean $a_1, \ldots, a_n$ y $b_1,\ldots, b_n$  $n$ parejas de valores reales. Sean $U$ y $V$ las variables aleatorias siguientes: 
$U=\sum\limits_{i=1}^n a_i X_i,\  V=\sum\limits_{i=1}^n b_i Y_i.$
Entonces la **covarianza** de las variables $U$ y $V$ se calcula usando la expresión siguiente:
$$
\mathrm{Cov}(U,V)=\sum_{i=1}^n\sum_{j=1}^n a_i b_j \mathrm{Cov}(X_i,Y_j).
$$



### Propiedades de la covarianza
<div class="dem">
**Demostración**

Usando la expresión de la **covarianza** podemos calcular la covarianza entre las variables $U$ y $V$ como:
$$
\begin{array}{rl}
\mathrm{Cov}(U,V) & =E(UV)-E(U)E(V)=E\left(\sum\limits_{i=1}^n a_i X_i\cdot \sum\limits_{j=1}^n b_j Y_j\right)- E\left(\sum\limits_{i=1}^n a_i X_i\right)E\left(\sum\limits_{j=1}^n b_j Y_j\right) \\ & =\sum\limits_{i=1}^n \sum\limits_{j=1}^n a_i b_j E\left(X_i Y_j\right)-\sum\limits_{i=1}^n a_i E(X_i)\sum\limits_{j=1}^n b_j E(Y_j) = \sum\limits_{i=1}^n \sum\limits_{j=1}^n a_i b_j E\left(X_i Y_j\right)-\sum\limits_{i=1}^n\sum\limits_{j=1}^n a_i b_j E(X_i) E(Y_j) \\ & = \sum\limits_{i=1}^n \sum\limits_{j=1}^n a_i b_j \left(E\left(X_i Y_j\right) - E(X_i) E(Y_j)\right) = \sum\limits_{i=1}^n \sum\limits_{j=1}^n a_i b_j \mathrm{Cov}(X_i,Y_j),
\end{array}
$$
tal como queríamos ver.

</div>

### Propiedades de la covarianza
Si en la combinación lineal sólo hay las componentes de una sola variable aleatoria $n$-dimensional, la proposición anterior se convierte en la proposición siguiente:

<l class="prop">Proposición (covarianza de una combinación lineal de variables aleatorias). </l>
Sean $(X_1,\ldots,X_n)$ una variable aleatoria $n$-dimensional.  Sean $a_1, \ldots, a_n$ y $b_1,\ldots, b_n$  $n$ parejas de valores reales. Sean $U$ y $V$ las variables aleatorias siguientes:
$U=\sum\limits_{i=1}^n a_i X_i,\  V=\sum\limits_{i=1}^n b_i X_i.$
Entonces la **covarianza** de las variables $U$ y $V$ se calcula usando la expresión siguiente:
$$
\mathrm{Cov}(U,V)=\sum_{i=1}^n a_i b_i \mathrm{Var}(X_i)+\sum_{i=1}^n\sum_{j=1,j\neq i}^n a_i b_j \mathrm{Cov}(X_i,X_j).
$$

### Propiedades de la covarianza
<div class="dem">
**Demostración**

Usando la misma técnica de demostración que en la proposición anterior, podemos calcular la covarianza entre las variables $U$ y $V$ como:
$$
\begin{array}{rl}
\mathrm{Cov}(U,V) & = \sum\limits_{i=1}^n \sum\limits_{j=1}^n a_i b_j \left(E\left(X_i X_j\right) - E(X_i) E(X_j)\right) = \sum\limits_{i=1}^n a_i b_i \left(E\left(X_i^2\right) - E(X_i)^2\right)+\sum\limits_{i=1}^n \sum\limits_{j=1,j\neq i}^n a_i b_j \mathrm{Cov}(X_i,X_j) \\ & = \sum\limits_{i=1}^n a_i b_i \mathrm{Var}(X_i)+\sum\limits_{i=1}^n \sum\limits_{j=1,j\neq i}^n a_i b_j \mathrm{Cov}(X_i,X_j),
\end{array}
$$
tal como queríamos ver.

</div>

### Propiedades de la covarianza
<l class="observ"> Observación. </l>
Una forma equivalente de escribir la covarianza anterior sería:
$$
\mathrm{Cov}(U,V)=\sum_{i=1}^n a_i b_i \mathrm{Var}(X_i)+2\sum_{i=1}^n\sum_{j=1,j>i}^n a_i b_j \mathrm{Cov}(X_i,X_j).
$$

### Propiedades de la covarianza
Como, en general $\mathrm{Var}(U)=\mathrm{Cov}(U,U)$, una consecuencia directa de la proposición anterior es la expresión de la varianza de una combinación lineal de variables aleatorias:

<l class="prop">Proposición (varianza de una combinación lineal de variables aleatorias). </l>
Sean $(X_1,\ldots,X_n)$ una variable aleatoria $n$-dimensional.  Sean $a_1, \ldots, a_n$  $n$ valores reales. Sea $U$ la variable aleatoria siguiente:
$U=\sum\limits_{i=1}^n a_i X_i.$
Entonces la **varianza** de la variable $U$ se calcula usando la expresión siguiente:
$$
\mathrm{Var}(U)=\sum_{i=1}^n a_i^2 \mathrm{Var}(X_i)+\sum_{i=1}^n\sum_{j=1,j\neq i}^n a_i a_j \mathrm{Cov}(X_i,X_j).
$$

### Propiedades de la covarianza
<div class="dem">
**Demostración**

Para la demostración, basta tener en cuenta que $\mathrm{Var}(U)=\mathrm{Cov}(U,U)$ y aplicar la expresión de la covariancia entre $U$ y $V$ en la proposición que nos da la covarianza de una combinación lineal de variables aleatorias.
</div>

<l class="observ"> Observación. </l>
En este caso, también existe una forma equivalente de escribir la varianza anterior:
$$
\mathrm{Var}(U)=\sum_{i=1}^n a_i^2 \mathrm{Var}(X_i)+2\sum_{i=1}^n\sum_{j=1,j>i}^n a_i a_j \mathrm{Cov}(X_i,X_j).
$$

### Propiedades de la covarianza

Una consecuencia de la proposición anterior es que si las variables son **independientes**, la **varianza** de la suma es la suma de varianzas:

<l class="prop">Proposición (varianza de la suma de variables aleatorias independientes). </l>
Sean $(X_1,\ldots,X_n)$ una variable aleatoria $n$-dimensional donde $X_1,\ldots, X_n$ son independientes.  
Entonces la **varianza** de la variable $X_1+\cdots X_n$ es la suma de las varianzas de cada variable aleatoria:
$$
\mathrm{Var}(X_1+\cdots + X_n)=\sum_{i=1}^n \mathrm{Var}(X_i).
$$

<div class="dem">
**Demostración**

Para la demostración, basta aplicar la proposición anterior de la varianza de una combinación lineal de variables aleatorias con $a_i=1$, para todo $i=1,\ldots,n$ y tener en cuenta que como son independientes, $\mathrm{Cov}(X_i,X_j)=0$, para todo $i\neq j$.
</div>

<!--chapter:end:6.Rmd-->

# Ley de los grandes números y Teorema Central del Límite

## Muestras aleatorias simples

El pilar básico sobre el que se sustenta la **estadística inferencial** es el concepto de **muestra aleatoria simple**.

Una **muestra aleatoria simple**, desde el punto de vista de la probabilidad es una distribución $n$ variables aleatorias, $X_1,\ldots, X_n$ todas independientes entre sí e idénticamente distribuidas ya que queremos simular la repetición de un experimento $n$ veces de forma independiente.

Por tanto, estudiar una **muestra aleatoria simple** equivale a estudiar su distribución.

### Introducción

En muchos casos, nos bastará estudiar la distribución de una variable que "represente" a dicha **muestra aleatoria simple**: la media muestral definida como $\overline{X}=\frac{X_1+\cdots + X_n}{n}$.

Las **leyes de los grandes números** nos dicen que, de alguna manera (que concretaremos más adelante), la media muestral y la media poblacional se "parecen" a la larga o cuando el número de repeticiones $n$ tiende a infinito.

El **Teorema Central del Límite** nos dice que la distribución de la media muestral tiende, sea cual sea la distribución de las variables $X_i$, a una normal. De ahí que la **distribución normal** sea la más importante en probabilidades y estadística.


### La distribución de la media muestral

Vamos cómo se distribuye la media de un conjunto de variables normales e idénticamente distribuidas:

<l class="prop">Proposición. Distribución de la media muestral de $n$ variables normales independientes e idénticamente distribuidas. </l>
Sean $X_1,\ldots, X_n$ $n$ variables normales de media $\mu$ y varianza $\sigma^2$, todas normales e independientes. Consideramos la variable $\overline{X}=\frac{X_1+\cdots + X_n}{n}$ la media muestral. Entonces la distribución de la variable aleatoria $\overline{X}$ es normal de la misma media $\mu$ de las $X_i$ y varianza $\frac{\sigma^2}{n}$.

### La distribución de la media muestral
<div class="dem">
**Demostración**

Consideramos la variable aleatoria $n$-dimensional $\mathbf{X}=(X_1,\ldots,X_n)$. Dicha variable tendrá la distribución normal $n$-dimensional con vector de medias $\mathbf{\mu}=(\mu,\ldots,\mu)^\top$ y matriz de covarianzas $\mathbf{\Sigma}$ diagonal ya que recordemos que las $X_i$ son independientes y, por tanto, incorreladas o de covarianza nula:
$$
\mathbf{\Sigma}=\begin{pmatrix}
\sigma^2 & 0 & \ldots & 0 \\
0 & \sigma^2 & \ldots & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & \ldots & \sigma^2
\end{pmatrix}.
$$
</div>
### La distribución de la media muestral
<div class="dem">
Para hallar la variable  $\overline{X}$, realizamos la transformación afín siguiente:
$$
\overline{X}=\left(\frac{1}{n},\ldots,\frac{1}{n}\right)\begin{pmatrix} X_1 \\ X_2\\\vdots \\ X_n \end{pmatrix}.
$$
Aplicando la proposición sobre la transformación afín sobre una variable normal $n$-dimensional que vimos en el capítulo de distribuciones $n$-dimensionales con matriz de cambio $\mathbf{C}=\left(\frac{1}{n},\ldots,\frac{1}{n}\right)$ y $\mathbf{c}=0$, tenemos que la distribución de $\overline{X}$ será normal de media $\mathbf{c}+\mathbf{C}\mathbf{\mu} = \mu$ y varianza (o matriz de covarianzas $1\times 1$):
$$
\mathbf{C}\mathbf{\Sigma}\mathbf{C}^\top =\left(\frac{1}{n},\ldots,\frac{1}{n}\right)\begin{pmatrix}
\sigma^2 & 0 & \ldots & 0 \\
0 & \sigma^2 & \ldots & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & \ldots & \sigma^2
\end{pmatrix} \begin{pmatrix}\frac{1}{n}\\\frac{1}{n}\\\vdots\\\frac{1}{n}\end{pmatrix} =\frac{\sigma^2}{n}.
$$
</div>

## Convergencia de sucesiones de variables aleatorias

### Introducción
En esta sección vamos a intentar concretar cómo la media muestral y la media poblacional de una **muestra aleatoria simple** se van pareciendo, así como la distribución de la **media muestral** se va "acercando" a la normalidad.

Para ello, necesitamos introducir un conjunto de conceptos relacionados con la convergencia de variables aleatorias. 

En primer lugar, introduciremos el concepto de **sucesión de variables aleatorias**:

<l class="definition"> Definición de sucesión de variables aleatorias. </l>
Consideremos un experimento aleatorio sobre un **espacio muestral** $\Omega$. Sea $P$ una probabilidad definida sobre el conjunto de sucesos de $\Omega$. Entonces, si $X_1,X_2,\ldots,X_n,\ldots$ son variables aleatorias definidas sobre $\Omega,P$, diremos que forman una **sucesión de variables aleatorias** y lo denotaremos por $\{X_n\}_{n=1}^\infty$.

### Ejemplo
<div class="example">
**Ejemplo: lanzamiento de un dado**

Consideremos el experimento aleatorio de ir lanzando un dado no trucado. Definimos la variable aleatoria $X_n$ como el resultado del dado el lanzamiento $n$-ésimo. 

Entonces, la sucesión de variables aleatorias $X_1,\ldots,X_n,\ldots$ sería la asociada al lanzamiento del dado.

¡Ojo! no confundir la sucesión de variables aleatorias $X_1,\ldots,X_n,\ldots$ con la sucesión de resultados de dichas variables aleatorias $x_1,\ldots, x_n,\ldots$. Lo primero correspondería a variables aleatorias con su función de probabilidad, esperanza, varianza, etc., y lo segundo sería simplemente una sucesión numérica de valores enteros entre 1 y 6.
</div>


### Convergencia casi segura
<l class="definition"> Definición de convergencia casi segura. </l>
Sea $X_1,\ldots,X_n,\ldots$ una sucesión de variables aleatorias y sea $X$ una variable aleatoria definida sobre el mismo espacio muestral $\Omega$ y con la misma probabilidad de sucesos. Diremos que la sucesión $\{X_n\}_{n=1}^\infty$ converge **casi seguramente** hacia $X$ si
$$
P(\{w\in \Omega\ |\ \lim_{n\to\infty} X_n(w)=X(w)\})=1.
$$
Lo denotaremos por $X_n\stackrel{c.s.}{\longrightarrow}X$.

### Convergencia casi segura

O sea, si el conjunto de elementos $w$ del espacio muestral $\Omega$ que cumplen que el límite de la sucesión de números reales $(X_n(w))_n$ tiende a $X(w)$ tiene probabilidad $1$.

De ahí viene el nombre de **casi segura**: el conjunto de valores $w$ del espacio muestral tal que la sucesión numérica $(X_n(w))_n$ **no converge** a $X(w)$ tiene probabilidad 0.


### Convergencia casi segura
Comprobar la **convergencia casi segura** a partir de la definición puede ser muy complicado. Por suerte, existe la proposición siguiente que nos hace la vida más fácil:

<l class="prop"> Proposición. </l>
Sea $X_1,\ldots,X_n,\ldots$ una sucesión de variables aleatorias y sea $X$ una variable aleatoria definida sobre el mismo espacio muestral $\Omega$ y con la misma probabilidad de sucesos. 
Entonces $X_n\stackrel{c.s.}{\longrightarrow}X$ si, y sólo si, para todo valor $\epsilon >0$, la serie siguiente
$$
\sum_{n=1}^\infty P(|X_n-X|>\epsilon),
$$
es convergente.

### Ejemplo
<div class="example">
Veamos si la sucesión $\{X_n\}_{n=1}^\infty$ tiene convergencia **casi segura** hacia la variable $X$ cuya **función de probabilidad** es:
<div class="center">
| $X$| 1 | 2 | 3 | 4 | 5 | 6
|--|--|--|--|--|--|--|
| $P_X$  | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$
</div>

En este caso el espacio muestral $\Omega$ es $\Omega=\{1,2,3,4,5,6\}$ y la **función de probabilidad** de cada $X_i$ corresponde con la tabla anterior. 

Seguidamente, de cara a aplica la proposición anterior, vamos a hallar la **función de probabilidad** de la variable $D_n=X_n-X$.
Los valores de la variable anterior son: $D_n(\Omega)=\{-5,-4,-3,-2,-1,0,1,2,3,4,5\}$.

La **función de probabilidad** conjunta de la variable $(X_n,X)$ será al ser $X_n$ y $X$ independientes:
$$
P_{X_nX}(x_n,x)=P_{X_n}(x_n)\cdot P_X(x)=\frac{1}{6}\cdot \frac{1}{6}=\frac{1}{36},
$$
para todo $x_n=1,2,3,4,5,6$ y para todo $x=1,2,3,4,5,6$.

</div>

### Ejemplo
<div class="example">
La **función de probabilidad** de la variable $D_n$ será:
$$
\begin{array}{rl}
P_{D_n}(-5) & =P_{X_nX}(1,6)=\frac{1}{36}, \\
P_{D_n}(-4) & =P_{X_nX}(2,6)+P_{X_nX}(1,5)=\frac{2}{36}, \\
P_{D_n}(-3) & =P_{X_nX}(3,6)+P_{X_nX}(2,5)+P_{X_nX}(1,4)=\frac{3}{36}, \\
P_{D_n}(-2) & =P_{X_nX}(4,6)+P_{X_nX}(3,5)+P_{X_nX}(2,4)+P_{X_nX}(1,3)=\frac{4}{36}, \\
P_{D_n}(-1) & =P_{X_nX}(5,6)+P_{X_nX}(4,5)+P_{X_nX}(3,4)+P_{X_nX}(2,3)+P_{X_nX}(1,2)=\frac{5}{36}, \\
P_{D_n}(0) & =P_{X_nX}(6,6)+P_{X_nX}(5,5)+P_{X_nX}(4,4)+P_{X_nX}(3,3)+P_{X_nX}(2,2)+P_{X_nX}(1,1)=\frac{6}{36}, \\
P_{D_n}(1) & =P_{X_nX}(6,5)+P_{X_nX}(5,4)+P_{X_nX}(4,3)+P_{X_nX}(3,2)+P_{X_nX}(2,1)=\frac{5}{36}, \\
P_{D_n}(2) & =P_{X_nX}(6,4)+P_{X_nX}(5,3)+P_{X_nX}(4,2)+P_{X_nX}(3,1)=\frac{4}{36}, \\
P_{D_n}(3) & =P_{X_nX}(6,3)+P_{X_nX}(5,2)+P_{X_nX}(4,1)=\frac{3}{36}, \\
P_{D_n}(4) & =P_{X_nX}(6,2)+P_{X_nX}(5,1)=\frac{2}{36}, \\
P_{D_n}(5) & =P_{X_nX}(6,1)=\frac{1}{36}.
\end{array}
$$

</div>

### Ejemplo
<div class="example">
Sea $\epsilon$ un valor real entre 0 y 1: $0<\epsilon <1$. Entonces el suceso $\{|D_n|>\epsilon\}$ será el complementario del suceso $\{D_n=0\}$ ya que el único valor entre $-5$ y $5$ que no cumple $|D_n|>\epsilon$ es el valor $D_n=0$. Por tanto:
$$
P(|D_n|>\epsilon)=1-P(D_n=0)=1-P_{D_n}(0)=1-\frac{1}{6}=\frac{5}{6}.
$$
La serie $\sum\limits_{n=1}^\infty \frac{5}{6}$ no es convergente de forma obvia. Por tanto, deducimos que la sucesión $\{X_n\}_{n=1}^\infty$ no converge **casi seguramente** hacia la variable $X$.

</div>


### Convergencia en probabilidad
<l class="definition"> Definición de convergencia en probabilidad. </l>
Sea $X_1,\ldots,X_n,\ldots$ una sucesión de variables aleatorias y sea $X$ una variable aleatoria definida sobre el mismo espacio muestral $\Omega$ y con la misma probabilidad de sucesos. Diremos que la sucesión $\{X_n\}_{n=1}^\infty$ converge **en probabilidad** hacia $X$ si para cualquier valor $\epsilon >0$,
$$
\lim_{n\to\infty} P(|X_n-X|>\epsilon \})=0.
$$
Lo denotaremos por $X_n\stackrel{c.p.}{\longrightarrow}X$.

### Convergencia en probabilidad
O sea, límite de la probabilidad de los sucesos formados por los $w\in\Omega$ tal que $|X_n(w)-X(w)|>\epsilon$ vale 0.

<l class="observ">Observación.</l>
Una definición equivalente de **convergencia en probabilidad** es que para todo valor $\epsilon >0$,
$$
\lim_{n\to\infty} P(|X_n(w)-X(w)|\leq \epsilon \})=1.
$$
<l class="observ">Observación. </l>
La convergencia **casi segura** implica la convergencia **en probabilidad** ya que si la sucesión $\{X_n\}_{n=1}^\infty$ converge **casi seguramente** hacia $X$, la serie $\sum_{n=1}^\infty P(|X_n-X|>\epsilon)$ será convergente y, por tanto, el límite de su término $P(|X_n-X|>\epsilon)$ tenderá a cero, hecho que equivale a la convergencia **en probabilidad**.



### Convergencia en probabilidad

El siguiente resultado nos puede ayudar algunas veces a comprobar la **convergencia en probabilidad**:

<l class="prop">Proposición. </l>
Sea $X_1,\ldots,X_n,\ldots$ una sucesión de variables aleatorias. Sea $\mu_n$ el valor medio de la variable $X_n$, $E(X_n)=\mu_n$ y $\sigma_n^2$ su varianza: $\mathrm{Var}(X_n)=\sigma_n^2$. Supongamos que $\lim_{n\to\infty}\sigma_n^2=0$. Entonces,
$$
X_n-\mu_n\stackrel{c.p.}{\longrightarrow} 0.
$$

### Convergencia en probabilidad

<div class="dem">
**Demostración**

Usando la desigualdad de Chebyschev, podemos escribir:
$$
P(|X_n-\mu_n|>\epsilon \}) \leq \frac{\sigma_n^2}{\epsilon^2}.
$$
Tomando límite a cada parte de la desigualdad anterior tenemos:
$$
0\leq \lim_{n\to\infty} P(|X_n-X|>\epsilon \}) \leq \lim_{n\to\infty}\frac{\sigma_n^2}{\epsilon^2}=0,
$$
de donde deducimos que $\lim_{n\to\infty} P(|X_n-X|>\epsilon \})=0$, tal como queríamos ver.
</div>

### Ejemplo
<div class="example">
**Ejemplo del lanzamiento de un dado**

En el ejemplo anterior del lanzamiento de un dado, no hay convergencia en probabilidad ya que comprobamos que para $0<\epsilon<1$,
$$
P(|X_n-X|>\epsilon)=\frac{5}{6}.
$$
Por tanto, para $0<\epsilon<1$,  $\lim_{n\to\infty} P(|X_n-X|>\epsilon \})=\frac{5}{6}\neq 0.$
</div>


### Ejemplo
<div class="example">
**Ejemplo**

Consideremos las variables aleatorias $X_n$ con función de densidad:
$$
f_{X_n}(x)=\begin{cases}
\lambda n\mathrm{e}^{-\lambda n x}, & \mbox{si }x>0,\\
0, & \mbox{en caso contrario.}
\end{cases}
$$
O sea, $X_n$ son exponenciales de parámetro $\lambda n$.

Veamos que $\{X_n\}_{n=1}^\infty\stackrel{c.p}{\longrightarrow} 0$.

Dado $\epsilon >0$, calculemos $P(|X_n|>\epsilon \})$:
$$
P(|X_n|>\epsilon \}) = \int_\epsilon^\infty \lambda n\mathrm{e}^{-\lambda n x}\, dx =\lambda n \left[\frac{1}{-\lambda n}\mathrm{e}^{-\lambda n x}\right]_\epsilon^\infty =\mathrm{e}^{-\lambda n \epsilon}\stackrel{n\to\infty}{\longrightarrow} 0,
$$
tal como queríamos ver.


</div>

### Convergencia en ley o en distribución 
<l class="definition"> Definición de convergencia en ley o distribución. </l>
Sea $X_1,\ldots,X_n,\ldots$ una sucesión de variables aleatorias y sea $X$ una variable aleatoria definida sobre el mismo espacio muestral $\Omega$ y con la misma probabilidad de sucesos. Sea $F_{X_n}$ y $F_X$ las funciones de distribución de la variable $X_n$ y $X$, respectivamente. Diremos que la sucesión $\{X_n\}_{n=1}^\infty$ converge **en ley, o en distribución** hacia $X$ si,
$$
\lim_{n\to\infty} F_{X_n}(x)=F(x),
$$
para todo valor $x\in\mathbb{R}$.

Lo denotaremos por $X_n\stackrel{{\cal L}}{\longrightarrow}X$.

### Convergencia en ley o en distribución 
El resultado siguiente simplifica algunas veces comprobar que la sucesión $X_n$ converge en ley hacia $X$:

<l class="prop"> Proposición. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias y sea $X$ una variable aleatoria definida sobre el mismo espacio muestral $\Omega$ y con la misma probabilidad de sucesos. Sean $\FunCar_{X_n}$ y $\FunCar_X$ las funciones características de $X_n$ y $X$, respectivamente. Entonces, la sucesión converge **en ley** hacia $X$, $X_n\stackrel{{\cal L}}{\longrightarrow}X$, si, y sólo si,
$$
\lim_{n} \FunCar_{X_n}(t) = \FunCar_X(t),
$$
para cualquier número $t\in\mathbb{R}$.

### Ejemplo
<div class="example">
**Ejemplo de la distribución binomial $B(n,p)$**

Veamos que si $X_n=B(n,p_n)$ tiene distribución binomial de parámetros $n$ y $p_n$, con $p_n=\frac{\lambda}{n}$, con $\lambda$ fijo,
$$
B(n,p)\stackrel{{\cal L}}{\longrightarrow}Poiss(\lambda).
$$

En el tema de distribuciones notables demostramos que para todo $k\in\{0,\ldots,n\}$,
$$
P(X_n = k)=\binom{n}{k}\cdot p_n^k\cdot (1-p_n)^{n-k}\stackrel{n\to\infty}{\longrightarrow} P(X=k)=\frac{\lambda^k}{k!}\cdot\mathrm{e}^{-\lambda}.
$$
Entonces tenemos que dado $x\in\mathbb{R}$, existe $k\in\{0,\ldots,n\}$, tal que $k\leq x< k+1$. Por tanto,
$$
\begin{array}{rl}
\lim\limits_{n\to\infty} F_{X_n}(x) & = \lim\limits_{n\to\infty} F_{X_n}(k)=\lim\limits_{n\to\infty} P(X_n=0)+\cdots + P(X_n=k) \\  & =\lim\limits_{n\to\infty} P(X_n=0)+\cdots + \lim\limits_{n\to\infty} P(X_n=k) = P(X=0)+\cdots + P(X=k)\\ &  =F_X(k)=F_X(x),
\end{array}
$$
tal como queríamos demostrar.
</div>

### Relaciones entre las distintas convergencias
El resultado siguiente nos dice cuando un tipo de convergencia implica la otra:

<l class="prop"> Proposición. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias y sea $X$ una variable aleatoria definida sobre el mismo espacio muestral $\Omega$ y con la misma probabilidad de sucesos. Entonces:

* Si $X_n\stackrel{c.s.}{\longrightarrow} X$, entonces $X_n\stackrel{c.p.}{\longrightarrow} X$.

* Si $X_n\stackrel{c.p.}{\longrightarrow} X$, entonces $X_n\stackrel{{\cal L}}{\longrightarrow} X$.

En resumen, la convergencia más fuerte es la **casi segura**, luego vendría la convergencia **en probabilidad** y, por último, la convergencia **en ley**:

$$
\mbox{Conv. casi segura }\Rightarrow \mbox{ Conv. en probabilidad }\Rightarrow\mbox{ Conv. en ley.}
$$

## Leyes de los grandes números

### Introducción 

Como ya comentamos al principio del tema, las **leyes de los grandes números** estudian el comportamiento de la **media muestral** $\overline{X}_n$ cuando la sucesión de variables aleatorias $\{X_n\}_{n=1}^\infty$ se va hacia infinito.

Más concretamente, diremos que una sucesión de variables aleatorias $\{X_n\}_{n=1}^\infty$ cumple una **ley de los grandes números** si existe un sucesión numérica $(a_n)_n$ tal que la sucesión de variables aleatorias $\{\overline{X}_n-a_n\}$ converge "de alguna manera" de las que hemos visto hacia 0.

Si este "alguna manera" es la convergencia más fuerte, o la **casi segura**, tendremos la **ley fuerte de los grandes números**. 

En cambio, si la convergencia es **en probabilidad**, tendremos la **ley débil de los grandes números**.

### Leyes débiles de los grandes números
<l class="prop"> Teorema. Ley débil de los grandes números. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes dos a dos tal que sus varianzas existen y están acotadas por una constante independiente de $n$. Entonces,
$$
\overline{X}_n-\frac{1}{n}\sum_{i=1}^n \mu_i\stackrel{c.p.}{\longrightarrow} 0,
$$
donde $\mu_i = E(X_i)$.

Dicho en otras palabras: en las condiciones de la proposición anterior, la diferencia entre la sucesión de **medias muestrales** como variables aleatorias y la sucesión numérica de la medias poblacionales de dichas variables aleatorias tiende en **probabilidad** hacia 0.

### Leyes débiles de los grandes números
<div class="dem">
**Demostración**

Como las variables son independientes dos a dos la varianza de la suma es la suma de las varianzas:
$$
\mathrm{Var}(\overline{X}_n)=\frac{1}{n^2}\mathrm{Var}(\sum_{i=1}^n X_i)=\frac{1}{n^2}\sum_{i=1}^n \sigma_i^2,
$$
donde $\sigma_i^2 = \mathrm{Var}(X_i)$.

Sabemos por hipótesis que existe una constante $M$ tal que $\sigma_i^2\leq M$ para todo $i$. Por tanto,
$$
\mathrm{Var}(\overline{X}_n)=\frac{1}{n^2}\sum_{i=1}^n \sigma_i^2\leq \frac{1}{n^2}Mn =\frac{M}{n}.
$$
</div>

### Leyes débiles de los grandes números
<div class="dem">
El valor del valor medio de la media muestral será:
$$
E(\overline{X}_n)=\frac{1}{n}\sum_{i=1}^n E(X_i)=\frac{1}{n}\sum_{i=1}^n \mu_i. 
$$
Usando la desigualdad de Chebyschev, deducimos, dado un $\epsilon >0$:
$$
P\left(\left|\overline{X}_n-\frac{1}{n}\sum_{i=1}^n \mu_i\right|>\epsilon\right) \leq \frac{\mathrm{Var}(\overline{X}_n)}{\epsilon^2}\leq \frac{M}{n\epsilon^2}.
$$
Por tanto, tomando límites en las dos partes de la desigualdad anterior, deducimos
$$
\lim_{n\to \infty}P\left(\left|\overline{X}_n-\frac{1}{n}\sum_{i=1}^n \mu_i\right|>\epsilon\right) =0,
$$
tal como queríamos ver.

</div>

### Leyes débiles de los grandes números

Derivadas del teorema anterior tenemos las consecuencias siguientes:

<l class="prop">Corolario. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes dos a dos tal que todas tienes la misma esperanza $\mu$ y la misma varianza $\sigma^2$. Entonces,
$$
\overline{X}_n\stackrel{c.p.}{\longrightarrow} \mu,
$$

<div class="dem">
**Demostración**

En este caso tenemos que $\mu_i=\mu$ y, por tanto, $\frac{1}{n}\sum\limits_{i=1}^n \mu_i =\frac{1}{n}\cdot n\mu=\mu$. Si aplicamos el teorema de la **ley débil de los grandes números** nos sale el resultado enunciado.
</div>

### Leyes débiles de los grandes números

Derivadas del teorema anterior tenemos las consecuencias siguientes:

<l class="prop">Corolario. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes dos a dos e idénticamente distribuidas tal que todas tienes la misma esperanza $\mu$. Entonces,
$$
\overline{X}_n\stackrel{c.p.}{\longrightarrow} \mu,
$$

<div class="dem">
**Demostración**

Trivial a partir del Corolario anterior.
</div>

### Ejemplo
<div class="example">
**Ejemplo del lanzamiento de una moneda**

Vamos a simular la **ley débil de los grandes números** en el caso en que el experimento aleatorio sea el lanzamiento de una moneda.

En este caso, tendremos que las variables aleatorias $X_n$ tendrán distribución de Bernoulli de parámetro $p=\frac{1}{2}$.

La variable $\overline{X}_n$ representa la proporción de caras ($X_n=1$) en el lanzamiento de la moneda $n$ veces. Nos preguntamos si dicha proporción de caras tiende al parámetro $p$ en probabilidad.

Vamos a hallar una muestra para cada variable $\overline{X}_n=\frac{\sum\limits_{i=1}^n X_i}{n}$.

Para ello, vamos a repetir el experimento de lanzar la moneda $N=100$ veces y lo repetimos $k=500$ ocasiones. 

Los resultados estarán en una matriz $k\times N =500\times 100$ donde cada fila de la matriz simulará una repetición del experimento de lanzar la moneda $N=100$ veces.
</div>

### Ejemplo
<div class="example">
Dada la fila $i$-ésima, iremos calculando $\overline{X}_1^{(i)},\overline{X}_2^{(i)},\ldots,\overline{X}_{N=100}^{(i)}$.

Luego, fijado un $\epsilon$, para cada $n$, aproximaremos la probabilidad $P\left(\left|\overline{X}_n-\frac{1}{2}\right|>\epsilon\right)$ usando la fórmula de Laplace: 
$$
p_n=P\left(\left|\overline{X}_n-\frac{1}{2}\right|>\epsilon\right) \approx\frac{\#\left\{\mbox{$i$ tal que  $\left|\overline{X}_n^{(i)}-\frac{1}{2}\right|>\epsilon$}\right\}}{k}.
$$

Para comprobar dicha afirmación, la idea es hallar para cada valor $n$, una muestra para cada variable $\overline{X}_n=\frac{\sum\limits_{i=1}^n X_i}{n}$.
</div>


### Ejemplo
<div class="example">
Para hallar una muestra de cada variable $\overline{X}_n$, seguimos los pasos siguientes:

* En primer lugar, simulamos la repetición del experimento de lanzar la moneda $N=100$ veces y lo repetimos $k=500$ ocasiones. 
Los resultados estarán en una matriz $k\times N =500\times 100$ donde cada fila de la matriz simulará una repetición del experimento de lanzar la moneda $N=100$ veces:
```{r}
N=100
k=500
set.seed(2019) ## fijamos la semila de aleatoriedad para que a todos nos dé lo mismo
valores.experimento=matrix(sample(c(0,1),N*k,replace=TRUE),k,N)
```
Los primeros resultados son:

```{r,echo=FALSE}
valores.experimento[1:5,1:13]
```

...
</div>


### Ejemplo
<div class="example">

* En segundo lugar, dada la fila $i$-ésima de la matriz anterior, iremos calculando $\overline{X}_1^{(i)},\overline{X}_2^{(i)},\ldots,\overline{X}_{N=100}^{(i)}$ guardando los resultados en una matriz de medias muestrales.
Antes de nada, creamos la función que nos realizará la operación anterior dado un vector cualquiera `x`:

```{r}
cálculo.xnbarra = function(x){
  return(cumsum(x)/(1:length(x)))
}
```

A partir de la matriz de los resultados, aplicamos la función anterior a cada fila y hallaremos una matriz con todas las $\overline{X}_n^{(i)}$:
```{r}
matriz.medias.muestrales = t(apply(valores.experimento,1,cálculo.xnbarra))
```

La columna $j$-ésima de la matriz `matriz.medias.muestrales` contiene una muestra de $k=500$ valores de la variable $\overline{X}_j$.
</div>

### Ejemplo
<div class="example">

* En último lugar, fijado un $\epsilon$, para cada $n$, aproximaremos la probabilidad $P\left(\left|\overline{X}_n-\frac{1}{2}\right|>\epsilon\right)$ usando la fórmula de Laplace: 
$$
p_n=P\left(\left|\overline{X}_n-\frac{1}{2}\right|>\epsilon\right) \approx\frac{\#\left\{\mbox{$i$ tal que  $\left|\overline{X}_n^{(i)}-\frac{1}{2}\right|>\epsilon$}\right\}}{k}.
$$
La columna $j$-ésima de la matriz `matriz.medias.muestrales` es una muestra de la variable $\overline{X}_j$. Por tanto, para hallar la aproximación de $p_n$, miramos cuántos valores de la columna $j$-ésima de la matriz anterior verifican $\left|\overline{X}_j^{l}-\frac{1}{2}\right|>\epsilon$, para $l=1,\ldots, k$:
```{r}
epsilon=0.1
probabilidades.pn= colSums(abs(matriz.medias.muestrales-0.5) > epsilon)/k
```
</div>

### Ejemplo
<div class="example">
Para ver los resultados, dibujamos el gráfico $n$ vs. $p_n$:
```{r,eval=FALSE}
plot(1:N,probabilidades.pn,type="l",xlab=expression(N),ylab=expression(p[n]),col="red")
```
Observamos que las probabilidades tienden a cero tal como nos dice el **Teorema de la ley débil de los grandes números**.

</div>




</div>

### Ejemplo

<div class="center">
```{r, echo=FALSE,fig=TRUE,fig.height=5.8}
epsilon=0.1
probabilidades.pn= colSums(abs(matriz.medias.muestrales-0.5) > epsilon)/k
#probabilidades.pn = c()
## for (j in 1:N){
##   pn=length(matriz.medias.muestrales[(abs(matriz.medias.muestrales[,j]-0.5)>epsilon),j])/k
##   probabilidades.pn=c(probabilidades.pn,pn)
## }
plot(1:N,probabilidades.pn,type="l",xlab=expression(N),ylab=expression(p[n]),main="Simulación de la convergencia en probabilidad",col="red")
```
</div>


### Convergencia de los momentos muestrales
Dada una sucesión de variables aleatorias, definimos los momentos muestrales de la forma siguiente:

<l class="definition"> Definición de los momentos muestrales de una sucesión de variables aleatorias.</l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias. Dado $k$ valor entero positivo, definimos el **momento muestral** de orden $k$ como la sucesión de variables aleatorias siguientes:
$$
\Momk_k^{(n)} = \frac{1}{n}\sum_{i=1}^n X_i^k.
$$

<l class="observ"> Observación: </l>
el **momento muestral** de orden $k=1$ es la **media muestral** $\overline{X}_n$.


### Convergencia de los momentos muestrales
<l class="definition"> Definición de los momentos muestrales centrados de una sucesión de variables aleatorias.</l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias. Dado $k$ valor entero positivo, definimos el **momento muestral centrado en la media** de orden $k$ como la sucesión de variables aleatorias siguientes:
$$
\MomCenk_k^{(n)} = \frac{1}{n}\sum_{i=1}^n (X_i-\overline{X}_n)^k.
$$

<l class="observ"> Observación: </l>
el **momento muestral centrado en la media** de orden $k=2$ es la **varianza muestral** $S_{X_n}^2$.


### Convergencia de los momentos muestrales
<l class="definition"> Definición de la covarianza y el coeficiente de correlación muestral de una sucesión de variables aleatorias.</l>
Sea $\{(X_n,Y_n)\}_{n=1}^\infty$ una sucesión de variables aleatorias bidimensionales. Definimos la  **covarianza muestral** como la sucesión de variables aleatorias siguientes:
$$
S_{X_n,Y_n} = \frac{1}{n}\sum_{i=1}^n (X_i-\overline{X}_n)(Y_i-\overline{Y}_n),
$$
y el **coeficiente de correlación muestral** como la sucesión de variables aleatorias siguientes:
$$
R_{X_n,Y_n}=\frac{S_{X_n,Y_n}}{\sqrt{S_{X_n}^2 S_{Y_n}^2}}.
$$

### Convergencia de los momentos muestrales
Dada $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias y $k$ un valor entero positivo, en el tema de Complementos de variables aleatorias, definimos los momentos y los momentos centrales de orden $k$ para cada de dichas variables como:
$$
\momento_k^{(n)} = E\left(X_n^k\right),\quad\momentocentral_k^{(n)}=E\left(\left(X_n-\mu_n\right)^k\right),
$$
donde $\mu_n$ es el valor medio de la variable $X_n$: $\mu_n = E(X_n)$.

### Convergencia de los momentos muestrales
Así mismo, dada $\{(X_n,Y_n)\}_{n=1}^\infty$ una sucesión de variables aleatorias bidimensionales, en el tema de variables aleatorias bidimensionales definimos para cada variable $(X_n,Y_n)$ la covarianza $\sigma_{X_nY_n}$ y el coeficiente de correlación $\rho_{X_nY_n}$:
$$
\sigma_{X_nY_n}=E((X_n-\mu_{X_n})(Y_n-\mu_{Y_n})),\quad \rho_{X_nY_n}=\frac{\sigma_{X_nY_n}}{\sqrt{\sigma_{X_n}^2\sigma_{Y_n}^2}}.
$$

### Convergencia de los momentos muestrales
Dada una sucesión de variables aleatorias $\{X_n\}_{n=1}^\infty$, el resultado siguiente nos relaciona los **momentos muestrales** y los **momentos muestrales centrados en la media** con los **momentos** y los **momentos centrales** de cada variable:

<l class="prop"> Teorema. Convergencia de los momentos muestrales y los momentos muestrales centrados en la media. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias **independientes dos a dos e idénticamente distribuidas** y dado un entero positivo $k$, supongamos que para cada $n$, existe el **momento de orden $k$**, $\momento_k$ y el **momento central de orden $k$**, $\momentocentral_k$, que no dependerán de $n$ al ser idénticamente distribuidas. Entonces las sucesiones de variables aleatorias $\{\Momk_n^{(k)}\}_{n=1}^\infty$ y $\{\MomCenk_n^{(k)}\}_{n=1}^\infty$ tienden a $\momento_k$ y $\momentocentral_k$, respectivamente, en **probabilidad**
$$
\Momk_n^{(k)}\stackrel{c.p.}{\longrightarrow} \momento_k,\quad \MomCenk_n^{(k)}\stackrel{c.p.}{\longrightarrow} \momentocentral_k.
$$


### Convergencia de los momentos muestrales
<div class="dem">
**Demostración**

Consideremos la sucesión de variables aleatorias $\{X_n^k\}_{n=1}^\infty$. Como las variables aleatorias de la sucesión  $\{X_n\}_{n=1}^\infty$ son independientes dos a dos e idénticamente distribuidas, las variables de la sucesión $\{X_n^k\}_{n=1}^\infty$ también lo serán.

La idea es aplicar la **ley débil de los grandes números** a la sucesión anterior.

El valor medio de cada variable de la sucesión $\{X_n^k\}_{n=1}^\infty$ será: $\tilde{\mu}_n^{(k)}= E(X_n^{k})=\momento_k$ el momento de orden $k$.

Entonces, si hacemos $\frac{1}{n}\sum\limits_{i=1}^n \tilde{\mu}_n^{(k)}$ obtenemos:
$\frac{1}{n} n\cdot \momento_k=\momento_k.$

</div>

### Convergencia de los momentos muestrales
<div class="dem">
Aplicando la **ley débil de los grandes números** a la sucesión $\{X_n^k\}_{n=1}^\infty$, tendremos que
$$
\overline{X^k}_n \stackrel{c.p.}{\longrightarrow}\momento_k,
$$
pero $\overline{X^k}_n$ vale:
$$
\overline{X^k}_n=\frac{1}{n}\sum_{i=1}^n X_i^k,
$$
variable aleatoria que coincide con el momento muestral de orden $k$, $\Momk_n^{(k)}$, tal como queríamos demostrar.

Dejamos como ejercicio la demostración de los momentos centrales. Razonando de la misma manera, no tiene dificultad alguna.



</div>

### Convergencia de los momentos muestrales
Enunciemos ahora el resultado para las covarianzas y las correlaciones muestrales:

<l class="prop"> Teorema: convergencia de la covarianza y el coeficiente de correlación muestrales. </l>
Sea $\{(X_n,Y_n)\}_{n=1}^\infty$ una sucesión de variables aleatorias bidimensionales independientes dos a dos e idénticamente distribuidas. 
Sea $\sigma_{X,Y}, \rho_{XY}$ la covarianza y el coeficiente de correlación de cada par de variables que, al ser idénticamente distribuidas, no dependen de $n$. Entonces las sucesiones de las covarianzas muestrales $\{S_{X_n,Y_n}\}_{n=1}^\infty$ y los coeficientes de correlación muestrales $\{R_{X_nY_n}\}_{n=1}^\infty$ tienden en probabilidad hacia $\sigma_{XY}$ y $\rho_{XY}$, respectivamente:
$$
S_{X_n,Y_n}\stackrel{c.p.}{\longrightarrow}\sigma_{XY},\quad R_{X_nY_n}\stackrel{c.p.}{\longrightarrow}\rho_{XY}.
$$


### Convergencia de los momentos muestrales
<div class="dem">
**Demostración**

Para la demostración basta aplicar la **ley débil de los grandes números** a las sucesiones $\{S_{X_n,Y_n}\}_{n=1}^\infty$ y $\{R_{X_nY_n}\}_{n=1}^\infty$. Dejamos los detalles como ejercicio.
</div>

### Leyes fuertes de los grandes números

Vamos a dar una versión de la ley débil de los grandes números pero en lugar de tener convergencia **en probabilidad**, tendremos convergencia **casi segura**.


<l class="prop"> Teorema de Kolmogorov. Ley fuerte de los grandes números. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes y con varianza $\sigma_n^2$. Supongamos que la serie
$\sum\limits_{n=1}^\infty \frac{\sigma_n^2}{n^2},$
es convergente. Entonces la sucesión de las medias muestrales $\{\overline{X}_n\}_{n=1}^\infty$ cumplen la
llamada **ley fuerte de los grandes números**:
$$
\overline{X}_n-\frac{1}{n}\sum_{i=1}^n \mu_i \stackrel{c.s.}{\longrightarrow} 0.
$$

### Leyes fuertes de los grandes números
Asociados al resultado anterior tenemos los corolarios siguientes:

<l class="prop"> Corolario. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes y con varianza $\sigma_n^2$. Supongamos que existe una constante $M$ tal que todas las varianzas están acotadas por $M$: $\sigma_n^2\leq M$, para todo $n$.
Entonces la sucesión de las medias muestrales $\{\overline{X}_n\}_{n=1}^\infty$ cumplen la
llamada **ley fuerte de los grandes números**:
$$
\overline{X}_n-\frac{1}{n}\sum_{i=1}^n \mu_i \stackrel{c.s.}{\longrightarrow} 0.
$$

### Leyes fuertes de los grandes números
<div class="dem">
**Demostración**

Si $\sigma_n^2\leq M$ para todo $n$, la serie numérica $\sum\limits_{n=1}^\infty \frac{\sigma_n^2}{n^2}$ será convergente ya que, por el criterio de acotación,
$$
\sum\limits_{n=1}^\infty \frac{\sigma_n^2}{n^2}\leq M\sum\limits_{n=1}^\infty \frac{1}{n^2},
$$
que es convergente.

Entonces aplicando el **Teorema de Kolmogorov** o la **ley fuerte de los grandes números**, tenemos el resultado.

</div>

### Leyes fuertes de los grandes números
<l class="prop"> Corolario. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes de Bernoulli con el mismo parámetro $p$ que es lo mismo que decir que son idénticamente distribuidas.
Entonces la sucesión de las medias muestrales convergen **casi seguramente** hacia $p$:
$$
\overline{X}_n \stackrel{c.s.}{\longrightarrow} p.
$$

<div class="dem">
**Demostración**

En este caso: 
$$
\frac{1}{n}\sum_{i=1}^n \mu_i = \frac{1}{n}\cdot np=p.
$$
También se verifica que $\sigma_n^2 =p(1-p)$. Por tanto, existe una constante $M$ ($M=p(1-p)$) tal que $\sigma_n^2\leq M$. Aplicando el Corolario anterior, obtenemos el resultado.

</div>

### Ejemplo
<div class="example">
**Ejemplo**

Vamos a repetir el ejemplo de las variables aleatorias de Bernoulli $X_n$, todas de parámetro $p=\frac{1}{2}$ y comprobar que las proporciones de caras cuando lanzamos la moneda $n$ veces, o sea, las medias muestrales $\overline{X}_n$ tienden **casi seguramente** hacia $p=\frac{1}{2}$.

La comprobación anterior es equivalente a ver que la serie:
$$
\sum_{n=1}^\infty P(|\overline{X}_n-p|>\epsilon),
$$
es convergente fijado $\epsilon >0$.
</div>

### Ejemplo
<div class="example">
Recordemos que en la variable `probabilidades.pn` calculábamos las probabilidades $P(|\overline{X}_n-p|>\epsilon)$ para un $\epsilon =0.1$. 

Comprobar que la serie anterior es convergente es equivalente a comprobar que las sumas parciales convergen:

```{r,eval=FALSE}
cumsum(probabilidades.pn)
```

El problema es que la `n` y la `N` escogidas son demasiado pequeñas. Para realizar el experimento actual tenéis que considerar `n=1000` y `N=5000`. Id con cuidado que el programa os tardará un rato.

```{r,echo=FALSE}
probabilidades.pn = read.table("../scripts/Probabilidadesn.txt")
probabilidades.pn = t(probabilidades.pn)
```
El gráfico de las sumas parciales se muestra a continuación:
```{r,eval=FALSE}
N=1000
plot(1:N,cumsum(probabilidades.pn),xlab=expression(n),
     ylab="Sumas parciales",col='red', type='l')
```
Como se puede observar, la serie parece que converge.

</div>

### Ejemplo

<div class="center">
```{r,echo=FALSE}
N=1000
plot(1:N,cumsum(probabilidades.pn),xlab=expression(n),ylab="Sumas parciales",col='red', type='l')
```
</div>

## Teorema Central del Límite

### Introducción

Sabemos que si una sucesión $\{X_n\}$ está formada por variables normales, la sucesión de medias muestrales $\left\{\overline{X}_n=\frac{\sum\limits_{i=1}^n X_i}{n}\right\}_{n=1}^\infty$ también son normales ya que vimos en el tema de variables multidimensionales que si aplicamos una transformación afín (y, en particular, lineal) a una variable normal multidimensional, el resultado es una normal.

Para calcular la variable $\overline{X}_n$, es obvio que la transformación lineal es la siguiente:
$$
\overline{X}_n = \left(\frac{1}{n},\ldots,\frac{1}{n}\right)\begin{pmatrix}X_1 \\\vdots\\ X_n\end{pmatrix}.
$$

### Introducción

Si además la sucesión de variables $X_n$ son normales todas con media $\mu$ y varianza $\sigma^2$, la sucesión $\left\{\overline{X}_n\right\}_{n=1}^\infty$ serán normales de media $\mu$ y varianza $\frac{\sigma^2}{n}$.

Estandarizando las variables anteriores, podemos concluir que las variables medias estandarizadas $Z_n =\left\{\frac{\overline{X}_n-\mu}{\frac{\sigma}{\sqrt{n}}}\right\}_{n=1}^\infty$ todas son $N(0,1)$.

El **Teorema Central del Límite** generaliza el resultado anterior en el sentido de que si las variables $X_n$ no tienen por qué tener la distribución normal pero son independientes e idénticamente distribuidas, las variables $Z_n$ correspondientes tienden **en ley** a una distribución normal estándar $N(0,1)$.

En general, se dice que los valores medios de cualquier secuencia de números  aproximadamente corresponde a una muestra de una normal.

### Teorema Central del Límite
<l class="prop"> Teorema Central del Límite </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes e idénticamente distribuidas con $E(X_n)=\mu$ y $\mathrm{Var}(X_n)=\sigma^2$ para todo $n$. Entonces:
$$
\frac{\sum\limits_{i=1}^n X_i-n\mu}{\sigma\sqrt{n}}\stackrel{{\cal L}}{\longrightarrow} N(0,1).
$$

### Teorema Central del Límite
<l class="observ"> Observación. </l>
Una condición equivalente a la tesis del **Teorema Central del Límite** es:
$$
\frac{\overline{X}_n-\mu}{\frac{\sigma}{\sqrt{n}}}\stackrel{{\cal L}}{\longrightarrow} N(0,1).
$$
Basta dividir por $n$ el numerador y el denominador de la tesis original del **Teorema Central del Límite**.

### Demostración
Para la demostración, usaremos dos propiedades de la función característica:

<l class="prop"> Proposición. </l>
Sea $Y_1,\ldots, Y_n$ $n$ variables aleatorias independientes. Sea $S_n$ la variable aleatoria suma de las variables anteriores, $S_n=\sum\limits_{i=1}^n Y_i$. Entonces, para calcular $\FunCar_{S_n}$, podemos usar la expresión siguiente::
$$
\FunCar_{S_n}(w)=\FunCar_{Y_1}(w)\cdots \FunCar_{Y_n}(w),
$$
donde $w$ es cualquier valor real.


### Demostración
<div class="dem">
**Demostración de la proposición**

Por definición:
$$
\begin{array}{rl}
\FunCar_{S_n}(w) & =E\left(\mathrm{e}^{\mathrm{i} w S_n}\right)=E\left(\mathrm{e}^{\mathrm{i} w \sum\limits_{i=1}^n Y_i}\right) = E\left(\mathrm{e}^{i w Y_1}\cdots \mathrm{e}^{i w Y_n}\right)\\ & \stackrel{\mbox{$Y_1,\ldots,Y_n$ son independientes}}{=} E\left(\mathrm{e}^{i w Y_1}\right)\cdots E\left(\mathrm{e}^{i w Y_n}\right) =\FunCar_{Y_1}(w)\cdots \FunCar_{Y_n}(w).
\end{array}
$$
</div>

### Demostración

<l class="prop"> Proposición. </l>
Sea $Y$ una variable aleatoria. Sea $U=kY$ la variable aleatoria $Y$ multiplicada por un valor real $k$. Entonces, para calcular $\FunCar_{U}$, podemos usar la expresión siguiente:
$$
\FunCar_{U}(w)=\FunCar_Y(kw),
$$
donde $w$ es cualquier valor real.


<div class="dem">
**Demostración de la proposición**

Por definición:
$$
\FunCar_{U}(w)=E\left(\mathrm{e}^{\mathrm{i} w U}\right) = E\left(\mathrm{e}^{\mathrm{i} w k Y}\right)=\FunCar_Y(kw).
$$
</div>

### Demostración


<div class="dem">
**Demostración del Teorema Central del Límite**

Usando la proposición que vimos al introducir la **convergencia en ley** que dice que una sucesión $\{X_n\}$ converge **en ley** hacia $X$ si, y sólo si, $\lim\limits_{\FunCar_{X_n}(t)}=\FunCar_{X}(t)$, donde $\FunCar$ representa la función característica y la condición anterior tiene que verificarse para todo valor $t\in\mathbb{R}$, basta demostrar que, si llamamos $Z_n$ a
$Z_n = \frac{\sum\limits_{i=1}^n X_i-n\mu}{\sigma\sqrt{n}},$
$$
\lim_{n\to \infty}\FunCar_{Z_n}(w)=\FunCar_Z(w),
$$
para cualquier valor $w\in\mathbb{R}$, siendo $Z=N(0,1)$.
</div>

### Demostración
<div class="dem">
Seguidamente, simplifiquemos la expresión $\FunCar_{Z_n}(w)=\FunCar_{\frac{\sum\limits_{i=1}^n X_i-n\mu}{\sigma\sqrt{n}}}(w)$ usando las dos proposiciones anteriores. En primer lugar, teniendo en cuenta que las variables $\left\{\frac{X_i-\mu}{\sigma\sqrt{n}}\right\}$ son independientes e idénticamente distribuidas, usando la primera proposición podemos escribir:
$$
\FunCar_{Z_n}(w) = \left(\FunCar_{\frac{X-\mu}{\sigma\sqrt{n}}}(w)\right)^n,
$$
donde $X$ representa cualquiera de las variables $X_i$.

Usando la segunda proposición, podemos simplificar la expresión anterior aún más:
$$
\FunCar_{Z_n}(w) = \left(\FunCar_{\frac{X-\mu}{\sigma\sqrt{n}}}(w)\right)^n = \left(\FunCar_{X-\mu}\left(\frac{w}{\sigma\sqrt{n}}\right)\right)^n.
$$

</div>

### Demostración
<div class="dem">
Si desarrollamos por Taylor alrededor del valor $\hat{w}=0$ la función característica $\FunCar_{X-\mu}\left(\hat{w}\right)$ hasta segundo orden, obtenemos:
$$
\FunCar_{X-\mu}\left(\hat{w}\right) = \FunCar_{X-\mu}\left(0\right)+ \FunCar_{X-\mu}'\left(0\right) \hat{w}+ \FunCar_{X-\mu}''\left(0\right)\frac{\hat{w}^2}{2}+O(\hat{w}^3),
$$
donde $O(\hat{w}^3)$ simboliza los términos de orden $\hat{w}^3$ y superiores.

Los valores $\FunCar_{X-\mu}\left(0\right)$, $\FunCar_{X-\mu}'\left(0\right)$ y $\FunCar_{X-\mu}''\left(0\right)$ valen: (ver tema de Complementos de variables aleatorias)
$$
\FunCar_{X-\mu}\left(0\right)=1, \ \FunCar_{X-\mu}'\left(0\right)=\frac{1}{\mathrm{i}}E(X-\mu)=0,\ \FunCar_{X-\mu}''\left(0\right)=\frac{1}{\mathrm{i}^2}E\left((X-\mu)^2\right)=-\sigma^2.
$$
El desarrollo anterior será:
$$
\FunCar_{X-\mu}\left(\hat{w}\right) =1 - \frac{1}{2}\hat{w}^2\sigma^2+O(\hat{w}^3),
$$
</div>

### Demostración
<div class="dem">

Aplicando la expresión anterior para $\hat{w}=\frac{w}{\sigma\sqrt{n}}$, obtenemos:
$$
\FunCar_{X-\mu}\left(\frac{w}{\sigma\sqrt{n}}\right) =1 - \frac{1}{2}\left(\frac{w}{\sigma\sqrt{n}}\right)^2\sigma^2+O\left(\frac{w}{\sigma\sqrt{n}}\right)^3= 1-\frac{w^2}{2n}+O\left(\frac{w^3}{n^{\frac{3}{2}}}\right),
$$

La función característica de la variable $Z_n$ será usando la expresión anterior:
$$
\FunCar_{Z_n}(w)=\left(\FunCar_{X-\mu}\left(\frac{w}{\sigma\sqrt{n}}\right)\right)^n = \left(1-\frac{w^2}{2n}+O\left(\frac{w^3}{n^{\frac{3}{2}}}\right)\right)^n
$$
El objetivo es calcular el límite de la expresión anterior:
$$
\lim_{n\to \infty}\FunCar_{Z_n}(w) = \lim_{n\to\infty} \left(1-\frac{w^2}{2n}+O\left(\frac{w^3}{n^{\frac{3}{2}}}\right)\right)^n = 
\lim_{n\to \infty}\mathrm{e}^{n\cdot \ln \left(1-\frac{w^2}{2n}+O\left(\frac{w^3}{n^{\frac{3}{2}}}\right)\right)}.
$$
</div>

### Demostración
<div class="dem">
Usando que para $z\approx 0$, $\ln(1-z)=z+O(z^2)$, el límite anterior será:
$$
\lim_{n\to \infty}\FunCar_{Z_n}(w) = 
\lim_{n\to \infty}\mathrm{e}^{n\cdot \left(-\frac{w^2}{2n}+O\left(\frac{w^4}{n^{2}}\right)\right)} = \lim_{n\to \infty}\mathrm{e}^{ \left(-\frac{w^2}{2}+O\left(\frac{w^4}{n}\right)\right)} = \mathrm{e}^{-\frac{w^2}{2}},
$$
y dicha expresión coincide con la función característica de la variable $N(0,1)$, $\FunCar_{Z}(w)$.

Recordad que en el tema de Complementos de variables aleatorias vimos que si la variable $U$ era $N(\mu,\sigma)$, $\FunCar_{U}(w)=\mathrm{e}^{\mathrm{i}w\mu-\frac{w^2\sigma^2}{2}}$. Aplicando la fórmula anterior para $\mu=0$ y $\sigma=1$, obtenemos $\FunCar_{Z}(w)=\mathrm{e}^{-\frac{w^2}{2}}.$
</div>

### Teorema Central del Límite en la práctica
El **Teorema Central del Límite** se aplica a la práctica en la forma siguiente:

Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes e idénticamente distribuidas con $E(X_i)=\mu$ y $\mathrm{Var}(X_i)=\sigma^2$. Entonces, podemos aproximar para $n$ grande ($n\geq 30$), la media muestral $\overline{X}_n$ por:
$$
\overline{X}_n =\frac{1}{n}\sum_{i=1}^n X_i \approx N\left(\mu,\frac{\sigma}{\sqrt{n}}\right),
$$
o también:
$$
\sum_{i=1}^n X_i \approx N\left(n\mu,\sigma\sqrt{n}\right),
$$

### Teorema Central del Límite en la práctica
Las aproximaciones anteriores se pueden obtener teniendo en cuenta que el **Teorema Central del Límite** nos dice que la variable 
$Z_n= \frac{\sum\limits_{i=1}^n X_i-n\mu}{\sigma\sqrt{n}}$ es aproximadamente una $N(0,1)$. Por tanto,
$$
\frac{\sum\limits_{i=1}^n X_i-n\mu}{\sigma\sqrt{n}} \approx N(0,1),\ \Rightarrow \sum_{i=1}^n X_i\approx \sigma\sqrt{n}\cdot N(0,1)+n\mu = N\left(n\mu,\sigma\sqrt{n}\right).
$$

Dividiendo por $n$ la aproximación anterior, obtenemos:
$$
\overline{X}_n =\frac{1}{n}\sum_{i=1}^n X_i \approx \frac{1}{n}N\left(n\mu,\sigma\sqrt{n}\right) =N\left(\mu,\frac{\sigma}{\sqrt{n}}\right).
$$


### Teorema de Moivre-Laplace
Si aplicamos el **Teorema Central del Límite** en el caso en que las variables $X_n$ son de Bernoulli de parámetro $p$, obtenemos el llamado **Teorema de Moivre-Laplace**:

<l class="prop"> Teorema de Moivre-Laplace </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes Bernoulli de parámetro $p$. La variable $\sum\limits_{i=1}^n X_i$ será binomial de parámetros $n$ y $p$, $B(n,p)$. Entonces:
$$
\frac{B(n,p)-np}{\sqrt{n\cdot p\cdot (1-p)}}\stackrel{{\cal L}}{\longrightarrow} N(0,1).
$$


### Teorema de Moivre-Laplace

En la práctica, decimos que podemos aproximar una variable binomial de parámetros $n$ y $p$ por una distribución normal de parámetros $\mu=np$ y $\sigma =\sqrt{n\cdot p\cdot (1-p)}$:
$$
B(n,p)\approx N(np,\sqrt{n\cdot p\cdot (1-p)}).
$$


### Aproximación de una suma de variables Poisson
Si aplicamos el **Teorema Central del Límite** en el caso en que las variables $X_n$ son de Poisson de parámetro $\lambda$, obtenemos el resultado siguiente:

<l class="prop"> Proposición. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes Poisson de parámetro $\lambda$. Entonces:
$$
\frac{\sum\limits_{i=1}^n X_i -n\lambda}{\sqrt{n\cdot \lambda}}\stackrel{{\cal L}}{\longrightarrow} N(0,1).
$$

### Aproximación de una suma de variables Poisson
Antes de ver la aplicación práctica del resultado anterior, veamos que suma de variables Poisson independientes de parámetro $\lambda$ es una variable Poisson de parámetro $n\lambda$:

<l class="prop"> Proposición. </l>
Sea $\{X_n\}_{n=1}^\infty$ una sucesión de variables aleatorias independientes Poisson de parámetro $\lambda$. Entonces la variable $\sum\limits_{i=1}^n X_i$ sigue la distribución de Poisson de parámetro $n\lambda$.

### Aproximación de una suma de variables Poisson
<div class="dem">
**Demostración**

En primer lugar, hallemos la función característica de la distribución de Poisson de parámetro $\lambda$. Sea $X=Poiss(\lambda)$. Su función característica en un valor $w$ será:
$$
\FunCar_X(w)=E\left(\mathrm{e}^{\mathrm{i} w X}\right)=\sum_{k=0}^\infty \mathrm{e}^{i w k}\frac{\lambda^k}{k!}\mathrm{e}^{-\lambda}=\mathrm{e}^{-\lambda} \sum_{k=0}^\infty \frac{\left(\lambda\mathrm{e}^{iw}\right)^k}{k!}=\mathrm{e}^{-\lambda}\cdot \mathrm{e}^{\lambda\mathrm{e}^{iw}}=\mathrm{e}^{\lambda \left(\mathrm{e}^{iw}-1\right)}.
$$
Sea ahora la variable $S_n=\sum\limits_{i=1}^n X_i$. Usando la proposición anterior que nos calcula la función característica de sumas de variables independientes, podemos escribir:
$$
\FunCar_{S_n}(w)=\FunCar_{X_1}(w)\cdots \FunCar_{X_n}(w)=\left(\mathrm{e}^{\lambda \left(\mathrm{e}^{iw}-1\right)}\right)^n =\mathrm{e}^{n\lambda \left(\mathrm{e}^{iw}-1\right)},
$$
función característica que corresponde a una variable de Poisson de parámetro $n\lambda$, $Poiss(n\lambda)$.
</div>


### Aproximación de una suma de variables Poisson

Usando la proposición anterior, tenemos que la suma de variables Poisson independientes de parámetro $\lambda$ sigue una distribución Poisson de parámetro $n\lambda$. Por tanto, podemos escribir usando el corolario del **Teorema Central del Límite** aplicado a variables Poisson:
$$
Poiss(n\lambda)\approx N(n\lambda,\sqrt{n\lambda}).
$$


### Ejemplo
<div class="example">
**Ejemplo de aplicación del Teorema de Moivre-Laplace**

Sea $X$ una distribución binomial de parámetros $n=50$ y $p=\frac{1}{3}$. 

Imaginemos que nos piden $P(X < 15)$ y $P(10\leq X\leq 20)$.

Vamos a calcular las probabilidades anteriores usando el **Teorema de Moivre-Laplace**. 

La variable $X$ es aproximadamente una distribución normal $X_N$ de parámetros $\mu = np=\frac{50}{3}=`r round(50/3,4)`$ y $\sigma=\sqrt{50\cdot\frac{1}{3}\cdot \frac{2}{3}}=`r round(sqrt(50*2/9),4)`$. 

Por tanto:
$$
\begin{array}{rl}
P(X< 15) & = P(X\leq 14) \approx P(X_N \leq 14)=P\left(Z\leq \frac{14-`r round(50/3,4)`}{`r round(sqrt(50*2/9),4)`}\right) =P(Z\leq `r round((14-50/3)/sqrt(50*2/9),4)`) = `r round(pnorm(14,50/3,sqrt(50*2/9)),4)`,\\
P(10\leq X\leq 20) & \approx P(10\leq X_N \leq 20) = P\left(\frac{10-`r round(50/3,4)`}{`r round(sqrt(50*2/9),4)`}\leq  Z\leq \frac{20-`r round(50/3,4)`}{`r round(sqrt(50*2/9),4)`}\right) = P(`r round((10-50/3)/sqrt(50*2/9),4)`\leq Z\leq `r round((20-50/3)/sqrt(50*2/9),4)`) \\ & = P(Z\leq `r round((20-50/3)/sqrt(50*2/9),4)`)-P(Z\leq `r round((10-50/3)/sqrt(50*2/9),4)`)=`r pnorm(20,50/3,sqrt(50*2/9),4)`-`r pnorm(10,50/3,sqrt(50*2/9),4)` = `r round(pnorm(20,50/3,sqrt(50*2/9))-pnorm(10,50/3,sqrt(50*2/9)),4)`,
\end{array}
$$
donde $Z=N(0,1)$.
</div>


### Ejemplo
<div class="example">
Comparemos los valores aproximados anteriores con los valores "exactos" proporcionados por `R`:
```{r}
pbinom(14,50,1/3)
pbinom(20,50,1/3)-pbinom(9,50,1/3)
```
Tenemos errores de `r round(abs(pbinom(14,50,1/3)-pnorm(14,50/3,sqrt(50*2/9))),5)` y `r round(pbinom(20,50,1/3)-pbinom(9,50,1/3)-(pnorm(20,50/3,sqrt(50*2/9))-pnorm(10,50/3,sqrt(50*2/9))),5)`, respectivamente.

Aunque $n$ no es pequeño, $n=50$, los errores anteriores no son demasiado pequeños.

Una razón por la que dichos errores no son pequeños es que aproximamos una distribución discreta (Binomial) cuyos valores van de 1 en 1 por una distribución normal, que es continua.

La corrección de continuidad de Fisher nos mejora la aproximación disminuyendo dichos errores.


</div>

### Corrección de continuidad de Fisher
Cuando aplicamos el **Teorema Central del Límite** y aproximamos una distribución discreta que tiene valores enteros por una normal, hemos de aplicar lo que se llama **corrección de continuidad de Fisher**. 

Sea $X$ la variable discreta que queremos aproximar y $X_N$ la variable normal que nos aparece cuando aplicamos el **Teorema Central del Límite**. Supongamos que queremos calcular $P(X\leq k)$, para un $k$ entero. Entonces debemos hacer:
$$
P(X\leq k)\approx P(X_N\leq k+0.5).
$$
O sea, para tener en cuenta el valor $k$ en la aproximación $X_N$ hay que sumarle la mitad entre dos valores consecutivos (0.5 si los valores son enteros) de la variable $X$.

### Corrección de continuidad de Fisher
Id con cuidado, si queremos calcular $P(X<k)$, hay que hacer $P(X<k) =P(X\leq k-1)\approx P(X_N \leq k-1+0.5)=P(X_N\leq k-0.5)$.

<div class="example">
**Ejemplo anterior** 

Si aplicamos la continuidad de Fisher en el ejemplo anterior, obtenemos:
$$
\begin{array}{rl}
P(X< 15) & = P(X\leq 14) \approx P(X_N \leq 14.5)=P\left(Z\leq \frac{14.5-`r round(50/3,4)`}{`r round(sqrt(50*2/9),4)`}\right) =P(Z\leq `r round((14.5-50/3)/sqrt(50*2/9),4)`) = `r round(pnorm(14.5,50/3,sqrt(50*2/9)),4)`,\\
P(10\leq X\leq 20) & P(X\leq 20)-P(X\leq 9)\approx P(X_N \leq 20.5)-P(X_N\leq 9.5) \\ & = P\left(Z\leq \frac{20.5-`r round(50/3,4)`}{`r round(sqrt(50*2/9),4)`}\right) - P\left(Z\leq \frac{9.5-`r round(50/3,4)`}{`r round(sqrt(50*2/9),4)`}\right)=  P(Z\leq `r round((20.5-50/3)/sqrt(50*2/9),4)`)-P(Z\leq `r round((9.5-50/3)/sqrt(50*2/9),4)`)\\ & =`r pnorm(20.5,50/3,sqrt(50*2/9),4)`-`r pnorm(9.5,50/3,sqrt(50*2/9),4)` = `r round(pnorm(20.5,50/3,sqrt(50*2/9))-pnorm(9.5,50/3,sqrt(50*2/9)),4)`,
\end{array}
$$
obteniendo unos errores de sólo `r round(abs(pbinom(14,50,1/3)-pnorm(14.5,50/3,sqrt(50*2/9))),5)` y `r round(pbinom(20,50,1/3)-pbinom(9,50,1/3)-(pnorm(20.5,50/3,sqrt(50*2/9))-pnorm(9.5,50/3,sqrt(50*2/9))),5)`, respectivamente.
</div>
### Simulación del Teorema Central del Límite
<div class="example">
**Ejemplo de simulación de la aproximación de una variable binomial a una distribución normal**

Para realizar la simulación anterior, consideremos una distribución binomial de parámetros $n=100$ y $p=\frac{1}{2}$.

Según el **Teorema Central del Límite**, tenemos que 
$$
\overline{X}_n=\frac{1}{n}B\left(n=100,p=\frac{1}{2}\right)\approx N\left(\mu = p=\frac{1}{2}=`r round(1/2,4)`,\sigma=\sqrt{\frac{\frac{1}{2}\cdot \frac{1}{2}}{100}}=`r round(sqrt(1/(400)),4)`\right).
$$

Para ver dicha aproximación, en primer lugar vamos a generar una muestra de $N=1000$ valores de una binomial de parámetros $n=100$ y $p=\frac{1}{2}$ y dividiendo por $n=100$, tenemos una muestra de $\overline{X}_n$:
```{r}
n=100
p=1/2
sigma=p*(1-p)
set.seed(2019)
muestra.binomial = rbinom(1000,n,p)
muestra.xnbarra = muestra.binomial/n
```
</div>

### Simulación del Teorema Central del Límite
<div class="example">
Para ver si la aproximación funciona, dibujaremos en una misma gráfica el histograma de frecuencias relativas de la muestra anterior y la curva de la función de densidad de la distribución normal de parámetros $\mu =\frac{1}{2}$ y $\sigma = `r round(sqrt(1/(400)),4)`$:

```{r,eval=FALSE}
hist(muestra.xnbarra,freq=FALSE,
     breaks=seq(from=min(muestra.xnbarra)-0.1,to=max(muestra.xnbarra)+0.1,by=0.01),
     main="Histograma de la distribución de las medias muestrales",
     xlab="valores variable",ylab="frecuencias relativas")
mu=p
sigma.xnbarra=sqrt(p*(1-p)/n)
x=seq(from=min(muestra.xnbarra),to=max(muestra.xnbarra),by=0.01)
lines(x,dnorm(x,mu,sigma.xnbarra),col='red')
```
Observamos que la aproximación es bastante buena.
</div>


### Simulación del Teorema Central del Límite

<div class="center">
```{r,echo=FALSE}
hist(muestra.xnbarra,freq=FALSE,
     breaks=seq(from=min(muestra.xnbarra)-0.1,to=max(muestra.xnbarra)+0.1,by=0.01),
     main="Histograma de la distribución de las medias muestrales",xlab="valores variable",ylab="frecuencias relativas")
mu=p
sigma.xnbarra=sqrt(p*(1-p)/n)
x=seq(from=min(muestra.xnbarra),to=max(muestra.xnbarra),by=0.01)
lines(x,dnorm(x,mu,sigma.xnbarra),col='red')
```
</div>

<!--chapter:end:7.Rmd-->

